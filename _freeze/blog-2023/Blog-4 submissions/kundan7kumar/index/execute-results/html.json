{
  "hash": "484abadfe264ffebb575632d2c714274",
  "result": {
    "markdown": "---\nauthor: \"Kundan Kumar\"\ntitle: \"The Split-Apply-Combine Strategy for Data Analysis\"\ncategory: Split-apply-combine\ndate: 2022-02-16\noutput: github_document\n---\n\n\n<!-- README.md is generated from README.Rmd. Please edit that file -->\n\n\n\n\n\n## Prompt:\n\nThe `plyr` package has by now been replaced by other, even faster\npackages, but the idea of *Split, apply, combine* is as relevant as\never.\n\nRead the paper [The Split-Apply-Combine Strategy for Data\nAnalysis](https://www.jstatsoft.org/article/view/v040i01) by Hadley\nWickham.\n\nWrite a blog post addressing the following questions:\n\n1.  The R code for the split-apply-combine paper is posted with the\n    paper. Pick one of the examples demonstrating `plyr` functionality\n    (such as `dlply` or `ddply`, ...) and rewrite the example using\n    functionality from the package `dplyr`. Make sure that your example\n    works and the results are identical.\n    \n**Solution:**\nThe author talks about the split-combine strategy for data analysis. This concept is similar to map -reduce technique for processing huge datasets. Split and apply is similar to map in which data is divided in the some with some criteria, while combine correspond to reduce combination of all datasets results into similar data structure and finally summarized the overall results.\n \nThe detailed r code for ‘dplyr’ package as below\n    \n\n::: {.cell hash='index_cache/html/unnamed-chunk-2_a048a6f9bb57896230062ede367f9e78'}\n\n```{.r .cell-code}\nlibrary(dplyr)\n#> \n#> Attaching package: 'dplyr'\n#> The following objects are masked from 'package:stats':\n#> \n#>     filter, lag\n#> The following objects are masked from 'package:base':\n#> \n#>     intersect, setdiff, setequal, union\nlibrary(plyr)\n#> ------------------------------------------------------------------------------\n#> You have loaded plyr after dplyr - this is likely to cause problems.\n#> If you need functions from both plyr and dplyr, please load plyr first, then dplyr:\n#> library(plyr); library(dplyr)\n#> ------------------------------------------------------------------------------\n#> \n#> Attaching package: 'plyr'\n#> The following objects are masked from 'package:dplyr':\n#> \n#>     arrange, count, desc, failwith, id, mutate, rename, summarise,\n#>     summarize\nlibrary(Lahman)\nlibrary(purrr)\n#> \n#> Attaching package: 'purrr'\n#> The following object is masked from 'package:plyr':\n#> \n#>     compact\nlibrary(broom)\nlibrary(ggplot2)\n\ndata(\"baseball\",package = \"plyr\")\n \n# Now Base ball case study\nhead(baseball)\n#>            id year stint team lg  g  ab  r  h X2b X3b hr rbi sb cs bb so ibb\n#> 4   ansonca01 1871     1  RC1    25 120 29 39  11   3  0  16  6  2  2  1  NA\n#> 44  forceda01 1871     1  WS3    32 162 45 45   9   4  0  29  8  0  4  0  NA\n#> 68  mathebo01 1871     1  FW1    19  89 15 24   3   1  0  10  2  1  2  0  NA\n#> 99  startjo01 1871     1  NY2    33 161 35 58   5   1  1  34  4  2  3  0  NA\n#> 102 suttoez01 1871     1  CL1    29 128 35 45   3   7  3  23  3  1  1  0  NA\n#> 106 whitede01 1871     1  CL1    29 146 40 47   6   5  1  21  2  2  4  1  NA\n#>     hbp sh sf gidp\n#> 4    NA NA NA   NA\n#> 44   NA NA NA   NA\n#> 68   NA NA NA   NA\n#> 99   NA NA NA   NA\n#> 102  NA NA NA   NA\n#> 106  NA NA NA   NA\n```\n:::\n\n::: {.cell hash='index_cache/html/unnamed-chunk-3_e495ad4a5d4936bf43be7cca72933d34'}\n\n```{.r .cell-code}\n# Summaries\nsummarise(baseball,nteam=length(unique(team)))\n#>   nteam\n#> 1   132\nsummarise(baseball,nplayers=length(unique(id)))\n#>   nplayers\n#> 1     1228\n```\n:::\n\n::: {.cell hash='index_cache/html/unnamed-chunk-4_da90480cfec48286cfeb34df5af9ed8b'}\n\n```{.r .cell-code}\n# mutate and filter\nbaberuth <- filter(baseball, id == \"ruthba01\") %>%\n  mutate(cyear = year - min(year) + 1)\n \n# plot line graph\nggplot(baberuth, aes(x = cyear, y = rbi / ab)) +\n  geom_line()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n:::\n\n::: {.cell hash='index_cache/html/unnamed-chunk-5_480968c5517285f6eb437c745e3355d6'}\n\n```{.r .cell-code}\n# Filter based on condition\nbaseball <- baseball %>%\n  filter(ab >= 25)\n \n# Adding cyear \nbaseball <- baseball %>%\n  group_by(id) %>%\n  mutate(cyear = year - min(year) + 1) %>%\n  ungroup()\n \n# fitting a Model \nmodel <- function(df) {\n  coef_df <- as.data.frame(t(coef(lm(rbi / ab ~ cyear, data = df))))\n  names(coef_df) <- c(\"intercept\", \"slope\")\n  rsq <- summary(lm(rbi / ab ~ cyear, data = df))$r.squared\n  coef_df$rsquare <- rsq\n  return(coef_df)\n}\nbmodels <- baseball %>%\n  group_by(id) %>%\n  do(model(.))\n \nbcoefs <- bind_rows(bmodels)\n \nbaseballcoef <- left_join(baseball, bcoefs, by = \"id\")\n \n# R-squared\nsubset(baseballcoef, rsquare > 0.999)$id\n#>  [1] \"lindbpa01\" \"carrocl02\" \"lindbpa01\" \"carrocl02\" \"jacksgr01\" \"jacksgr01\"\n#>  [7] \"splitpa01\" \"woodwi01\"  \"splitpa01\" \"woodwi01\"  \"bannifl01\" \"bannifl01\"\n#> [13] \"bedrost01\" \"davisma01\" \"penaal01\"  \"davisma01\" \"penaal01\"  \"bedrost01\"\n#> [19] \"powerte01\" \"cookde01\"  \"powerte01\" \"cookde01\"  \"violafr01\" \"violafr01\"\n#> [25] \"wakefti01\" \"wakefti01\" \"weathda01\" \"weathda01\" \"burbada01\" \"burbada01\"\n#> [31] \"oliveda02\" \"oliveda02\"\n \n# histogram  R-squared\nggplot(bcoefs, aes(x = rsquare)) +\n  geom_histogram(binwidth = 0.01)\n#> Warning: Removed 1 rows containing non-finite values (`stat_bin()`).\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n\n\n2.  Which (base R) functions do you know that support the\n    split-apply-combine strategy? In your opinion, are these sufficient?\n    State why or why not?\n\n**Solution:**\nThe base R functions which supports split-apply-combine.\n\n- **split()** : This function splits data frame into groups based on the certain criteria.\n\n- **apply()** : This functions applies to rows/columns of a matrices or array.These are few apply functions.\n            \n  - **tapply()** : It applies to subsets of a vector defined by one or more factors.\n  - **sapply()** : It applies to each element of a list or vector and simplifies the                        results into a vector or matrix.\n  - **lapply()** : It applies to each element of a list and returns a list of the same                      length.\n\n- **aggregate()** : This functions is used to group data by one or more variables. It is used to combine the results into a new data frame.\n\nThese functions are not sufficient to split-apply-combine strategy.These base R function that supports the split-apply-combine strategy. These base function has limited functionality and cannot be sufficient functionality to accomplish complex data manipulation. For e.g. aggregate() splits a data frame into subsets based on criteria and also used to compute a summary statistic. This is good for simpler tasks. It is not best option for more complex tasks, which requires several steps/loops and also cannot handle missing data very well, thus lead to inefficient for large data-sets.\n\nSo, R packages like dplyr, plyr etc provides  flexible and efficient packaging for complex grouping, filtering and summarizing. These packages provides efficient and optimized code for working with large data-sets.\n\n\n3. The ChatGPT response to the prompt \"Describe the split-apply-combine paradigm\" is given below. Generally, the chatbot's answers are decent. ChatGPT does have problems getting details right. Which details would you change in the response? \n\n    \n>    The \"split-apply-combine\" paradigm is a data analysis strategy used in statistics and data science to analyze grouped data. It consists of three steps:\n>\n>    Split: The data is first split into groups based on one or more variables of interest.\n>\n>    Apply: A specific operation or function is applied to each group of data, usually for the purpose of aggregating, summarizing, or transforming the data within each group.\n>\n> Combine: The results of the operation applied to each group are then combined and returned as a single output.\n>\n> The split-apply-combine paradigm is particularly useful in cases where the data cannot be analyzed as a whole and instead must be analyzed in smaller, more manageable chunks. This allows for more efficient data processing and improved scalability. The paradigm is commonly implemented using tools such as the \"groupby\" function in the R and Python programming languages, and the \"dplyr\" library in R.\n\n**Solution:**\n\nThe ChatGPT response are very basic, it didn’t have explain these three terms very well and which functions requires to perform this tasks. It can be explained better. One examples is:\n\n- **Split:** It divides the data into groups based on or more criteria/variables. This can be achieved by split() function or group by function.\n\n- **Apply:** This operation applies to each group of data separately which is used for aggregating, transforming and summarizing the data within each group. It can be done by lapply, tapply, or summarize functions.\n\n- **Combine:** This operations applies to each group combined and return a single output .This can be done by functions like rbind, cbind,aggregate, or bind_rows.\n\nIn general, More detailed explanation will be helpful to understand the concepts. Moreover, Providing few  examples of specific functions can be used for each step of the split-apply-combine paradigm will be really helpful.\n\n------------------------------------------------------------------------------\n\nYou can write your answers directly the `README.Rmd` file. \nMake sure that the file knits (you will need to activate any packages your use in your code chunks with a call to `library(xxx)`, where xxx is the name of the package, such as `plyr` ).\nCommit your changes and push to your repo;  add any files in the `README_files` directory to your repository. \n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}