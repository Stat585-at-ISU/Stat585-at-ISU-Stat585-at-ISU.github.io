{
  "hash": "b69735e3a57e3b7e0b327fff75d25d5b",
  "result": {
    "markdown": "---\nauthor: Logan Johnson\ntitle: \"'plyr' to d'plyr'\"\ncategory: Split-apply-combine\ndate: 2022-02-16\noutput: github_document\n---\n\n\n<!-- README.md is generated from README.Rmd. Please edit that file -->\n\n\n\n\n\n## Prompt:\n\nThe `plyr` package has by now been replaced by other, even faster\npackages, but the idea of *Split, apply, combine* is as relevant as\never.\n\nRead the paper [The Split-Apply-Combine Strategy for Data\nAnalysis](https://www.jstatsoft.org/article/view/v040i01) by Hadley\nWickham.\n\nWrite a blog post addressing the following questions:\n\n1.  The R code for the split-apply-combine paper is posted with the\n    paper. Pick one of the examples demonstrating `plyr` functionality\n    (such as `dlply` or `ddply`, ...) and rewrite the example using\n    functionality from the package `dplyr`. Make sure that your example\n    works and the results are identical.\n    \n## Example from plyr package\n    \n\n::: {.cell hash='index_cache/html/unnamed-chunk-2_6a640a9eb6b4ee58e8abc58d2694d582'}\n\n```{.r .cell-code}\nlibrary(plyr)\n\nbaseball <- baseball\n\nhead(baseball[c(\"id\",\"year\")], n = 10)\n#>            id year\n#> 4   ansonca01 1871\n#> 44  forceda01 1871\n#> 68  mathebo01 1871\n#> 99  startjo01 1871\n#> 102 suttoez01 1871\n#> 106 whitede01 1871\n#> 113  yorkto01 1871\n#> 121 ansonca01 1872\n#> 143 burdoja01 1872\n#> 167 forceda01 1872\n\nbaseball_1 <- ddply(baseball, .(id), transform, \n  cyear = year - min(year) + 1)\n\nhead(baseball_1[c(\"id\",\"year\",\"cyear\")], n = 10)\n#>           id year cyear\n#> 1  aaronha01 1954     1\n#> 2  aaronha01 1955     2\n#> 3  aaronha01 1956     3\n#> 4  aaronha01 1957     4\n#> 5  aaronha01 1958     5\n#> 6  aaronha01 1959     6\n#> 7  aaronha01 1960     7\n#> 8  aaronha01 1961     8\n#> 9  aaronha01 1962     9\n#> 10 aaronha01 1963    10\n\ntail(baseball_1[c(\"id\",\"year\",\"cyear\")], n = 10)\n#>              id year cyear\n#> 21690 zimmech01 1895    12\n#> 21691 zimmech01 1896    13\n#> 21692 zimmech01 1897    14\n#> 21693 zimmech01 1898    15\n#> 21694 zimmech01 1899    16\n#> 21695 zimmech01 1899    16\n#> 21696 zimmech01 1900    17\n#> 21697 zimmech01 1901    18\n#> 21698 zimmech01 1902    19\n#> 21699 zimmech01 1903    20\n```\n:::\n\n\n\n## Remade with dplyr package\n\n\n::: {.cell hash='index_cache/html/unnamed-chunk-3_b606a40ab453215ed09a37d2e650e3ea'}\n\n```{.r .cell-code}\nlibrary(dplyr)\n#> \n#> Attaching package: 'dplyr'\n#> The following objects are masked from 'package:plyr':\n#> \n#>     arrange, count, desc, failwith, id, mutate, rename, summarise,\n#>     summarize\n#> The following objects are masked from 'package:stats':\n#> \n#>     filter, lag\n#> The following objects are masked from 'package:base':\n#> \n#>     intersect, setdiff, setequal, union\n\nbaseball <- baseball\n\nhead(baseball[c(\"id\",\"year\")], n = 10)\n#>            id year\n#> 4   ansonca01 1871\n#> 44  forceda01 1871\n#> 68  mathebo01 1871\n#> 99  startjo01 1871\n#> 102 suttoez01 1871\n#> 106 whitede01 1871\n#> 113  yorkto01 1871\n#> 121 ansonca01 1872\n#> 143 burdoja01 1872\n#> 167 forceda01 1872\n\nbaseball_2 <- baseball %>% \n  arrange(id) %>% \n  group_by(id) %>% \n  mutate(cyear = year-min(year) + 1)\n\nhead(baseball_2[c(\"id\",\"year\",\"cyear\")], n = 10)\n#> # A tibble: 10 × 3\n#> # Groups:   id [1]\n#>    id         year cyear\n#>    <chr>     <int> <dbl>\n#>  1 aaronha01  1954     1\n#>  2 aaronha01  1955     2\n#>  3 aaronha01  1956     3\n#>  4 aaronha01  1957     4\n#>  5 aaronha01  1958     5\n#>  6 aaronha01  1959     6\n#>  7 aaronha01  1960     7\n#>  8 aaronha01  1961     8\n#>  9 aaronha01  1962     9\n#> 10 aaronha01  1963    10\n\ntail(baseball_2[c(\"id\",\"year\",\"cyear\")], n = 10)\n#> # A tibble: 10 × 3\n#> # Groups:   id [1]\n#>    id         year cyear\n#>    <chr>     <int> <dbl>\n#>  1 zimmech01  1895    12\n#>  2 zimmech01  1896    13\n#>  3 zimmech01  1897    14\n#>  4 zimmech01  1898    15\n#>  5 zimmech01  1899    16\n#>  6 zimmech01  1899    16\n#>  7 zimmech01  1900    17\n#>  8 zimmech01  1901    18\n#>  9 zimmech01  1902    19\n#> 10 zimmech01  1903    20\n```\n:::\n\n\n2.  Which (base R) functions do you know that support the\n    split-apply-combine strategy? In your opinion, are these sufficient?\n    State why or why not?\n    \n- I'm not super familiar with base R functions in the split-apply-combine area. I know of apply and lapply, and I have heard of some of the other functions. I honestly have not used them before. I do feel like they take more work to achieve the similar function of dplyr. The coding and naming of the base R functions is confusing to me. I do think that there are probably use cases for these functions compared with the dplyr package. Overall, I do not think that the base R functions for the split-apply-combine strategy are sufficient because they are not as user accessible for normal people. It would take more time and understanding of R to be able to achieve a similar output in base R compared to dplyr.\n\n3. The ChatGPT response to the prompt \"Describe the split-apply-combine paradigm\" is given below. Generally, the chatbot's answers are decent. ChatGPT does have problems getting details right. Which details would you change in the response? \n\n    \n>    The \"split-apply-combine\" paradigm is a data analysis strategy used in statistics and data science to analyze grouped data. It consists of three steps:\n>\n>    Split: The data is first split into groups based on one or more variables of interest.\n>\n>    Apply: A specific operation or function is applied to each group of data, usually for the purpose of aggregating, summarizing, or transforming the data within each group.\n>\n> Combine: The results of the operation applied to each group are then combined and returned as a single output.\n>\n> The split-apply-combine paradigm is particularly useful in cases where the data cannot be analyzed as a whole and instead must be analyzed in smaller, more manageable chunks. This allows for more efficient data processing and improved scalability. The paradigm is commonly implemented using tools such as the \"groupby\" function in the R and Python programming languages, and the \"dplyr\" library in R.\n\n- I think I would change the last part of the response. I don't think that the data is necessarily split into chunks but rather managed in a more efficient manner that allows for a function or modification to be applied throughout the desired parts of the data.\n\n\nYou can write your answers directly the `README.Rmd` file. \nMake sure that the file knits (you will need to activate any packages your use in your code chunks with a call to `library(xxx)`, where xxx is the name of the package, such as `plyr` ).\nCommit your changes and push to your repo;  add any files in the `README_files` directory to your repository. \n\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}