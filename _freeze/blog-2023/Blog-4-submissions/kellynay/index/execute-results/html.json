{
  "hash": "51c31e75c205e172b9f18438f87e3f48",
  "result": {
    "markdown": "---\nauthor: \"Kelly Nascimento Thompson\"\ntitle: \"Testing the 'dplyr' functionality \"\ncategories: Split-apply-combine\ndate: 2023-02-16\noutput: github_document\n---\n\n\n<!-- README.md is generated from README.Rmd. Please edit that file -->\n\n\n\n\n\n## Prompt:\n\nThe `plyr` package has by now been replaced by other, even faster\npackages, but the idea of *Split, apply, combine* is as relevant as\never.\n\nRead the paper [The Split-Apply-Combine Strategy for Data\nAnalysis](https://www.jstatsoft.org/article/view/v040i01) by Hadley\nWickham.\n\nWrite a blog post addressing the following questions:\n\n1.  The R code for the split-apply-combine paper is posted with the\n    paper. Pick one of the examples demonstrating `plyr` functionality\n    (such as `dlply` or `ddply`, ...) and rewrite the example using\n    functionality from the package `dplyr`. Make sure that your example\n    works and the results are identical.\n\n#Case study Baseball:\n#Example page 14:\n\n::: {.cell hash='index_cache/html/unnamed-chunk-2_3a3858f19fcb49f474af01fee8e3d749'}\n\n```{.r .cell-code}\n# Using \"plyr\" package\n\nlibrary(\"plyr\")\n# Get performance of a batter over his career\n# Calculate \"career year\"\n\nbaberuth <- subset(baseball, id == \"ruthba01\")\nbaberuth_plyr <- transform(baberuth, cyear = year - min(year) + 1)\n\n# Do the same for all players\n\nbaseball_all <- ddply(baseball, .(id), transform,\n    cyear = year - min(year) + 1)\n```\n:::\n\n\n#Example page 14:\n\n::: {.cell hash='index_cache/html/unnamed-chunk-3_2223ecad8ac0fcdfd4419d18d2ecef49'}\n\n```{.r .cell-code}\n# Using \"dplyr\" package\nlibrary(\"tidyr\")\nlibrary(\"dplyr\")\n#> \n#> Attaching package: 'dplyr'\n#> The following objects are masked from 'package:plyr':\n#> \n#>     arrange, count, desc, failwith, id, mutate, rename, summarise,\n#>     summarize\n#> The following objects are masked from 'package:stats':\n#> \n#>     filter, lag\n#> The following objects are masked from 'package:base':\n#> \n#>     intersect, setdiff, setequal, union\n\n# Calculate \"career year\"\n\nbaberuth <- filter(baseball, id == \"ruthba01\")\nbaberuth_dplyr <- mutate(baberuth, cyear = year - min(year) + 1)\n\n# Do the same for all players\n\nbaseball <- baseball %>% group_by(id) %>%\n  mutate(cyear = year - min(year) + 1) %>%\n  arrange(baseball$id) %>% ungroup(id)\n```\n:::\n\n\n2.  Which (base R) functions do you know that support the\n    split-apply-combine strategy? In your opinion, are these sufficient?\n    State why or why not?\n\nNested loops or the apply family of functions, however they present some disadvantages.\n \nNested loops:\nA disadvantage is that there is lots of book-keeping code because the array size is hard coded in several places and output structures need to be created before filling them with data.\n\nApply family of functions - apply(), lapply(), mapply():\nThese simplify the task, but the process to go from a 2d array of models to 3d array of residuals is not straightforward.\n\nFor data frames:\nThe split-apply-combine strategy can be achieved as follows: \nSplit: split()\nApply: lapply()\nCombine: rbind()\n\nThe major complication is giving appropriate labels to the data because types of label will depend on the output data structure (i.e arrays = dimnames and data frames = additional columns). For this reason, mapply() is needed to match source data to extract informative labels.\n\n3. The ChatGPT response to the prompt \"Describe the split-apply-combine paradigm\" is given below. Generally, the chatbot's answers are decent. ChatGPT does have problems getting details right. Which details would you change in the response? \n\n    \n>    The \"split-apply-combine\" paradigm is a data analysis strategy used in statistics and data science to analyze grouped data. It consists of three steps:\n>\n>    Split: The data is first split into groups based on one or more variables of interest.\n>\n>    Apply: A specific operation or function is applied to each group of data, usually for the purpose of aggregating, summarizing, or transforming the data within each group.\n>\n> Combine: The results of the operation applied to each group are then combined and returned as a single output.\n>\n> The split-apply-combine paradigm is particularly useful in cases where the data cannot be analyzed as a whole and instead must be analyzed in smaller, more manageable chunks. This allows for more efficient data processing and improved scalability. The paradigm is commonly implemented using tools such as the \"groupby\" function in the R and Python programming languages, and the \"dplyr\" library in R.\n\nThe term \"analyze grouped data\" seems too general to describe the split-apply-combine strategy. Even though the following bullet points describe each of the steps individually, it would be ideal to have an introductory sentence similar to what is shown in the paper from Hadley Wickman.\n\nI would change it this way: \"The 'split-apply-combine\" paradigm is a data analysis strategy used in statistics and data science to break up a larger data set into manageable pieces, operate on each piece independently, and then put all the pieces back together.\"\n\nPerhaps the \"apply\" step is a little wordy. I would change it to \"calculate summary statistics on each data group.\"\n\nThe final paragraph looks correct for concluding sentences and explains why this strategy is useful in data science. Since ChatGPT mentioned the \"groupby\" function, it would be necessary to add the five key functions from the \"dplyr\" library: filter(), arrange(), select(), mutate(), and summarise().\n\n\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}