{
  "hash": "a702b68968a4854d98f0f9e9db6b337a",
  "result": {
    "markdown": "---\nauthor: \"Yingchao Zhou\"\ntitle: \"Split, apply, combine\"\ncategories: Split-apply-combine\ndate: 2023-02-16\noutput: md_document\n---\n\n\n<!-- README.md is generated from README.Rmd. Please edit that file -->\n\n\n\n\n\n## Prompt:\n\nThe `plyr` package has by now been replaced by other, even faster\npackages, but the idea of *Split, apply, combine* is as relevant as\never.\n\nRead the paper [The Split-Apply-Combine Strategy for Data\nAnalysis](https://www.jstatsoft.org/article/view/v040i01) by Hadley\nWickham.\n\nWrite a blog post addressing the following questions:\n\n1.  The R code for the split-apply-combine paper is posted with the\n    paper. Pick one of the examples demonstrating `plyr` functionality\n    (such as `dlply` or `ddply`, ...) and rewrite the example using\n    functionality from the package `dplyr`. Make sure that your example\n    works and the results are identical.\n\n2.  Which (base R) functions do you know that support the\n    split-apply-combine strategy? In your opinion, are these sufficient?\n    State why or why not?\n\n3. The ChatGPT response to the prompt \"Describe the split-apply-combine paradigm\" is given below. Generally, the chatbot's answers are decent. ChatGPT does have problems getting details right. Which details would you change in the response? \n\n    \n>    The \"split-apply-combine\" paradigm is a data analysis strategy used in statistics and data science to analyze grouped data. It consists of three steps:\n>\n>    Split: The data is first split into groups based on one or more variables of interest.\n>\n>    Apply: A specific operation or function is applied to each group of data, usually for the purpose of aggregating, summarizing, or transforming the data within each group.\n>\n> Combine: The results of the operation applied to each group are then combined and returned as a single output.\n>\n> The split-apply-combine paradigm is particularly useful in cases where the data cannot be analyzed as a whole and instead must be analyzed in smaller, more manageable chunks. This allows for more efficient data processing and improved scalability. The paradigm is commonly implemented using tools such as the \"groupby\" function in the R and Python programming languages, and the \"dplyr\" library in R.\n\n\nYou can write your answers directly the `README.Rmd` file. \nMake sure that the file knits (you will need to activate any packages your use in your code chunks with a call to `library(xxx)`, where xxx is the name of the package, such as `plyr` ).\nCommit your changes and push to your repo;  add any files in the `README_files` directory to your repository. \n\n### 1 Rewrite plyr example using dplyr  \n\nI choose `ddply`.\n\nCheck out `ddply` first:\n\n\n::: {.cell hash='YingchaoZhou_cache/html/unnamed-chunk-2_8ff237c230aa3be6c46874d0262863b8'}\n\n```{.r .cell-code}\nlibrary(\"ggplot2\")\nlibrary(\"plyr\")\noptions(digits = 3)\n\n## check original baseball dataset first\nhead(baseball[,c(\"id\", \"year\")])\n#>            id year\n#> 4   ansonca01 1871\n#> 44  forceda01 1871\n#> 68  mathebo01 1871\n#> 99  startjo01 1871\n#> 102 suttoez01 1871\n#> 106 whitede01 1871\n```\n:::\n\n::: {.cell hash='YingchaoZhou_cache/html/unnamed-chunk-3_a6af766ae8f933f7801386092592f6e5'}\n\n```{.r .cell-code}\nbaseball1 <- ddply(baseball, .(id), transform, \n  cyear = year - min(year) + 1)\nhead(baseball1[,c(\"id\", \"year\", \"cyear\")])\n#>          id year cyear\n#> 1 aaronha01 1954     1\n#> 2 aaronha01 1955     2\n#> 3 aaronha01 1956     3\n#> 4 aaronha01 1957     4\n#> 5 aaronha01 1958     5\n#> 6 aaronha01 1959     6\n```\n:::\n\n\nThis operation creates a new variable \"cyear\", which is the year of a record minus the minimum year record for the same id, then plus 1. We also notice the records are grouped by the same id.\n\nWe can take a closer look for id \"aaronha01\" to make sure we have the right understanding:\n\n\n::: {.cell hash='YingchaoZhou_cache/html/unnamed-chunk-4_cf172ed77e7117303e4486622e1439e7'}\n\n```{.r .cell-code}\nbaseball[baseball$id == \"aaronha01\",c(\"id\", \"year\")]\n#>              id year\n#> 37157 aaronha01 1954\n#> 37795 aaronha01 1955\n#> 38408 aaronha01 1956\n#> 39023 aaronha01 1957\n#> 39645 aaronha01 1958\n#> 40291 aaronha01 1959\n#> 40921 aaronha01 1960\n#> 41642 aaronha01 1961\n#> 42323 aaronha01 1962\n#> 43076 aaronha01 1963\n#> 43824 aaronha01 1964\n#> 44578 aaronha01 1965\n#> 45338 aaronha01 1966\n#> 46122 aaronha01 1967\n#> 46880 aaronha01 1968\n#> 47703 aaronha01 1969\n#> 48618 aaronha01 1970\n#> 49524 aaronha01 1971\n#> 50416 aaronha01 1972\n#> 51294 aaronha01 1973\n#> 52200 aaronha01 1974\n#> 52657 aaronha01 1975\n#> 53564 aaronha01 1976\n```\n:::\n\n::: {.cell hash='YingchaoZhou_cache/html/unnamed-chunk-5_c7d003073da7f4deabc0b460e07b17cd'}\n\n```{.r .cell-code}\nbaseball1[baseball1$id == \"aaronha01\",c(\"id\", \"year\", \"cyear\")]\n#>           id year cyear\n#> 1  aaronha01 1954     1\n#> 2  aaronha01 1955     2\n#> 3  aaronha01 1956     3\n#> 4  aaronha01 1957     4\n#> 5  aaronha01 1958     5\n#> 6  aaronha01 1959     6\n#> 7  aaronha01 1960     7\n#> 8  aaronha01 1961     8\n#> 9  aaronha01 1962     9\n#> 10 aaronha01 1963    10\n#> 11 aaronha01 1964    11\n#> 12 aaronha01 1965    12\n#> 13 aaronha01 1966    13\n#> 14 aaronha01 1967    14\n#> 15 aaronha01 1968    15\n#> 16 aaronha01 1969    16\n#> 17 aaronha01 1970    17\n#> 18 aaronha01 1971    18\n#> 19 aaronha01 1972    19\n#> 20 aaronha01 1973    20\n#> 21 aaronha01 1974    21\n#> 22 aaronha01 1975    22\n#> 23 aaronha01 1976    23\n```\n:::\n\n\nNext we rewrite this example using dplyr:\n\n\n::: {.cell hash='YingchaoZhou_cache/html/unnamed-chunk-6_35c637a83e19b591f737ce10b8a64d07'}\n\n```{.r .cell-code}\nlibrary(dplyr)\n#> \n#> Attaching package: 'dplyr'\n#> The following objects are masked from 'package:plyr':\n#> \n#>     arrange, count, desc, failwith, id, mutate, rename, summarise,\n#>     summarize\n#> The following objects are masked from 'package:stats':\n#> \n#>     filter, lag\n#> The following objects are masked from 'package:base':\n#> \n#>     intersect, setdiff, setequal, union\nbaseball %>% group_by(id) %>%\n  arrange(id) %>%\n  mutate(cyear = year - min(year) + 1) -> baseball2\n```\n:::\n\n\n\nCheck whether the two datasets are the same.\n\n\n::: {.cell hash='YingchaoZhou_cache/html/unnamed-chunk-7_40c2ba36fa42bd5825e7b6e3e9da9176'}\n\n```{.r .cell-code}\nbaseball1 %>% select_if(~ !any(is.na(.))) -> baseball1\nbaseball2 %>% select_if(~ !any(is.na(.))) -> baseball2\n\nsum(baseball1 != baseball2)\n#> [1] 0\n```\n:::\n\n\n### 2 Base R option  \n\nI know some functions in the \"apply\" family can do split-apply-combine operations, like `apply`, `lapply`, `sapply`. I think these are useful functions and can get a lot of work done. But sometimes they are tricky in what type of data they would take, the specification of dimension, etc. For example, `lapply` can take a list or vector and return a list, which takes a lot of space when the list object is large. \n\n### 3 Change to ChatGPT  \n\nThere is no `groupby` function in R. I would say SQL has a `group by` operator and SAS has a `by` operator.\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}