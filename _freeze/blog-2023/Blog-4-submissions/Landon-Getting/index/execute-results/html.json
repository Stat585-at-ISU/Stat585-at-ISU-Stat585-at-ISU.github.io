{
  "hash": "241e867c19af6fbe210c51ca3d347ed2",
  "result": {
    "markdown": "---\nauthor: \"Landon Getting\"\ntitle: \"dplyr vs plyr\"\ncategory: Split-apply-combine\ndate: 2023-02-16\noutput: github_document\n---\n\n\n<!-- README.md is generated from README.Rmd. Please edit that file -->\n\n\n\n\n::: {.cell hash='index_cache/html/unnamed-chunk-2_de798631f2165701dc7a8c3e3c5fa199'}\n\n```{.r .cell-code}\n# loading in necessary libraries and data sets\nlibrary(plyr)\nlibrary(dplyr)\ndata(\"baseball\")\n```\n:::\n\n\n**Read the paper [The Split-Apply-Combine Strategy for Data Analysis](https://www.jstatsoft.org/article/view/v040i01) by Hadley Wickham.**\n\n## Question 1 - dplyr and plyr\n\n**The R code for the split-apply-combine paper is posted with the paper. Pick one of the examples demonstrating `plyr` functionality (such as `dlply` or `ddply`, ...) and rewrite the example using functionality from the package `dplyr`. Make sure that your example works and the results are identical.**\n\nIn the baseball case study, Hadley first shows an example where we need to create a new column called \"cyear\" which states how long the player has been playing. Since each row represents a year, this calculation needs to be preformed for every row. He starts by using Base R functions to accomplish this operation for a single player.\n\n\n::: {.cell hash='index_cache/html/unnamed-chunk-3_96e205b9093e4040026441e324fa1155'}\n\n```{.r .cell-code}\nbaberuth <- subset(baseball, id == \"ruthba01\") # similiar to dplyr filter\n\nbaberuth <- transform(baberuth, \n                      cyear = year - min(year) + 1) # similiar to dplyr mutate\n\nbaberuth[,c(\"id\",\"year\",\"cyear\",\"rbi\")] # checking to see if it worked\n#>             id year cyear rbi\n#> 14646 ruthba01 1914     1   2\n#> 15457 ruthba01 1915     2  21\n#> 16238 ruthba01 1916     3  15\n#> 16776 ruthba01 1917     4  12\n#> 17286 ruthba01 1918     5  66\n#> 17790 ruthba01 1919     6 114\n#> 18329 ruthba01 1920     7 137\n#> 18834 ruthba01 1921     8 171\n#> 19363 ruthba01 1922     9  99\n#> 19883 ruthba01 1923    10 131\n#> 20420 ruthba01 1924    11 121\n#> 20967 ruthba01 1925    12  66\n#> 21507 ruthba01 1926    13 150\n#> 22038 ruthba01 1927    14 164\n#> 22572 ruthba01 1928    15 142\n#> 23110 ruthba01 1929    16 154\n#> 23656 ruthba01 1930    17 153\n#> 24167 ruthba01 1931    18 163\n#> 24694 ruthba01 1932    19 137\n#> 25199 ruthba01 1933    20 103\n#> 25702 ruthba01 1934    21  84\n#> 26477 ruthba01 1935    22  12\n```\n:::\n\n\nNext, Hadley introduces ddply as a method to perform the calculation for each of the players for each of the years they played.\n\n\n::: {.cell hash='index_cache/html/unnamed-chunk-4_d603110959682a91dec156e395913208'}\n\n```{.r .cell-code}\n# calculating how long every player has played using plyr\n# dataframe to dataframe\nbaseball_plyr <- ddply(baseball, # dataframe\n                  .(id), # split up by id\n                  transform, \n                  cyear = year - min(year) + 1) # processing function\n\nbaseball_plyr[baseball_plyr$id == \"ruthba01\",\n              c(\"id\",\"year\",\"cyear\",\"rbi\")] # checking to see if it worked\n#>             id year cyear rbi\n#> 17005 ruthba01 1914     1   2\n#> 17006 ruthba01 1915     2  21\n#> 17007 ruthba01 1916     3  15\n#> 17008 ruthba01 1917     4  12\n#> 17009 ruthba01 1918     5  66\n#> 17010 ruthba01 1919     6 114\n#> 17011 ruthba01 1920     7 137\n#> 17012 ruthba01 1921     8 171\n#> 17013 ruthba01 1922     9  99\n#> 17014 ruthba01 1923    10 131\n#> 17015 ruthba01 1924    11 121\n#> 17016 ruthba01 1925    12  66\n#> 17017 ruthba01 1926    13 150\n#> 17018 ruthba01 1927    14 164\n#> 17019 ruthba01 1928    15 142\n#> 17020 ruthba01 1929    16 154\n#> 17021 ruthba01 1930    17 153\n#> 17022 ruthba01 1931    18 163\n#> 17023 ruthba01 1932    19 137\n#> 17024 ruthba01 1933    20 103\n#> 17025 ruthba01 1934    21  84\n#> 17026 ruthba01 1935    22  12\n```\n:::\n\n\nWith dplyr, I can perform this operation with *mutate*. Looks like it matches up with plyr!\n\n\n::: {.cell hash='index_cache/html/unnamed-chunk-5_a80abd1c6d0cdc156e8da486fbaa6c2c'}\n\n```{.r .cell-code}\n# dplyr one less line than plyr!\nbaseball_dplyr <- mutate(baseball, # dataframe to use\n                         cyear = year - min(year) + 1, # function to perform\n                         .by = id) # split by id\n\nbaseball_dplyr[baseball_dplyr$id == \"ruthba01\",\n              c(\"id\",\"year\",\"cyear\",\"rbi\")] # checking to see if it matches \n#>             id year cyear rbi\n#> 14646 ruthba01 1914     1   2\n#> 15457 ruthba01 1915     2  21\n#> 16238 ruthba01 1916     3  15\n#> 16776 ruthba01 1917     4  12\n#> 17286 ruthba01 1918     5  66\n#> 17790 ruthba01 1919     6 114\n#> 18329 ruthba01 1920     7 137\n#> 18834 ruthba01 1921     8 171\n#> 19363 ruthba01 1922     9  99\n#> 19883 ruthba01 1923    10 131\n#> 20420 ruthba01 1924    11 121\n#> 20967 ruthba01 1925    12  66\n#> 21507 ruthba01 1926    13 150\n#> 22038 ruthba01 1927    14 164\n#> 22572 ruthba01 1928    15 142\n#> 23110 ruthba01 1929    16 154\n#> 23656 ruthba01 1930    17 153\n#> 24167 ruthba01 1931    18 163\n#> 24694 ruthba01 1932    19 137\n#> 25199 ruthba01 1933    20 103\n#> 25702 ruthba01 1934    21  84\n#> 26477 ruthba01 1935    22  12\n```\n:::\n\n\n## Question 2 - split, apply, combine and Base R\n\n**Which (base R) functions do you know that support the split-apply-combine strategy? In your opinion, are these sufficient? State why or why not?**\n\nThe only Base R functions that I am familiar with that support the split-apply-combine strategy are *split()* and *lapply()*. Although I initially thought these would be adequate, Hadley makes a great point on page 4 of the paper when he discusses the lack of label continuity if utilizing the Base R functions. As demonstrated on the previous question, the plyr and dplyr functions are also nicely convenient and reduce the number of unique function calls.\n\n## Question 3 - What did ChatGPT miss?\n\n**The ChatGPT response to the prompt \"Describe the split-apply-combine paradigm\" is given below. Generally, the chatbot's answers are decent. ChatGPT does have problems getting details right. Which details would you change in the response?**\n\n> The \"split-apply-combine\" paradigm is a data analysis strategy used in statistics and data science to analyze grouped data. It consists of three steps:\n>\n> Split: The data is first split into groups based on one or more variables of interest.\n>\n> Apply: A specific operation or function is applied to each group of data, usually for the purpose of aggregating, summarizing, or transforming the data within each group.\n>\n> Combine: The results of the operation applied to each group are then combined and returned as a single output.\n>\n> The split-apply-combine paradigm is particularly useful in cases where the data cannot be analyzed as a whole and instead must be analyzed in smaller, more manageable chunks. This allows for more efficient data processing and improved scalability. The paradigm is commonly implemented using tools such as the \"groupby\" function in the R and Python programming languages, and the \"dplyr\" library in R.\n\nChatGPT's definition of the *'Split'* step is fairly short and suggests splitting based on some variables. Although this is correct, I think considering the split to be based on a *conditional* statement is more intuitive. This includes cases where you may need to perform a split-apply-combine (or other operations) just to create the variables necessary for a more complex split.\n\nIn addition, Hadley brings up an important assumption in page 2 of the paper that potentially should have been included in the closing paragraph of ChatGPT's response:\n\n> *\"Note that plyr makes the strong assumption that each piece of data will be processed only once and independently of all other pieces. This means that you can not use these tools when each iteration requires overlapping data (like a running mean), or it depends on the previous iteration (like in a dynamic simulation).\"*\n\nI think ChatGPT's response may have been more robust if it included a short sentence on the limits or downsides of the approach in contrast to the efficiency and scaleability praise. However, it is amazing that it can provide such a response in the first place!\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}