{
  "hash": "b307fd5e3c3ae0bd7bf27b7109bf7d04",
  "result": {
    "markdown": "---\nauthor: \"Caio dos Santos\"\ntitle: \"plyr-dplyr-baseR\"\ncategories: Split-apply-combine\ndate: 2023-02-16\noutput: github_document\neditor_options: \n  markdown: \n    wrap: 72\n---\n\n\n<!-- README.md is generated from README.Rmd. Please edit that file -->\n\n\n\n\n\n## Prompt:\n\nThe `plyr` package has by now been replaced by other, even faster\npackages, but the idea of *Split, apply, combine* is as relevant as\never.\n\nRead the paper [The Split-Apply-Combine Strategy for Data\nAnalysis](https://www.jstatsoft.org/article/view/v040i01) by Hadley\nWickham.\n\nWrite a blog post addressing the following questions:\n\n1.  The R code for the split-apply-combine paper is posted with the\n    paper. Pick one of the examples demonstrating `plyr` functionality\n    (such as `dlply` or `ddply`, ...) and rewrite the example using\n    functionality from the package `dplyr`. Make sure that your example\n    works and the results are identical.\n\n2.  Which (base R) functions do you know that support the\n    split-apply-combine strategy? In your opinion, are these sufficient?\n    State why or why not?\n\n3.  The ChatGPT response to the prompt \"Describe the split-apply-combine\n    paradigm\" is given below. Generally, the chatbot's answers are\n    decent. ChatGPT does have problems getting details right. Which\n    details would you change in the response?\n\n> The \"split-apply-combine\" paradigm is a data analysis strategy used in\n> statistics and data science to analyze grouped data. It consists of\n> three steps:\n>\n> Split: The data is first split into groups based on one or more\n> variables of interest.\n>\n> Apply: A specific operation or function is applied to each group of\n> data, usually for the purpose of aggregating, summarizing, or\n> transforming the data within each group.\n>\n> Combine: The results of the operation applied to each group are then\n> combined and returned as a single output.\n>\n> The split-apply-combine paradigm is particularly useful in cases where\n> the data cannot be analyzed as a whole and instead must be analyzed in\n> smaller, more manageable chunks. This allows for more efficient data\n> processing and improved scalability. The paradigm is commonly\n> implemented using tools such as the \"groupby\" function in the R and\n> Python programming languages, and the \"dplyr\" library in R.\n\nYou can write your answers directly the `README.Rmd` file. Make sure\nthat the file knits (you will need to activate any packages your use in\nyour code chunks with a call to `library(xxx)`, where xxx is the name of\nthe package, such as `plyr` ). Commit your changes and push to your\nrepo; add any files in the `README_files` directory to your repository.\n\n# 1 - Ozone example\n\nThis section contais the ***Ozone example*** described in [The\nSplit-Apply-Combine Strategy for Data\nAnalysis](https://www.jstatsoft.org/article/view/v040i01). I have\nremoved some of the parts to reduce the output but I have kept the\nessential parts for us to demonstrate de functionalities of ***plyr***\nand ***dplyr***\n\n\n::: {.cell hash='index_cache/html/unnamed-chunk-2_7ad384a103df09d4bf2c0e81e642cc96'}\n\n```{.r .cell-code}\nlibrary(MASS)\nlibrary(plyr)\nlibrary(reshape2)\n\nvalue <- ozone[1, 1, ]\ntime <- 1:72 / 12\nmonth.abbr <- c(\"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \n \"Jun\", \"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\")\nmonth <- factor(rep(month.abbr, length = 72), levels = month.abbr)\nyear <- rep(1:6, each = 12)\n\n\ndeseas1 <- rlm(value ~ month - 1)\n\n\ndeseasf <- function(value) rlm(value ~ month - 1, maxit = 50)\nmodels <- alply(ozone, 1:2, deseasf)\n#> Warning in rlm.default(x, y, weights, method = method, wt.method = wt.method, :\n#> 'rlm' failed to converge in 50 steps\n\n#> Warning in rlm.default(x, y, weights, method = method, wt.method = wt.method, :\n#> 'rlm' failed to converge in 50 steps\n\n#> Warning in rlm.default(x, y, weights, method = method, wt.method = wt.method, :\n#> 'rlm' failed to converge in 50 steps\n\n#> Warning in rlm.default(x, y, weights, method = method, wt.method = wt.method, :\n#> 'rlm' failed to converge in 50 steps\n\n#> Warning in rlm.default(x, y, weights, method = method, wt.method = wt.method, :\n#> 'rlm' failed to converge in 50 steps\n\n#> Warning in rlm.default(x, y, weights, method = method, wt.method = wt.method, :\n#> 'rlm' failed to converge in 50 steps\n\n#> Warning in rlm.default(x, y, weights, method = method, wt.method = wt.method, :\n#> 'rlm' failed to converge in 50 steps\nfailed <- laply(models, function(x) !x$converged)\n\n\ncoefs <- laply(models, coef)\ndimnames(coefs)[[3]] <- month.abbr\nnames(dimnames(coefs))[3] <- \"month\"\n\ndeseas <- laply(models, resid)\ndimnames(deseas)[[3]] <- 1:72\nnames(dimnames(deseas))[3] <- \"time\"\n\n\n\ncoefs_df <- melt(coefs)\nhead(coefs_df)\n#>     lat   long month    value\n#> 1 -21.2 -113.8   Jan 264.3964\n#> 2 -18.7 -113.8   Jan 261.3284\n#> 3 -16.2 -113.8   Jan 260.9643\n#> 4 -13.7 -113.8   Jan 258.9999\n#> 5 -11.2 -113.8   Jan 255.9999\n#> 6  -8.7 -113.8   Jan 254.9999\n```\n:::\n\n\nThis far, we have successfully extracted the trends for for each month\nand sampling point (combination of latitude, longitude, and month). Now,\nwe can use ***plyr*** to calculate average trends for each sampling\npoint across months (combination of latitude and longitude). The *ddply\n**function takes as an argument a data frame and outputs a data frame as\nwell. Note*****: the original exmaple redefined the coef_df data frame\nusing the** *ddply* function. Here, I changed the name to coefs_df_plyr\nso we conserved the coef_df data frame unchanged, since we want to reuse\nthis data frame using ***dplyr*** and ***base R***\n\n\n::: {.cell hash='index_cache/html/unnamed-chunk-3_1fb0234287ea1c2a8f79eba0b7d4331b'}\n\n```{.r .cell-code}\n\ncoefs_df_plyr <- ddply(coefs_df, .(lat, long), transform, \n  avg = mean(value),\n  std = value / max(value)\n)\nlevels(coefs_df_plyr$month) <- month.abbr\nhead(coefs_df_plyr)\n#>     lat   long month    value      avg       std\n#> 1 -21.2 -113.8   Jan 264.3964 268.6604 0.9277068\n#> 2 -21.2 -113.8   Feb 259.2036 268.6604 0.9094862\n#> 3 -21.2 -113.8   Mar 255.0000 268.6604 0.8947368\n#> 4 -21.2 -113.8   Apr 252.0052 268.6604 0.8842288\n#> 5 -21.2 -113.8   May 258.5089 268.6604 0.9070486\n#> 6 -21.2 -113.8   Jun 265.3387 268.6604 0.9310129\n```\n:::\n\n\nTo do accomplish the same with the ***dplyr*** package, we can use use\nthe group_by and mutate functions\n\n\n::: {.cell hash='index_cache/html/unnamed-chunk-4_a5f7366c17759e7ecc057652f1ff1146'}\n\n```{.r .cell-code}\nlibrary('dplyr')\n#> \n#> Attaching package: 'dplyr'\n#> The following objects are masked from 'package:plyr':\n#> \n#>     arrange, count, desc, failwith, id, mutate, rename, summarise,\n#>     summarize\n#> The following object is masked from 'package:MASS':\n#> \n#>     select\n#> The following objects are masked from 'package:stats':\n#> \n#>     filter, lag\n#> The following objects are masked from 'package:base':\n#> \n#>     intersect, setdiff, setequal, union\n\ncoefs_df %>%\n  group_by(lat, long) %>%\n  mutate(\n    avg = mean(value),\n    std = value / max(value)\n  ) %>%\n  arrange(lat, long) %>%\n  data.frame() -> coefs_df_dplyr\n\nlevels(coefs_df_dplyr$month) <- month.abbr\n\nhead(coefs_df_dplyr)\n#>     lat   long month    value      avg       std\n#> 1 -21.2 -113.8   Jan 264.3964 268.6604 0.9277068\n#> 2 -21.2 -113.8   Feb 259.2036 268.6604 0.9094862\n#> 3 -21.2 -113.8   Mar 255.0000 268.6604 0.8947368\n#> 4 -21.2 -113.8   Apr 252.0052 268.6604 0.8842288\n#> 5 -21.2 -113.8   May 258.5089 268.6604 0.9070486\n#> 6 -21.2 -113.8   Jun 265.3387 268.6604 0.9310129\n```\n:::\n\n\nWe can check that the outputs are identical\n\n\n::: {.cell hash='index_cache/html/unnamed-chunk-5_214d0241a28bd5fa64d58211d743c1ee'}\n\n```{.r .cell-code}\nall(coefs_df_dplyr == coefs_df_plyr)\n#> [1] TRUE\n```\n:::\n\n\n\n# 2 - Base R function for split-apply-combine\n\nBase R has a set of functions that can deal with splitting datasets into smaller pieces, applying an operation to that\nsmaller piece and combining it into a complete dataset again. A couple examples would be:\n\na- The ***apply*** family of functions combined with the ***split*** function\n\n::: {.cell hash='index_cache/html/unnamed-chunk-6_1153e90196d367ac46515953f59b652d'}\n\n```{.r .cell-code}\ncoefs_df_base1 <- lapply(split(coefs_df, coefs_df[c('lat', 'long')]),\n                        function(df) {\n                          df$avg <- mean(df$value)\n                          df$std <- df$value / max(df$value)\n                          \n                          return(df)\n                        })\ncoefs_df_base1 <- do.call('rbind', c(coefs_df_base1, make.row.names = FALSE))\nlevels(coefs_df_base1$month) <- month.abbr\n\nhead(coefs_df_base1)\n#>     lat   long month    value      avg       std\n#> 1 -21.2 -113.8   Jan 264.3964 268.6604 0.9277068\n#> 2 -21.2 -113.8   Feb 259.2036 268.6604 0.9094862\n#> 3 -21.2 -113.8   Mar 255.0000 268.6604 0.8947368\n#> 4 -21.2 -113.8   Apr 252.0052 268.6604 0.8842288\n#> 5 -21.2 -113.8   May 258.5089 268.6604 0.9070486\n#> 6 -21.2 -113.8   Jun 265.3387 268.6604 0.9310129\n```\n:::\n\n\nb - There is also a function called ***by***\n\n::: {.cell hash='index_cache/html/unnamed-chunk-7_58df0b617c8bbbe969045b460631ecd5'}\n\n```{.r .cell-code}\ncoefs_df_base2 <- by(coefs_df, coefs_df[c('lat', 'long')],\n                      function(df) {\n                          df$avg <- mean(df$value)\n                          df$std <- df$value / max(df$value)\n                          \n                          return(df)\n                        })\n\ncoefs_df_base2 <- do.call('rbind', c(coefs_df_base2, make.row.names = FALSE))\nlevels(coefs_df_base2$month) <- month.abbr\n\nhead(coefs_df_base2)\n#>     lat   long month    value      avg       std\n#> 1 -21.2 -113.8   Jan 264.3964 268.6604 0.9277068\n#> 2 -21.2 -113.8   Feb 259.2036 268.6604 0.9094862\n#> 3 -21.2 -113.8   Mar 255.0000 268.6604 0.8947368\n#> 4 -21.2 -113.8   Apr 252.0052 268.6604 0.8842288\n#> 5 -21.2 -113.8   May 258.5089 268.6604 0.9070486\n#> 6 -21.2 -113.8   Jun 265.3387 268.6604 0.9310129\n```\n:::\n\n\nI believe these functions are sufficient. However, I enjoy the simplicity that the Tidyverse brings to data-analysis. The tidyverse functions come with several pre-made decisions, allowing the user to focus more on the data itself than on the code. However, defaults and pre-made decisions tend to be limiting in terms of generalization.  In base R, there is a constant need of book-keeping in terms of how to write the code and the fact that sometimes the output of one function will not match the input of the next function the user might want to apply. That being said, I use base R more often than the Tidyverse for the possibility of generalizing the functions and converting code between different programming languages.\n\n\n# 3 - ChatGPT output \n\nThe majority of what ChatGPT answered seems correct to me. Only a couple details really stand out as incorrect. The output talks about using a \"groupby\" function in programming languages but none of these two listed languages really have a \"group by\" function among their standard functions. However, there is one main package or library for each of these languages that implements this grouping. In R, the ***dplyr*** package comes with the \"group_by\" function. In Python, the ***pandas*** library comes with the method called \"groupby\" for data frames.\n\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}