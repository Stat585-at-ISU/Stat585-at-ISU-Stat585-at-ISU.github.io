{
  "hash": "4a9df45ad4df58b7e3f31005914e24ad",
  "result": {
    "markdown": "---\nauthor: \"Denise Bradford\"\ntitle: \"Blog post 4 - Split-Apply-Combine\"\ncategory: Split-apply-combine\ndate: 2022-02-16\noutput: github_document\n---\n\n\n<!-- README.md is generated from README.Rmd. Please edit that file -->\n\n\n\n\n\n## Prompt:\n\nThe `plyr` package has by now been replaced by other, even faster\npackages, but the idea of *Split, apply, combine* is as relevant as\never.\n\nRead the paper [The Split-Apply-Combine Strategy for Data\nAnalysis](https://www.jstatsoft.org/article/view/v040i01) by Hadley\nWickham.\n\nWrite a blog post addressing the following questions:\n\n1.  The R code for the split-apply-combine paper is posted with the\n    paper. Pick one of the examples demonstrating `plyr` functionality\n    (such as `dlply` or `ddply`, ...) and rewrite the example using\n    functionality from the package `dplyr`. Make sure that your example\n    works and the results are identical.\n\n::: {.cell hash='index_cache/html/unnamed-chunk-2_d76828aaac9fdc3e5df1eb424b88a6b7'}\n\n```{.r .cell-code}\ndata(\"baseball\")\nsubset_baseball <- baseball %>% filter(year > 2000)\n\n#plyr example\nplyr::ddply(subset_baseball, .(team, lg), \n            summarise, hbp = mean(hbp, na.rm = TRUE), \n            year = max(year) ) %>% \n  head()\n#>   team lg       hbp year\n#> 1  ANA AL 0.1818182 2004\n#> 2  ARI NL 1.7846154 2007\n#> 3  ATL NL 1.4583333 2007\n#> 4  BAL AL 1.9189189 2007\n#> 5  BOS AL 1.2878788 2007\n#> 6  CHA AL 2.3513514 2007\n\n#dplyr example\nsubset_baseball %>% \n  group_by(team,lg) %>% \n dplyr::do(mean = mean(.$hbp, na.rm = TRUE),\n           year = max(.$year)) %>% \n  unnest() %>%\n  head()\n#> # A tibble: 6 Ã— 4\n#>   team  lg     mean  year\n#>   <chr> <chr> <dbl> <int>\n#> 1 ANA   AL    0.182  2004\n#> 2 ARI   NL    1.78   2007\n#> 3 ATL   NL    1.46   2007\n#> 4 BAL   AL    1.92   2007\n#> 5 BOS   AL    1.29   2007\n#> 6 CHA   AL    2.35   2007\n```\n:::\n\n::: {.cell hash='index_cache/html/unnamed-chunk-3_7d20eacf56d2def61191485db4b77a97'}\n\n```{.python .cell-code}\nfrom pybaseball import batting_stats_range\nimport numpy as np\n\nsubset_baseball = batting_stats_range('2008-05-01', '2010-11-08')\nsubset_baseball.head()\n\nsubset_baseball.groupby(['Tm','Lev']).agg({'HBP': 'mean', 'OBP': 'max'}).head()\n\n```\n:::\n\n\n2.  Which (base R) functions do you know that support the\n    split-apply-combine strategy? In your opinion, are these sufficient?\n    State why or why not?\n    \n    Functions that support the split-apply-combine strategy in base R such as: \n    `by()`, `do.call()`,`reshape()`,`aggregate()`,`subset()`.\n    In my opinion, I believe that some of these functions are \n    sufficient (like `subset()`) when looking at a larger dataset, \n    it will be useful to see what the data look like without\n    knowing what the actual table contents. \n\n3. The ChatGPT response to the prompt \"Describe the split-apply-combine paradigm\" is given below. Generally, the chatbot's answers are decent. ChatGPT does have problems getting details right. Which details would you change in the response? \n\n    \n>    The \"split-apply-combine\" paradigm is a data analysis strategy used in statistics and data science to analyze grouped data. It consists of three steps:\n>\n>    Split: The data is first split into groups based on one or more variables of interest.\n>\n>    Apply: A specific operation or function is applied to each group of data, usually for the purpose of aggregating, summarizing, or transforming the data within each group.\n>\n> Combine: The results of the operation applied to each group are then combined and returned as a single output.\n>\n> The split-apply-combine paradigm is particularly useful in cases where the data cannot be analyzed as a whole and instead must be analyzed in smaller, more manageable chunks. This allows for more efficient data processing and improved scalability. The paradigm is commonly implemented using tools such as the \"groupby\" function in the R and Python programming languages, and the \"dplyr\" library in R.\n\n\"...cases where the data cannot be analyzed as a whole and instead must be analyzed in smaller, more manageable chunks.\" The details that I would not completely agree with this statement for the fact that the split-apply-combine method can be perform other functional things that are useful. We can use the functionality to explore the data when we have a large dataset. This method could be used to combine data that are similar from different data sources, for example state related outcomes.\n\nYou can write your answers directly the `README.Rmd` file. \nMake sure that the file knits (you will need to activate any packages your use in your code chunks with a call to `library(xxx)`, where xxx is the name of the package, such as `plyr` ).\nCommit your changes and push to your repo;  add any files in the `README_files` directory to your repository. \n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}