{
  "hash": "279dc565ccd3c2ff9a1534af35aeef19",
  "result": {
    "markdown": "---\nauthor: \"Sudesh Ramesh Bhagat\"\ntitle: \"Web scraping etiquette\"\ncategories: \"Errors and warnings in packages\"\ndate: \"2023-04-06\"\noutput:\n  github_document: default\n  html_document: default\n---\n\n \n## Prompt:\nWith great power comes great responsibility - a large part of the web is based on data and services that scrape those data. \nNow that we start to apply scraping mechanisms, we need to think about how to apply those skills without becoming a burden to the internet society.\n\nFind sources on ethical web scraping - some readings that might help you get started with that are: \n\n  - [James Densmore](https://towardsdatascience.com/ethics-in-web-scraping-b96b18136f01)\n\n  - R package [polite](https://github.com/dmi3kno/polite)\n\n  - [JAMI @ EMPIRICAL](https://www.empiricaldata.org/dataladyblog/a-guide-to-ethical-web-scraping)\n\n\nAfter reading through some of the ethics essays\nwrite a blog post addressing the following questions: \n\n1. **What are your main three takeaways for ethical web scraping? - Give examples, or cite your sources.**\n\nBased on the reading, Ethics in Web Scraping, the first key takeaway for ethical web scraping is that it is moral to provide a User Agent string that states the purpose of the web scraping and offers contact information. The second important takeaway is that web scraping is done to add value to the data and not duplicate it. The third important key takeaway is to always credit the original content and do not plagiarize. For example, it is ethical to include a statement on your website about how the data was sourced and how it will be utilized.\n\n\n2. **What is a ROBOTS.TXT file? Identify one instance and explain what it allows/prevents.**\n\nROBOTS.TXT file is also called the Robots Exclusion Standards. It guides the web-crawling software where it is allowed or not-allowed within the website. This file is a part of the Robots Exclusion Protocol, created to monitor and regulate how robots crawl the web. An example is the ROBOTS.TXT file of the New York Times (Ref: https://www.nytimes.com/robots.txt). This file allows twitterbot whereas disallows omgilibot, omgili and ia_achiever. \n\n\n3. **Identify a website that you would like to scrape (or one an example from class) and implement a scrape using the `polite` package.**\n\nI have implemented polite package with other packages to scrape the web site.An example of a website considered for scraping is https://en.wikipedia.org/wiki/National_day its a website which explain about national day of different nations .A sample code using the polite package is as follows: \n\n::: {.cell warnings='false' hash='index_cache/html/unnamed-chunk-1_c0f23161549883122124de7722e63a4a'}\n\n```{.r .cell-code}\n# national day for each country \n# To clean data\nlibrary(tidyverse)\nlibrary(lubridate)\nlibrary(janitor)\n\n# To scrape data\nlibrary(rvest)\nlibrary(httr)\nlibrary(polite)\n\nurl <- \"https://en.wikipedia.org/wiki/National_day\"\nurl_bow <- polite::bow(url)\nurl_bow\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n<polite session> https://en.wikipedia.org/wiki/National_day\n    User-agent: polite R package\n    robots.txt: 456 rules are defined for 33 bots\n   Crawl delay: 5 sec\n  The path is scrapable for this user-agent\n```\n:::\n\n```{.r .cell-code}\nind_html <-\n  polite::scrape(url_bow) %>%  # scrape web page\n  rvest::html_nodes(\"table.wikitable\") %>% # pull out specific table\n  rvest::html_table(fill = TRUE) \nind_tab <- \n  ind_html[[1]] %>% \n  clean_names()\nind_tab\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 312 × 3\n   nation                         date        significance_of_this_date         \n   <chr>                          <chr>       <chr>                             \n 1 Acadia (Canada)                15 August   Assumption Day was preferred over…\n 2 Afghanistan                    19 August   Independence from United Kingdom …\n 3 Albania                        28 November Albanian Flag Day: Raising of the…\n 4 Alderney (British Islands)     15 December Homecoming Day, the return of the…\n 5 Algeria                        5 July      Independence Day (Algeria) in 1962\n 6 American Samoa (United States) 17 April    US Flag Day, commemorates the dat…\n 7 Andorra                        8 September Our Lady of Meritxell Day, patron…\n 8 Angola                         11 November Independence from Portugal in 1975\n 9 Anguilla (United Kingdom)      30 May      Anguilla Day; the beginning of th…\n10 Antigua and Barbuda            1 November  Independence from the United King…\n# ℹ 302 more rows\n```\n:::\n\n```{.r .cell-code}\n#reference:https://en.wikipedia.org/wiki/National_day\n```\n:::\n\n\n\nInstructions:\n\nSubmit to your repo. Make sure that all of the github actions pass (check menu item Actions - all of the actions should have green checks)\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}