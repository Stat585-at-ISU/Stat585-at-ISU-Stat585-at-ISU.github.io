{
  "hash": "77ee287170ace80113b6f195f3fbce78",
  "result": {
    "markdown": "---\nauthor: \"Muxin Hua\"\ntitle: \"Web scraping etiquette ...\"\ncategories: \"Errors and warnings in packages\"\ndate: \"2023-04-06\"\noutput: github_document\n---\n\n\n## Prompt:\n\nWith great power comes great responsibility - a large part of the web is based on data and services that scrape those data. Now that we start to apply scraping mechanisms, we need to think about how to apply those skills without becoming a burden to the internet society.\n\nFind sources on ethical web scraping - some readings that might help you get started with that are:\n\n-   [James Densmore](https://towardsdatascience.com/ethics-in-web-scraping-b96b18136f01)\n\n-   R package [polite](https://github.com/dmi3kno/polite)\n\n-   [JAMI \\@ EMPIRICAL](https://www.empiricaldata.org/dataladyblog/a-guide-to-ethical-web-scraping)\n\nAfter reading through some of the ethics essays write a blog post addressing the following questions:\n\n1.  **What are your main three takeaways for ethical web scraping? - Give examples, or cite your sources.**\n\nMy takeaways are from both side: being respectful and grateful when scraping, and being open to ethical scrapers when being an owner.\n\nTo me, scraping is like making a cold call: it takes two to make the deal. Visitors should leave the customer alone if there’s a “No soliciting”. If no such a sign, visitors need to knock on the door before getting in. After getting in, visitors are responsible for identifying themselves, following the instructions from the owner, being polite, and saying thanks before leaving. These correspond to access APIs if there’s any, reasonably request data, respect rules and data, showing gratitude.\n\nOn the other hand, the owner can make rules or signs to avoid confusion. If the owner decides to start a conversation, respecting the visitors' follow rules, explain why he needs the visitors to leave if there’s any situation. These correspond to considering public APIs, allowing ethical scrapers, and reaching out to scrapers before blocking.\n\n1.  **What is a ROBOTS.TXT file? Identify one instance and explain what it allows/prevents.**\n\n    A robots.txt file tells scrappers which URLs can be accessed. Here's a line of `robots.txt`.\n\n    > User-agent: Googlebot\n    >\n    > Disallow: /nogooglebot/\n\nThe user agent named Googlebot is not allowed to crawl any URL that starts with <https://example.com/nogooglebot/>.\n\n> User-agent: \\*\n>\n> Allow: /\n\nAbove lines mean all user agent are allowed to crawl the entire site.\n\n**Identify a website that you would like to scrape (or one an example from class) and implement a scrape using the `polite` package.**\n\n::: {.cell hash='index_cache/html/unnamed-chunk-1_57ba9e51b2f00452275b5920f0c434c0'}\n\n```{.r .cell-code}\nlibrary(polite)\nlibrary(rvest)\nlibrary(dplyr)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n\nAttaching package: 'dplyr'\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n```\n:::\n\n```{.r .cell-code}\nurl <- \"https://en.wikipedia.org/wiki/AFC_Asian_Cup_records_and_statistics\"\nsession <- bow(url, user_agent = \"hiiiua blog-10 assignment\")\n\nsection <- scrape(session) %>% html_nodes(\"#mw-content-text > div.mw-parser-output > table:nth-child(5)\")\n\nsection %>% html_table()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[[1]]\n# A tibble: 19 × 6\n    Year `Host(s)`                           Winners     Winni…¹ Top s…² Best …³\n   <int> <chr>                               <chr>       <chr>   <chr>   <chr>  \n 1  1956 Hong Kong                           South Korea Kim Su… Nahum … —      \n 2  1960 South Korea                         South Korea Kim Yo… Cho Yo… —      \n 3  1964 Israel                              Israel      Yosef … Inder … —      \n 4  1968 Iran                                Iran        Mahmou… Homayo… —      \n 5  1972 Thailand                            Iran        Mohamm… Hossei… Ebrahi…\n 6  1976 Iran                                Iran        Heshma… Gholam… Ali Pa…\n 7  1980 Kuwait                              Kuwait      Carlos… Behtas… —      \n 8  1984 Singapore                           Saudi Arab… Khalil… Jia Xi… Jia Xi…\n 9  1988 Qatar                               Saudi Arab… Carlos… Lee Ta… Kim Jo…\n10  1992 Japan                               Japan       Hans O… Fahad … Kazuyo…\n11  1996 United Arab Emirates                Saudi Arab… Nelo V… Ali Da… Khodad…\n12  2000 Lebanon                             Japan       Philip… Lee Do… Hirosh…\n13  2004 China                               Japan       Zico    A'ala … Shunsu…\n14  2007 Indonesia Malaysia Thailand Vietnam Iraq        Jorvan… Younis… Younis…\n15  2011 Qatar                               Japan       Albert… Koo Ja… Keisuk…\n16  2015 Australia                           Australia   Ange P… Ali Ma… Massim…\n17  2019 United Arab Emirates                Qatar       Félix … Almoez… Almoez…\n18  2023 Qatar                               TBD         TBD     TBD     TBD    \n19  2027 Saudi Arabia                        TBD         TBD     TBD     TBD    \n# … with abbreviated variable names ¹​`Winning coach`, ²​`Top scorer(s) (goals)`,\n#   ³​`Best player award`\n```\n:::\n:::\n\n\n\nInstructions:\n\nSubmit to your repo. Make sure that all of the github actions pass (check menu item Actions - all of the actions should have green checks)\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}