{
  "hash": "7b895799d6640e9b54fb498965c9cda8",
  "result": {
    "markdown": "---\nauthor: \"Motina\"\ntitle: \"Web scraping etiquette ...\"\ncategories: \"Errors and warnings in packages\"\ndate: \"2023-04-06\"\noutput: github_document\n---\n\n \n## Prompt:\n\nWith great power comes great responsibility - a large part of the web is based on data and services that scrape those data. \nNow that we start to apply scraping mechanisms, we need to think about how to apply those skills without becoming a burden to the internet society.\n\nFind sources on ethical web scraping - some readings that might help you get started with that are: \n\n  - [James Densmore](https://towardsdatascience.com/ethics-in-web-scraping-b96b18136f01)\n\n  - R package [polite](https://github.com/dmi3kno/polite)\n\n  - [JAMI @ EMPIRICAL](https://www.empiricaldata.org/dataladyblog/a-guide-to-ethical-web-scraping)\n\n\nAfter reading through some of the ethics essays\nwrite a blog post addressing the following questions: \n\n1. **What are your main three takeaways for ethical web scraping? - Give examples, or cite your sources.**\nHere are three key takeaways from the article:\n\n>**Use public APIs whenever possible:** Instead of scraping data directly from a website, use its API if it has it. By using an API, you'll get the data in a structured and consistent format and you'll reduce the website's server load.\n\n>**Respect the website's terms of use:** When scraping data from a website, be transparent about your intentions. Providing a clear user agent string identifies you as a scraper rather than a malicious bot, requesting data at a reasonable rate, and only saving the data you need. If you keep anything, make sure you don't pass it off as your own.\n\n>**Provide value:** Instead of just taking data from a website, try to give something back. The data can be used in a way to benefit the website or its users, such as driving traffic to the site, crediting it in an article, or finding other ways to use it.\n\nSource: [James Densmore's article \"Ethics in Web Scraping\"] (https://towardsdatascience.com/ethics-in-web-scraping-b96b18136f01)\n\n2. **What is a ROBOTS.TXT file? Identify one instance and explain what it allows/prevents.**\n\nFor `robots.txt`, it's a file placed in a site's root directory that tells web scrapers how they can crawl the site. You can allow or disallow certain web scraping activities in the file, or define how often requests should be made. The `robots.txt` file on Twitter, for example, doesn't let scrapers crawl the `/search` and `/notifications` sections of the site. Therefore, web scrapers shouldn't scrape or access these parts of the site without permission.\n\n3. **Identify a website that you would like to scrape (or one an example from class) and implement a scrape using the `polite` package.**\n\n\n\n::: {.cell hash='index_cache/html/unnamed-chunk-1_c59aaf92f24dba5f8f92108298595b1e'}\n\n```{.r .cell-code}\nlibrary(polite)\nlibrary(rvest)\nlibrary(purrr)\nlibrary(dplyr)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n\nAttaching package: 'dplyr'\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n```\n:::\n\n```{.r .cell-code}\n# Set the URL to scrape\nurl <- \"https://www.nytimes.com/elections/2016/results/iowa\"\n\n# Create a polite session to request permission to scrape the site\nsession <- bow(url)\n\n# Use the session to retrieve the HTML content of the page\nhtml <- scrape(session)\n\n# Extract the tables from the HTML using rvest\ntables <- html %>% html_table(fill = TRUE)\n\n# Print a summary of each table using purrr \ntables %>% purrr::map(summary) %>% head()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[[1]]\n Candidate       Candidate            Party              Votes          \n Mode:logical   Length:11          Length:11          Length:11         \n NA's:11        Class :character   Class :character   Class :character  \n                Mode  :character   Mode  :character   Mode  :character  \n     Pct.                              E.V.          \n Length:11          Mode:logical   Length:11         \n Class :character   NA's:11        Class :character  \n Mode  :character                  Mode  :character  \n\n[[2]]\n Vote by county        Trump             Clinton         \n Length:99          Length:99          Length:99         \n Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character  \n\n[[3]]\n Candidate       Candidate            Party              Votes          \n Mode:logical   Length:6           Length:6           Length:6          \n NA's:6         Class :character   Class :character   Class :character  \n                Mode  :character   Mode  :character   Mode  :character  \n     Pct.                         \n Length:6           Mode:logical  \n Class :character   NA's:6        \n Mode  :character                 \n\n[[4]]\n Vote by county       Grassley            Judge          \n Length:99          Length:99          Length:99         \n Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character  \n\n[[5]]\n District\\n          Dist.    Leader                            \n Min.   :1.00              Length:4           Length:4          \n 1st Qu.:1.75              Class :character   Class :character  \n Median :2.50              Mode  :character   Mode  :character  \n Mean   :2.50                                                   \n 3rd Qu.:3.25                                                   \n Max.   :4.00                                                   \n     Rpt.                         \n Length:4           Mode:logical  \n Class :character   NA's:4        \n Mode  :character                 \n                                  \n                                  \n                                  \n\n[[6]]\n Seat\\n          Seat    Leader                                 Rpt.          \n Min.   : 2           Length:25          Length:25          Length:25         \n 1st Qu.:14           Class :character   Class :character   Class :character  \n Median :26           Mode  :character   Mode  :character   Mode  :character  \n Mean   :26                                                                   \n 3rd Qu.:38                                                                   \n Max.   :50                                                                   \n               \n Mode:logical  \n NA's:25       \n               \n               \n               \n               \n```\n:::\n:::\n\n\n\nInstructions:\n\nSubmit to your repo. Make sure that all of the github actions pass (check menu item Actions - all of the actions should have green checks)\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}