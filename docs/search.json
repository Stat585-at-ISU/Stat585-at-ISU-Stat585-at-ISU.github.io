[
  {
    "objectID": "labs/02_lab_2023.html",
    "href": "labs/02_lab_2023.html",
    "title": "Lab 2 - Getting that data",
    "section": "",
    "text": "pdf files are for text, right?\nLooking under the hood …\n\nThe final deliverable is again a self-contained RMarkdown file and a dataset."
  },
  {
    "objectID": "labs/02_lab_2023.html#deliverable-1",
    "href": "labs/02_lab_2023.html#deliverable-1",
    "title": "Lab 2 - Getting that data",
    "section": "Deliverable (1)",
    "text": "Deliverable (1)\nCreate a markdown table with a description of the structure of your repository (i.e. which files are where, and what is included). The structure is not going to be graded itself, just your description of the structure. You will find that good structures are easier to describe :)\nCombine all of your service call data sets into one, draw a barchart of the number of service calls by day, colour by service log file."
  },
  {
    "objectID": "labs/02_lab_2023.html#deliverable-2",
    "href": "labs/02_lab_2023.html#deliverable-2",
    "title": "Lab 2 - Getting that data",
    "section": "Deliverable (2)",
    "text": "Deliverable (2)\nIn case things went horribly wrong, and you could not get things to work, describe what you did, which error you encountered, and what strategies you tried before you gave up/ the time for the lab was up."
  },
  {
    "objectID": "labs/01-slides.html#how-this-is-going-to-work",
    "href": "labs/01-slides.html#how-this-is-going-to-work",
    "title": "Lab 1 - Funny File Formats",
    "section": "How this is going to work",
    "text": "How this is going to work\n\nFind your team\nYou are asked to work through a set of questions\nThe deliverable is a final push to your github repository and (in Canvas) an upload of the link to your repository. Don’t forget that ALL of the team members should contribute to the repo :)"
  },
  {
    "objectID": "labs/01-slides.html#agenda-for-today",
    "href": "labs/01-slides.html#agenda-for-today",
    "title": "Lab 1 - Funny File Formats",
    "section": "Agenda for today",
    "text": "Agenda for today\n\nLink RStudio and git\nDeal with the weather (stations) …\n… and some funny file formats"
  },
  {
    "objectID": "labs/01-slides.html#repo-for-the-lab",
    "href": "labs/01-slides.html#repo-for-the-lab",
    "title": "Lab 1 - Funny File Formats",
    "section": "Repo for the lab",
    "text": "Repo for the lab\n\nAccept the link to the github classroom assignment (sent by email).\nCheck whether one of your team members has already created a team. In that case, join them. If none of your team members is listed yet, create a team.\nLink the repository to RStudio … (see next set of slides)"
  },
  {
    "objectID": "labs/01-slides.html#connecting-rstudio-and-git",
    "href": "labs/01-slides.html#connecting-rstudio-and-git",
    "title": "Lab 1 - Funny File Formats",
    "section": "Connecting RStudio and git",
    "text": "Connecting RStudio and git\nWork through chapter 12 of Jenny Bryan’s book “Happy git with R”\nUse your lab’s repository as the example repository in RStudio.\nAdd a link to the lab repository in your write-up."
  },
  {
    "objectID": "labs/01-slides.html#weather-stations",
    "href": "labs/01-slides.html#weather-stations",
    "title": "Lab 1 - Funny File Formats",
    "section": "Weather stations",
    "text": "Weather stations\n\nThe National Climate Data Center at NOAA publishes information on temperature and precipitation across a network of stations in the US.\nThe Data can be accessed through via https://www.ncei.noaa.gov/pub/data/ushcn/v2.5/, a code book with a description of the data structure is available at https://www.ncei.noaa.gov/pub/data/ushcn/v2.5/readme.txt\n\nDownload a copy of the file ushcn-v2.5-stations.txt.\nMake yourself familar with the command read_fwf from package readr.\nUse the codebook description for the stations file, extract all columns and bring them into the intended format (i.e. numbers are numbers)\nCreate a plot with ggplot2 to show latitude, longitude and elevation. Can you also include state information and time zone?\nDeliverable: include the code necessary to read the file and to create the plot in README.Rmd. Also include the file ushcn-v2.5-stations.txt to your repository."
  },
  {
    "objectID": "labs/01-slides.html#funny-file-formats",
    "href": "labs/01-slides.html#funny-file-formats",
    "title": "Lab 1 - Funny File Formats",
    "section": "Funny file formats",
    "text": "Funny file formats\n\nThe file ushcn.tavg.latest.raw.tar.gz at ftp://ftp.ncdc.noaa.gov/pub/data/ushcn/v2.5 contains data on average temperatures across the US.\n\nDownload the file and get it to open with tools available in R. (Double-clicking is cheating! :) )\nDetermine how many files are contained inside ushcn.tavg.latest.raw.tar.gz and the name of the file containing the temperature data of your home towns or Fort Dodge, IA (please specify).\nDeliverable: In the Rmarkdown file include the code necessary to extract files from the archive ushcn.tavg.latest.raw.tar.gz. Include code to answer the above questions.\n\nIf things don’t work write a paragraph on why things do not work and what you have tried."
  },
  {
    "objectID": "labs/04-lab-slides.html#lab-organization",
    "href": "labs/04-lab-slides.html#lab-organization",
    "title": "Lab 4 - Adding a shiny app",
    "section": "Lab organization",
    "text": "Lab organization\nTeams:\n\nUser-interface https://classroom.github.com/a/03nFXsNc\nSpatial https://classroom.github.com/a/K6iMZ-4m\nTemporal https://classroom.github.com/a/5NgNwe04\n\n\nAs last time, there is a github classroom link. Select the invite with your team’s number (or create a team in case there is none yet).\nHofmann, don’t forget the Zoom breakout rooms. Join the room that matches your team number.\nFinal deliverable: submit a link to your repository in Canvas (This will show me that you are done working on your project).\nOur goal for today: add a shiny up to the R package!"
  },
  {
    "objectID": "labs/04-lab-slides.html#make-sure-to-talk",
    "href": "labs/04-lab-slides.html#make-sure-to-talk",
    "title": "Lab 4 - Adding a shiny app",
    "section": "Make sure to talk!",
    "text": "Make sure to talk!\nAll team members are supposed to contribute … last time you might have realized that it is a pretty big mess if everybody writes into the README file all at the same time.\nThis time: figure out a plan before you start working. Include your plan as a table in the README.Rmd file for lab #4."
  },
  {
    "objectID": "labs/04-lab-slides.html#our-goal-for-this-lab",
    "href": "labs/04-lab-slides.html#our-goal-for-this-lab",
    "title": "Lab 4 - Adding a shiny app",
    "section": "Our Goal for this lab",
    "text": "Our Goal for this lab\n\ncreate a shiny app within the R package …\n… and make sure that the package passes R CMD check"
  },
  {
    "objectID": "labs/04-lab-slides.html#repo-for-the-lab",
    "href": "labs/04-lab-slides.html#repo-for-the-lab",
    "title": "Lab 4 - Adding a shiny app",
    "section": "Repo for the lab",
    "text": "Repo for the lab\n\nAccept the link to the github classroom assignment (sent by email).\nCheck whether one of your team members has already created a team. In that case, join them. If none of your team members is listed yet, create a team.\nLink the repository to RStudio …"
  },
  {
    "objectID": "labs/03-lab-slides.html#lab-organization",
    "href": "labs/03-lab-slides.html#lab-organization",
    "title": "Lab 3 - Making a package",
    "section": "Lab organization",
    "text": "Lab organization\n\nIn Canvas, look up on which team you are.\nAs last time, there is a github classroom link. Select the invite with your team’s number (or create a team in case there is none yet).\nHofmann, don’t forget the Zoom breakout rooms. Join the room that matches your team number.\nFinal deliverable: submit a link to your repository in Canvas (This will show me that you are done working on your project).\nOur goal for today: create an R package!"
  },
  {
    "objectID": "labs/03-lab-slides.html#make-sure-to-talk",
    "href": "labs/03-lab-slides.html#make-sure-to-talk",
    "title": "Lab 3 - Making a package",
    "section": "Make sure to talk!",
    "text": "Make sure to talk!\nAll team members are supposed to contribute … last time you might have realized that it is a pretty big mess if everybody writes into the README file all at the same time.\nThis time: figure out a plan before you start working. Include your plan as a table in the README.Rmd file for lab #3."
  },
  {
    "objectID": "labs/03-lab-slides.html#our-goal-for-this-lab",
    "href": "labs/03-lab-slides.html#our-goal-for-this-lab",
    "title": "Lab 3 - Making a package",
    "section": "Our Goal for this lab",
    "text": "Our Goal for this lab\n\ncreate an R package …\n… based on the code from last time …\n… and make sure that the package passes R CMD check"
  },
  {
    "objectID": "labs/03-lab-slides.html#repo-for-the-lab",
    "href": "labs/03-lab-slides.html#repo-for-the-lab",
    "title": "Lab 3 - Making a package",
    "section": "Repo for the lab",
    "text": "Repo for the lab\n\nAccept the link to the github classroom assignment (sent by email).\nCheck whether one of your team members has already created a team. In that case, join them. If none of your team members is listed yet, create a team.\nLink the repository to RStudio …"
  },
  {
    "objectID": "labs/03-lab-slides.html#package-specifications-functions",
    "href": "labs/03-lab-slides.html#package-specifications-functions",
    "title": "Lab 3 - Making a package",
    "section": "Package specifications: Functions",
    "text": "Package specifications: Functions\n\nThe package should contain a set of functions (see Lab 2 sample code):\n\nget_pd_presslog (url, save_as)\nthis function is supposed to download the current ames pd presslog and save a copy to a specified location\npdf_to_tbl (pdf, save_as) takes as input a (path to a pdf) presslog from Ames PD and returns a tibble. If save_as is specified, it also saves a copy of the result as csv file to a local file.\nget_presslog (from, to) takes as input two dates/times and returns all (available) service calls made to the Ames PD during the specified time frame.\n\nYou could think about setting defaults, such as\n\nurl = \"https://data.city.ames.ia.us/publicinformation/PressLog.pdf\" or\nsave_as = sprintf(\"presslog_amespd_%s.pdf\", lubridate::today())"
  },
  {
    "objectID": "labs/03-lab-slides.html#package-specifications-data",
    "href": "labs/03-lab-slides.html#package-specifications-data",
    "title": "Lab 3 - Making a package",
    "section": "Package specifications: Data",
    "text": "Package specifications: Data\n\nInclude a data set called presslog_ames in the package, that contains all available data on service calls to the Ames PD based on presslogs available from Lab 2.\nMake sure to document the data and include an example use case."
  },
  {
    "objectID": "labs/03-lab-slides.html#does-the-package-pass-the-tests",
    "href": "labs/03-lab-slides.html#does-the-package-pass-the-tests",
    "title": "Lab 3 - Making a package",
    "section": "Does the package pass the tests?",
    "text": "Does the package pass the tests?\n\nRun command check locally (under Build > Check) to if the package still passes.\nThere should be no errors, warnings, or notes.\n\n0 errors ✔️ | 0 warnings ✔️ | 0 notes ✔️\nR CMD check succeeded\nMake sure to give your team a lot of time to hunt down these problems."
  },
  {
    "objectID": "LICENSE.html",
    "href": "LICENSE.html",
    "title": "Stat 585",
    "section": "",
    "text": "Version 3, 29 June 2007\nCopyright © 2007 Free Software Foundation, Inc. <http://fsf.org/>\nEveryone is permitted to copy and distribute verbatim copies of this license document, but changing it is not allowed.\n\n\nThe GNU General Public License is a free, copyleft license for software and other kinds of works.\nThe licenses for most software and other practical works are designed to take away your freedom to share and change the works. By contrast, the GNU General Public License is intended to guarantee your freedom to share and change all versions of a program–to make sure it remains free software for all its users. We, the Free Software Foundation, use the GNU General Public License for most of our software; it applies also to any other work released this way by its authors. You can apply it to your programs, too.\nWhen we speak of free software, we are referring to freedom, not price. Our General Public Licenses are designed to make sure that you have the freedom to distribute copies of free software (and charge for them if you wish), that you receive source code or can get it if you want it, that you can change the software or use pieces of it in new free programs, and that you know you can do these things.\nTo protect your rights, we need to prevent others from denying you these rights or asking you to surrender the rights. Therefore, you have certain responsibilities if you distribute copies of the software, or if you modify it: responsibilities to respect the freedom of others.\nFor example, if you distribute copies of such a program, whether gratis or for a fee, you must pass on to the recipients the same freedoms that you received. You must make sure that they, too, receive or can get the source code. And you must show them these terms so they know their rights.\nDevelopers that use the GNU GPL protect your rights with two steps: (1) assert copyright on the software, and (2) offer you this License giving you legal permission to copy, distribute and/or modify it.\nFor the developers’ and authors’ protection, the GPL clearly explains that there is no warranty for this free software. For both users’ and authors’ sake, the GPL requires that modified versions be marked as changed, so that their problems will not be attributed erroneously to authors of previous versions.\nSome devices are designed to deny users access to install or run modified versions of the software inside them, although the manufacturer can do so. This is fundamentally incompatible with the aim of protecting users’ freedom to change the software. The systematic pattern of such abuse occurs in the area of products for individuals to use, which is precisely where it is most unacceptable. Therefore, we have designed this version of the GPL to prohibit the practice for those products. If such problems arise substantially in other domains, we stand ready to extend this provision to those domains in future versions of the GPL, as needed to protect the freedom of users.\nFinally, every program is threatened constantly by software patents. States should not allow patents to restrict development and use of software on general-purpose computers, but in those that do, we wish to avoid the special danger that patents applied to a free program could make it effectively proprietary. To prevent this, the GPL assures that patents cannot be used to render the program non-free.\nThe precise terms and conditions for copying, distribution and modification follow.\n\n\n\n\n\n“This License” refers to version 3 of the GNU General Public License.\n“Copyright” also means copyright-like laws that apply to other kinds of works, such as semiconductor masks.\n“The Program” refers to any copyrightable work licensed under this License. Each licensee is addressed as “you”. “Licensees” and “recipients” may be individuals or organizations.\nTo “modify” a work means to copy from or adapt all or part of the work in a fashion requiring copyright permission, other than the making of an exact copy. The resulting work is called a “modified version” of the earlier work or a work “based on” the earlier work.\nA “covered work” means either the unmodified Program or a work based on the Program.\nTo “propagate” a work means to do anything with it that, without permission, would make you directly or secondarily liable for infringement under applicable copyright law, except executing it on a computer or modifying a private copy. Propagation includes copying, distribution (with or without modification), making available to the public, and in some countries other activities as well.\nTo “convey” a work means any kind of propagation that enables other parties to make or receive copies. Mere interaction with a user through a computer network, with no transfer of a copy, is not conveying.\nAn interactive user interface displays “Appropriate Legal Notices” to the extent that it includes a convenient and prominently visible feature that (1) displays an appropriate copyright notice, and (2) tells the user that there is no warranty for the work (except to the extent that warranties are provided), that licensees may convey the work under this License, and how to view a copy of this License. If the interface presents a list of user commands or options, such as a menu, a prominent item in the list meets this criterion.\n\n\n\nThe “source code” for a work means the preferred form of the work for making modifications to it. “Object code” means any non-source form of a work.\nA “Standard Interface” means an interface that either is an official standard defined by a recognized standards body, or, in the case of interfaces specified for a particular programming language, one that is widely used among developers working in that language.\nThe “System Libraries” of an executable work include anything, other than the work as a whole, that (a) is included in the normal form of packaging a Major Component, but which is not part of that Major Component, and (b) serves only to enable use of the work with that Major Component, or to implement a Standard Interface for which an implementation is available to the public in source code form. A “Major Component”, in this context, means a major essential component (kernel, window system, and so on) of the specific operating system (if any) on which the executable work runs, or a compiler used to produce the work, or an object code interpreter used to run it.\nThe “Corresponding Source” for a work in object code form means all the source code needed to generate, install, and (for an executable work) run the object code and to modify the work, including scripts to control those activities. However, it does not include the work’s System Libraries, or general-purpose tools or generally available free programs which are used unmodified in performing those activities but which are not part of the work. For example, Corresponding Source includes interface definition files associated with source files for the work, and the source code for shared libraries and dynamically linked subprograms that the work is specifically designed to require, such as by intimate data communication or control flow between those subprograms and other parts of the work.\nThe Corresponding Source need not include anything that users can regenerate automatically from other parts of the Corresponding Source.\nThe Corresponding Source for a work in source code form is that same work.\n\n\n\nAll rights granted under this License are granted for the term of copyright on the Program, and are irrevocable provided the stated conditions are met. This License explicitly affirms your unlimited permission to run the unmodified Program. The output from running a covered work is covered by this License only if the output, given its content, constitutes a covered work. This License acknowledges your rights of fair use or other equivalent, as provided by copyright law.\nYou may make, run and propagate covered works that you do not convey, without conditions so long as your license otherwise remains in force. You may convey covered works to others for the sole purpose of having them make modifications exclusively for you, or provide you with facilities for running those works, provided that you comply with the terms of this License in conveying all material for which you do not control copyright. Those thus making or running the covered works for you must do so exclusively on your behalf, under your direction and control, on terms that prohibit them from making any copies of your copyrighted material outside their relationship with you.\nConveying under any other circumstances is permitted solely under the conditions stated below. Sublicensing is not allowed; section 10 makes it unnecessary.\n\n\n\nNo covered work shall be deemed part of an effective technological measure under any applicable law fulfilling obligations under article 11 of the WIPO copyright treaty adopted on 20 December 1996, or similar laws prohibiting or restricting circumvention of such measures.\nWhen you convey a covered work, you waive any legal power to forbid circumvention of technological measures to the extent such circumvention is effected by exercising rights under this License with respect to the covered work, and you disclaim any intention to limit operation or modification of the work as a means of enforcing, against the work’s users, your or third parties’ legal rights to forbid circumvention of technological measures.\n\n\n\nYou may convey verbatim copies of the Program’s source code as you receive it, in any medium, provided that you conspicuously and appropriately publish on each copy an appropriate copyright notice; keep intact all notices stating that this License and any non-permissive terms added in accord with section 7 apply to the code; keep intact all notices of the absence of any warranty; and give all recipients a copy of this License along with the Program.\nYou may charge any price or no price for each copy that you convey, and you may offer support or warranty protection for a fee.\n\n\n\nYou may convey a work based on the Program, or the modifications to produce it from the Program, in the form of source code under the terms of section 4, provided that you also meet all of these conditions:\n\na) The work must carry prominent notices stating that you modified it, and giving a relevant date.\nb) The work must carry prominent notices stating that it is released under this License and any conditions added under section 7. This requirement modifies the requirement in section 4 to “keep intact all notices”.\nc) You must license the entire work, as a whole, under this License to anyone who comes into possession of a copy. This License will therefore apply, along with any applicable section 7 additional terms, to the whole of the work, and all its parts, regardless of how they are packaged. This License gives no permission to license the work in any other way, but it does not invalidate such permission if you have separately received it.\nd) If the work has interactive user interfaces, each must display Appropriate Legal Notices; however, if the Program has interactive interfaces that do not display Appropriate Legal Notices, your work need not make them do so.\n\nA compilation of a covered work with other separate and independent works, which are not by their nature extensions of the covered work, and which are not combined with it such as to form a larger program, in or on a volume of a storage or distribution medium, is called an “aggregate” if the compilation and its resulting copyright are not used to limit the access or legal rights of the compilation’s users beyond what the individual works permit. Inclusion of a covered work in an aggregate does not cause this License to apply to the other parts of the aggregate.\n\n\n\nYou may convey a covered work in object code form under the terms of sections 4 and 5, provided that you also convey the machine-readable Corresponding Source under the terms of this License, in one of these ways:\n\na) Convey the object code in, or embodied in, a physical product (including a physical distribution medium), accompanied by the Corresponding Source fixed on a durable physical medium customarily used for software interchange.\nb) Convey the object code in, or embodied in, a physical product (including a physical distribution medium), accompanied by a written offer, valid for at least three years and valid for as long as you offer spare parts or customer support for that product model, to give anyone who possesses the object code either (1) a copy of the Corresponding Source for all the software in the product that is covered by this License, on a durable physical medium customarily used for software interchange, for a price no more than your reasonable cost of physically performing this conveying of source, or (2) access to copy the Corresponding Source from a network server at no charge.\nc) Convey individual copies of the object code with a copy of the written offer to provide the Corresponding Source. This alternative is allowed only occasionally and noncommercially, and only if you received the object code with such an offer, in accord with subsection 6b.\nd) Convey the object code by offering access from a designated place (gratis or for a charge), and offer equivalent access to the Corresponding Source in the same way through the same place at no further charge. You need not require recipients to copy the Corresponding Source along with the object code. If the place to copy the object code is a network server, the Corresponding Source may be on a different server (operated by you or a third party) that supports equivalent copying facilities, provided you maintain clear directions next to the object code saying where to find the Corresponding Source. Regardless of what server hosts the Corresponding Source, you remain obligated to ensure that it is available for as long as needed to satisfy these requirements.\ne) Convey the object code using peer-to-peer transmission, provided you inform other peers where the object code and Corresponding Source of the work are being offered to the general public at no charge under subsection 6d.\n\nA separable portion of the object code, whose source code is excluded from the Corresponding Source as a System Library, need not be included in conveying the object code work.\nA “User Product” is either (1) a “consumer product”, which means any tangible personal property which is normally used for personal, family, or household purposes, or (2) anything designed or sold for incorporation into a dwelling. In determining whether a product is a consumer product, doubtful cases shall be resolved in favor of coverage. For a particular product received by a particular user, “normally used” refers to a typical or common use of that class of product, regardless of the status of the particular user or of the way in which the particular user actually uses, or expects or is expected to use, the product. A product is a consumer product regardless of whether the product has substantial commercial, industrial or non-consumer uses, unless such uses represent the only significant mode of use of the product.\n“Installation Information” for a User Product means any methods, procedures, authorization keys, or other information required to install and execute modified versions of a covered work in that User Product from a modified version of its Corresponding Source. The information must suffice to ensure that the continued functioning of the modified object code is in no case prevented or interfered with solely because modification has been made.\nIf you convey an object code work under this section in, or with, or specifically for use in, a User Product, and the conveying occurs as part of a transaction in which the right of possession and use of the User Product is transferred to the recipient in perpetuity or for a fixed term (regardless of how the transaction is characterized), the Corresponding Source conveyed under this section must be accompanied by the Installation Information. But this requirement does not apply if neither you nor any third party retains the ability to install modified object code on the User Product (for example, the work has been installed in ROM).\nThe requirement to provide Installation Information does not include a requirement to continue to provide support service, warranty, or updates for a work that has been modified or installed by the recipient, or for the User Product in which it has been modified or installed. Access to a network may be denied when the modification itself materially and adversely affects the operation of the network or violates the rules and protocols for communication across the network.\nCorresponding Source conveyed, and Installation Information provided, in accord with this section must be in a format that is publicly documented (and with an implementation available to the public in source code form), and must require no special password or key for unpacking, reading or copying.\n\n\n\n“Additional permissions” are terms that supplement the terms of this License by making exceptions from one or more of its conditions. Additional permissions that are applicable to the entire Program shall be treated as though they were included in this License, to the extent that they are valid under applicable law. If additional permissions apply only to part of the Program, that part may be used separately under those permissions, but the entire Program remains governed by this License without regard to the additional permissions.\nWhen you convey a copy of a covered work, you may at your option remove any additional permissions from that copy, or from any part of it. (Additional permissions may be written to require their own removal in certain cases when you modify the work.) You may place additional permissions on material, added by you to a covered work, for which you have or can give appropriate copyright permission.\nNotwithstanding any other provision of this License, for material you add to a covered work, you may (if authorized by the copyright holders of that material) supplement the terms of this License with terms:\n\na) Disclaiming warranty or limiting liability differently from the terms of sections 15 and 16 of this License; or\nb) Requiring preservation of specified reasonable legal notices or author attributions in that material or in the Appropriate Legal Notices displayed by works containing it; or\nc) Prohibiting misrepresentation of the origin of that material, or requiring that modified versions of such material be marked in reasonable ways as different from the original version; or\nd) Limiting the use for publicity purposes of names of licensors or authors of the material; or\ne) Declining to grant rights under trademark law for use of some trade names, trademarks, or service marks; or\nf) Requiring indemnification of licensors and authors of that material by anyone who conveys the material (or modified versions of it) with contractual assumptions of liability to the recipient, for any liability that these contractual assumptions directly impose on those licensors and authors.\n\nAll other non-permissive additional terms are considered “further restrictions” within the meaning of section 10. If the Program as you received it, or any part of it, contains a notice stating that it is governed by this License along with a term that is a further restriction, you may remove that term. If a license document contains a further restriction but permits relicensing or conveying under this License, you may add to a covered work material governed by the terms of that license document, provided that the further restriction does not survive such relicensing or conveying.\nIf you add terms to a covered work in accord with this section, you must place, in the relevant source files, a statement of the additional terms that apply to those files, or a notice indicating where to find the applicable terms.\nAdditional terms, permissive or non-permissive, may be stated in the form of a separately written license, or stated as exceptions; the above requirements apply either way.\n\n\n\nYou may not propagate or modify a covered work except as expressly provided under this License. Any attempt otherwise to propagate or modify it is void, and will automatically terminate your rights under this License (including any patent licenses granted under the third paragraph of section 11).\nHowever, if you cease all violation of this License, then your license from a particular copyright holder is reinstated (a) provisionally, unless and until the copyright holder explicitly and finally terminates your license, and (b) permanently, if the copyright holder fails to notify you of the violation by some reasonable means prior to 60 days after the cessation.\nMoreover, your license from a particular copyright holder is reinstated permanently if the copyright holder notifies you of the violation by some reasonable means, this is the first time you have received notice of violation of this License (for any work) from that copyright holder, and you cure the violation prior to 30 days after your receipt of the notice.\nTermination of your rights under this section does not terminate the licenses of parties who have received copies or rights from you under this License. If your rights have been terminated and not permanently reinstated, you do not qualify to receive new licenses for the same material under section 10.\n\n\n\nYou are not required to accept this License in order to receive or run a copy of the Program. Ancillary propagation of a covered work occurring solely as a consequence of using peer-to-peer transmission to receive a copy likewise does not require acceptance. However, nothing other than this License grants you permission to propagate or modify any covered work. These actions infringe copyright if you do not accept this License. Therefore, by modifying or propagating a covered work, you indicate your acceptance of this License to do so.\n\n\n\nEach time you convey a covered work, the recipient automatically receives a license from the original licensors, to run, modify and propagate that work, subject to this License. You are not responsible for enforcing compliance by third parties with this License.\nAn “entity transaction” is a transaction transferring control of an organization, or substantially all assets of one, or subdividing an organization, or merging organizations. If propagation of a covered work results from an entity transaction, each party to that transaction who receives a copy of the work also receives whatever licenses to the work the party’s predecessor in interest had or could give under the previous paragraph, plus a right to possession of the Corresponding Source of the work from the predecessor in interest, if the predecessor has it or can get it with reasonable efforts.\nYou may not impose any further restrictions on the exercise of the rights granted or affirmed under this License. For example, you may not impose a license fee, royalty, or other charge for exercise of rights granted under this License, and you may not initiate litigation (including a cross-claim or counterclaim in a lawsuit) alleging that any patent claim is infringed by making, using, selling, offering for sale, or importing the Program or any portion of it.\n\n\n\nA “contributor” is a copyright holder who authorizes use under this License of the Program or a work on which the Program is based. The work thus licensed is called the contributor’s “contributor version”.\nA contributor’s “essential patent claims” are all patent claims owned or controlled by the contributor, whether already acquired or hereafter acquired, that would be infringed by some manner, permitted by this License, of making, using, or selling its contributor version, but do not include claims that would be infringed only as a consequence of further modification of the contributor version. For purposes of this definition, “control” includes the right to grant patent sublicenses in a manner consistent with the requirements of this License.\nEach contributor grants you a non-exclusive, worldwide, royalty-free patent license under the contributor’s essential patent claims, to make, use, sell, offer for sale, import and otherwise run, modify and propagate the contents of its contributor version.\nIn the following three paragraphs, a “patent license” is any express agreement or commitment, however denominated, not to enforce a patent (such as an express permission to practice a patent or covenant not to sue for patent infringement). To “grant” such a patent license to a party means to make such an agreement or commitment not to enforce a patent against the party.\nIf you convey a covered work, knowingly relying on a patent license, and the Corresponding Source of the work is not available for anyone to copy, free of charge and under the terms of this License, through a publicly available network server or other readily accessible means, then you must either (1) cause the Corresponding Source to be so available, or (2) arrange to deprive yourself of the benefit of the patent license for this particular work, or (3) arrange, in a manner consistent with the requirements of this License, to extend the patent license to downstream recipients. “Knowingly relying” means you have actual knowledge that, but for the patent license, your conveying the covered work in a country, or your recipient’s use of the covered work in a country, would infringe one or more identifiable patents in that country that you have reason to believe are valid.\nIf, pursuant to or in connection with a single transaction or arrangement, you convey, or propagate by procuring conveyance of, a covered work, and grant a patent license to some of the parties receiving the covered work authorizing them to use, propagate, modify or convey a specific copy of the covered work, then the patent license you grant is automatically extended to all recipients of the covered work and works based on it.\nA patent license is “discriminatory” if it does not include within the scope of its coverage, prohibits the exercise of, or is conditioned on the non-exercise of one or more of the rights that are specifically granted under this License. You may not convey a covered work if you are a party to an arrangement with a third party that is in the business of distributing software, under which you make payment to the third party based on the extent of your activity of conveying the work, and under which the third party grants, to any of the parties who would receive the covered work from you, a discriminatory patent license (a) in connection with copies of the covered work conveyed by you (or copies made from those copies), or (b) primarily for and in connection with specific products or compilations that contain the covered work, unless you entered into that arrangement, or that patent license was granted, prior to 28 March 2007.\nNothing in this License shall be construed as excluding or limiting any implied license or other defenses to infringement that may otherwise be available to you under applicable patent law.\n\n\n\nIf conditions are imposed on you (whether by court order, agreement or otherwise) that contradict the conditions of this License, they do not excuse you from the conditions of this License. If you cannot convey a covered work so as to satisfy simultaneously your obligations under this License and any other pertinent obligations, then as a consequence you may not convey it at all. For example, if you agree to terms that obligate you to collect a royalty for further conveying from those to whom you convey the Program, the only way you could satisfy both those terms and this License would be to refrain entirely from conveying the Program.\n\n\n\nNotwithstanding any other provision of this License, you have permission to link or combine any covered work with a work licensed under version 3 of the GNU Affero General Public License into a single combined work, and to convey the resulting work. The terms of this License will continue to apply to the part which is the covered work, but the special requirements of the GNU Affero General Public License, section 13, concerning interaction through a network will apply to the combination as such.\n\n\n\nThe Free Software Foundation may publish revised and/or new versions of the GNU General Public License from time to time. Such new versions will be similar in spirit to the present version, but may differ in detail to address new problems or concerns.\nEach version is given a distinguishing version number. If the Program specifies that a certain numbered version of the GNU General Public License “or any later version” applies to it, you have the option of following the terms and conditions either of that numbered version or of any later version published by the Free Software Foundation. If the Program does not specify a version number of the GNU General Public License, you may choose any version ever published by the Free Software Foundation.\nIf the Program specifies that a proxy can decide which future versions of the GNU General Public License can be used, that proxy’s public statement of acceptance of a version permanently authorizes you to choose that version for the Program.\nLater license versions may give you additional or different permissions. However, no additional obligations are imposed on any author or copyright holder as a result of your choosing to follow a later version.\n\n\n\nTHERE IS NO WARRANTY FOR THE PROGRAM, TO THE EXTENT PERMITTED BY APPLICABLE LAW. EXCEPT WHEN OTHERWISE STATED IN WRITING THE COPYRIGHT HOLDERS AND/OR OTHER PARTIES PROVIDE THE PROGRAM “AS IS” WITHOUT WARRANTY OF ANY KIND, EITHER EXPRESSED OR IMPLIED, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE. THE ENTIRE RISK AS TO THE QUALITY AND PERFORMANCE OF THE PROGRAM IS WITH YOU. SHOULD THE PROGRAM PROVE DEFECTIVE, YOU ASSUME THE COST OF ALL NECESSARY SERVICING, REPAIR OR CORRECTION.\n\n\n\nIN NO EVENT UNLESS REQUIRED BY APPLICABLE LAW OR AGREED TO IN WRITING WILL ANY COPYRIGHT HOLDER, OR ANY OTHER PARTY WHO MODIFIES AND/OR CONVEYS THE PROGRAM AS PERMITTED ABOVE, BE LIABLE TO YOU FOR DAMAGES, INCLUDING ANY GENERAL, SPECIAL, INCIDENTAL OR CONSEQUENTIAL DAMAGES ARISING OUT OF THE USE OR INABILITY TO USE THE PROGRAM (INCLUDING BUT NOT LIMITED TO LOSS OF DATA OR DATA BEING RENDERED INACCURATE OR LOSSES SUSTAINED BY YOU OR THIRD PARTIES OR A FAILURE OF THE PROGRAM TO OPERATE WITH ANY OTHER PROGRAMS), EVEN IF SUCH HOLDER OR OTHER PARTY HAS BEEN ADVISED OF THE POSSIBILITY OF SUCH DAMAGES.\n\n\n\nIf the disclaimer of warranty and limitation of liability provided above cannot be given local legal effect according to their terms, reviewing courts shall apply local law that most closely approximates an absolute waiver of all civil liability in connection with the Program, unless a warranty or assumption of liability accompanies a copy of the Program in return for a fee.\nEND OF TERMS AND CONDITIONS\n\n\n\n\nIf you develop a new program, and you want it to be of the greatest possible use to the public, the best way to achieve this is to make it free software which everyone can redistribute and change under these terms.\nTo do so, attach the following notices to the program. It is safest to attach them to the start of each source file to most effectively state the exclusion of warranty; and each file should have at least the “copyright” line and a pointer to where the full notice is found.\n<one line to give the program's name and a brief idea of what it does.>\nCopyright (C) <year>  <name of author>\n\nThis program is free software: you can redistribute it and/or modify\nit under the terms of the GNU General Public License as published by\nthe Free Software Foundation, either version 3 of the License, or\n(at your option) any later version.\n\nThis program is distributed in the hope that it will be useful,\nbut WITHOUT ANY WARRANTY; without even the implied warranty of\nMERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\nGNU General Public License for more details.\n\nYou should have received a copy of the GNU General Public License\nalong with this program.  If not, see <http://www.gnu.org/licenses/>.\nAlso add information on how to contact you by electronic and paper mail.\nIf the program does terminal interaction, make it output a short notice like this when it starts in an interactive mode:\n<program>  Copyright (C) <year>  <name of author>\nThis program comes with ABSOLUTELY NO WARRANTY; for details type 'show w'.\nThis is free software, and you are welcome to redistribute it\nunder certain conditions; type 'show c' for details.\nThe hypothetical commands show w and show c should show the appropriate parts of the General Public License. Of course, your program’s commands might be different; for a GUI interface, you would use an “about box”.\nYou should also get your employer (if you work as a programmer) or school, if any, to sign a “copyright disclaimer” for the program, if necessary. For more information on this, and how to apply and follow the GNU GPL, see <http://www.gnu.org/licenses/>.\nThe GNU General Public License does not permit incorporating your program into proprietary programs. If your program is a subroutine library, you may consider it more useful to permit linking proprietary applications with the library. If this is what you want to do, use the GNU Lesser General Public License instead of this License. But first, please read <http://www.gnu.org/philosophy/why-not-lgpl.html>."
  },
  {
    "objectID": "projects/project-requirements.html",
    "href": "projects/project-requirements.html",
    "title": "Stat 585",
    "section": "",
    "text": "For the final project you are asked to create an R package. You are free to choose package functionality, but there should be\n\na minimum of five functions with a coherent theme,\na shiny app show-casing some of the functionality\na website for the package\na README page with installation instructions and basic demonstration of functionality\nevidence of testing the functionality\n8-10 page report detailing your work. This report should be written as a package vignette, included in your package’s documentation.\n\nYou are asked to present your work as a team in one of the speaking slots during dead week and finals week. Each team member is supposed to present for about 5 mins."
  },
  {
    "objectID": "projects/project-samples.html",
    "href": "projects/project-samples.html",
    "title": "Project Samples",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\nTitle\n\n\nAuthor\n\n\n\n\n\n\n2019 Project Abstracts\n\n\n\n\n\n\n2022 Project Abstracts\n\n\n\n\n\n\nExploring 1973 U.S Arrests Data\n\n\nAli Sk Saqlain\n\n\n\n\nCyChecks - Examining Pay Patterns Across Iowa State University\n\n\nBrianna Lawton, Virginia Nichols, Lydia English, Yones Khaledian, Stephanie Reinders\n\n\n\n\nBayesAPLM - Bayesian Variable Selection for additive partial linear model\n\n\nBufei Guo\n\n\n\n\nWhat People Talk About When they Talk About Professors\n\n\nDanyang Zhang, Yuhang Lin, Mohammad Fili\n\n\n\n\nFind Your Flight with R\n\n\nDapeng Hu, Yang Qiao, Min Zhang, Xin Zhang, Zerui Zhang\n\n\n\n\nPetFindr - Find pets near me!\n\n\nEarl Hur, Jessica Kueon, Hana Lee, Amin Shirazi, Miranda Tilton\n\n\n\n\nwoRldnews\n\n\nEshita Zaman, Coskun Erden, Alex Cleveringa\n\n\n\n\nStock market prediction\n\n\nGhazal Shah Abadi, Parastoo Akbari,\n\n\n\n\nstatfoRdummies\n\n\nJoe Zemmels, Charlotte Roiger, Eryn Blagg, Gulzina Kuttubekova\n\n\n\n\nredres - Redress Your Mixed Model Assumptions\n\n\nKatherine Goode, Yonghui Huo, Jing Zhao, Kellie McClernon, Yudi Zhang\n\n\n\n\npitcheR\n\n\nKieran Liming, Robert Castaneda, Gabrielle Collins, Abigail Collins, Abraham Adokwei\n\n\n\n\nAn R package to visualize U.S. Census Data\n\n\nLin Quan, Zirou Zhou, Xiaolan Wan\n\n\n\n\nDealing with the current weather data\n\n\nQing He, Jing Hou, Jing Li, Yuchen Wang, Ying Zheng\n\n\n\n\nBuild modularized shiny app with ggpaintr\n\n\nWangqian Ju, Zhili Qiao, Jinji Pang\n\n\n\n\nReal Estate Marketing Analysis\n\n\nXiyuan Sun, Steven Harms, Oscar Aguilar, Gani Agadilov\n\n\n\n\nPost Selection Inference of Estimation from Penalized Matrix Decomposition\n\n\nYunhui Qi\n\n\n\n\nSentiAnalyzer - Sentiment analysis for consumer review\n\n\nZahra Khoshmanesh, Atousa Zarindast, Joshua Budi\n\n\n\n\nThe ggfun package\n\n\nZhenzhen Chen, Yawei Ge, Weiquan Luo\n\n\n\n\nAn R package to visualize US Census data\n\n\nZirou Zhou, Lin Quan, Xiaolan Wan\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "projects/projectSamples/2022/Wangqian-Ju-abstract.html",
    "href": "projects/projectSamples/2022/Wangqian-Ju-abstract.html",
    "title": "Build modularized shiny app with ggpaintr",
    "section": "",
    "text": "We here introduce an open-source R package ggpaintr, for building a modularized shiny app in the similar grammar of ggplot2. This package provides built-in modules for both ui and server side of a shiny app so that a shiny app with a graphical user interface for ggplot2 can be easily implemented. And users can write and provide their own modules to further extend and customize the package’s functionality. A shiny app called ggpaintr_app is built with the ggpaintr package and included in the package. ggpaintr_app serves as a shiny app for those unfamiliar with the Grammar of Graphics or ggplot2 but want to create a plot using ggplot2. The corresponding ggplot2 R codes will also be provided once a plot has been created. Additionally, another shiny app called ggpaintr_iris_app is included in the package to showcase how to deploy the basic functionality of this package to build other shiny apps or packages."
  },
  {
    "objectID": "projects/projectSamples/2022/Zirou-Zhou-abstract.html",
    "href": "projects/projectSamples/2022/Zirou-Zhou-abstract.html",
    "title": "An R package to visualize US Census data",
    "section": "",
    "text": "The data of unemployment and household income for the U.S. States is publicly available on USDA. We create an R package and a shiny app to visualize unemployed rate and household income spatially and temporally across United States."
  },
  {
    "objectID": "projects/projectSamples/2022/Eshita-Zaman-abstract.html",
    "href": "projects/projectSamples/2022/Eshita-Zaman-abstract.html",
    "title": "woRldnews",
    "section": "",
    "text": "We created an R package that enables the user to query a global API for news articles in a Shiny app. Users can search by country, language, category, and date range. A data frame is generated that includes the headline, a description, date of publication, a clickable hyperlink and the image associated with the article where provided for the top 20 headlines."
  },
  {
    "objectID": "projects/projectSamples/2022/Saqlain-abstract.html",
    "href": "projects/projectSamples/2022/Saqlain-abstract.html",
    "title": "Exploring 1973 U.S Arrests Data",
    "section": "",
    "text": "The goal of the package ‘aliapp’ is to visualize and explore the 1973 US Arrests data using an interactive dashboard made by R and Shiny. The dataset used here is an in-built dataset in base R. The Shiny app has functionalities to visualize crime rates of different arrests statewise with the help of a bar chart as well as a colour-themed map."
  },
  {
    "objectID": "projects/projectSamples/2022/Abadi-Ghazal-abstract.html",
    "href": "projects/projectSamples/2022/Abadi-Ghazal-abstract.html",
    "title": "Stock market prediction",
    "section": "",
    "text": "Stock market is the aggregation of buyers and sellers of stocks, which represent ownership claims on businesses. This might include securities listed on a public stock exchange, as well as stock that is only traded privately, such as shares of private companies. Stock market prediction has always been of great importance. However, predicting has always been challenging. This package helps in predicting stock price movement using sentiment analysis and web scrapping. Team-9 package"
  },
  {
    "objectID": "projects/projectSamples/2022/Bufei-Guo-abstract.html",
    "href": "projects/projectSamples/2022/Bufei-Guo-abstract.html",
    "title": "BayesAPLM - Bayesian Variable Selection for additive partial linear model",
    "section": "",
    "text": "BayesAPLM provides a variable selection tool in the spirit of the stochastic shotgun search algorithm. By embedding a unique model based screening and using fast Cholesky updates, BayesAPLM produces a highly scalable algorithm to explore gigantic model spaces and rapidly identify the regions of high posterior probabilities. It outputs the log (unnormalized) posterior probability of a set of best (highest probability) models."
  },
  {
    "objectID": "projects/projectSamples/2022/Danyang-Zhang-abstract.html",
    "href": "projects/projectSamples/2022/Danyang-Zhang-abstract.html",
    "title": "What People Talk About When they Talk About Professors",
    "section": "",
    "text": "We aim to analyze information of professors on ratemyprofessors.com. We extracted information such as ratings, comments, tags, etc. from the website. We also did a sentiment analysis on comments and visualized different types of word to give a direct impression in a shiny app."
  },
  {
    "objectID": "projects/projectSamples/2022/Kieran-Liming-abstract.html",
    "href": "projects/projectSamples/2022/Kieran-Liming-abstract.html",
    "title": "pitcheR",
    "section": "",
    "text": "pitcheR is a package designed to take Statcast data (detailed pitch by pitch data from MLB games) and easily visualize it in graphics that are interpretable and useful for anyone looking into big league pitchers. The package can also find trends over time, either game to game or over certain dates, for a pitchers descriptive statistics which helps us look deeper into how the pitcher is throwing the ball."
  },
  {
    "objectID": "projects/projectSamples/2022/Lin-Quan-abstract.html",
    "href": "projects/projectSamples/2022/Lin-Quan-abstract.html",
    "title": "An R package to visualize U.S. Census Data",
    "section": "",
    "text": "The data of unemployment and household income for the U.S. States is publicly available on USDA. We create an R package and a shiny app to visualize unemployed rate and household income spatially and temporally across United States."
  },
  {
    "objectID": "projects/projectSamples/2022/Yunhui-Qi-abstract.html",
    "href": "projects/projectSamples/2022/Yunhui-Qi-abstract.html",
    "title": "Post Selection Inference of Estimation from Penalized Matrix Decomposition",
    "section": "",
    "text": "Penalized matrix decomposition (PMD) has been used as a multivariate analysis tool in many disciplines such as precision medicine, integrative omics data analysis. However, since it is an estimation tool, its accuracy ic not guaranteed. We developed a set of tests so that we can do the post selection inference on the estimation from PMD. In this package TestPMD, we focus on sparse canonical correlation analysis using PMD. This package provides functions for estimation, test of canonical correlations, test of the canonical loadings, visualization using scatter plot, bar plot and fisher exact test for group enrichment analysis. Users can therefore decide the dimension used for downstream analysis, which feature truly contributes to the canonical component and how these results relate to the covariates. For some statisticians, it is not easy to gain biological insights from the identified features due to the complex name of molecules. So, we provide a search tool which can be used to pull the top 5 papers from PubMed by searching the feature names. A shiny app is created to facilitate the use of TestPMD."
  },
  {
    "objectID": "projects/projectSamples/projects-2022.html",
    "href": "projects/projectSamples/projects-2022.html",
    "title": "2022 Project Abstracts",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\nTitle\n\n\nAuthor\n\n\n\n\n\n\nExploring 1973 U.S Arrests Data\n\n\nAli Sk Saqlain\n\n\n\n\nBayesAPLM - Bayesian Variable Selection for additive partial linear model\n\n\nBufei Guo\n\n\n\n\nWhat People Talk About When they Talk About Professors\n\n\nDanyang Zhang, Yuhang Lin, Mohammad Fili\n\n\n\n\nwoRldnews\n\n\nEshita Zaman, Coskun Erden, Alex Cleveringa\n\n\n\n\nStock market prediction\n\n\nGhazal Shah Abadi, Parastoo Akbari,\n\n\n\n\npitcheR\n\n\nKieran Liming, Robert Castaneda, Gabrielle Collins, Abigail Collins, Abraham Adokwei\n\n\n\n\nAn R package to visualize U.S. Census Data\n\n\nLin Quan, Zirou Zhou, Xiaolan Wan\n\n\n\n\nBuild modularized shiny app with ggpaintr\n\n\nWangqian Ju, Zhili Qiao, Jinji Pang\n\n\n\n\nPost Selection Inference of Estimation from Penalized Matrix Decomposition\n\n\nYunhui Qi\n\n\n\n\nAn R package to visualize US Census data\n\n\nZirou Zhou, Lin Quan, Xiaolan Wan\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "projects/projectSamples/projects-2019.html",
    "href": "projects/projectSamples/projects-2019.html",
    "title": "2019 Project Abstracts",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\nTitle\n\n\nAuthor\n\n\n\n\n\n\nCyChecks - Examining Pay Patterns Across Iowa State University\n\n\nBrianna Lawton, Virginia Nichols, Lydia English, Yones Khaledian, Stephanie Reinders\n\n\n\n\nFind Your Flight with R\n\n\nDapeng Hu, Yang Qiao, Min Zhang, Xin Zhang, Zerui Zhang\n\n\n\n\nPetFindr - Find pets near me!\n\n\nEarl Hur, Jessica Kueon, Hana Lee, Amin Shirazi, Miranda Tilton\n\n\n\n\nstatfoRdummies\n\n\nJoe Zemmels, Charlotte Roiger, Eryn Blagg, Gulzina Kuttubekova\n\n\n\n\nredres - Redress Your Mixed Model Assumptions\n\n\nKatherine Goode, Yonghui Huo, Jing Zhao, Kellie McClernon, Yudi Zhang\n\n\n\n\nDealing with the current weather data\n\n\nQing He, Jing Hou, Jing Li, Yuchen Wang, Ying Zheng\n\n\n\n\nReal Estate Marketing Analysis\n\n\nXiyuan Sun, Steven Harms, Oscar Aguilar, Gani Agadilov\n\n\n\n\nSentiAnalyzer - Sentiment analysis for consumer review\n\n\nZahra Khoshmanesh, Atousa Zarindast, Joshua Budi\n\n\n\n\nThe ggfun package\n\n\nZhenzhen Chen, Yawei Ge, Weiquan Luo\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "projects/projectSamples/2019/Earl-Hur-abstract.html",
    "href": "projects/projectSamples/2019/Earl-Hur-abstract.html",
    "title": "PetFindr - Find pets near me!",
    "section": "",
    "text": "Adopting a pet from an animal shelter is a great idea, but is a stressful process. Our R package petfindr will allow users to make pet searching an easier process.\nOur package is an R client for the Petfinder API which collects pet data from petfinder.com. We have written functions to allow R users to access the Petfinder API and provide useful tools to users to find their new furry friends that fit the user’s preferences (e.g., dogs or cats, breeds, age, gender, etc.) from the user’s accessible location. We have also built a Shiny application for visualization, such as creating an interactive map of animal shelters (to show where the pets are located) with pictures of the pets and descriptions of the pets (with pop-up text)."
  },
  {
    "objectID": "projects/projectSamples/2019/Qing-He-abstract.html",
    "href": "projects/projectSamples/2019/Qing-He-abstract.html",
    "title": "Dealing with the current weather data",
    "section": "",
    "text": "It is important to get current weather data of the airports in time. Our package collects the information of the current weather (XML) data from the website of NOAA’s National Weather Service and show it on appropriate plots. Our Shiny app shows the plots with the chosen weather elements and the chosen airports by the user."
  },
  {
    "objectID": "projects/projectSamples/2019/Zahra-Khoshmanesh-abstract.html",
    "href": "projects/projectSamples/2019/Zahra-Khoshmanesh-abstract.html",
    "title": "SentiAnalyzer - Sentiment analysis for consumer review",
    "section": "",
    "text": "Consumer reviews are very instrumental in projecting the development and direction of businesses. The wealth of information provided with online reviews can be analyzed to access the general sentiment of the consumer towards the product/service. This sentiment analysis will provide general idea and quantitative measure of the consumer’s sentiment.\nThe required data set, in .tsv format, consist of a text review and a binary input of 0 or 1 indicating whether the consumer liked the item or not. These will be balanced using “ROSE” package, which attempts to generate synthetic data by randomly over-sampling examples in case of imbalance data.\nThen using a text mining package “tm”, it will mine for the words/word base of interest such as keywords that conveys sentiment based on dictionary list provided by the package. This “stream-lined” tokens that were independent variables on the raw dataset is then joined in a matrix through either of the three algorithms of the user’s choice such as Bag of Words, Tfdfi, or Bigram and will be analyzed based on its sentiment. Next, using “caTools” package, we split the data set to 0.2 data and 0.8 training set split ratio to be fed to different classification models of provided by the existing machine learning algorithms training models.\nThe package also compares the accuracy of the prediction model based on the machine learning algorithm which the user can choose from: decision tree, naïve bayes, or random forest. The result is different parameters of the sentiment prediction that is built in a confusion matrix: Accuracy, Precision, Recall, and F1 score. Lastly, these parameters will be visualized as a wordcloud as well as presented in an interactive Shiny app. Overall, this package will put together different algorithms and visualization of a version of natural language processing (NLP) and will allow a broader audience of user to access this tool."
  },
  {
    "objectID": "projects/projectSamples/2019/Dapeng-Hu-abstract.html",
    "href": "projects/projectSamples/2019/Dapeng-Hu-abstract.html",
    "title": "Find Your Flight with R",
    "section": "",
    "text": "Finding the cheapest flight from point A to point B can be a headache for most of us, especially with other multiple constraints, such as duration, departure and arrival time, layover, etc. The flight searching engines do not provide detailed enough filters for those “picky” customers, and it’s also time consuming to constantly check the flight information. Our project (R package) allows us to scrape information from Skyscanner API, and keep track of that per unit time. The functions in our package also enable us to filter and sort the available flights based on customized constraints. Outcomes are presented with both text and user-friendly figures. Finally, we build a Shiny web page to make flight searching process easy and fun."
  },
  {
    "objectID": "projects/projectSamples/2019/Zhenzhen-Chen-abstract.html",
    "href": "projects/projectSamples/2019/Zhenzhen-Chen-abstract.html",
    "title": "The ggfun package",
    "section": "",
    "text": "The ggfun package wants to expand some of the existing ggplot2 functionalities by wrapping up some new layer functions and existing methods.\nThe current functionalities including creating arrow map for US election, adding new objects in the existing layers, achieving some complicated data transformation and visualization etc."
  },
  {
    "objectID": "projects/projectSamples/2019/Xiyuan-Sun-abstract.html",
    "href": "projects/projectSamples/2019/Xiyuan-Sun-abstract.html",
    "title": "Real Estate Marketing Analysis",
    "section": "",
    "text": "We wrote an R package ‘realEstAnalytics’, which provides an R function for each Zillow API service, making it easy to make API calls and process the response into convenient, R-friendly data structures.\nWe will also build a Shiny app, which allows users to choose parameters they care about, then score and rank US counties to buy a house. We would set parameter bars such as Air Quality, Income, Living Cost, Income/Cost ratio, crime rate, the population in our shiny app. We would need multiple data sources for this purpose."
  },
  {
    "objectID": "projects/projectSamples/2019/Katherine-Goode-abstract.html",
    "href": "projects/projectSamples/2019/Katherine-Goode-abstract.html",
    "title": "redres - Redress Your Mixed Model Assumptions",
    "section": "",
    "text": "We have created a package that takes random effect, or mixed, models fitted using lmer from the lme4 package and returns residual diagnostics. There are functions for calculating the marginal standardized residuals, conditional residuals, and generalized residuals. The user can look at residual plots for these residuals or any of the residuals also provided by lme4. In the Shiny app, the user can interact with the residual plots to identify outliers or other problematic observations and potential exploratory variables."
  },
  {
    "objectID": "projects/projectSamples/2019/Joe-Zemmels-abstract.html",
    "href": "projects/projectSamples/2019/Joe-Zemmels-abstract.html",
    "title": "statfoRdummies",
    "section": "",
    "text": "Intro stats classes can be rough for some people, even more so for others. As instructors and TA’s for intro statistics classes we see what students struggle with the most. In order to help our students, we have taken 4 often confusing topic and visualized them, hoping that with use of these visualizations these topics become a little less confusing. Let’s hope that our students think so too."
  },
  {
    "objectID": "projects/projectSamples/2019/Brianna-Lawton-abstract.html",
    "href": "projects/projectSamples/2019/Brianna-Lawton-abstract.html",
    "title": "CyChecks - Examining Pay Patterns Across Iowa State University",
    "section": "",
    "text": "Salary data for Iowa State University employees is publicly available through the state government. We’ve developed Cychecks, an R package, for the purpose of examining and interpreting this dataset. This package will allow users to compare pay between genders, positions, and departments, for instance, and display the results in a dynamic interface. While this data is publicly available, we also understand that salaries are sensitive, personal information and therefore we will be anonymizing all names. We hope Cychecks will provide useful fodder for discussing pay patterns within a publicly funded university."
  },
  {
    "objectID": "projects/index.html",
    "href": "projects/index.html",
    "title": "Project Samples",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\nTitle\n\n\nAuthor\n\n\n\n\n\n\n2022 Project Abstracts\n\n\n\n\n\n\n2019 Project Abstracts\n\n\n\n\n\n\nExploring 1973 U.S Arrests Data\n\n\nAli Sk Saqlain\n\n\n\n\nCyChecks - Examining Pay Patterns Across Iowa State University\n\n\nBrianna Lawton, Virginia Nichols, Lydia English, Yones Khaledian, Stephanie Reinders\n\n\n\n\nBayesAPLM - Bayesian Variable Selection for additive partial linear model\n\n\nBufei Guo\n\n\n\n\nWhat People Talk About When they Talk About Professors\n\n\nDanyang Zhang, Yuhang Lin, Mohammad Fili\n\n\n\n\nFind Your Flight with R\n\n\nDapeng Hu, Yang Qiao, Min Zhang, Xin Zhang, Zerui Zhang\n\n\n\n\nPetFindr - Find pets near me!\n\n\nEarl Hur, Jessica Kueon, Hana Lee, Amin Shirazi, Miranda Tilton\n\n\n\n\nwoRldnews\n\n\nEshita Zaman, Coskun Erden, Alex Cleveringa\n\n\n\n\nStock market prediction\n\n\nGhazal Shah Abadi, Parastoo Akbari,\n\n\n\n\nstatfoRdummies\n\n\nJoe Zemmels, Charlotte Roiger, Eryn Blagg, Gulzina Kuttubekova\n\n\n\n\nredres - Redress Your Mixed Model Assumptions\n\n\nKatherine Goode, Yonghui Huo, Jing Zhao, Kellie McClernon, Yudi Zhang\n\n\n\n\npitcheR\n\n\nKieran Liming, Robert Castaneda, Gabrielle Collins, Abigail Collins, Abraham Adokwei\n\n\n\n\nAn R package to visualize U.S. Census Data\n\n\nLin Quan, Zirou Zhou, Xiaolan Wan\n\n\n\n\nDealing with the current weather data\n\n\nQing He, Jing Hou, Jing Li, Yuchen Wang, Ying Zheng\n\n\n\n\nBuild modularized shiny app with ggpaintr\n\n\nWangqian Ju, Zhili Qiao, Jinji Pang\n\n\n\n\nReal Estate Marketing Analysis\n\n\nXiyuan Sun, Steven Harms, Oscar Aguilar, Gani Agadilov\n\n\n\n\nPost Selection Inference of Estimation from Penalized Matrix Decomposition\n\n\nYunhui Qi\n\n\n\n\nSentiAnalyzer - Sentiment analysis for consumer review\n\n\nZahra Khoshmanesh, Atousa Zarindast, Joshua Budi\n\n\n\n\nThe ggfun package\n\n\nZhenzhen Chen, Yawei Ge, Weiquan Luo\n\n\n\n\nAn R package to visualize US Census data\n\n\nZirou Zhou, Lin Quan, Xiaolan Wan\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "projects/project-rubric.html",
    "href": "projects/project-rubric.html",
    "title": "Project Rubric",
    "section": "",
    "text": "For the final project you are asked to create an R package. You are free to choose package functionality, but there should be\n\na minimum of five functions with a coherent theme,\na shiny app show-casing some of the functionality\na website for the package\na README page with installation instructions and basic demonstration of functionality\nevidence of testing the functionality\n8-10 page report detailing your work. This report should be written as a package vignette, included in your package’s documentation.\n\nYou are asked to present your work as a team in one of the speaking slots during dead week and finals week. Each team member is supposed to present for about 5 mins."
  },
  {
    "objectID": "projects/project-rubric.html#grading-rubric",
    "href": "projects/project-rubric.html#grading-rubric",
    "title": "Project Rubric",
    "section": "Grading Rubric:",
    "text": "Grading Rubric:\n\nPackage (40 points)\n\n\n\n\n\n\n\n\n\n\n\nCriteria\nPoints\nOutstanding (> 90%)\nGood (70-90%)\nNeeds work (50-70%)\nNeeds a lot of work (< 50%)\n\n\n\n\nPackage Topic\n10\nPackage is useful and coherent, addressing a well-defined problem.\nPackage is useful, but may have some implementation gaps or lack a coherent solution to the main problem the package addresses\nPackage is incoherent, including functions not aimed at addressing the stated issue\nPackage does not address a single problem or consists of seemingly random functions\n\n\nBuilds and Installs\n5\nPackage builds and installs correctly.\nPackage builds and installs correctly with only minor modifications.\nPackage builds and installs correctly with major modifications.\nPackage does not build and install correctly during the grading process.\n\n\nDocumentation\n5\nEach exported function is well documented, with examples detailing its use. Package uses pkgdown to present documentation to the reader.\nMost functions are well documented, but gaps in examples or full documentation exist. Documentation on pkgdown exists, but may have some deficiencies or be slightly out of date.\nSome functions are documented, but large gaps in documentation and examples exist, making it difficult to understand how to use the package functions. Package documentation may exist, but pkgdown is not used to make the documentation easily available on the web.\nThe package is poorly documented, or existing documentation is not easy to read and understand. No attempt to use pkgdown to make documentation available online.\n\n\nTesting\n5\nPackage has over 90% test coverage with meaningful tests. Functions are structured to do only one thing to make testing efficient. Package integrated with TravisCI and Codecov.io, and test coverage and status are reported in the package README.\nPackage has over 80% test coverage. Tests cover some important functionality but unnecessary tests exist and/or tests miss important areas of coverage. Functions may not be written to perform only one task. Travis integration and Codecov.io integration are set up but may not be working consistently.\nPackage has less than 80% test coverage with meaningful tests. Functions are not well structured for testing. Travis CI or Codecov.io integration is not working.\nPackage has minimal or no useful testing. No attempt to make use of Travis CI or Codecov.io to show package testing status.\n\n\nPackage Data\n5\nPackage includes some data which is useful for demonstrating the package functions. Data is well documented and used in the examples and the package vignette.\nPackage includes data used to demonstrate the package, but documentation is lacking and/or the data is not integrated into examples and the package vignette. Package may include some data which is not properly documented or necessary to the package’s functions\nPackage includes data but it is not well documented. Examples and vignettes may use data which is not included in the package and is also not explained or documented well.\nPackage does not include data or includes data with no documentation or explanation\n\n\nSpelling\n5\nPackage and documentation is spell-checked\nSome spelling errors are present but writing is mostly coherent\nPackage documentation and function comments have noticable lapses in spelling and/or grammar.\nPackage documentation is poorly spell-checked, has incomprehensible grammar, or is non-existent\n\n\nDependencies/Imports\n3\nPackage has dependencies and imports that make sense\nPackage has a few extra imported packages, or packages which are listed as dependencies that could be imported instead\nPackage is missing imports or dependencies\nNo attempt has been made to list imports and dependencies in a coherent fashion\n\n\nExported functions\n2\nOnly functions which are intended to be shown to the user are exported; all exported functions have examples and supporting documentation\nSome attention has been given to only exporting functions intended for user use, but there are some issues with the implementation\nAll functions are exported, or functions that are intended for user use have not been exported\nNo attention has been paid to which functions should be imported or exported\n\n\n\n\n\nShiny App (30 Points)\n\n\n\n\n\n\n\n\n\n\n\nCriteria\nPoints\nOutstanding (> 90%)\nGood (70-90%)\nNeeds work (50-70%)\nNeeds a lot of work (< 50%)\n\n\n\n\nInstallation\n10\nInstallation instructions are complete, shinyApp loads and runs without problems\nminor things have to be taken care of before the app runs or installation instructions are missing crucial information\nminor things have to be taken care of before the app runs and installation instructions are missing crucial information\nmajor steps need to be taken to ensure that the app runs, installation instructions are missing or not helpful\n\n\nFunctionality\n10\nThe shiny app provides access to an important piece of the package and works smoothly.\nThe app demonstrates a minor aspect of the package. The app stops working intermittently.\n\n\n\n\nComplexity\n10\nMultiple interactive UI elements are implemented\n\n\nThe app is quite simplistic.\n\n\n\n\n\nVignette (30 Points)\n\n\n\n\n\n\n\n\n\n\n\nCriteria\nPoints\nOutstanding (> 90%)\nGood (70-90%)\nNeeds work (50-70%)\nNeeds a lot of work (< 50%)\n\n\n\n\nUses pkgdown and github /docs\n8\nReport is formatted as a vignette using pkgdown and integrated into the github repository using the /docs folder.\nReport can be generated reproducibly and is located in the /docs folder, but does not use pkgdown or is not connected to the package’s github.io site\nReport is not reproducible or not located in the correct location\nReport consists of loosely connected pieces\n\n\nContent\n7\nReport describes the use of the package and package functions, unifying the separate functions included in the package to solve a single problem or task. Each major function is included in the vignette, with substantial additional text explaining the use of the function to solve a real-world problem.\nReport describes the use of the package and package functions, but does not present the package as a unified entity aimed at a specific single task. Some descriptions are sparse; the vignette may leave the reader with additional questions that are not completely answered. Code examples may only cover specific use cases instead of a more general approach\nVignette does not include all major functions, examples do not demonstrate major package functionality, and additional textual descriptions may be sparse or absent in places.\nVignette does not demonstrate major package functionality, and only includes minimal text description of the package’s capabilities.\n\n\nGraphs and Tables\n10\nGraphs and tables included in the package vignette are designed for a specific purpose and are carefully constructed to communicate with the reader. Each graph or table illustrates one point or package feature. Formatting and styling show that some optimization and care went into the creation of the table or graph\nGraphs and tables are well constructed but may have minor flaws or poor labeling decisions.\nMany graphs or tables have minor problems, or may be poorly chosen or redundant.\nGraphs and tables do not support questions and findings. Major problems with presentation - graphs may be missing or fail to generate.\n\n\nText\n5\nEnglish is polished, concise, and clear. No grammar or spelling mistakes\nClear and concise, but not elegant. Some spelling/grammar errors\nReadable, but unnecessarily verbose or lacking in detail. Many errors that compromise readability.\nBarely readable, with many spelling and grammar errors. No evidence of any proof-reading."
  },
  {
    "objectID": "labs.html",
    "href": "labs.html",
    "title": "Labs",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\nTitle\n\n\nAuthor\n\n\n\n\n\n\nLab 4 - Adding a shiny app\n\n\n\n\n\n\nLab 3 - Making a package\n\n\n\n\n\n\nLab 2 - Getting that data\n\n\n\n\n\n\nLab 1 - Funny File Formats\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "Projects",
    "section": "",
    "text": "You can have a look at the scope of some projects from 2019 and 2022\nThis class requires a presentation and a report for a final project. Final projects are team-based with teams consisting of 3 to 5 members.\nFor the final project you are asked to create an R package. You are free to choose package functionality, but there should be\n\na minimum of five functions with a coherent theme,\na shiny app show-casing some of the functionality\na website for the package\na README page with installation instructions and basic demonstration of functionality\nevidence of testing the functionality\n8-10 page report detailing your work. This report should be written as a package vignette, included in your package’s documentation.\n\nYou are asked to present your work as a team in one of the speaking slots during dead week and finals week. Each team member is supposed to present for about 5 mins.\nThere are several stages to the project. Only the last two stages are graded. All other stages are not graded. You should use them as an opportunity to get feedback. For stages 1-3 feedback will be given as soon as you submit your contribution, i.e. you don’t have to wait until after Spring break to submit your project idea.\n\nStage 1 (by Mar 10, not graded): Identify team and topic\nStage 2 (by Apr 14, not graded): Functional Package\nStage 3 (by Apr 28, not graded): Testing and Documentation\n\nAbstract and Presentation slots\n\nStage 4: Presentation (Dead week and Finals, graded)\nStage 5 (May 9th, graded): Package submission to canvas (Finals week)\n\nWe will be using the following project rubric for evaluating the final submission. Presentations are peer-evaluated. Feedback will be given in this form."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Data Technologies for Statistical Analysis",
    "section": "",
    "text": "TR 2:10 - 3:25 pm, Lagomarcino 1445, see zoom link in Canvas\nOffice Hours: by appointment\nInstructor: Heike Hofmann, hofmann at iastate dot edu\nTA: Ganesh Krishnan, ganeshk at iastate dot edu\n\n\n\nSupposedly. Source"
  },
  {
    "objectID": "index.html#course-description",
    "href": "index.html#course-description",
    "title": "Data Technologies for Statistical Analysis",
    "section": "Course description:",
    "text": "Course description:\nNot all data lives in nice, clean spreadsheets, not all data fits in a computer’s main memory. As statisticians we cannot always rely on other people and sciences to get the data into formats that we can deal with: we will discuss aspects of statistical computing as they are relevant for data analysis. Read and work with data in different formats: flat files, databases, web technologies. Elements of literate programming help us with making our workflow transparent and analyses reproducible. We will discuss communication of results in form of R packages and interactive web applications."
  },
  {
    "objectID": "index.html#learn-how-to",
    "href": "index.html#learn-how-to",
    "title": "Data Technologies for Statistical Analysis",
    "section": "Learn how to…",
    "text": "Learn how to…\n\nread and combine data from flat files, SQL database, binary netCDF, and making use of web technologies as data source.\ncompute with data.\nclean the data, check the quality, impute missing values.\nwrite efficient and reproducible code so others are able to replicate the analysis.\ndevelop software, individually and collaboratively, debug, profile and package R code.\nexperiment with event driven programming to build an interactive graphic, and a GUI.\npull data together to solve a contemporary problem."
  },
  {
    "objectID": "index.html#more-info",
    "href": "index.html#more-info",
    "title": "Data Technologies for Statistical Analysis",
    "section": "More info…",
    "text": "More info…\nUse the navigation bar above!\nThe course organization on GitHub: https://github.com/stat585-at-ISU\nRepo that creates this website: https://github.com/Stat585-at-ISU/Stat585-at-ISU.github.io"
  },
  {
    "objectID": "blog-2023/Blog-5-submissions/xyzyc/index.html",
    "href": "blog-2023/Blog-5-submissions/xyzyc/index.html",
    "title": "Keep track of results and data",
    "section": "",
    "text": "Frontmatter check"
  },
  {
    "objectID": "blog-2023/Blog-5-submissions/xyzyc/index.html#prompt",
    "href": "blog-2023/Blog-5-submissions/xyzyc/index.html#prompt",
    "title": "Keep track of results and data",
    "section": "Prompt:",
    "text": "Prompt:\nIn May 2015 Science retracted - without consent of the lead author - a paper on how canvassers can sway people’s opinions about gay marriage, see also: http://www.sciencemag.org/news/2015/05/science-retracts-gay-marriage-paper-without-agreement-lead-author-lacour The Science Editor-in-Chief cited as reasons for the retraction that the original survey data was not made available for independent reproduction of results, that survey incentives were misrepresented and that statements made about sponsorships turned out to be incorrect. The investigation resulting in the retraction was triggered by two Berkeley grad students who attempted to replicate the study and discovered that the data must have been faked.\nFiveThirtyEight has published an article with more details on the two Berkeley students’ work.\nMalicious changes to the data such as in the LaCour case are hard to prevent, but more rigorous checks should be built into the scientific publishing system. All too often papers have to be retracted for unintended reasons. Retraction Watch is a data base that keeps track of retracted papers (see the related Science magazine publication).\nRead the paper Ten Simple Rules for Reproducible Computational Research by Sandve et al.\nWrite a blog post addressing the questions:\n\nPick one of the papers from Retraction Watch that were retracted because of errors in the paper (you might want to pick a paper from the set of featured papers, because there are usually more details available). Describe what went wrong. Would any of the rules by Sandve et al. have helped in this situation?\n\nI picked a research article “Optimization Method of Sports Service Network Node Layout Based on Network Communication” in social science area. The reasons for retraction are concerns about data, image and unreliable data.\nThe journal “Security and Communication Networks” found out that a graph that was unrelated to this paper was submitted to the journal, which had appeared in several other submissions, all with text claiming to have generated the graph. This raised the concerns about the authenticity of data.\nAfter communication, the authors claimed they had duplicated the graph by accident, but could not provide their raw data or further evidence.\nThe rules “1. For Every Result, Keep Track of How It Was Produced”, and “7. Always Store Raw Data behind Plots” can be helpful in this case. If there is a clean record of data, code and generated files, this kind of mistake may be avoided. Even if a submission mistake happens, there could be evidence for the correctness of the results.\n\nAfter reading the paper by Sandve et al. describe which rule you are most likely to follow and why, and which rule you find the hardest to follow and will likely not (be able to) follow in your future projects.\n\nMost likely to follow: Always Store Raw Data behind Plots. I store some results as .RData files and put appropriate names to indicated what plots/tables they generate. This avoids re-running the code and allows me to check back easily. I should use this along with version control of the code. Actually, I think I should store intermediate results too. Sometimes I write too many steps as a single function and only output the final result. This makes it hard to check the behavior of the program.\nHard to follow: Archive the Exact Versions of All External Programs Used. I don’t really know how to do this except recording the name and version of the program."
  },
  {
    "objectID": "blog-2023/Blog-5-submissions/xyzyc/index.html#submission",
    "href": "blog-2023/Blog-5-submissions/xyzyc/index.html#submission",
    "title": "Keep track of results and data",
    "section": "Submission",
    "text": "Submission\n\nPush your changes to your repository.\nYou are ready to call it good, once all your github actions pass without an error. You can check on that by selecting ‘Actions’ on the menu and ensure that the last item has a green checkmark. The action for this repository checks the yaml of your contribution for the existence of the author name, a title, date and categories. Don’t forget the space after the colon! Once the action passes, the badge along the top will also change its color accordingly. As of right now, the status for the YAML front matter is:\n\n\n\n\nFrontmatter check\n\n\n---\nauthor: \"Your Name\"\ntitle: \"Specify your title\"\ndate: \"2023-02-23\"\ncategories: \"Ethics and Reproducibility...\"\n---"
  },
  {
    "objectID": "blog-2023/Blog-5-submissions/kundan7kumar/index.html",
    "href": "blog-2023/Blog-5-submissions/kundan7kumar/index.html",
    "title": "Ethics and Reproducibility",
    "section": "",
    "text": "Frontmatter check"
  },
  {
    "objectID": "blog-2023/Blog-5-submissions/kundan7kumar/index.html#prompt",
    "href": "blog-2023/Blog-5-submissions/kundan7kumar/index.html#prompt",
    "title": "Ethics and Reproducibility",
    "section": "Prompt:",
    "text": "Prompt:\nIn May 2015 Science retracted - without consent of the lead author - a paper on how canvassers can sway people’s opinions about gay marriage, see also: http://www.sciencemag.org/news/2015/05/science-retracts-gay-marriage-paper-without-agreement-lead-author-lacour The Science Editor-in-Chief cited as reasons for the retraction that the original survey data was not made available for independent reproduction of results, that survey incentives were misrepresented and that statements made about sponsorships turned out to be incorrect. The investigation resulting in the retraction was triggered by two Berkeley grad students who attempted to replicate the study and discovered that the data must have been faked.\nFiveThirtyEight has published an article with more details on the two Berkeley students’ work.\nMalicious changes to the data such as in the LaCour case are hard to prevent, but more rigorous checks should be built into the scientific publishing system. All too often papers have to be retracted for unintended reasons. Retraction Watch is a data base that keeps track of retracted papers (see the related Science magazine publication).\nRead the paper Ten Simple Rules for Reproducible Computational Research by Sandve et al.\nWrite a blog post addressing the questions:\n\nPick one of the papers from Retraction Watch that were retracted because of errors in the paper (you might want to pick a paper from the set of featured papers, because there are usually more details available). Describe what went wrong. Would any of the rules by Sandve et al. have helped in this situation?\n\nSolution:\nI chose Stimulus-triggered fate conversion of somatic cells into pluripotency, which was retracted due to discovery of multiple instances of image manipulation and duplication. The author duplicated some of the images within the experiment, used images from different experiments, and presented them as if they were from the same experiment. This will be the main concerns about reproducibility and findings of the results.\nI think if they followed “Sandve et al” ten rules for reproducible computational research Paper, I could help them in preventing the issues in the paper. For e.g. Rule 5: “Record all intermediate results, when possible in standardized formats” would have helped ensure that any changes to images were documented and justified. Also Rule 2:”Avoid Manual Data Manipulation Steps”, it would have ensure any changes in the images and image directory were documented. I think by following the ten rules, such retracted would have not happened.\nReferences: https://www.researchgate.net/publication/259984904_Stimulus-triggered_fate_conversion_of_somatic_cells_into_pluripotency\n\nAfter reading the paper by Sandve et al. describe which rule you are most likely to follow and why, and which rule you find the hardest to follow and will likely not (be able to) follow in your future projects.\n\nSolution:\n“Sandve et al” presented ten rules for reproducible computational research. I find all of them are quite interesting, but I like Rule 1: For Every Result, Keep Track of How It Was Produced ,I think this rule is very important as it will help in of keeping a detailed record of every step taken during the research process, including data cleaning, preprocessing, and analysis. So, keeping track how every result is produced, it becomes easier to reproduce the results and help further in ensuring the validity of the research outputs. Moreover, second most rules I like is Rule 4: Version Control All Custom Scripts, as it will help in not losing any work and keep track of all rough work of each steps of the code during research development.\nHowever, the hardest rule, I find to follow is Rule 9: Connect Textual Statements to Underlying Results. It is not necessary to have access of all the tools and resources specially when we are dealing with huge datasets or some data only belong to certain organization, so it will difficult to reproduce the results. It is difficult to follow in practice due to the time and resource requirements, technical difficulties, and personal concerns of organizations. However, this rule is very nice and help to increase transparency and reliability of the work.\nI think that this rule is quite difficult to follow in my current setting of my research."
  },
  {
    "objectID": "blog-2023/Blog-5-submissions/kundan7kumar/index.html#submission",
    "href": "blog-2023/Blog-5-submissions/kundan7kumar/index.html#submission",
    "title": "Ethics and Reproducibility",
    "section": "Submission",
    "text": "Submission\n\nPush your changes to your repository.\nYou are ready to call it good, once all your github actions pass without an error. You can check on that by selecting ‘Actions’ on the menu and ensure that the last item has a green checkmark. The action for this repository checks the yaml of your contribution for the existence of the author name, a title, date and categories. Don’t forget the space after the colon! Once the action passes, the badge along the top will also change its color accordingly. As of right now, the status for the YAML front matter is:\n\n\n\n\nFrontmatter check\n\n\n---\nauthor: \"Kundan Kumar\"\ntitle: \"Ethics and Reproducibility\"\ndate: \"2023-02-23\"\ncategories: \"Ethics and Reproducibility...\"\n---"
  },
  {
    "objectID": "blog-2023/Blog-5-submissions/anyeshar/index.html",
    "href": "blog-2023/Blog-5-submissions/anyeshar/index.html",
    "title": "Reading about COVID Calculators",
    "section": "",
    "text": "Frontmatter check"
  },
  {
    "objectID": "blog-2023/Blog-5-submissions/anyeshar/index.html#prompt",
    "href": "blog-2023/Blog-5-submissions/anyeshar/index.html#prompt",
    "title": "Reading about COVID Calculators",
    "section": "Prompt:",
    "text": "Prompt:\nIn May 2015 Science retracted - without consent of the lead author - a paper on how canvassers can sway people’s opinions about gay marriage, see also: http://www.sciencemag.org/news/2015/05/science-retracts-gay-marriage-paper-without-agreement-lead-author-lacour The Science Editor-in-Chief cited as reasons for the retraction that the original survey data was not made available for independent reproduction of results, that survey incentives were misrepresented and that statements made about sponsorships turned out to be incorrect. The investigation resulting in the retraction was triggered by two Berkeley grad students who attempted to replicate the study and discovered that the data must have been faked.\nFiveThirtyEight has published an article with more details on the two Berkeley students’ work.\nMalicious changes to the data such as in the LaCour case are hard to prevent, but more rigorous checks should be built into the scientific publishing system. All too often papers have to be retracted for unintended reasons. Retraction Watch is a data base that keeps track of retracted papers (see the related Science magazine publication).\nRead the paper Ten Simple Rules for Reproducible Computational Research by Sandve et al.\nWrite a blog post addressing the questions:\n\nPick one of the papers from Retraction Watch that were retracted because of errors in the paper (you might want to pick a paper from the set of featured papers, because there are usually more details available). Describe what went wrong. Would any of the rules by Sandve et al. have helped in this situation?\n\nThe reason COVID-19 admissions calculators by Victor Grech was retracted was because they based their paper on very early data and drew incorrect conclusions. The paper seems to throw around numbers without really putting thought into where they are coming from. This author could implement rule 7 and 10. We know they got the data from the World Health Organization, but do not know what formulas they are using to create this “calculator”.\n\nAfter reading the paper by Sandve et al. describe which rule you are most likely to follow and why, and which rule you find the hardest to follow and will likely not (be able to) follow in your future projects.\n\nRule 1: For Every Result, Keep Track of How It Was Produced is probably the rule I am most likely to follow. I have found it is not only helpful for reproducibility, but also for recording for myself. Knowing how I got things makes it 10 times easier when I am going back and writing about them. The rule that is hardest to follow is Rule 2: Avoid Manual Data Manipulation Steps. A lot of what we do is data cleaning and manipulation. I do not think I can avoid doing this in my research."
  },
  {
    "objectID": "blog-2023/Blog-5-submissions/anyeshar/index.html#submission",
    "href": "blog-2023/Blog-5-submissions/anyeshar/index.html#submission",
    "title": "Reading about COVID Calculators",
    "section": "Submission",
    "text": "Submission\n\nPush your changes to your repository.\nYou are ready to call it good, once all your github actions pass without an error. You can check on that by selecting ‘Actions’ on the menu and ensure that the last item has a green checkmark. The action for this repository checks the yaml of your contribution for the existence of the author name, a title, date and categories. Don’t forget the space after the colon! Once the action passes, the badge along the top will also change its color accordingly. As of right now, the status for the YAML front matter is:"
  },
  {
    "objectID": "blog-2023/Blog-5-submissions/Landon-Getting/index.html",
    "href": "blog-2023/Blog-5-submissions/Landon-Getting/index.html",
    "title": "TREEFINDER - Leveraging Research Software for Political Agendas",
    "section": "",
    "text": "Frontmatter check"
  },
  {
    "objectID": "blog-2023/Blog-5-submissions/Landon-Getting/index.html#prompt",
    "href": "blog-2023/Blog-5-submissions/Landon-Getting/index.html#prompt",
    "title": "TREEFINDER - Leveraging Research Software for Political Agendas",
    "section": "Prompt:",
    "text": "Prompt:\nIn May 2015 Science retracted - without consent of the lead author - a paper on how canvassers can sway people’s opinions about gay marriage, see also: http://www.sciencemag.org/news/2015/05/science-retracts-gay-marriage-paper-without-agreement-lead-author-lacour The Science Editor-in-Chief cited as reasons for the retraction that the original survey data was not made available for independent reproduction of results, that survey incentives were misrepresented and that statements made about sponsorships turned out to be incorrect. The investigation resulting in the retraction was triggered by two Berkeley grad students who attempted to replicate the study and discovered that the data must have been faked.\nFiveThirtyEight has published an article with more details on the two Berkeley students’ work.\nMalicious changes to the data such as in the LaCour case are hard to prevent, but more rigorous checks should be built into the scientific publishing system. All too often papers have to be retracted for unintended reasons. Retraction Watch is a data base that keeps track of retracted papers (see the related Science magazine publication).\nRead the paper Ten Simple Rules for Reproducible Computational Research by Sandve et al.\nWrite a blog post addressing the questions:\n\nPick one of the papers from Retraction Watch that were retracted because of errors in the paper (you might want to pick a paper from the set of featured papers, because there are usually more details available). Describe what went wrong. Would any of the rules by Sandve et al. have helped in this situation?\n\nI choose to examine ‘TREEFINDER: a powerful graphical analysis environment for molecular phylogenetics’ which is a collaboration between 3 authors: Jobb, Haeseler, and Strimmer [1]. Although this paper remains of Retraction Watch’s ’Top 10 most highly cited retracted papers’, the reason for its retraction was unexpected. The first author, Gangolf Jobb, decided to limit the software license geographically which made the software unavailable for some scientists [2]. According to an article in the journal Science, Jobb specifically excluded European countries which immigration policies that he disagreed with [3].\nThis action violated the rules of the journal and therefore the article was retracted. Haeseler and Strimmer, the other two authors, were unable to influence the software licensing changes and agreed with the retraction. In a paper from the University of Nebraska evaluating the Retraction Watch list, researchers determined the results to be valid despite the retraction [4].\nIdeally, all of the authors would have subscribed to Rule 10 from Sandve et al and provided public access to scripts, runs, and results. However, since one of the authors decided not to adhere to this rule, it is difficult to determine other rules which may have prevented the retraction. Depending on the legal ownership of the software, the other authors could have followed Rule 3 and released an older version of the software for public use.\n\nAfter reading the paper by Sandve et al. describe which rule you are most likely to follow and why, and which rule you find the hardest to follow and will likely not (be able to) follow in your future projects.\n\nI am most likely to follow Rule 7 and store the raw data utilized for plots. As described by Sandve, this can be naturally followed if utilizing a system like R to generate visuals which I plan to utilize. I believe Rule 3 may be the hardest to follow. Even if I archive the exact versions of all external programs used in a system like CyBox, the university may move to a new system in a few years and the programs may be lost. Setting up a contingency plan for storing files and programs in the long term may be difficult and even unnecessary if the pace of current research surpasses my work prior to degradation of a short term plan. However, I will follow the rules to the best of my ability!"
  },
  {
    "objectID": "blog-2023/Blog-5-submissions/Landon-Getting/index.html#citations",
    "href": "blog-2023/Blog-5-submissions/Landon-Getting/index.html#citations",
    "title": "TREEFINDER - Leveraging Research Software for Political Agendas",
    "section": "Citations",
    "text": "Citations\n[1] Jobb, G., von Haeseler, A. & Strimmer, K. RETRACTED ARTICLE: TREEFINDER: a powerful graphical analysis environment for molecular phylogenetics. BMC Evol Biol 4, 18 (2004). https://doi.org/10.1186/1471-2148-4-18\n[2] https://bmcecolevol.biomedcentral.com/articles/10.1186/s12862-015-0513-z\n[3] https://www.science.org/content/article/paper-retracted-after-scientist-bans-use-his-software-countries-welcome-refugees\n[4] Jan, Rosy; Bano, Shohar; Syed, Ikhlaq ur Rehman; and Mehraj, Midhat, “Context Analysis of Top Seven Retracted Articles: ShouldRetraction Watch Revisit the List?” (2018). Library Philosophy and Practice (e-journal). 2016."
  },
  {
    "objectID": "blog-2023/Blog-5-submissions/Hiiiua/index.html",
    "href": "blog-2023/Blog-5-submissions/Hiiiua/index.html",
    "title": "Retraction",
    "section": "",
    "text": "Frontmatter check"
  },
  {
    "objectID": "blog-2023/Blog-5-submissions/Hiiiua/index.html#prompt",
    "href": "blog-2023/Blog-5-submissions/Hiiiua/index.html#prompt",
    "title": "Retraction",
    "section": "Prompt:",
    "text": "Prompt:\nIn May 2015 Science retracted - without consent of the lead author - a paper on how canvassers can sway people’s opinions about gay marriage, see also: http://www.sciencemag.org/news/2015/05/science-retracts-gay-marriage-paper-without-agreement-lead-author-lacour The Science Editor-in-Chief cited as reasons for the retraction that the original survey data was not made available for independent reproduction of results, that survey incentives were misrepresented and that statements made about sponsorships turned out to be incorrect. The investigation resulting in the retraction was triggered by two Berkeley grad students who attempted to replicate the study and discovered that the data must have been faked.\nFiveThirtyEight has published an article with more details on the two Berkeley students’ work.\nMalicious changes to the data such as in the LaCour case are hard to prevent, but more rigorous checks should be built into the scientific publishing system. All too often papers have to be retracted for unintended reasons. Retraction Watch is a data base that keeps track of retracted papers (see the related Science magazine publication).\nRead the paper Ten Simple Rules for Reproducible Computational Research by Sandve et al.\nWrite a blog post addressing the questions:\n\nPick one of the papers from Retraction Watch that were retracted because of errors in the paper (you might want to pick a paper from the set of featured papers, because there are usually more details available). Describe what went wrong. Would any of the rules by Sandve et al. have helped in this situation?\nThe article The Antidiabetic Metformin as an Adjunct to Antidepressants in Patients with Major Depressive Disorder: A Proof-of-Concept, Randomized, Double-Blind, Placebo-Controlled Trial has been distracted. Data in this article have oddities, like uncommon exactly differed by one of the numbers of patients experienced adverse event. The data is also suspicious in the way of glaring similarity to the numbers in a clinic trial of another add-on drug published by the same author.\n\nI think the first two basic rules from Sandve et al might help.\nRule 1: For every result, keep track of how it was produced. and Rule 2: Avoid manual data manipulation steps.\nFor the author of the retracted article, being honest about the source of the data is the key of avoiding such situation. Even though the data looked like highly impossible and coincidental, it still validate the experiment if it’s not fallacy in how it’s produced. If the real data is not idea, stay away from manipulation and reporting what they have.\n\nAfter reading the paper by Sandve et al. describe which rule you are most likely to follow and why, and which rule you find the hardest to follow and will likely not (be able to) follow in your future projects.\nRule 1 and 2 are the most likely to follow rules for me, because they are the foundations of data analysis. I would also follow rule 4. I find tracking version by Git is easy and helps reducing time if I need to look back to whatever I did previously. Rule 7 and 10 are also important: including raw data with plots and open source to public, getting ready to be inspected are important for result reproduction.\n\nI do find rule 5 hard to follow. Recording all the intermediate results and possible in standardized formats are time costly and storage costly, especially there are times finding intermediate results are flaw and deficient. Rule 6 is hard to follow in terms of habit. In a consistent analysis, it’s a normal and necessary to set random seed to keep track of the results and to make sure they are done in the correct way. So it is hard to remember all the steps with randomness, but this is a good reminder. Rule 9 is hard to follow because it’s an advance rule of rule 5.If I can follow rule 5 strictly, I would like to take some notes of textual interpretation, but details would be too time consuming."
  },
  {
    "objectID": "blog-2023/Blog-5-submissions/Hiiiua/index.html#submission",
    "href": "blog-2023/Blog-5-submissions/Hiiiua/index.html#submission",
    "title": "Retraction",
    "section": "Submission",
    "text": "Submission\n\nPush your changes to your repository.\nYou are ready to call it good, once all your github actions pass without an error. You can check on that by selecting ‘Actions’ on the menu and ensure that the last item has a green checkmark. The action for this repository checks the yaml of your contribution for the existence of the author name, a title, date and categories. Don’t forget the space after the colon! Once the action passes, the badge along the top will also change its color accordingly. As of right now, the status for the YAML front matter is:\n\n\n\n\nFrontmatter check\n\n\n---\nauthor: \"Your Name\"\ntitle: \"Specify your title\"\ndate: \"2023-02-23\"\ncategories: \"Ethics and Reproducibility...\"\n---"
  },
  {
    "objectID": "blog-2023/Blog-5-submissions/charlestbonk/index.html",
    "href": "blog-2023/Blog-5-submissions/charlestbonk/index.html",
    "title": "UC Berkeley’s Ninov 2.0",
    "section": "",
    "text": "Frontmatter check"
  },
  {
    "objectID": "blog-2023/Blog-5-submissions/charlestbonk/index.html#prompt",
    "href": "blog-2023/Blog-5-submissions/charlestbonk/index.html#prompt",
    "title": "UC Berkeley’s Ninov 2.0",
    "section": "Prompt:",
    "text": "Prompt:\nIn May 2015 Science retracted - without consent of the lead author - a paper on how canvassers can sway people’s opinions about gay marriage, see also: http://www.sciencemag.org/news/2015/05/science-retracts-gay-marriage-paper-without-agreement-lead-author-lacour The Science Editor-in-Chief cited as reasons for the retraction that the original survey data was not made available for independent reproduction of results, that survey incentives were misrepresented and that statements made about sponsorships turned out to be incorrect. The investigation resulting in the retraction was triggered by two Berkeley grad students who attempted to replicate the study and discovered that the data must have been faked.\nFiveThirtyEight has published an article with more details on the two Berkeley students’ work.\nMalicious changes to the data such as in the LaCour case are hard to prevent, but more rigorous checks should be built into the scientific publishing system. All too often papers have to be retracted for unintended reasons. Retraction Watch is a data base that keeps track of retracted papers (see the related Science magazine publication).\nRead the paper Ten Simple Rules for Reproducible Computational Research by Sandve et al.\nWrite a blog post addressing the questions:\n\nPick one of the papers from Retraction Watch that were retracted because of errors in the paper (you might want to pick a paper from the set of featured papers, because there are usually more details available). Describe what went wrong. Would any of the rules by Sandve et al. have helped in this situation?\n\nThe Retraction Watch article I chose to investigate is Exclusive: Deepfake pioneer to lose two papers after misconduct finding of faked data for two main reasons: 1) a commentor uses “imho” and imho, “imho” should be used more and 2) the irony of it all. Hao Li worked at UC Berkeley, which is known for Victor Ninov, a chemist who faked discovering Element 118 “Ninovium” (now known as Oganesson for the man who actually discovered the element) and ruined his entire career. If Li genuinely did not fake his data, he should have learned from the past and did more to ensure that his data was reproducible, and put more effort into letting people know the simulations were pre-constructed in the event of communication errors (like I don’t know, maybe slapping a watermark on the simulation that said “Hey, this is pre-constructed, we are having some issues rn with communicating”).\nThe steps he should have taken from Sandve et al. would be 1, 7, and 8. For “1 : For Every Result, Keep Track of How It Was Produced”, he could have simply included a log and held himself accountable for acknowledging that the simulations were pre-generated, rather than hiding that fact. Yes, he would have looked a little silly on stage admitting there was a communication bug, but less silly than what he looks now. “7 : Always Store Raw Data behind Plots” applies less to plots and more to the simulations. If the simulation was supposed to be real, show that it is real. That may not be always feasible with the magnitude of arrays needed to contain data for the entire image and simulation, but having it somewhat accessible and visible rather than hidden behind the curtain would have made him more creditable. Finally, “8 : Generate Hierarchical Analysis Output, Allowing Layers of Increasing Detail to Be Inspected” could be easily fixed by not including this debug output in the first place. Make sure that it works and then make sure that it works again. 10 times. And then, know how to fix the communication errors if they show up. He shouldn’t have banked on his debug code being a good safety net, assuming that it really was debug code.\nIdeally, he would have made his script public, that way everyone could see it, work with it, and help debug if need be, but also the code was probably extremely expensive, so I do understand not following Rule 10.\n\nAfter reading the paper by Sandve et al. describe which rule you are most likely to follow and why, and which rule you find the hardest to follow and will likely not (be able to) follow in your future projects.\n\nI already follow “Rule 4: Version Control All Custom Scripts” and “Rule 6: For Analyses That Include Randomness, Note Underlying Random Seeds” religiously. If I can think of any reason as to push my code to Git, I will. Even if it may not need to exist there, I will push it to be safe and protect myself from fat-fingering myself into failure. With Rule 6, if I don’t need the data to be truly random, I will set a seed, and run it with a few different randomly generated, but constant seeds, that way I can show it works with different numbers than my nicely picked seed."
  },
  {
    "objectID": "blog-2023/Blog-5-submissions/charlestbonk/index.html#submission",
    "href": "blog-2023/Blog-5-submissions/charlestbonk/index.html#submission",
    "title": "UC Berkeley’s Ninov 2.0",
    "section": "Submission",
    "text": "Submission\n\nPush your changes to your repository.\nYou are ready to call it good, once all your github actions pass without an error. You can check on that by selecting ‘Actions’ on the menu and ensure that the last item has a green checkmark. The action for this repository checks the yaml of your contribution for the existence of the author name, a title, date and categories. Don’t forget the space after the colon! Once the action passes, the badge along the top will also change its color accordingly. As of right now, the status for the YAML front matter is:\n\n\n\n\nFrontmatter check\n\n\n---\nauthor: \"Your Name\"\ntitle: \"Specify your title\"\ndate: \"2023-02-23\"\ncategories: \"Ethics and Reproducibility...\"\n---"
  },
  {
    "objectID": "blog-2023/Blog-5-submissions/charchit/index.html",
    "href": "blog-2023/Blog-5-submissions/charchit/index.html",
    "title": "Retraction",
    "section": "",
    "text": "Frontmatter check"
  },
  {
    "objectID": "blog-2023/Blog-5-submissions/charchit/index.html#prompt",
    "href": "blog-2023/Blog-5-submissions/charchit/index.html#prompt",
    "title": "Retraction",
    "section": "Prompt:",
    "text": "Prompt:\nIn May 2015 Science retracted - without consent of the lead author - a paper on how canvassers can sway people’s opinions about gay marriage, see also: http://www.sciencemag.org/news/2015/05/science-retracts-gay-marriage-paper-without-agreement-lead-author-lacour The Science Editor-in-Chief cited as reasons for the retraction that the original survey data was not made available for independent reproduction of results, that survey incentives were misrepresented and that statements made about sponsorships turned out to be incorrect. The investigation resulting in the retraction was triggered by two Berkeley grad students who attempted to replicate the study and discovered that the data must have been faked.\nFiveThirtyEight has published an article with more details on the two Berkeley students’ work.\nMalicious changes to the data such as in the LaCour case are hard to prevent, but more rigorous checks should be built into the scientific publishing system. All too often papers have to be retracted for unintended reasons. Retraction Watch is a data base that keeps track of retracted papers (see the related Science magazine publication).\nRead the paper Ten Simple Rules for Reproducible Computational Research by Sandve et al.\nWrite a blog post addressing the questions:\n\nPick one of the papers from Retraction Watch that were retracted because of errors in the paper (you might want to pick a paper from the set of featured papers, because there are usually more details available). Describe what went wrong. Would any of the rules by Sandve et al. have helped in this situation?\n\nFrom the retraction watch, I picked the paper “Selective killing of cancer cells by a small molecule targeting the stress response to ROS” The retraction reason was the unavailability of original data for the figures. I was surprised that it was still published in the “nature” journal.\nThe rules by Sandve et al. will defintely help in this situation. Specially the Data related rules which this paper had mistakes in. Rule 2, Rule 5, and Rule 7 would have been the best thing to do for this paper.\n\nAfter reading the paper by Sandve et al. describe which rule you are most likely to follow and why, and which rule you find the hardest to follow and will likely not (be able to) follow in your future projects.\n\nI will most likely to follow Rule 4 which is version control. I did not know about how good the git version control is and after learning it in the class I am more likely to follow it and even like to have versions of my code.\nThe rule which might be hardest to follow for me is Rule 5, keeping track of intermediate results. We generate tons of data in my lab. Not everything is useful and some of the results are just useless. Keeping track of them takes time which could be better utilized in storing only the successful results. However, I will try to find a way to do this efficiently and make a process where I could dump all the data in cybox folder quickly."
  },
  {
    "objectID": "blog-2023/Blog-5-submissions/charchit/index.html#submission",
    "href": "blog-2023/Blog-5-submissions/charchit/index.html#submission",
    "title": "Retraction",
    "section": "Submission",
    "text": "Submission\n\nPush your changes to your repository.\nYou are ready to call it good, once all your github actions pass without an error. You can check on that by selecting ‘Actions’ on the menu and ensure that the last item has a green checkmark. The action for this repository checks the yaml of your contribution for the existence of the author name, a title, date and categories. Don’t forget the space after the colon! Once the action passes, the badge along the top will also change its color accordingly. As of right now, the status for the YAML front matter is:\n\n\n\n\nFrontmatter check\n\n\n---\nauthor: \"Your Name\"\ntitle: \"Specify your title\"\ndate: \"2023-02-23\"\ncategories: \"Ethics and Reproducibility...\"\n---"
  },
  {
    "objectID": "blog-2023/Blog-5-submissions/kellynay/index.html",
    "href": "blog-2023/Blog-5-submissions/kellynay/index.html",
    "title": "Rules for Research Reproducibility",
    "section": "",
    "text": "Frontmatter check"
  },
  {
    "objectID": "blog-2023/Blog-5-submissions/kellynay/index.html#prompt",
    "href": "blog-2023/Blog-5-submissions/kellynay/index.html#prompt",
    "title": "Rules for Research Reproducibility",
    "section": "Prompt:",
    "text": "Prompt:\nIn May 2015 Science retracted - without consent of the lead author - a paper on how canvassers can sway people’s opinions about gay marriage, see also: http://www.sciencemag.org/news/2015/05/science-retracts-gay-marriage-paper-without-agreement-lead-author-lacour The Science Editor-in-Chief cited as reasons for the retraction that the original survey data was not made available for independent reproduction of results, that survey incentives were misrepresented and that statements made about sponsorships turned out to be incorrect. The investigation resulting in the retraction was triggered by two Berkeley grad students who attempted to replicate the study and discovered that the data must have been faked.\nFiveThirtyEight has published an article with more details on the two Berkeley students’ work.\nMalicious changes to the data such as in the LaCour case are hard to prevent, but more rigorous checks should be built into the scientific publishing system. All too often papers have to be retracted for unintended reasons. Retraction Watch is a data base that keeps track of retracted papers (see the related Science magazine publication).\nRead the paper Ten Simple Rules for Reproducible Computational Research by Sandve et al.\nWrite a blog post addressing the questions:\n\nPick one of the papers from Retraction Watch that were retracted because of errors in the paper (you might want to pick a paper from the set of featured papers, because there are usually more details available). Describe what went wrong. Would any of the rules by Sandve et al. have helped in this situation?\n\nMy search in The Retraction Watch Database was a result of the following criteria: Subject (Environmental Science - ENV); Country (United States); Article Type (Research Article); Date (From 01/01/2020 to 01/01/2023).\nI selected the paper “Resilience Enhancing Characteristics of Land Eviction-Displaced Communities in Uganda’s Oil Exploration Areas,” published on 09/01/2017 (10.4236/ojapps.2017.79033). Retraction notice link: https://www.scirp.org/pdf/OJAppS_2017090815165454.pdf\nThe reasons for retraction include errors in analyses, data errors, and errors in results and/or conclusions. The retraction notice released by the publisher said the publication results were invalid overall.\nRule 1 by Sandve et al. - For every result, keep track of how it was produced - would be helpful in this situation because authors would have documented an analysis workflow that keeps track of all steps from getting the raw data up until reaching the results. The workflow analysis should include, at minimum, details on programs used, parameters investigated, and manual procedures, allowing the work to be reproduced in the future.\n\nAfter reading the paper by Sandve et al. describe which rule you are most likely to follow and why, and which rule you find the hardest to follow and will likely not (be able to) follow in your future projects.\n\nRule 1 is the one I most likely can follow because keeping track of how results are produced is a common practice for researchers working with federal grants, for instance, as these results are usually published in quarterly reports to the funding agency while the project is progressing towards the final deliverables.\nRule 10 is the hardest to follow in my research area because I work with geospatial data from private properties (farmers in the STRIPS project). I would be partially able to provide public access to scripts, runs, and results from my research data in field sites owned by Iowa State University; however, for the privacy protection of landowners, I could not release all of my data and results."
  },
  {
    "objectID": "blog-2023/Blog-5-submissions/kellynay/index.html#submission",
    "href": "blog-2023/Blog-5-submissions/kellynay/index.html#submission",
    "title": "Rules for Research Reproducibility",
    "section": "Submission",
    "text": "Submission\n\nPush your changes to your repository.\nYou are ready to call it good, once all your github actions pass without an error. You can check on that by selecting ‘Actions’ on the menu and ensure that the last item has a green checkmark. The action for this repository checks the yaml of your contribution for the existence of the author name, a title, date and categories. Don’t forget the space after the colon! Once the action passes, the badge along the top will also change its color accordingly. As of right now, the status for the YAML front matter is:\n\n\n\n\nFrontmatter check\n\n\n---\nauthor: \"Kelly Nascimento Thompson\"\ntitle: \"Rules for Research Reproducibility\"\ndate: \"2023-02-23\"\ncategories: \"Ethics and Reproducibility...\"\n---"
  },
  {
    "objectID": "blog-2023/Blog-5-submissions/drbradford12/BradfordDeniseBlog5.html",
    "href": "blog-2023/Blog-5-submissions/drbradford12/BradfordDeniseBlog5.html",
    "title": "Retraction Watch – Reliability and Sensitivity of Neuromuscular and Perceptual Fatigue Measures in Collegiate Men’s Basketball",
    "section": "",
    "text": "Reliability and Sensitivity of Neuromuscular and Perceptual Fatigue Measures in Collegiate Men’s Basketball\n Edwards, T., Spiteri, T., Piggott, B., Bonhotal, J., Haff, G. G., & Joyce, C.\n 10.1519/JSC.0000000000002517\n\nThe following reasons from the retraction watch database cite the following:\n\nError in Analyses\nError in Methods\nError in Results and/or Conclusions\n\nIf the authors, would’ve taken the advice of Sandve, the following rules would have been helpful in making sure that the article was not retracted:\n\nRule 1: For Every Result, Keep Track of How It Was Produced\nRule 5: Record All Intermediate Results, When Possible in Standardized Formats\n\nIt appears in the article that the sample size of the group was 12 Men’s basketball players, the researchers used 90% confidence intervals without adjusting for the limited sample size. The researchers did not describe any methods that were used statistically to determine the table outcomes.\n\n\nRule 4: Version Control All Custom Scripts and Rule 10: Provide Public Access to Scripts, Runs, and Results will be the rule that I’m most likely to follow. At this point between the advancement of technologies, like Github and Rstudio, when programming for a project we can easily add the availability to the public easily.\n\nRule 3: Archive the Exact Versions of All External Programs Used will be the hardest to follow when I tend to keep my local environment behind to maintain consistency and limited hurdles when making sure that things work to move forward. Package dependencies tend to be hard to keep up to date with versions."
  },
  {
    "objectID": "blog-2023/Blog-5-submissions/HarunCelikOtto/index.html",
    "href": "blog-2023/Blog-5-submissions/HarunCelikOtto/index.html",
    "title": "Blog Five",
    "section": "",
    "text": "Frontmatter check"
  },
  {
    "objectID": "blog-2023/Blog-5-submissions/HarunCelikOtto/index.html#prompt",
    "href": "blog-2023/Blog-5-submissions/HarunCelikOtto/index.html#prompt",
    "title": "Blog Five",
    "section": "Prompt:",
    "text": "Prompt:\nIn May 2015 Science retracted - without consent of the lead author - a paper on how canvassers can sway people’s opinions about gay marriage, see also: http://www.sciencemag.org/news/2015/05/science-retracts-gay-marriage-paper-without-agreement-lead-author-lacour The Science Editor-in-Chief cited as reasons for the retraction that the original survey data was not made available for independent reproduction of results, that survey incentives were misrepresented and that statements made about sponsorships turned out to be incorrect. The investigation resulting in the retraction was triggered by two Berkeley grad students who attempted to replicate the study and discovered that the data must have been faked.\nFiveThirtyEight has published an article with more details on the two Berkeley students’ work.\nMalicious changes to the data such as in the LaCour case are hard to prevent, but more rigorous checks should be built into the scientific publishing system. All too often papers have to be retracted for unintended reasons. Retraction Watch is a data base that keeps track of retracted papers (see the related Science magazine publication).\nRead the paper Ten Simple Rules for Reproducible Computational Research by Sandve et al.\nWrite a blog post addressing the questions:\n\nPick one of the papers from Retraction Watch that were retracted because of errors in the paper (you might want to pick a paper from the set of featured papers, because there are usually more details available). Describe what went wrong. Would any of the rules by Sandve et al. have helped in this situation?\nAfter reading the paper by Sandve et al. describe which rule you are most likely to follow and why, and which rule you find the hardest to follow and will likely not (be able to) follow in your future projects."
  },
  {
    "objectID": "blog-2023/Blog-5-submissions/HarunCelikOtto/index.html#submission",
    "href": "blog-2023/Blog-5-submissions/HarunCelikOtto/index.html#submission",
    "title": "Blog Five",
    "section": "Submission",
    "text": "Submission\n\nPush your changes to your repository.\nYou are ready to call it good, once all your github actions pass without an error. You can check on that by selecting ‘Actions’ on the menu and ensure that the last item has a green checkmark. The action for this repository checks the yaml of your contribution for the existence of the author name, a title, date and categories. Don’t forget the space after the colon! Once the action passes, the badge along the top will also change its color accordingly. As of right now, the status for the YAML front matter is:\n\n\n\n\nFrontmatter check\n\n\n---\nauthor: \"Your Name\"\ntitle: \"Specify your title\"\ndate: \"2023-02-23\"\ncategories: \"Ethics and Reproducibility...\"\n---"
  },
  {
    "objectID": "blog-2023/Blog-5-submissions/valeriehan6/index.html",
    "href": "blog-2023/Blog-5-submissions/valeriehan6/index.html",
    "title": "Reproducibility",
    "section": "",
    "text": "Frontmatter check"
  },
  {
    "objectID": "blog-2023/Blog-5-submissions/valeriehan6/index.html#prompt",
    "href": "blog-2023/Blog-5-submissions/valeriehan6/index.html#prompt",
    "title": "Reproducibility",
    "section": "Prompt:",
    "text": "Prompt:\nIn May 2015 Science retracted - without consent of the lead author - a paper on how canvassers can sway people’s opinions about gay marriage, see also: http://www.sciencemag.org/news/2015/05/science-retracts-gay-marriage-paper-without-agreement-lead-author-lacour The Science Editor-in-Chief cited as reasons for the retraction that the original survey data was not made available for independent reproduction of results, that survey incentives were misrepresented and that statements made about sponsorships turned out to be incorrect. The investigation resulting in the retraction was triggered by two Berkeley grad students who attempted to replicate the study and discovered that the data must have been faked.\nFiveThirtyEight has published an article with more details on the two Berkeley students’ work.\nMalicious changes to the data such as in the LaCour case are hard to prevent, but more rigorous checks should be built into the scientific publishing system. All too often papers have to be retracted for unintended reasons. Retraction Watch is a data base that keeps track of retracted papers (see the related Science magazine publication).\nRead the paper Ten Simple Rules for Reproducible Computational Research by Sandve et al.\nWrite a blog post addressing the questions:\n\nPick one of the papers from Retraction Watch that were retracted because of errors in the paper (you might want to pick a paper from the set of featured papers, because there are usually more details available). Describe what went wrong. Would any of the rules by Sandve et al. have helped in this situation?\n\nI chose to read this paper:\nLiwen Hu, Shunsuke Saito, Lingyu Wei, Koki Nagano, Jaewoo Seo, Jens Fursund, Iman Sadeghi, Carrie Sun, Yen-Chun Chen, and Hao Li. 2017. Avatar digitization from a single image for real-time rendering. ACM Trans. Graph. 36, 6, Article 195 (December 2017), 14 pages. https://doi.org/10.1145/3130800.31310887.\nThis paper is one of two papers coauthored by Hao Li that will be retracted soon due to the publishers discovering falsification of data in the papers. Given that it appears that the authors purposely falsified the results, I think the main way to prevent a situation like this happening again would more details on the process so that someone reading the article could reproduce the results with different images. The most pertinent rules would be 1, 2, and 10. However, I’m not sure if requiring rule 10 would be possible in such a situation since I don’t know if you could still make a company based on the methods in the paper if you share all the code.\n\nAfter reading the paper by Sandve et al. describe which rule you are most likely to follow and why, and which rule you find the hardest to follow and will likely not (be able to) follow in your future projects.\n\nRule 2 (avoiding manual data manipulation steps) is the rules I am most likely to follow since tidyverse makes it really easy to use code to manipulate/explore data. I think in general the thing that makes the rules hard to follow strictly is recording so much information. In particular, Rule 1 (keeping track of how every result was produced) is probably the most difficult, though I can see why it would make my future self’s life so much easier."
  },
  {
    "objectID": "blog-2023/Blog-5-submissions/valeriehan6/index.html#submission",
    "href": "blog-2023/Blog-5-submissions/valeriehan6/index.html#submission",
    "title": "Reproducibility",
    "section": "Submission",
    "text": "Submission\n\nPush your changes to your repository.\nYou are ready to call it good, once all your github actions pass without an error. You can check on that by selecting ‘Actions’ on the menu and ensure that the last item has a green checkmark. The action for this repository checks the yaml of your contribution for the existence of the author name, a title, date and categories. Don’t forget the space after the colon! Once the action passes, the badge along the top will also change its color accordingly. As of right now, the status for the YAML front matter is:\n\n\n\n\nFrontmatter check\n\n\n---\nauthor: \"Your Name\"\ntitle: \"Specify your title\"\ndate: \"2023-02-23\"\ncategories: \"Ethics and Reproducibility...\"\n---"
  },
  {
    "objectID": "blog-2023/Blog-5-submissions/IanParzyszek/index.html",
    "href": "blog-2023/Blog-5-submissions/IanParzyszek/index.html",
    "title": "Replication of Data Presentation",
    "section": "",
    "text": "I found this retracted paper, “Synthetic lethality of combined glutaminase and Hsp90 inhibition in mTORC1-driven tumor cells” (https://retractionwatch.com/2023/02/01/former-harvard-researchers-lose-pnas-paper-for-reusing-data/).\n\nIn this paper there was several instances of duplicated figures and reused data. However, after it was retraced the author said that this error did/would not change their conclusions.\nI believe that this error could have been avoided if they adhered to “Rule 7: Always Store Raw Data behind Plots” and maybe if they would have tried to replicate their results themselves. Rule 7 could have helped by making sure that these figures and plots corresponded to the correct data. Or if they would have just tried to repeat their results they might have also caught the mistake of duplicating the figures.\n\nI think the hardest thing for me to follow will be “Rule 2: Avoid Manual Data Manipulation Steps”. This is because my data cleaning and manipulation skills are not that developed, well not yet:). I tend to not know the best way to manipulate data, so I usually have to go through things line by line in not the most efficient, robust, and repeatable way.\n\n```"
  },
  {
    "objectID": "blog-2023/Blog-5-submissions/loganjohnson0/index.html",
    "href": "blog-2023/Blog-5-submissions/loganjohnson0/index.html",
    "title": "Importance of Data Reproducibility",
    "section": "",
    "text": "Frontmatter check"
  },
  {
    "objectID": "blog-2023/Blog-5-submissions/loganjohnson0/index.html#prompt",
    "href": "blog-2023/Blog-5-submissions/loganjohnson0/index.html#prompt",
    "title": "Importance of Data Reproducibility",
    "section": "Prompt:",
    "text": "Prompt:\nIn May 2015 Science retracted - without consent of the lead author - a paper on how canvassers can sway people’s opinions about gay marriage, see also: http://www.sciencemag.org/news/2015/05/science-retracts-gay-marriage-paper-without-agreement-lead-author-lacour The Science Editor-in-Chief cited as reasons for the retraction that the original survey data was not made available for independent reproduction of results, that survey incentives were misrepresented and that statements made about sponsorships turned out to be incorrect. The investigation resulting in the retraction was triggered by two Berkeley grad students who attempted to replicate the study and discovered that the data must have been faked.\nFiveThirtyEight has published an article with more details on the two Berkeley students’ work.\nMalicious changes to the data such as in the LaCour case are hard to prevent, but more rigorous checks should be built into the scientific publishing system. All too often papers have to be retracted for unintended reasons. Retraction Watch is a data base that keeps track of retracted papers (see the related Science magazine publication).\nRead the paper Ten Simple Rules for Reproducible Computational Research by Sandve et al.\nWrite a blog post addressing the questions:\n\nPick one of the papers from Retraction Watch that were retracted because of errors in the paper (you might want to pick a paper from the set of featured papers, because there are usually more details available). Describe what went wrong. Would any of the rules by Sandve et al. have helped in this situation?\nAfter reading the paper by Sandve et al. describe which rule you are most likely to follow and why, and which rule you find the hardest to follow and will likely not (be able to) follow in your future projects."
  },
  {
    "objectID": "blog-2023/Blog-5-submissions/loganjohnson0/index.html#responses",
    "href": "blog-2023/Blog-5-submissions/loganjohnson0/index.html#responses",
    "title": "Importance of Data Reproducibility",
    "section": "Responses",
    "text": "Responses\n\nAttached is the link to the Article from Retraction Watch that I picked. This article appears to have gained attention when readers noticed the error bars on the graph from Figure 9 were simply the letter “T”. This is obviously a concern because it raises questions about the underlying data, the methods for collecting and analyzing the data, and the overall confidence in the data. After the journal was made aware of these concerns about the paper, they conducted an investigation on the paper which ultimately led to the paper’s retraction. The journal identified that the data used in the study was not generated. There was also incorrect notation in some of the equations used in the paper as well as references in the paper that were retracted prior to submission.\n\n\nIt is concerning that a paper with this many errors made it through the peer review process. This is obviously a separate concern, but I think there were some steps that the journal could have used to determine the quality of the data prior. I think Rules 1, 2, 7, and 10 all could have helped to avoid the publishing of the paper in the first place. Again, I think there were greater underlying problems with this paper apart from their ability to manage and report their data and also some concerns that this paper made it through the peer-review process in the first place. But I think if the authors applied some of these data management strategies outline by Sandve et al. that this retraction likely would not have happened.\n\n\nThrough STAT 585 and the information that I have learned thus far, I will most definitely implement version control (Rule 4) in my research. I have already begun to transition existing projects onto my GitHub. I think this is a basic part that I have not done previously that will help me and future students as well. The challenge that I faced previously was a lack of understanding of Git and GitHub that hindered my ability to apply that version control to my research.\n\n\nI think the hardest rule to follow might be Rule 2. I think with some of the data that I have on a small scale, it is easier to manipulate that manually versus have a code or workflow for that. With some of the larger projects and data that I have, it is definitely easier and more efficient to manipulate it with code. I just think there will be times that it is easier done by hand or manually than it would be to write it all out."
  },
  {
    "objectID": "blog-2023/Blog-5-submissions/loganjohnson0/index.html#submission",
    "href": "blog-2023/Blog-5-submissions/loganjohnson0/index.html#submission",
    "title": "Importance of Data Reproducibility",
    "section": "Submission",
    "text": "Submission\n\nPush your changes to your repository.\nYou are ready to call it good, once all your github actions pass without an error. You can check on that by selecting ‘Actions’ on the menu and ensure that the last item has a green checkmark. The action for this repository checks the yaml of your contribution for the existence of the author name, a title, date and categories. Don’t forget the space after the colon! Once the action passes, the badge along the top will also change its color accordingly. As of right now, the status for the YAML front matter is:\n\n\n\n\nFrontmatter check"
  },
  {
    "objectID": "blog-2023/Blog-5-submissions/Atefeha1995/AnisiAtefeh.html",
    "href": "blog-2023/Blog-5-submissions/Atefeha1995/AnisiAtefeh.html",
    "title": "How to make our research reproducible",
    "section": "",
    "text": "Frontmatter check"
  },
  {
    "objectID": "blog-2023/Blog-5-submissions/Atefeha1995/AnisiAtefeh.html#prompt",
    "href": "blog-2023/Blog-5-submissions/Atefeha1995/AnisiAtefeh.html#prompt",
    "title": "How to make our research reproducible",
    "section": "Prompt:",
    "text": "Prompt:\nIn May 2015 Science retracted - without consent of the lead author - a paper on how canvassers can sway people’s opinions about gay marriage, see also: http://www.sciencemag.org/news/2015/05/science-retracts-gay-marriage-paper-without-agreement-lead-author-lacour The Science Editor-in-Chief cited as reasons for the retraction that the original survey data was not made available for independent reproduction of results, that survey incentives were misrepresented and that statements made about sponsorships turned out to be incorrect. The investigation resulting in the retraction was triggered by two Berkeley grad students who attempted to replicate the study and discovered that the data must have been faked.\nFiveThirtyEight has published an article with more details on the two Berkeley students’ work.\nMalicious changes to the data such as in the LaCour case are hard to prevent, but more rigorous checks should be built into the scientific publishing system. All too often papers have to be retracted for unintended reasons. Retraction Watch is a data base that keeps track of retracted papers (see the related Science magazine publication).\nRead the paper Ten Simple Rules for Reproducible Computational Research by Sandve et al.\nWrite a blog post addressing the questions:\n\nPick one of the papers from Retraction Watch that were retracted because of errors in the paper (you might want to pick a paper from the set of featured papers, because there are usually more details available). Describe what went wrong. Would any of the rules by Sandve et al. have helped in this situation?\n\nI choose the retracted work that received the most citations after 2020. According to a study titled “Primary Prevention of Cardiovascular Disease with a Mediterranean Diet,” those with high cardiovascular risk had a lower incidence of serious cardiovascular events while following a Mediterranean diet that included extra-virgin olive oil and nuts. When the manuscript was retracted in 2018, it had 1905 citations, and since then, 950 more times have been cited. This study was retracted after the editor pointed out that 11 of the 934 reports of randomized trials had baseline variable distributions that did not seem consistent with randomization. The reviewer also mentioned that they repeated the analysis for these 11 reports, and that in 5 of them, standard errors or standard deviations, were mistakenly provided. The authors have subsequently withdrawn their first report. Their most recent report, which explains the reanalysis, has been released. I think that if the authors adhered to rules 4, 5, and 6, they could avoid these issues. They might have discovered their errors in the analysis results if they had controlled their versions and kept track of intermediate results. Also, providing the reviewer with the necessary details about random processes may aid them in coming to the same conclusions.\n\nAfter reading the paper by Sandve et al. describe which rule you are most likely to follow and why, and which rule you find the hardest to follow and will likely not (be able to) follow in your future projects.\n\nIn my earlier works, I adhered to guidelines 1, 2, 4, 5, 7 and 9. I believe that rules 3 and 6 are also simple to adhere to. The hardest regulations, in my opinion, are rules 8 and 10. It may not always be simple to generate the outcome of a hierarchical analysis because the file comprising all the information and analyses must be accessible to the public. Rule 10 is difficult since, in addition to the necessary skills, it requires a lot of effort from researchers and authors to document all the versions of their scripts, runs, and results. Even though it is difficult, we must do it. By doing this, we can stay well away of any future problems and make it easier for others to continue our analysis or work with the same data. Being able to post all the codes and information of my works there so that everyone can easily access them and avoid having to reinvent the wheel makes working with Git and GitHub quite exciting for me."
  },
  {
    "objectID": "blog-2023/Blog-5-submissions/Atefeha1995/AnisiAtefeh.html#submission",
    "href": "blog-2023/Blog-5-submissions/Atefeha1995/AnisiAtefeh.html#submission",
    "title": "How to make our research reproducible",
    "section": "Submission",
    "text": "Submission\n\nPush your changes to your repository.\nYou are ready to call it good, once all your github actions pass without an error. You can check on that by selecting ‘Actions’ on the menu and ensure that the last item has a green checkmark. The action for this repository checks the yaml of your contribution for the existence of the author name, a title, date and categories. Don’t forget the space after the colon! Once the action passes, the badge along the top will also change its color accordingly. As of right now, the status for the YAML front matter is:\n\n\n\n\nFrontmatter check"
  },
  {
    "objectID": "blog-2023/Blog-5-submissions/anphan0828/index.html",
    "href": "blog-2023/Blog-5-submissions/anphan0828/index.html",
    "title": "Paper retracted alert!",
    "section": "",
    "text": "Frontmatter check"
  },
  {
    "objectID": "blog-2023/Blog-5-submissions/anphan0828/index.html#prompt",
    "href": "blog-2023/Blog-5-submissions/anphan0828/index.html#prompt",
    "title": "Paper retracted alert!",
    "section": "Prompt:",
    "text": "Prompt:\nIn May 2015 Science retracted - without consent of the lead author - a paper on how canvassers can sway people’s opinions about gay marriage, see also: http://www.sciencemag.org/news/2015/05/science-retracts-gay-marriage-paper-without-agreement-lead-author-lacour The Science Editor-in-Chief cited as reasons for the retraction that the original survey data was not made available for independent reproduction of results, that survey incentives were misrepresented and that statements made about sponsorships turned out to be incorrect. The investigation resulting in the retraction was triggered by two Berkeley grad students who attempted to replicate the study and discovered that the data must have been faked.\nFiveThirtyEight has published an article with more details on the two Berkeley students’ work.\nMalicious changes to the data such as in the LaCour case are hard to prevent, but more rigorous checks should be built into the scientific publishing system. All too often papers have to be retracted for unintended reasons. Retraction Watch is a data base that keeps track of retracted papers (see the related Science magazine publication).\nRead the paper Ten Simple Rules for Reproducible Computational Research by Sandve et al.\nWrite a blog post addressing the questions:\n\nPick one of the papers from Retraction Watch that were retracted because of errors in the paper (you might want to pick a paper from the set of featured papers, because there are usually more details available). Describe what went wrong. Would any of the rules by Sandve et al. have helped in this situation?\n\nI picked the paper: Selective killing of cancer cells by a small molecule targeting the stress response to ROS published in 2011 and retracted in 2018, also the 10th most highly cited retracted papers. The retraction note was saying that Fig. 1d and Supplementary Fig. 31b were lacking of original data, and the problem persisted even after two previous corrigendum updates in 2012 and 2015.\nFollowing Sandve et al., this problem seems to be a violation to Rule 7 (Always Store Raw Data behind Plots). From what I saw from the paper, Fig. 1d is not exactly a plot, but a picture of western blots experiments proving the effect of piperlongumine. So, it came to me, and very possible, that the authors have already discarded their lab notes so they cannot submit the raw data anymore, and they also cannot reproduce the experiments. Eventually, the paper was retracted due to missing raw data. As I mentioned, if Rule 7 was followed, the authors might have avoided this situation.\n\nAfter reading the paper by Sandve et al. describe which rule you are most likely to follow and why, and which rule you find the hardest to follow and will likely not (be able to) follow in your future projects.\n\nEvery rule is so relatable and I am glad that I read these. The first rule (For Every Result, Keep Track of How It Was Produced) is what I am most likely to follow because I have set a goal for myself this year to keep track of everything I have done, even the smallest bug. I was so frustrated last year because of repeating a series of debugging steps countless of times. I always thought I would be able to resolve this bug so I did not think of recording it, and I have paid the price! What supposed to be solved within 5 minutes had cost me 1 hour of debugging.\nAnother rule that I found pretty nice and new is Rule 8: Generate Hierarchical Analysis Output. I did not think of using hyperlinks to store links to intermediate data (since those are large and I usually have to store them on a cloud system or HPC) and so my data were just scattered everywhere without a record.\nThe hardest rule could be Rule 10: Provide Public Access to Scripts, Runs, and Results because of our embarrassment of showing the world our inefficient and messy code! I know this is a good advice and I hope I can follow it some day, but right now “my code works” is all I need. That is also the reason why I take this course at the beginning, because the course content is so tempting!"
  },
  {
    "objectID": "blog-2023/Blog-5-submissions/anphan0828/index.html#submission",
    "href": "blog-2023/Blog-5-submissions/anphan0828/index.html#submission",
    "title": "Paper retracted alert!",
    "section": "Submission",
    "text": "Submission\n\nPush your changes to your repository.\nYou are ready to call it good, once all your github actions pass without an error. You can check on that by selecting ‘Actions’ on the menu and ensure that the last item has a green checkmark. The action for this repository checks the yaml of your contribution for the existence of the author name, a title, date and categories. Don’t forget the space after the colon! Once the action passes, the badge along the top will also change its color accordingly. As of right now, the status for the YAML front matter is:\n\n\n\n\nFrontmatter check\n\n\n---\nauthor: \"Your Name\"\ntitle: \"Specify your title\"\ndate: \"2023-02-23\"\ncategories: \"Ethics and Reproducibility...\"\n---"
  },
  {
    "objectID": "blog-2023/Blog-5-submissions/hardtme/index.html",
    "href": "blog-2023/Blog-5-submissions/hardtme/index.html",
    "title": "Ethics in Reproducible Research",
    "section": "",
    "text": "Frontmatter check"
  },
  {
    "objectID": "blog-2023/Blog-5-submissions/hardtme/index.html#prompt",
    "href": "blog-2023/Blog-5-submissions/hardtme/index.html#prompt",
    "title": "Ethics in Reproducible Research",
    "section": "Prompt:",
    "text": "Prompt:\nIn May 2015 Science retracted - without consent of the lead author - a paper on how canvassers can sway people’s opinions about gay marriage, see also: http://www.sciencemag.org/news/2015/05/science-retracts-gay-marriage-paper-without-agreement-lead-author-lacour The Science Editor-in-Chief cited as reasons for the retraction that the original survey data was not made available for independent reproduction of results, that survey incentives were misrepresented and that statements made about sponsorships turned out to be incorrect. The investigation resulting in the retraction was triggered by two Berkeley grad students who attempted to replicate the study and discovered that the data must have been faked.\nFiveThirtyEight has published an article with more details on the two Berkeley students’ work.\nMalicious changes to the data such as in the LaCour case are hard to prevent, but more rigorous checks should be built into the scientific publishing system. All too often papers have to be retracted for unintended reasons. Retraction Watch is a data base that keeps track of retracted papers (see the related Science magazine publication).\nRead the paper Ten Simple Rules for Reproducible Computational Research by Sandve et al.\nWrite a blog post addressing the questions:\n\nPick one of the papers from Retraction Watch that were retracted because of errors in the paper (you might want to pick a paper from the set of featured papers, because there are usually more details available). Describe what went wrong. Would any of the rules by Sandve et al. have helped in this situation?\n\nI chose the paper “Synthetic lethality of combined glutaminase and Hsp90 inhibition in mTORC1-driven tumor cells,” as described in this Retraction Watch article. In this paper, the authors presented the same data in multiple figures without noting that they did so. This situation might have been avoided if the authors had followed Sandve et al.’s rule 7: always store raw data behind plots. If the authors knew the particular figures that went with all of the data they wanted to plot, they could have ensured that all of their figures showed all of the appropriate data without duplication. However, John Blenis, the paper’s corresponding author, has had corrections issued for earlier papers due to data omission and data duplication issues. This makes me wonder if the data duplication in the figures was not an innocent mistake that could have been fixed by following Sandve et al.’s rules.\n\nAfter reading the paper by Sandve et al. describe which rule you are most likely to follow and why, and which rule you find the hardest to follow and will likely not (be able to) follow in your future projects.\n\nThe rule I find easiest to follow is rule 6: for analyses that include randomness, note underlying random seeds. Whenever I run an analysis that involves a (pseudo-)random process like drawing random numbers or running a Bayesian sampler (such as fitting stan models via the rstan package), I always seed a seed beforehand so I can get the same results back every time I run the analysis. However, it sounds like I need to do a better job of documenting which random seed I used in reports of my work. The rule I find hardest to follow is rule 2: avoid manual data manipulation steps. In my work, I always save the code I use to modify data, but I typically don’t try to automate the data manipulation process. (As an aside, I do not really like the term “data manipulation” since it sounds like we could be doing nefarious things with our data. I prefer “data cleaning” or “data wrangling.”)"
  },
  {
    "objectID": "blog-2023/Blog-5-submissions/santos-cl/index.html",
    "href": "blog-2023/Blog-5-submissions/santos-cl/index.html",
    "title": "Dotting I’s and crossing T’s…",
    "section": "",
    "text": "Frontmatter check\nIn May 2015 Science retracted - without consent of the lead author - a paper on how canvassers can sway people’s opinions about gay marriage, see also: http://www.sciencemag.org/news/2015/05/science-retracts-gay-marriage-paper-without-agreement-lead-author-lacour The Science Editor-in-Chief cited as reasons for the retraction that the original survey data was not made available for independent reproduction of results, that survey incentives were misrepresented and that statements made about sponsorships turned out to be incorrect. The investigation resulting in the retraction was triggered by two Berkeley grad students who attempted to replicate the study and discovered that the data must have been faked.\nFiveThirtyEight has published an article with more details on the two Berkeley students’ work.\nMalicious changes to the data such as in the LaCour case are hard to prevent, but more rigorous checks should be built into the scientific publishing system. All too often papers have to be retracted for unintended reasons. Retraction Watch is a data base that keeps track of retracted papers (see the related Science magazine publication).\nRead the paper Ten Simple Rules for Reproducible Computational Research by Sandve et al.\nWrite a blog post addressing the questions:"
  },
  {
    "objectID": "blog-2023/Blog-5-submissions/santos-cl/index.html#the-retracted-paper",
    "href": "blog-2023/Blog-5-submissions/santos-cl/index.html#the-retracted-paper",
    "title": "Dotting I’s and crossing T’s…",
    "section": "The retracted paper",
    "text": "The retracted paper\nThe paper titled Monitoring of Sports Health Indicators Based on Wearable Nanobiosensors went viral among the data-science community on Twitter in late December of 2022. I remember that a couple co-workers and I saw a bar graph- Figure 9 in the manuscript- and thought that the error bars were similar to the capital letter T. However, we did not think twice about it. According to Retraction Watch, the paper was retracted from the journal in late December of 2022.\nAlthough the paper has gotten famous for the T-shaped error bars, that was not the only reason the paper was retracted. The journal has stated that the fact that the error bars appeared to be the letter T was a factor. However, they have also shed light on the fact that the authors stated that they did not generate or analyze any new datasets in the current study. Ultimately, the journal concluded that there were questions about the reliability of the study.\nIn Sandve, et al. (2013), several rules are described to facilitate reproducible research. The article in question could, honestly, have benefited from having followed every single one of them. However, in special, Rule 1(For Every Result, Keep Track of How It Was Produced) seems to be particularly relevant in this question. Had the authors been able to demonstrate how the results were produced, part of de doubt about this paper would have been dismissed. Secondly, I believe Rule 10 (Provide Public Access to Scripts, Runs, and Results) would have been also important in this case. Providing public access to the scripts, runs, and results would allow for third-party verification of the results."
  },
  {
    "objectID": "blog-2023/Blog-5-submissions/santos-cl/index.html#rules-i-am-inclined-to-follow-or-not",
    "href": "blog-2023/Blog-5-submissions/santos-cl/index.html#rules-i-am-inclined-to-follow-or-not",
    "title": "Dotting I’s and crossing T’s…",
    "section": "Rules I am inclined to follow (or not)",
    "text": "Rules I am inclined to follow (or not)\nIn general, the rules that deal with keeping track of scripts, intermediate results, and how results were produced are the ones I am most likely to follow (e.g. rules 1, 2, 4, and 7). I believe this is really advantageous when analyzing data. I believe separate sub-directories for raw data and intermediate data is important because that way I can always go back to the raw data if something seems out of place. There is usually a script that I call “data-processing.R” or something like it. This script processes the raw data into intermediate data. Then, I usually have the “data-analysis.R” script also, generally. This script takes the intermediate data and outputs results.\nI am most likely not to follow rule 10, I believe. Depending on the field of study, collecting data is costly and labor-intensive. I tend to not want to share data until I am sure that there is nothing more I can extract from those data."
  },
  {
    "objectID": "blog-2023/Blog-5-submissions/sudi007/index.html",
    "href": "blog-2023/Blog-5-submissions/sudi007/index.html",
    "title": "Ethics and Reproducibility",
    "section": "",
    "text": "blog-5-sudi007"
  },
  {
    "objectID": "blog-2023/Blog-5-submissions/sudi007/index.html#prompt",
    "href": "blog-2023/Blog-5-submissions/sudi007/index.html#prompt",
    "title": "Ethics and Reproducibility",
    "section": "Prompt:",
    "text": "Prompt:\nIn May 2015 Science retracted - without consent of the lead author - a paper on how canvassers can sway people’s opinions about gay marriage, see also: http://www.sciencemag.org/news/2015/05/science-retracts-gay-marriage-paper-without-agreement-lead-author-lacour The Science Editor-in-Chief cited as reasons for the retraction that the original survey data was not made available for independent reproduction of results, that survey incentives were misrepresented and that statements made about sponsorships turned out to be incorrect. The investigation resulting in the retraction was triggered by two Berkeley grad students who attempted to replicate the study and discovered that the data must have been faked.\nFiveThirtyEight has published an article with more details on the two Berkeley students’ work.\nMalicious changes to the data such as in the LaCour case are hard to prevent, but more rigorous checks should be built into the scientific publishing system. All too often papers have to be retracted for unintended reasons. Retraction Watch is a data base that keeps track of retracted papers (see the related Science magazine publication).\nRead the paper Ten Simple Rules for Reproducible Computational Research by Sandve et al.\nWrite a blog post addressing the questions:\n\nPick one of the papers from Retraction Watch that were retracted because of errors in the paper (you might want to pick a paper from the set of featured papers, because there are usually more details available). Describe what went wrong. Would any of the rules by Sandve et al. have helped in this situation?\n\n[What went wrong]: This paper was published in the journal, Lancet, on February 28, 1998, by Andrew Wakefield and 12 other authors. The paper claimed to have established links between the measles, mumps, and rubella vaccine (MMR) and autism, after conducting research on 12 participants However, the paper was retracted in 2010 due to incorrect data manipulation. This issue came to light when several researchers tried to duplicate the results of this study and failed in the endeavor. Thereafter, it was retracted with some on its team of authors stating that the original data was misinterpreted and that in reality, the data was insufficient to reveal any causal links between the MMR vaccine and autism. As this study had created a world-wide stir, such retraction caught the attention of the media. Consequently, journalists investigated the authenticity of the study and upon interviewing the participants, it surfaced that their medical details did not match with those stated in the article. Eventually, the vested interests of the researchers were exposed in this rare case of fraud. However, in other similar studies with such incorrect data manipulation but without fraudulent intentions, the implementation of Sandve et al.’s rules 1 and 2 would have helped the situation. According to Sandve et al., good research practices involve keeping track of how every result was produced. In this study, the research data did not match the actual data, generating incorrect results. If the data itself was cross-checked and how the results were produced properly document at each step, such discrepancies could have been avoided.\n\nAfter reading the paper by Sandve et al. describe which rule you are most likely to follow and why, and which rule you find the hardest to follow and will likely not (be able to) follow in your future projects.\n\nAfter reading the Sandve et al. paper, all the rules described in it appear to be a pre-requisite to produce an exemplar research paper. However, if I had to choose one that I am most likely to follow, it would be rule 9, Connect Textual Statements to Underlying Results. This is because I have often looked at the results of my research projects and wondered how they should be interpreted in the context of the research. Linking the results to the statements from my notes and emails would thus make it easy to write the results section of any of the research projects I take up in the future. On the other hand, following rule 8, Generate Hierarchical Analysis Output, Allowing Layers of Increasing Detail to Be Inspected, appears the hardest from the list. That is because data analysis itself is a substantial task entailing writing and running codes, which may sometimes need to be closely examined, re-written and re-run. To remember and find the time to accommodate rule 8 is easier said than done. As a result, following rule 8 in the near future appears to be more of a challenge than the remaining rules."
  },
  {
    "objectID": "blog-2023/Blog-5-submissions/sudi007/index.html#submission",
    "href": "blog-2023/Blog-5-submissions/sudi007/index.html#submission",
    "title": "Ethics and Reproducibility",
    "section": "Submission",
    "text": "Submission\n\nPush your changes to your repository.\nYou are ready to call it good, once all your github actions pass without an error. You can check on that by selecting ‘Actions’ on the menu and ensure that the last item has a green checkmark. The action for this repository checks the yaml of your contribution for the existence of the author name, a title, date and categories. Don’t forget the space after the colon! Once the action passes, the badge along the top will also change its color accordingly. As of right now, the status for the YAML front matter is:\n\n\n\n\nFrontmatter check\n\n\n---\nauthor: \"Sudesh Bhagat\"\ntitle: \"Ethics and Reproducibility\"\ndate: \"2023-02-23\"\ncategories: \"Ethics and Reproducibility...\"\n---"
  },
  {
    "objectID": "blog-2023/Blog-5-submissions/gnbltrn/index.html",
    "href": "blog-2023/Blog-5-submissions/gnbltrn/index.html",
    "title": "Stat 585",
    "section": "",
    "text": "Frontmatter check"
  },
  {
    "objectID": "blog-2023/Blog-5-submissions/gnbltrn/index.html#prompt",
    "href": "blog-2023/Blog-5-submissions/gnbltrn/index.html#prompt",
    "title": "Stat 585",
    "section": "Prompt:",
    "text": "Prompt:\nIn May 2015 Science retracted - without consent of the lead author - a paper on how canvassers can sway people’s opinions about gay marriage, see also: http://www.sciencemag.org/news/2015/05/science-retracts-gay-marriage-paper-without-agreement-lead-author-lacour The Science Editor-in-Chief cited as reasons for the retraction that the original survey data was not made available for independent reproduction of results, that survey incentives were misrepresented and that statements made about sponsorships turned out to be incorrect. The investigation resulting in the retraction was triggered by two Berkeley grad students who attempted to replicate the study and discovered that the data must have been faked.\nFiveThirtyEight has published an article with more details on the two Berkeley students’ work.\nMalicious changes to the data such as in the LaCour case are hard to prevent, but more rigorous checks should be built into the scientific publishing system. All too often papers have to be retracted for unintended reasons. Retraction Watch is a data base that keeps track of retracted papers (see the related Science magazine publication).\nRead the paper Ten Simple Rules for Reproducible Computational Research by Sandve et al.\nWrite a blog post addressing the questions:\n\nPick one of the papers from Retraction Watch that were retracted because of errors in the paper (you might want to pick a paper from the set of featured papers, because there are usually more details available). Describe what went wrong. Would any of the rules by Sandve et al. have helped in this situation?\nAfter reading the paper by Sandve et al. describe which rule you are most likely to follow and why, and which rule you find the hardest to follow and will likely not (be able to) follow in your future projects."
  },
  {
    "objectID": "blog-2023/Blog-5-submissions/gnbltrn/index.html#submission",
    "href": "blog-2023/Blog-5-submissions/gnbltrn/index.html#submission",
    "title": "Stat 585",
    "section": "Submission",
    "text": "Submission\n\nPush your changes to your repository.\nYou are ready to call it good, once all your github actions pass without an error. You can check on that by selecting ‘Actions’ on the menu and ensure that the last item has a green checkmark. The action for this repository checks the yaml of your contribution for the existence of the author name, a title, date and categories. Don’t forget the space after the colon! Once the action passes, the badge along the top will also change its color accordingly. As of right now, the status for the YAML front matter is:\n\n\n\n\nFrontmatter check\n\n\n---\nauthor: \"Your Name\"\ntitle: \"Specify your title\"\ndate: \"2023-02-23\"\ncategories: \"Ethics and Reproducibility...\"\n---"
  },
  {
    "objectID": "blog-2023/Blog-5-submissions/motinaaa/index.html",
    "href": "blog-2023/Blog-5-submissions/motinaaa/index.html",
    "title": "The One Where Ethics Meet Reproducibility",
    "section": "",
    "text": "Frontmatter check"
  },
  {
    "objectID": "blog-2023/Blog-5-submissions/motinaaa/index.html#prompt",
    "href": "blog-2023/Blog-5-submissions/motinaaa/index.html#prompt",
    "title": "The One Where Ethics Meet Reproducibility",
    "section": "Prompt:",
    "text": "Prompt:\nIn May 2015 Science retracted - without consent of the lead author - a paper on how canvassers can sway people’s opinions about gay marriage, see also: http://www.sciencemag.org/news/2015/05/science-retracts-gay-marriage-paper-without-agreement-lead-author-lacour The Science Editor-in-Chief cited as reasons for the retraction that the original survey data was not made available for independent reproduction of results, that survey incentives were misrepresented and that statements made about sponsorships turned out to be incorrect. The investigation resulting in the retraction was triggered by two Berkeley grad students who attempted to replicate the study and discovered that the data must have been faked.\nFiveThirtyEight has published an article with more details on the two Berkeley students’ work.\nMalicious changes to the data such as in the LaCour case are hard to prevent, but more rigorous checks should be built into the scientific publishing system. All too often papers have to be retracted for unintended reasons. Retraction Watch is a data base that keeps track of retracted papers (see the related Science magazine publication).\nRead the paper Ten Simple Rules for Reproducible Computational Research by Sandve et al.\nWrite a blog post addressing the questions:\n\nPick one of the papers from Retraction Watch that were retracted because of errors in the paper (you might want to pick a paper from the set of featured papers, because there are usually more details available). Describe what went wrong. Would any of the rules by Sandve et al. have helped in this situation?\n\n\n‘I was fired up’: Psychiatrist effort prompts retraction of antidepressant treatment paper\n\n\nThe article discusses suspected research misconduct in two studies on the use of metformin and cilostazol as adjunctive therapies for depression. The studies were conducted in Egypt and published in two journals. Eric Ross, a psychiatrist, raised concerns about the studies after noticing data irregularities. One study was retracted by the journal Neurotherapeutics, while the other study is still under investigation by the publisher of CNS Neuroscience & Therapeutics. The corresponding author of the papers denies any wrongdoing and has threatened legal action.\n\n\nSandve et al.’s rules for detecting scientific fraud and misconduct may have helped in this situation, particularly rule #2 (Avoid Manual Data Manipulation Steps) and rule #1 (For Every Result, Keep Track of How It Was Produced).\n\n\nAfter reading the paper by Sandve et al. describe which rule you are most likely to follow and why, and which rule you find the hardest to follow and will likely not (be able to) follow in your future projects.\n\n\nRule 1 is a good practice to follow. Keeping track of how results were produced ensures that my analyses can be reproduced, which is a fundamental aspect of scientific research. Reproducibility enables others to verify my findings, and for me to check and validate my own work. Additionally, it can help me spot errors and identify areas for improvement, leading to more robust and accurate results. Finally, it can enhance the transparency and credibility of my research.\n\n\nRule 9 could be difficult to follow for me. Connecting textual statements to underlying results requires careful organization and documentation of data and analysis, which can be time-consuming and challenging to maintain, especially for large and complex projects. Furthermore, the rule may require a significant shift in my workflow and documentation practices, which may be hard to implement in my ongoing project working with collaborators who have different documentation styles or preferences. ## Submission\n\n\nPush your changes to your repository.\nYou are ready to call it good, once all your github actions pass without an error. You can check on that by selecting ‘Actions’ on the menu and ensure that the last item has a green checkmark. The action for this repository checks the yaml of your contribution for the existence of the author name, a title, date and categories. Don’t forget the space after the colon! Once the action passes, the badge along the top will also change its color accordingly. As of right now, the status for the YAML front matter is:\n\n\n\n\nFrontmatter check\n\n\n---\nauthor: \"Motina\"\ntitle: \"The One Where Ethics Meet Reproducibility\"\ndate: \"2023-02-23\"\ncategories: \"Ethics and Reproducibility...\"\n---"
  },
  {
    "objectID": "blog-2023/Blog-5-submissions/maxwellskinner2002/index.html",
    "href": "blog-2023/Blog-5-submissions/maxwellskinner2002/index.html",
    "title": "Reproducing Randomness",
    "section": "",
    "text": "Frontmatter check"
  },
  {
    "objectID": "blog-2023/Blog-5-submissions/maxwellskinner2002/index.html#prompt",
    "href": "blog-2023/Blog-5-submissions/maxwellskinner2002/index.html#prompt",
    "title": "Reproducing Randomness",
    "section": "Prompt:",
    "text": "Prompt:\nIn May 2015 Science retracted - without consent of the lead author - a paper on how canvassers can sway people’s opinions about gay marriage, see also: http://www.sciencemag.org/news/2015/05/science-retracts-gay-marriage-paper-without-agreement-lead-author-lacour The Science Editor-in-Chief cited as reasons for the retraction that the original survey data was not made available for independent reproduction of results, that survey incentives were misrepresented and that statements made about sponsorships turned out to be incorrect. The investigation resulting in the retraction was triggered by two Berkeley grad students who attempted to replicate the study and discovered that the data must have been faked.\nFiveThirtyEight has published an article with more details on the two Berkeley students’ work.\nMalicious changes to the data such as in the LaCour case are hard to prevent, but more rigorous checks should be built into the scientific publishing system. All too often papers have to be retracted for unintended reasons. Retraction Watch is a data base that keeps track of retracted papers (see the related Science magazine publication).\nRead the paper Ten Simple Rules for Reproducible Computational Research by Sandve et al.\nWrite a blog post addressing the questions:\n\nPick one of the papers from Retraction Watch that were retracted because of errors in the paper (you might want to pick a paper from the set of featured papers, because there are usually more details available). Describe what went wrong. Would any of the rules by Sandve et al. have helped in this situation?\n\nAnswer: From the Retraction Watch database, there contained an article titled Facial expressions can detect Parkinson’s disease: preliminary evidence from videos collected online. https://www.nature.com/articles/s41746-021-00502-8 . It was retracted because of the authors used a data pre-processing tool which resulted in an information leak from train to test samples. This made it so there were incorrect classification metrics.\nFollowing some of the rules by Sandve et all, I believe this mistake could have been avoided or at least mitigated. Much of the data manipulation was done manually through individual lines of code rather than through a more robust method like something from the sklearn package in Python. Looking at the code for their clustering analysis, they split the train and test sets manually rather than through a sklearn train, test, split method. This possibly led to the train and test sets being bled together, leading to inaccurate results.\n\nAfter reading the paper by Sandve et al. describe which rule you are most likely to follow and why, and which rule you find the hardest to follow and will likely not (be able to) follow in your future projects.\n\nSome of the most useful rules I personally will start using is rule 10. After reading over multiple papers involving data science topics, I didn’t know before that the scripts used in the paper were so readily available. I always knew Github could be used to store results and all of the methods used, but I didn’t know it was becoming the standard. In doing research in the future, I will make sure to document cleanly and publish all of my work in a github repo so my results can be replicated as accurately as possible.\nOne of the rules that will be the hardest to follow is rule 6. In projects containing a level of randomness, to be able to reproduce results, you have to have the same seed used in the experiment. One example I would think of that would make things difficult to replicate would be the train and test splits, making sure those are exact and completely reproducible. While with a proper statistical analysis, randomly splitting the test and train sets should be yielding similar results regardless of the split, it is still difficult to make it exact and reproducible for that kind of case."
  },
  {
    "objectID": "blog-2023/Blog-5-submissions/maxwellskinner2002/index.html#submission",
    "href": "blog-2023/Blog-5-submissions/maxwellskinner2002/index.html#submission",
    "title": "Reproducing Randomness",
    "section": "Submission",
    "text": "Submission\n\nPush your changes to your repository.\nYou are ready to call it good, once all your github actions pass without an error. You can check on that by selecting ‘Actions’ on the menu and ensure that the last item has a green checkmark. The action for this repository checks the yaml of your contribution for the existence of the author name, a title, date and categories. Don’t forget the space after the colon! Once the action passes, the badge along the top will also change its color accordingly. As of right now, the status for the YAML front matter is:\n\n\n\n\nFrontmatter check\n\n\n---\nauthor: \"Your Name\"\ntitle: \"Specify your title\"\ndate: \"2023-02-23\"\ncategories: \"Ethics and Reproducibility...\"\n---"
  },
  {
    "objectID": "blog-2023/Blog-5-submissions/Sabrenar/index.html",
    "href": "blog-2023/Blog-5-submissions/Sabrenar/index.html",
    "title": "Ethically Managing Data",
    "section": "",
    "text": "Frontmatter check"
  },
  {
    "objectID": "blog-2023/Blog-5-submissions/Sabrenar/index.html#prompt",
    "href": "blog-2023/Blog-5-submissions/Sabrenar/index.html#prompt",
    "title": "Ethically Managing Data",
    "section": "Prompt:",
    "text": "Prompt:\nIn May 2015 Science retracted - without consent of the lead author - a paper on how canvassers can sway people’s opinions about gay marriage, see also: http://www.sciencemag.org/news/2015/05/science-retracts-gay-marriage-paper-without-agreement-lead-author-lacour The Science Editor-in-Chief cited as reasons for the retraction that the original survey data was not made available for independent reproduction of results, that survey incentives were misrepresented and that statements made about sponsorships turned out to be incorrect. The investigation resulting in the retraction was triggered by two Berkeley grad students who attempted to replicate the study and discovered that the data must have been faked.\nFiveThirtyEight has published an article with more details on the two Berkeley students’ work.\nMalicious changes to the data such as in the LaCour case are hard to prevent, but more rigorous checks should be built into the scientific publishing system. All too often papers have to be retracted for unintended reasons. Retraction Watch is a data base that keeps track of retracted papers (see the related Science magazine publication).\nRead the paper Ten Simple Rules for Reproducible Computational Research by Sandve et al.\nWrite a blog post addressing the questions:\n\nPick one of the papers from Retraction Watch that were retracted because of errors in the paper (you might want to pick a paper from the set of featured papers, because there are usually more details available). Describe what went wrong. Would any of the rules by Sandve et al. have helped in this situation?\n\nI chose the paper “Synthetic lethality of combined glutaminase and Hsp90 inhibition in mTORC1-driven tumor cells.” There were errors in several figures resulting from data duplication. It appears as if the authors re-used several images across different figures. The Retraction Watch post also mentioned that this was not the only time these authors had issues with data leading to retractions or corrections. Each time the authors responded that these errors “do not compromise the conclusions in the paper.” Rule 9 from Sandve et al.’s paper would have helped in this situation. Rule 9, connect textual statements to underlying results, would have helped the authors keep track of which images go with which figures.\n\nAfter reading the paper by Sandve et al. describe which rule you are most likely to follow and why, and which rule you find the hardest to follow and will likely not (be able to) follow in your future projects.\n\nI am most likely to follow rule 5: record all intermediate results, when possible. I frequently need to break down an analysis pipeline in order to understand it. As such, I already tend to save intermediate “progress” steps whether it’s an image or a .rds file. If I don’t need to save a step then I can comment out the line in the code that saves the data. I find the hardest rule to follow is rule 3: archive the exact versions of all external programs used. While this can be easily done with R containers, this will not be helpful for others to be able to replicate later since they may not have access to the R container. In addition, package updates may change the data analysis process. For example, functions will be replaced, or new functions will add new avenues of analysis. As such, the code should be flexible enough to handle small changes in package versions before being updated after an extended amount of time as passed."
  },
  {
    "objectID": "blog-2023/Blog-5-submissions/Sabrenar/index.html#submission",
    "href": "blog-2023/Blog-5-submissions/Sabrenar/index.html#submission",
    "title": "Ethically Managing Data",
    "section": "Submission",
    "text": "Submission\n\nPush your changes to your repository.\nYou are ready to call it good, once all your github actions pass without an error. You can check on that by selecting ‘Actions’ on the menu and ensure that the last item has a green checkmark. The action for this repository checks the yaml of your contribution for the existence of the author name, a title, date and categories. Don’t forget the space after the colon! Once the action passes, the badge along the top will also change its color accordingly. As of right now, the status for the YAML front matter is:\n\n\n\n\nFrontmatter check\n\n\n---\nauthor: \"Your Name\"\ntitle: \"Specify your title\"\ndate: \"2023-02-23\"\ncategories: \"Ethics and Reproducibility...\"\n---"
  },
  {
    "objectID": "blog-2023/Blog-5-submissions/luobo119/index.html",
    "href": "blog-2023/Blog-5-submissions/luobo119/index.html",
    "title": "Reproducible Computational Research",
    "section": "",
    "text": "Frontmatter check"
  },
  {
    "objectID": "blog-2023/Blog-5-submissions/luobo119/index.html#prompt",
    "href": "blog-2023/Blog-5-submissions/luobo119/index.html#prompt",
    "title": "Reproducible Computational Research",
    "section": "Prompt:",
    "text": "Prompt:\nIn May 2015 Science retracted - without consent of the lead author - a paper on how canvassers can sway people’s opinions about gay marriage, see also: http://www.sciencemag.org/news/2015/05/science-retracts-gay-marriage-paper-without-agreement-lead-author-lacour The Science Editor-in-Chief cited as reasons for the retraction that the original survey data was not made available for independent reproduction of results, that survey incentives were misrepresented and that statements made about sponsorships turned out to be incorrect. The investigation resulting in the retraction was triggered by two Berkeley grad students who attempted to replicate the study and discovered that the data must have been faked.\nFiveThirtyEight has published an article with more details on the two Berkeley students’ work.\nMalicious changes to the data such as in the LaCour case are hard to prevent, but more rigorous checks should be built into the scientific publishing system. All too often papers have to be retracted for unintended reasons. Retraction Watch is a data base that keeps track of retracted papers (see the related Science magazine publication).\nRead the paper Ten Simple Rules for Reproducible Computational Research by Sandve et al.\nWrite a blog post addressing the questions:\n\nPick one of the papers from Retraction Watch that were retracted because of errors in the paper (you might want to pick a paper from the set of featured papers, because there are usually more details available). Describe what went wrong. Would any of the rules by Sandve et al. have helped in this situation?\n\nThe article ‘Inhaled Nitric Oxide Protects Cerebral Autoregulation and Reduces Hippocampal Necrosis After Traumatic Brain Injury Through Inhibition of ET-1, ERK MAPK and IL-6 Upregulation in Pigs’ has been retracted. This article has problems with duplicated plots, identical data found in an earlier publication, unclear descriptions of the experiment conducted, and unmatched data of animals reported with the surgical records.\nThe entire retraction details are as followed:\nThe Editor-in-Chief has retracted this article on the request of William M. Armstead. An institutional investigation by the University of Pennsylvania found that images in Figures 6A, B, C, E and F duplicate, without attribution, images in earlier publications that reported on different experiments; numerical data, presented in the histogram of Figure 6G, appeared identical to data found in earlier publications [1, 2]. The University notes that the authors were unable to provide raw data supporting the results for Figure 6G; the methodology section of the article did not accurately describe the conduct of the reported experiment; and the number, age or treatment condition of the animals reported did not match the surgical records.\nVictor Curvello and William M. Amrstead agree to this retraction. Philip Pastor and Monica S. Vavilala have not responded to any correspondence from the editor or publisher about this retraction.\nThe following rules might help:\n\nRule 7: Always Store Raw Data behind Plots. It might help if they can raw data supporting the results for Figure 6G.\nRule 9: Connect Textual Statements to Underlying Results. It might help if they have textual statements for all figures allowing peers to make their own assessment of the claims they make.\nRule 10: Provide Public Access to Scripts, Runs, and Results.\n\n\nAfter reading the paper by Sandve et al. describe which rule you are most likely to follow and why, and which rule you find the hardest to follow and will likely not (be able to) follow in your future projects.\n\nRule 1 is most important to me, but I think Rule 1 is closely related to other rules. Simulations and applications usually are important parts of my research. For simulations, the setting of parameters is essential, and sometimes random seeds (related to Rule 6) might also be needed to reproduce the results that support the conclusion. For applications, the accessibility of original data is important for reproducible results. So providing public access to the input data and code like stating in Rule 10 is also important. And many cleaning steps might be needed for the raw data in the application, so keep track of all details is a golden rule to follow.\nI think Rule 8 is hard to follow. Even though it is essential to check the data behind the summarized results, it is hard for the co-authors and readers to generalize useful information from these data. So I think storing raw data behind the plots for reproducing as suggested in Rule 7 or connecting textual statements to underlying results as suggested in Rule 9 is more useful. We might do this for self check, but a hypertext as suggested in this rule seems unnecessary to me."
  },
  {
    "objectID": "blog-2023/Blog-5-submissions/AArabio/index.html",
    "href": "blog-2023/Blog-5-submissions/AArabio/index.html",
    "title": "Number 10",
    "section": "",
    "text": "Frontmatter check\n\n\n\nPick one of the papers from Retraction Watch that were retracted because of errors in the paper (you might want to pick a paper from the set of featured papers, because there are usually more details available). Describe what went wrong. Would any of the rules by Sandve et al. have helped in this situation?\n\nFrom Retraction Watch, under the “Top 10 most highly cited retracted papers”, is a paper entitled, “Selective killing of cancer cells by a small molecule targeting the stress response to ROS”. This paper is listed 10 on the list and was published in the journal Nature in 2011. This article recieved 612 citations prior to its retraction in 2018 and 206 citations even after its retraction. There were also two corrigendums to this article prior to its retraction; one correigendum in 2012 and another in 2015. The integrity of the paper was comprimised as there were issues with reported data, figure legends, and reported measurements.\nThe official reason for retaction of this article is stated as, “This Letter is being retracted owing to issues with Fig. 1d and Supplementary Fig. 31b, and the unavailability of original data for these figures, which raises concerns regarding the integrity of the figures. Nature published two previous corrections related to this Letter1,2. These issues in aggregate undermine the confidence in the integrity of this study. Authors Michael Foley, Monica Schenone, Nicola J. Tolliday, Todd R. Golub, Steven A. Carr, Alykhan F. Shamji, Andrew M. Stern and Stuart L. Schreiber agree with the Retraction. Authors Lakshmi Raj, Takao Ide, Aditi U. Gurkar, Anna Mandinova and Sam W. Lee disagree with the Retraction. Author Xiaoyu Li did not respond.” as stated through the Retraction Note.\nSome of the rules by Sandve et al. that may have helped in this situation include:\nRule 2: Avoid Manual Data Manupulation steps\nRule 7: Always Store Raw Data behind Plots\nRule 9: Connect Textual Statements to Underlying Results\nand\nRule 10: Provide Public Access to Scripts, Runs, and Results\n\nAfter reading the paper by Sandve et al. describe which rule you are most likely to follow and why, and which rule you find the hardest to follow and will likely not (be able to) follow in your future projects.\n\nThe rule that I am most lilely to follow from Sandve et al ’s Ten Simple Rules is Rule 1: For Every Result, Keep Track of How It Was Produced …\nThis is a rule that I have been trying to follow since I have began working with code for my research. I began to work with code for my project as I am trying to formulate a novel method for document analysis and the importance of reproducibility for this process is very important.\nThe rule that I will likey not be able to follow in my future projects is Rule 3: Archive the Exact Versions of All External Programs Used …\nThis rule is more difficult to follow as I am not always aware of the particular versions of packages or resources that I am using. Through lab procedure I understand how important this rule is but it is not something that I have been great in doing so far with my coding practices."
  },
  {
    "objectID": "blog-2023/Blog-5-submissions/Starwiiin/index.html",
    "href": "blog-2023/Blog-5-submissions/Starwiiin/index.html",
    "title": "Ethics and Reproducibility…",
    "section": "",
    "text": "Frontmatter check"
  },
  {
    "objectID": "blog-2023/Blog-5-submissions/Starwiiin/index.html#prompt",
    "href": "blog-2023/Blog-5-submissions/Starwiiin/index.html#prompt",
    "title": "Ethics and Reproducibility…",
    "section": "Prompt:",
    "text": "Prompt:\nIn May 2015 Science retracted - without consent of the lead author - a paper on how canvassers can sway people’s opinions about gay marriage, see also: http://www.sciencemag.org/news/2015/05/science-retracts-gay-marriage-paper-without-agreement-lead-author-lacour The Science Editor-in-Chief cited as reasons for the retraction that the original survey data was not made available for independent reproduction of results, that survey incentives were misrepresented and that statements made about sponsorships turned out to be incorrect. The investigation resulting in the retraction was triggered by two Berkeley grad students who attempted to replicate the study and discovered that the data must have been faked.\nFiveThirtyEight has published an article with more details on the two Berkeley students’ work.\nMalicious changes to the data such as in the LaCour case are hard to prevent, but more rigorous checks should be built into the scientific publishing system. All too often papers have to be retracted for unintended reasons. Retraction Watch is a data base that keeps track of retracted papers (see the related Science magazine publication).\nRead the paper Ten Simple Rules for Reproducible Computational Research by Sandve et al.\nWrite a blog post addressing the questions:\n\nPick one of the papers from Retraction Watch that were retracted because of errors in the paper (you might want to pick a paper from the set of featured papers, because there are usually more details available). Describe what went wrong. Would any of the rules by Sandve et al. have helped in this situation?\n\nParvin’s answer: From the Retraction Watch website, among the top 10 most highly retracted papers, I picked the paper with the title of “Selective killing of cancer cells by a small molecule targeting the stress response to ROS”. This paper has been retracted because of issues and data availability related to Fig. 1d, and supplementary Fig. 31b. Basically, these two figures shows the results of the experiments that authors did; in the other words, authors summarized their results using showing the associations by graphical figures. Unfortunately, the authors did not provided the original data related to these two figures when the Nature asked them. The fact of not providing the original results of their experiment questioned the integrity and correctness of this study. Some of the authors agreed with the retraction while rest of the authors never reply to this letters. Based on the article with the tittle of “Ten Simple Rules for Reproducible Computational Research”, I think rule number 7 which is “Always Store Raw Data behind Plots” is the first helpful rule to this study. If the authors had saved the raw data related to the plots, they could share them. Then, possibly rule number 5 which is “Record All Intermediate Results, When Possible in Standardized Formats” could help them to have the intermediate and final results to defend from themselves. Then, rule number 10 which is “Provide Public Access to Scripts, Runs, and Results” could prevent any problem or suspicions related to the experiments.\n\nAfter reading the paper by Sandve et al. describe which rule you are most likely to follow and why, and which rule you find the hardest to follow and will likely not (be able to) follow in your future projects.\n\nParvin’s answer: I always follow all the rules except than rules number 4 and 10. For me, these two rules are not easy to follow because of some reasons. About rule number 4, I sometimes need to update my R or Anaconda version, or update some packages; keep tracking of theses details for each research parts is not easy for me because I may forget to do it while I am busy. About rule number 10, I often cannot publish my scripts and data because most of data set I use are not public. People must have grants and enrolled research projects, pay for the data to have them. THerefore, publishing the codes and data is limited."
  },
  {
    "objectID": "blog-2023/Blog-5-submissions/Starwiiin/index.html#submission",
    "href": "blog-2023/Blog-5-submissions/Starwiiin/index.html#submission",
    "title": "Ethics and Reproducibility…",
    "section": "Submission",
    "text": "Submission\n\nPush your changes to your repository.\nYou are ready to call it good, once all your github actions pass without an error. You can check on that by selecting ‘Actions’ on the menu and ensure that the last item has a green checkmark. The action for this repository checks the yaml of your contribution for the existence of the author name, a title, date and categories. Don’t forget the space after the colon! Once the action passes, the badge along the top will also change its color accordingly. As of right now, the status for the YAML front matter is:\n\n\n\n\nFrontmatter check\n\n\n---\nauthor: \"Your Name\"\ntitle: \"Specify your title\"\ndate: \"2023-02-23\"\ncategories: \"Ethics and Reproducibility...\"\n---"
  },
  {
    "objectID": "blog-2023/Blog-9-submissions/xyzyc/index.html#prompt",
    "href": "blog-2023/Blog-9-submissions/xyzyc/index.html#prompt",
    "title": "Fix TeamUNL",
    "section": "Prompt:",
    "text": "Prompt:\nFix one of the problems in one of our community packages at https://github.com/Stat585-at-ISU/lab-3-all-all-for-one-and-one-for-all, and write about it."
  },
  {
    "objectID": "blog-2023/Blog-9-submissions/xyzyc/index.html#instructions",
    "href": "blog-2023/Blog-9-submissions/xyzyc/index.html#instructions",
    "title": "Fix TeamUNL",
    "section": "Instructions:",
    "text": "Instructions:\nWhat we want to know is the exact warning or error message of the item you fixed, and a description of what you did, also as specific as possible.\nDescribe your experience below. Push this blog post to your blog-9 repo. Make sure the front matter check passes.\nWhich error or warning did you fix? … and how?\nBefore the spring break, I fixed several things for TeamUNL:\n\nBy adding ^presslog.*\\.pdf$ to the .RBuildignore file, the check function will ignore the pdf files in the R package folder.\nI created a global.R file in the R folder inside the package, and write a line utils::globalVariables(c(\"presslog_ames\")) to avoid the global variable binding problem. The package passed the check with no problems. In this blog, I switched to the method used in class, i.e., add presslog_ames <- NULL and data(presslog_ames, envir  = enviroment()) to the function, and specify importFrom utils data.\nFix the dependencies by writing appropriate importFrom argument in front of the functions.\n\nIn this blog, when I try function call get_presslog (\"2023-02-14\", to = \"2023-02-14\"), I get error “character string is not in a standard unambiguous format”. The function get_presslog is written for presslog_ames.rda where the Call Received Date/Time is a date object. However, the Call Received Date/Time in the current file is character. So I updated the dataset."
  },
  {
    "objectID": "blog-2023/Blog-9-submissions/kundan7kumar/index.html#prompt",
    "href": "blog-2023/Blog-9-submissions/kundan7kumar/index.html#prompt",
    "title": "Error Fixing for the package",
    "section": "Prompt:",
    "text": "Prompt:\nFix one of the problems in one of our community packages at https://github.com/Stat585-at-ISU/lab-3-all-all-for-one-and-one-for-all, and write about it."
  },
  {
    "objectID": "blog-2023/Blog-9-submissions/kundan7kumar/index.html#instructions",
    "href": "blog-2023/Blog-9-submissions/kundan7kumar/index.html#instructions",
    "title": "Error Fixing for the package",
    "section": "Instructions:",
    "text": "Instructions:\nWhat we want to know is the exact warning or error message of the item you fixed, and a description of what you did, also as specific as possible.\nSolution:\nThe error, i am getting Error in purrr::map(): ℹ In index: 1. Caused by error: ! HTTP error 401. Bad credentials\nRate limit remaining: 59/60 Rate limit reset at: 2023-03-29 03:21:47 UTC\nDescribe your experience below. Push this blog post to your blog-9 repo. Make sure the front matter check passes.\nWhich error or warning did you fix? … and how? I tried fixing the error by setting the key the github but it is not working. I am not sure what causing the error.I have key set up earlier,it is working fine for others.\nError: Consider adding importFrom(“utils”, “download.file”, “write.csv”) to your NAMESPACE file.\nFinally, I fixed the error and able to fix few warning and notes check for Team3.\n\nI have changed separate(Call_Received_Date_Time) function to separate(‘Call_Received_Date_Time’) as it is unable to recognize the variable globally.\nI have included the few imports and param in the R file like #’ @importFrom utils download.file\n\n#’ @importFrom magrittr %>%\n#’ @importFrom lubridate ymd_hms\n#’ @importFrom pdftools pdf_text\n#’ @importFrom stringr str_replace_all\n#’ @param pdf name of pdf with data\n#’ @param save_as optional for saving a csv file\nThis helps to fix the 2 notes to 0 notes , but unable to fix the 2 warning."
  },
  {
    "objectID": "blog-2023/Blog-9-submissions/anyeshar/index.html",
    "href": "blog-2023/Blog-9-submissions/anyeshar/index.html",
    "title": "Fixing thing from Lab 2",
    "section": "",
    "text": "Fix one of the problems in one of our community packages at https://github.com/Stat585-at-ISU/lab-3-all-all-for-one-and-one-for-all, and write about it."
  },
  {
    "objectID": "blog-2023/Blog-9-submissions/anyeshar/index.html#instructions",
    "href": "blog-2023/Blog-9-submissions/anyeshar/index.html#instructions",
    "title": "Fixing thing from Lab 2",
    "section": "Instructions:",
    "text": "Instructions:\nWhat we want to know is the exact warning or error message of the item you fixed, and a description of what you did, also as specific as possible.\nDescribe your experience below. Push this blog post to your blog-9 repo. Make sure the front matter check passes.\nWhich error or warning did you fix? … and how? Warning: cannot open file ‘presslog-20230306.csv’: No such file or directoryError in file(file, “rt”) : cannot open the connection\nThis was due to the fact that we updated the presslog date to the current day we were working on it. That means if we used it a different day, it would be outdated. I changed the file it was looking for to be a general press log file. It did not have a specific date attatched.\nget_presslog <- function(from, to) { df <- utils::read.csv(“presslog-%s%02d%02d.csv”) # Change the date to be today’s date df[c(‘Date’, ‘Time’)] <- stringr::str_split_fixed(df\\(Call.Received.Date.Time, ' ', 2)  calls <- df[df\\)Date >= from & df$Date <= to, ] print(calls)\nWhile this isn’t an absolute solution because it depends on the previous function to save as presslog-%s%02d%02d.csv. This does work for any date and we will not have to change the date every time."
  },
  {
    "objectID": "blog-2023/Blog-9-submissions/Landon-Getting/index.html",
    "href": "blog-2023/Blog-9-submissions/Landon-Getting/index.html",
    "title": "Solving package problems!",
    "section": "",
    "text": "Frontmatter check\n\n\n\nWhich error or warning did you fix? … and how?\nAfter running devtools::check() for Team 3, I received several errors regarding a lack of visible bindings or variable definitions. I decided to focus on the errors regarding the get_presslog function:\n\nget_presslog: no visible binding for global variable ‘presslog_ames’\nget_presslog: no visible global function definition for ‘ymd’\nget_presslog: no visible global function definition for ‘%>%’\nget_presslog: no visible binding for global variable ‘Call_Received_Date’`\n\nI fixed the first error by specifically referencing the package of origin for the presslog_ames data object.\nTeam3::presslog_ames rather than presslog_ames.\nNext, I added similar references for all instances of the ymd() function.\nlubridate::ymd() rather than ymd().\nWhile attempting to solve the final warning for the get_presslog function, I ran into a plethora of issues. I added the prefix .data$ to eliminate the visible binding problem, but then I needed to add @importFrom rlang .data to the roxygen comments.\n.data$Call_Received_Date rather than Call_Received_Date\nOnce I added the @importFrom tag, ran devtools::document(), and added rlang to the description file, I thought I was in the clear. However, I received the following error when performing the check:\nNo root directory found in C:/Users/[my directories]/lab-3-all-all-for-one-and-one-for-all oits parent     directories. Root criterion: contains a file \"DESCRIPTION\" with contents matching \"^Package:\nI struggled with this problem but figured out that the description file had a small error in it. Instead of imports:, the description file had import: which caused not to recognize the following packages to import.\nAfter fixing this error, I ran devtools::check() and the get_presslog binding or definition issues were resolved."
  },
  {
    "objectID": "blog-2023/Blog-9-submissions/Hiiiua/index.html",
    "href": "blog-2023/Blog-9-submissions/Hiiiua/index.html",
    "title": "Fix a warning in CMD check",
    "section": "",
    "text": "Frontmatter check"
  },
  {
    "objectID": "blog-2023/Blog-9-submissions/Hiiiua/index.html#prompt",
    "href": "blog-2023/Blog-9-submissions/Hiiiua/index.html#prompt",
    "title": "Fix a warning in CMD check",
    "section": "Prompt:",
    "text": "Prompt:\nFix one of the problems in one of our community packages at https://github.com/Stat585-at-ISU/lab-3-all-all-for-one-and-one-for-all, and write about it."
  },
  {
    "objectID": "blog-2023/Blog-9-submissions/Hiiiua/index.html#instructions",
    "href": "blog-2023/Blog-9-submissions/Hiiiua/index.html#instructions",
    "title": "Fix a warning in CMD check",
    "section": "Instructions:",
    "text": "Instructions:\nWhat we want to know is the exact warning or error message of the item you fixed, and a description of what you did, also as specific as possible.\nDescribe your experience below. Push this blog post to your blog-9 repo. Make sure the front matter check passes.\nWhich error or warning did you fix? … and how?\nmy answer\nThe warning message from the item I fixed is\n❯ checking dependencies in R code ... WARNING   '::' or ':::' import not declared from: ‘purrr’\nThis must results from using a function from `purrr` package with import missing, so I went to the R code, spotted the function with code purrr:: . In the function defined there, I added one line with #' @import purrr, ran the function devtool::document to make sure `NAMESPACE` is properly updated, I also update Imports in DESCRIPTION.\nThis is an easy warning to fixed as long as familiarizing with the documentation process in R package and being able to find the function loaded the package."
  },
  {
    "objectID": "blog-2023/Blog-9-submissions/charlestbonk/index.html#prompt",
    "href": "blog-2023/Blog-9-submissions/charlestbonk/index.html#prompt",
    "title": "Stat 585",
    "section": "Prompt:",
    "text": "Prompt:\nFix one of the problems in one of our community packages at https://github.com/Stat585-at-ISU/lab-3-all-all-for-one-and-one-for-all, and write about it."
  },
  {
    "objectID": "blog-2023/Blog-9-submissions/charlestbonk/index.html#instructions",
    "href": "blog-2023/Blog-9-submissions/charlestbonk/index.html#instructions",
    "title": "Stat 585",
    "section": "Instructions:",
    "text": "Instructions:\nWhat we want to know is the exact warning or error message of the item you fixed, and a description of what you did, also as specific as possible.\nDescribe your experience below. Push this blog post to your blog-9 repo. Make sure the front matter check passes.\nWhich error or warning did you fix? … and how?"
  },
  {
    "objectID": "blog-2023/Blog-9-submissions/TWiedRW/index.html#prompt",
    "href": "blog-2023/Blog-9-submissions/TWiedRW/index.html#prompt",
    "title": "Errors and warnings in packages",
    "section": "Prompt:",
    "text": "Prompt:\nFix one of the problems in one of our community packages at https://github.com/Stat585-at-ISU/lab-3-all-all-for-one-and-one-for-all, and write about it.\nThe error that I fixed is not actually one that R detected. When I was finding errors in the various packages, I noticed that the file names when downloading the pdf file from Team6 attached “NULL” to the end of the file name. The output came from the get_pd_presslog function. This was easily fixed by changing the cat function into paste.\n\n#Original line\nprint(cat('Some text:', 'user input'))\n\nSome text: user inputNULL\n\n#New line\nprint(paste('Some text:', 'user input'))\n\n[1] \"Some text: user input\"\n\n\nThe problem with these types of errors is that they can sometimes go unnoticed when writing code.\nThere was one other error that I fixed. The function arguments for the url and save locations were assigned immediately inside the function, so any user input for these arguments would be ignored.\n\n#Original format\nfunction(arg1, arg2){\n  arg1 <- 'Some default url'\n  arg2 <- 'Some default save location'\n  #Rest of function here\n}\n\n#New format\nfunction(arg1 = 'Some default url', arg2 = 'Some default save location'){\n  #Rest of function here\n}\n\nAgain, this is an error that R would not alert users of since it computationally does not produce any warnings or errors. In this case, the danger would be old files with the same name would be replaced when running the function again. The url for the source would not change, but it is better to put the default into the function argument rather than writing over the argument in the code."
  },
  {
    "objectID": "blog-2023/Blog-9-submissions/charchit/index.html#prompt",
    "href": "blog-2023/Blog-9-submissions/charchit/index.html#prompt",
    "title": "all-for-one",
    "section": "Prompt:",
    "text": "Prompt:\nFix one of the problems in one of our community packages at https://github.com/Stat585-at-ISU/lab-3-all-all-for-one-and-one-for-all, and write about it."
  },
  {
    "objectID": "blog-2023/Blog-9-submissions/charchit/index.html#instructions",
    "href": "blog-2023/Blog-9-submissions/charchit/index.html#instructions",
    "title": "all-for-one",
    "section": "Instructions:",
    "text": "Instructions:\nWhat we want to know is the exact warning or error message of the item you fixed, and a description of what you did, also as specific as possible.\nDescribe your experience below. Push this blog post to your blog-9 repo. Make sure the front matter check passes.\nWhich error or warning did you fix? … and how? Fixed the warning for Team 3. While installing the team 3 package, it was giving warning for Rcurl function we used to read the URL, when we first started working on “lab-3-all-all-for-one-and-one-for-all”. So after adding the @import packages in description file, and importing all and updates in the namespace file the warnings were eliminated. Then later on while installing the package, it was giving warning that stat::filter was replacing the dplyr::filter. So we used dplyr::filter instead of “filter” to remove the stat::filter warning when installing the package.\nExperience: Fixing this was more frustrating than writing the code the first time. Specially when we wrote the code as a team. I forgot a lot of the things we did when building the package first time. Reproducibility seems very important even when working on a small project like this. I watched the lectures again to recall what we did and how Dr. Hofmann fixed some things in the class. The challenge is, it takes more time to document all the things we have done. It is a combination of laziness and calling some things just “good enough” and move on, instead of willing to sit down and write the documentation. I definitely think it is more important to document and write the things we have done during the code, hopefully I can change my habit of documenting as I go along in my research. Thanks for introducing this."
  },
  {
    "objectID": "blog-2023/Blog-9-submissions/kellynay/index.html#prompt",
    "href": "blog-2023/Blog-9-submissions/kellynay/index.html#prompt",
    "title": "Fixing Package Errors",
    "section": "Prompt:",
    "text": "Prompt:\nFix one of the problems in one of our community packages at https://github.com/Stat585-at-ISU/lab-3-all-all-for-one-and-one-for-all, and write about it."
  },
  {
    "objectID": "blog-2023/Blog-9-submissions/kellynay/index.html#instructions",
    "href": "blog-2023/Blog-9-submissions/kellynay/index.html#instructions",
    "title": "Fixing Package Errors",
    "section": "Instructions:",
    "text": "Instructions:\nWhat we want to know is the exact warning or error message of the item you fixed, and a description of what you did, also as specific as possible.\nDescribe your experience below. Push this blog post to your blog-9 repo. Make sure the front matter check passes.\nWhich error or warning did you fix? … and how?\nI worked with my Lab3 - Team 3 colleagues to fix some of the issues highlighted by Ganesh when he graded our lab assignment.\nExact warning message: Warning: replacing previous import ‘dplyr::filter’ by ‘stats::filter’ when loading ‘Team3’ ** testing if installed package can be loaded from final location Warning: replacing previous import ‘dplyr::filter’ by ‘stats::filter’ when loading ‘Team3’ ** testing if installed package keeps a record of temporary installation path\nThe get_presslog function was throwing a warning due to the following (Line 19 in get_presslog.R):\n\ndata_subset <- data %>% filter(Call_Received_Date >= from2) %>% filter(Call_Received_Date <= to2)\n\nWe fixed the error by doing:\n\ndata_subset <- data %>% dplyr::filter(Call_Received_Date >= from2) %>% dplyr::filter(Call_Received_Date <= to2)\n\nIn summary, we replaced ‘stats::filter’ by ‘dplyr::filter’.\nWe also addressed this issue in the NAMESPACE file by writing on Line 12: importFrom(“stats”, “filter”)"
  },
  {
    "objectID": "blog-2023/Blog-9-submissions/drbradford12/index.html#prompt",
    "href": "blog-2023/Blog-9-submissions/drbradford12/index.html#prompt",
    "title": "Stat 585",
    "section": "Prompt:",
    "text": "Prompt:\nFix one of the problems in one of our community packages at https://github.com/Stat585-at-ISU/lab-3-all-all-for-one-and-one-for-all, and write about it."
  },
  {
    "objectID": "blog-2023/Blog-9-submissions/drbradford12/index.html#instructions",
    "href": "blog-2023/Blog-9-submissions/drbradford12/index.html#instructions",
    "title": "Stat 585",
    "section": "Instructions:",
    "text": "Instructions:\nWhat we want to know is the exact warning or error message of the item you fixed, and a description of what you did, also as specific as possible.\nDescribe your experience below. Push this blog post to your blog-9 repo. Make sure the front matter check passes.\nWhich error or warning did you fix? … and how?"
  },
  {
    "objectID": "blog-2023/Blog-9-submissions/HarunCelikOtto/index.html",
    "href": "blog-2023/Blog-9-submissions/HarunCelikOtto/index.html",
    "title": "Undefined Object Error",
    "section": "",
    "text": "Frontmatter check"
  },
  {
    "objectID": "blog-2023/Blog-9-submissions/HarunCelikOtto/index.html#prompt",
    "href": "blog-2023/Blog-9-submissions/HarunCelikOtto/index.html#prompt",
    "title": "Undefined Object Error",
    "section": "Prompt:",
    "text": "Prompt:\nFix one of the problems in one of our community packages at https://github.com/Stat585-at-ISU/lab-3-all-all-for-one-and-one-for-all, and write about it."
  },
  {
    "objectID": "blog-2023/Blog-9-submissions/HarunCelikOtto/index.html#instructions",
    "href": "blog-2023/Blog-9-submissions/HarunCelikOtto/index.html#instructions",
    "title": "Undefined Object Error",
    "section": "Instructions:",
    "text": "Instructions:\nWhat we want to know is the exact warning or error message of the item you fixed, and a description of what you did, also as specific as possible.\nMy search for an error was to try and load all of the packages to then run checks on them to see which ones I could immediately jump into. I definitely didn’t go in numerical order but I did find that I got an error after trying devtools::load_all(\"Team6/\"). The exact message can be seen from the screenshot below.\n\n\n\nFirst Error on `load_all()`\n\n\nI could see from the console that the error was in the get_pd_presslog() function of the package. Running rlang::last_trace() and opening up the get_pd_presslog() function document I found the following.\n\n\n\nTraceback Error and Function\n\n\nThe Traceback mentioned that the error was in an object called “link”. Checking the function file, I found that there was an instance where the function was called with a variable called “link” which was supposed to supply the {url} argument to the function.\nThe first problem is that the variable “link” is assigned after the function is called so download.file() doesn’t have a {url} argument supplied to it. This causes the function to fail and therefore load_all() fails to run.\nThe second problem is that there is no need to call the get_pd_presslog() function in the function documentation. That is better reserved for a testing environment set up with usethis::use_testthat().\nMy goal was only to have the package load properly so removing those two lines allowed me to load the package and run a devtools::check() without any problems. Here are the results.\n\n\n\nPackage loaded and check() output"
  },
  {
    "objectID": "blog-2023/Blog-9-submissions/valeriehan6/index.html#prompt",
    "href": "blog-2023/Blog-9-submissions/valeriehan6/index.html#prompt",
    "title": "Fixing a note",
    "section": "Prompt:",
    "text": "Prompt:\nFix one of the problems in one of our community packages at https://github.com/Stat585-at-ISU/lab-3-all-all-for-one-and-one-for-all, and write about it."
  },
  {
    "objectID": "blog-2023/Blog-9-submissions/valeriehan6/index.html#instructions",
    "href": "blog-2023/Blog-9-submissions/valeriehan6/index.html#instructions",
    "title": "Fixing a note",
    "section": "Instructions:",
    "text": "Instructions:\nWhat we want to know is the exact warning or error message of the item you fixed, and a description of what you did, also as specific as possible.\nDescribe your experience below. Push this blog post to your blog-9 repo. Make sure the front matter check passes.\nWhich error or warning did you fix? … and how?\nI fixed a note in Team 2’s package. The note was\nchecking top-level files ... NOTE\n  Non-standard file/directory found at top level:\n    ‘presslog_amespd_2023-03-07.pdf’\nI looked up the note on Google and found a Stack Overflow post describing a similar issue. I then resolved the note by adding ^presslog_amespd_2023-03-07\\.pdf$ to the .Rbuildignore file."
  },
  {
    "objectID": "blog-2023/Blog-9-submissions/IanParzyszek/index.html#prompt",
    "href": "blog-2023/Blog-9-submissions/IanParzyszek/index.html#prompt",
    "title": "Trying to Make the World a Better Place",
    "section": "Prompt:",
    "text": "Prompt:\nFix one of the problems in one of our community packages at https://github.com/Stat585-at-ISU/lab-3-all-all-for-one-and-one-for-all, and write about it."
  },
  {
    "objectID": "blog-2023/Blog-9-submissions/IanParzyszek/index.html#instructions",
    "href": "blog-2023/Blog-9-submissions/IanParzyszek/index.html#instructions",
    "title": "Trying to Make the World a Better Place",
    "section": "Instructions:",
    "text": "Instructions:\nWhat we want to know is the exact warning or error message of the item you fixed, and a description of what you did, also as specific as possible.\nDescribe your experience below. Push this blog post to your blog-9 repo. Make sure the front matter check passes.\nWhich error or warning did you fix? … and how?\nFor team number 1 when I ran the devtools::check() I recieved this error message:\nRunning the tests in ‘tests/testthat.R’ failed. Last 13 lines of output: > # * https://r-pkgs.org/tests.html > # * https://testthat.r-lib.org/reference/test_package.html#special-files > > library(testthat) > library(Team1) > > test_check(“Team1”) Error in test_dir(): ! No test files found\nI then did some googling and found that Hadly had tried to answer this question for someone on github in 2015, and mentioned that there may be something wrong with the directory. Still not having any luck, I decided to look at Team2, lucky enough theirs ran without error. The only major difference that I saw at the surface was that Team1 had a testfile and Team2 did not. The only thing was that Team1 did not have any test in the test file. My solution was simply removing the “test” folder from the directory, I reran it, and received no errors."
  },
  {
    "objectID": "blog-2023/Blog-9-submissions/loganjohnson0/index.html#prompt",
    "href": "blog-2023/Blog-9-submissions/loganjohnson0/index.html#prompt",
    "title": "All For One",
    "section": "Prompt:",
    "text": "Prompt:\nFix one of the problems in one of our community packages at https://github.com/Stat585-at-ISU/lab-3-all-all-for-one-and-one-for-all, and write about it."
  },
  {
    "objectID": "blog-2023/Blog-9-submissions/loganjohnson0/index.html#instructions",
    "href": "blog-2023/Blog-9-submissions/loganjohnson0/index.html#instructions",
    "title": "All For One",
    "section": "Instructions:",
    "text": "Instructions:\nWhat we want to know is the exact warning or error message of the item you fixed, and a description of what you did, also as specific as possible.\nDescribe your experience below. Push this blog post to your blog-9 repo. Make sure the front matter check passes.\nWhich error or warning did you fix? … and how?\nThe error messages that I fixed were within the Team2 package and included various import requirements in NAMESPACE and the DESCRIPTION files. To fix these issues, I added in the “@importFrom” component to the function to the pdf_to_tbl package for the utils and magrittr packages for the write.csv and %>% functions, respectively. I also added the libraries to the functions that were called within the R package to make more clear where each function is intended to be pulled from. I then documented these changes and loaded the package again.\nThere was also an issue in the pdf_to_tbl function where “.,” as a global variable was not defined. In this instance, I simply removed the “.,” from the pdf_to_tbl function as the data was already being piped from the area above and the “.,” notation was not necessary.\nI also fixed two issues that I found when running the package. I removed the exact url from the input section of the function and instead put it at the top of the area within the section. I also changed the format of the save_as function and instead removed the “./data/” part of the save_as function to improve the saving of the pdf files."
  },
  {
    "objectID": "blog-2023/Blog-9-submissions/Atefeha1995/index.html#prompt",
    "href": "blog-2023/Blog-9-submissions/Atefeha1995/index.html#prompt",
    "title": "Errors and warnings in packages",
    "section": "Prompt:",
    "text": "Prompt:\nFix one of the problems in one of our community packages at https://github.com/Stat585-at-ISU/lab-3-all-all-for-one-and-one-for-all, and write about it."
  },
  {
    "objectID": "blog-2023/Blog-9-submissions/Atefeha1995/index.html#instructions",
    "href": "blog-2023/Blog-9-submissions/Atefeha1995/index.html#instructions",
    "title": "Errors and warnings in packages",
    "section": "Instructions:",
    "text": "Instructions:\nWhat we want to know is the exact warning or error message of the item you fixed, and a description of what you did, also as specific as possible.\nDescribe your experience below. Push this blog post to your blog-9 repo. Make sure the front matter check passes.\nWhich error or warning did you fix? … and how?\nFor team 4, I ran check(“Team4”), and this was the result:\n❯ checking dependencies in R code ... NOTE Namespaces in Imports field not imported from:   'readr' 'stringr' All declared Imports should be used.\n0 errors ✔ | 0 warnings ✔ | 1 note ✖\nSo, I changed the Imports set in Description file, and omitted ‘readr’ and ‘stringr’. It seems that these packages were not required. Here is the new result for check(“Team4”) command:\n0 errors ✔ | 0 warnings ✔ | 0 notes ✔\nFor Team6, When I ran document(“Team6”), I got this error message:\n> document(\"Team6\") ℹ Updating Team6 documentation ℹ Loading Team6 Warning message: [press_log_data.R:15] @source requires a value\nThen I went to press_log_data.R file, and I checked row number 15. It seems that they forgot to add an appropriate source there. So, I added the source of the data there. Then, I ran the command one more time and the problem has been solved.\n> document(\"Team6\") ℹ Updating Team6 documentation ℹ Loading Team6 Writing press_log_data.Rd\nThis was the note when I ran check(“Team6”):\n❯ checking top-level files ... NOTE Non-standard files/directories found at top level:  'presslog-20230306.csv' 'presslog_amespd_2023-03-06.pdf'\n0 errors ✔ | 1 warning ✖ | 1 note ✖\nI deleted those two extra files (presslog-20230306.csv and presslog_amespd_2023-03-06.pdf), and the note has been removed.\n0 errors ✔ | 1 warning ✖ | 0 notes ✔\nFor Team2, when I ran check(“Team2”), I got this error:\n> check(\"Team2\") ℹ Updating Team2 documentation ℹ Loading Team2 Error: 'ames_presslog' is not an exported object from 'namespace:Team2'\nI checked and found that ‘ames_presslog’ is not exported in namespace, and it is not in man files. So, I deleted the ‘ames_presslog.R’ from the R folder, and it’s data from the Data folder. Then, I ran check() command again, and this was the result:\n0 errors ✔ | 4 warnings ✖ | 2 notes ✖\nthis was one of the warning messages:\n❯ checking Rd \\usage sections ... WARNING Undocumented arguments in documentation object 'get_presslog' 'date.column' Functions with \\usage entries need to have the appropriate \\alias entries, and all their arguments documented. The \\usage entries must correspond to syntactically valid R code. See chapter 'Writing R documentation files' in the 'Writing R  Extensions' manual.\nconsidering the message I went to the get_presslog.R file in the R folder of the Team2 package, and I added the date.column which is one of the inputs for the get_presslog function, as a parameter using the command line below.\n#' @param date.column The column which contains the Date and time\nI saved the changes, and checked it again. The number of warnings was reduced to 3.\n0 errors ✔ | 3 warnings ✖ | 2 notes ✖"
  },
  {
    "objectID": "blog-2023/Blog-9-submissions/anphan0828/index.html#prompt",
    "href": "blog-2023/Blog-9-submissions/anphan0828/index.html#prompt",
    "title": "The painful green ticks",
    "section": "Prompt:",
    "text": "Prompt:\nFix one of the problems in one of our community packages at https://github.com/Stat585-at-ISU/lab-3-all-all-for-one-and-one-for-all, and write about it.\nWhich error or warning did you fix? … and how?\nI chose Team2’s package to fix and enjoyed the pain. I used devtools to install, load, document, check, and repeated all over again.\nFirst try, 2 notes (seems easy to solve!):\n\nNon-standard file/directory found at top level: easy, put the .pdf extension in .Rbuildignore\nUndefined global functions or variables: %>% . download.file presslog_ames write.csv. I went to each R source file and added @importFrom (e.g., purrr %>%, utils download.file, utils write.csv), then rerun devtools::document() to update the NAMESPACE file. For the dot (“.”), I could not figure out which package it came from, so I had to edit the code to not use “.” within an lapply function. For the presslog_ames dataset, it was not loaded into the environment before using, so I declared it.\n\nSecond try, 1 error (that is worse than 2 notes!):\n\nNamespace dependency missing from DESCRIPTION Imports/Depends entries: purrr. So, it gets imported previously, but the DESCRIPTION file did not have that information (I felt weird that devtools::document() only updates NAMESPACE, not DESCRIPTION. I went ahead and manually added purrr under Imports.\n\nThird try, 1 warning (I’m getting there!!):\n\nDocumented arguments not in in documentation object ‘get_presslog’: ‘df’. I wasn’t sure about the @usage tag, so I just override the argument df passed into the function with the presslog_ames data (not the best way, but it works)\n\nFourth try (I lied, it took me way many more times to reach here but I only describe the main problems): SUCCESS!! 0 errors, 0 warnings, 0 notes!"
  },
  {
    "objectID": "blog-2023/Blog-9-submissions/hardtme/index.html#prompt",
    "href": "blog-2023/Blog-9-submissions/hardtme/index.html#prompt",
    "title": "I Fixed It!",
    "section": "Prompt:",
    "text": "Prompt:\nFix one of the problems in one of our community packages at https://github.com/Stat585-at-ISU/lab-3-all-all-for-one-and-one-for-all, and write about it."
  },
  {
    "objectID": "blog-2023/Blog-9-submissions/hardtme/index.html#instructions",
    "href": "blog-2023/Blog-9-submissions/hardtme/index.html#instructions",
    "title": "I Fixed It!",
    "section": "Instructions:",
    "text": "Instructions:\nWhat we want to know is the exact warning or error message of the item you fixed, and a description of what you did, also as specific as possible.\nDescribe your experience below. Push this blog post to your blog-9 repo. Make sure the front matter check passes.\nWhich error or warning did you fix? … and how?\nI fixed the following note from my lab 3 group’s TwoTeam4 package (This package was so named because it was my group’s second attempt at a package, and was an improvement over the first version, Team4):\n> checking R code for possible problems ... NOTE\n  get_pd_presslog: no visible global function definition for\n    ‘download.file’\n  get_presslog: no visible binding for global variable ‘plog_df’\n  get_presslog: no visible binding for global variable ‘Call Received\n    Date/Time’\n  get_presslog: no visible binding for global variable ‘NewDate’\n  pdf_to_tbl: no visible binding for global variable ‘tail’\n  pdf_to_tbl: no visible global function definition for ‘write.csv’\n  Undefined global functions or variables:\n    Call Received Date/Time NewDate download.file plog_df tail write.csv\n  Consider adding\n    importFrom(\"utils\", \"download.file\", \"tail\", \"write.csv\")\n  to your NAMESPACE file.\nMy first step was to go into the get_pd_presslog and get_presslog functions and add utils:: in front of the functions that were mentioned in the note. For example, instead of download.file, the get_pd_presslog function now includes utils::download.file. Since the functions were short, I preferred to account for each manually instead of using an importFrom() statement in the NAMESPACE file.\nAfter completing the first step, my note was reduced to\nchecking R code for possible problems ... NOTE\n  get_presslog: no visible binding for global variable ‘plog_df’\n  get_presslog: no visible binding for global variable ‘Call Received\n    Date/Time’\n  get_presslog: no visible binding for global variable ‘NewDate’\n  Undefined global functions or variables:\n    Call Received Date/Time NewDate plog_df\nI next wanted to remove the “no visible binding for global variable” notes. These notes of this type referring to “Call Received Date/Time” and “NewDate” were coming from code using tidyverse functions, so I followed the suggestion at this link to include the .data pronoun from rlang. This produced an error since rlang was not listed as a dependency in the DESCRIPTION file for the package. I added rlang as an import and the error went away.\nAfter adding the .data pronoun to the get_presslog function, the note was reduced to\n> checking R code for possible problems ... NOTE\n  get_presslog: no visible binding for global variable ‘plog_df’\n  Undefined global functions or variables:\n    plog_df\nTo solve the last part of the note, I added the line of code plog_df <- TwoTeam4::plog_df to the get_presslog function. This tells R that we want the TwoTeam4 version of plog_df.\nAfter all these fixes, R CMD Check finished with 0 errors, 0 warnings, and 0 notes. Yay!"
  },
  {
    "objectID": "blog-2023/Blog-9-submissions/santos-cl/index.html#prompt",
    "href": "blog-2023/Blog-9-submissions/santos-cl/index.html#prompt",
    "title": "Fixing a thing",
    "section": "Prompt:",
    "text": "Prompt:\nFix one of the problems in one of our community packages at https://github.com/Stat585-at-ISU/lab-3-all-all-for-one-and-one-for-all, and write about it."
  },
  {
    "objectID": "blog-2023/Blog-9-submissions/santos-cl/index.html#instructions",
    "href": "blog-2023/Blog-9-submissions/santos-cl/index.html#instructions",
    "title": "Fixing a thing",
    "section": "Instructions:",
    "text": "Instructions:\nWhat we want to know is the exact warning or error message of the item you fixed, and a description of what you did, also as specific as possible.\nDescribe your experience below. Push this blog post to your blog-9 repo. Make sure the front matter check passes.\nWhich error or warning did you fix? … and how?\nFor this week’s blog, I decided to keep working on the Team2 package. The warning I identified dealt with us forgetting to include a library in the Imports section of the description, and using library within the functions. The error would be similar to the following message:\n checking dependencies in R code ... WARNING\n  'library' or 'require' calls not declared from:\n    'tabulizer' 'tidyverse'\n  'library' or 'require' calls in package code:\n    'tabulizer' 'tidyverse'\n    Please use :: or requireNamespace() instead.\n    See section 'Suggested packages' in the 'Writing R Extensions' manual.\nThe reason for this was that within the function pdf_to_table we were importing the library, like this:\npdf_to_tbl <- function(pdf, save_as = NULL) {\n\n  library(tidyverse)       <--------- This command was problematic\n  library(tabulizer)       <--------- This command was problematic\n \n  plog <- tabulizer::extract_tables(file = pdf, method = \"lattice\")\n  df <- lapply(plog, extract_data_frame_page)\n\n  # identify the numeric columns, since some pages miss all \"Report Number Assigned to Event\"\n  n <- length(df)\n  numeric_columns <- df %>% lapply(., function(x)sapply(x, class)) %>%\n    lapply(., function(x)which(x == \"numeric\")) %>%\n    unlist %>% unique\n\n  ## Combining the different pages\n  df <- do.call(rbind, df)\n  df[numeric_columns] <- suppressWarnings(lapply(df[numeric_columns], function(x)as.numeric(x)))\n\n  if (!is.null(save_as) && dir.exists(dirname(save_as))){\n    utils::write.csv(df, save_as, row.names = FALSE)\n  }\n\n  return(df)\n\n}\n\n\nI did three things to clear this warning: - Substitute the tidyverse call for the magrittr - Check if the name spaces “magrittr” and “tabulize” were available - In case they were, load the name space - Add magrittr and tabulizer to the Imports seciton of the description file\nThe updated function is as it follows:\npdf_to_tbl <- function(pdf, save_as = NULL) {\n\n  \n  if(!requireNamespace(\"tabulizer\", quietly = TRUE)){\n    warning(\"The tabulizer package is required for this function\")\n    return(NULL)\n  }\n  \n  if(!requireNamespace(\"magrittr\", quietly = TRUE)){\n    warning(\"The magrittr package is required for this function\")\n    return(NULL)\n  }\n  \n  \n  loadNamespace('magrittr')\n \n  \n  \n  plog <- tabulizer::extract_tables(file = pdf, method = \"lattice\")\n  df <- lapply(plog, extract_data_frame_page)\n\n  # identify the numeric columns, since some pages miss all \"Report Number Assigned to Event\"\n  n <- length(df)\n  numeric_columns <- df %>% lapply(., function(x)sapply(x, class)) %>%\n    lapply(., function(x)which(x == \"numeric\")) %>%\n    unlist %>% unique\n\n  ## Combining the different pages\n  df <- do.call(rbind, df)\n  df[numeric_columns] <- suppressWarnings(lapply(df[numeric_columns], function(x)as.numeric(x)))\n\n  if (!is.null(save_as) && dir.exists(dirname(save_as))){\n    utils::write.csv(df, save_as, row.names = FALSE)\n  }\n\n  return(df)\n\n}\n\nThe description file now also contains the updated Imports section\nPackage: Team2\nTitle: Get police presslogs\nVersion: 0.0.0.9000\nAuthors@R: c(\n    person(\"Caio\", \"dos Santos\", , \"clsantos@iastate.edu\", role = c(\"aut\", \"cre\")),\n    person(\"Alexandrea\", \"Arabio\", , \"aarabio@iastate.edu\", role = \"aut\"),\n    person(\"Maxwell\", \"Skinner\", , \"mskinn25@iastate.edu\", role = \"aut\")\n  )\nDescription: This package contains 3 functions to download, extract, and\n    filter presslog data. Also, it contains a sample data set.\nLicense: MIT + file LICENSE\nEncoding: UTF-8\nRoxygen: list(markdown = TRUE)\nRoxygenNote: 7.2.3\nImports: \n    lubridate,\n    tabulizer,\n    magrittr\nDepends: \n    R (>= 2.10)\nLazyData: true\nLitrVersionUsed: 0.7.0\nLitrId: afd1fe153acf34706b65fe5d2dcc1315"
  },
  {
    "objectID": "blog-2023/Blog-9-submissions/sudi007/index.html#prompt",
    "href": "blog-2023/Blog-9-submissions/sudi007/index.html#prompt",
    "title": "Errors and warnings in packages",
    "section": "Prompt:",
    "text": "Prompt:\nFix one of the problems in one of our community packages at https://github.com/Stat585-at-ISU/lab-3-all-all-for-one-and-one-for-all, and write about it."
  },
  {
    "objectID": "blog-2023/Blog-9-submissions/sudi007/index.html#instructions",
    "href": "blog-2023/Blog-9-submissions/sudi007/index.html#instructions",
    "title": "Errors and warnings in packages",
    "section": "Instructions:",
    "text": "Instructions:\nWhat we want to know is the exact warning or error message of the item you fixed, and a description of what you did, also as specific as possible. The following was the warning i got\nget_pd_presslog: no visible global function definition for ‘download.file’ get_presslog: no visible binding for global variable ‘presslog_ames’ get_presslog: no visible global function definition for ‘ymd’ get_presslog: no visible global function definition for ‘%>%’ get_presslog: no visible global function definition for ‘filter’ get_presslog: no visible binding for global variable ‘Call_Received_Date’ pdf_to_tbl: no visible global function definition for ‘extract_tables’ pdf_to_tbl: no visible global function definition for ‘%>%’ pdf_to_tbl: no visible global function definition for ‘separate’ pdf_to_tbl: no visible binding for global variable ‘Call_Received_Date_Time’ pdf_to_tbl: no visible global function definition for ‘write.csv’ pdf_to_tbl: no visible global function definition for ‘as_tibble’ Undefined global functions or variables: %>% Call_Received_Date Call_Received_Date_Time as_tibble download.file extract_tables filter presslog_ames separate write.csv ymd Consider adding importFrom(“stats”, “filter”) importFrom(“utils”, “download.file”, “write.csv”) to your NAMESPACE file.\nThe way i fixed the error was to add the following to Namespace file importFrom(“stats”, “filter”) importFrom(“utils”, “download.file”, “write.csv”)\nI fixed the error in the following manner:\n1) I ran series of checks on the Team3 package using the devtools::check() to produce the error. \n\n2) Once the issue was identified, I observed that it was missing some import function on the name space file.\n\n3) To fix this warning message, I added importFrom() statements to the NAMESPACE file. These statements tell R which functions and variables from other packages are needed. In my case, I added importFrom() statements for the filter, download.file, and write.csv functions from the stats and utils packages.\nDescribe your experience below. Push this blog post to your blog-9 repo. Make sure the front matter check passes\nAlthough fixing the namespace issues can be challenging in R, it is an important step in developing a well-functioning and properly organized package. The goal of namespace management is to ensure that each function in your package can access the functions and the variables it needs from other packages, without polluting the global environment or causing conflicts with other packages. A key challenge I faced was to ensure that all the packages were correctly imported and defined. It was helpful that after making all the changes, there was a tool to recheck if there were any errors.\nWhich error or warning did you fix? … and how?"
  },
  {
    "objectID": "blog-2023/Blog-9-submissions/motinaaa/index.html#prompt",
    "href": "blog-2023/Blog-9-submissions/motinaaa/index.html#prompt",
    "title": "Green is the new Black",
    "section": "Prompt:",
    "text": "Prompt:\nFix one of the problems in one of our community packages at https://github.com/Stat585-at-ISU/lab-3-all-all-for-one-and-one-for-all, and write about it."
  },
  {
    "objectID": "blog-2023/Blog-9-submissions/motinaaa/index.html#instructions",
    "href": "blog-2023/Blog-9-submissions/motinaaa/index.html#instructions",
    "title": "Green is the new Black",
    "section": "Instructions:",
    "text": "Instructions:\nWhat we want to know is the exact warning or error message of the item you fixed, and a description of what you did, also as specific as possible.\nDescribe your experience below. Push this blog post to your blog-9 repo. Make sure the front matter check passes.\nWhich error or warning did you fix? … and how?\nFirstly, I did eeny meeny miny moe to pick a number, got 5, so I checked Team5 package:))\nI ran the check(), No warnings or errors, just some notes I saw. First note said all declared imports should be used. So I went to the description file and removed the mentioned packages from imports. Easy-peasy, fixed that note.\nNext note was about missing dependencies to other packages. Checked the .R code, and I added the dependencies in the description file under imports. Sorted!\nAnother note was about considering adding importFrom(\"stats\",\"filter\"). Addressed this by going to the .R file and adding dplyr:: before filter function. Then added @importFrom dplyr filter in the beginning of the file. After that, ran document() to build them in the NAMESPACE file and then ran check(). Fixed a bunch of these notes too!\nThen I tackled the global bindings and added \"Variable_Name\" <- \"Variable_Name\" <- NULL to the addressed functions. Tadaaaaa, green checkmarks all around for Team 5! Woohoo!\nI think I was supposed to fix just one of these notes, but my OCD kicked in and I ended up fixing them all. Just wanted to see those green marks! 😅"
  },
  {
    "objectID": "blog-2023/Blog-9-submissions/maxwellskinner2002/index.html#prompt",
    "href": "blog-2023/Blog-9-submissions/maxwellskinner2002/index.html#prompt",
    "title": "Stat 585",
    "section": "Prompt:",
    "text": "Prompt:\nFix one of the problems in one of our community packages at https://github.com/Stat585-at-ISU/lab-3-all-all-for-one-and-one-for-all, and write about it."
  },
  {
    "objectID": "blog-2023/Blog-9-submissions/maxwellskinner2002/index.html#instructions",
    "href": "blog-2023/Blog-9-submissions/maxwellskinner2002/index.html#instructions",
    "title": "Stat 585",
    "section": "Instructions:",
    "text": "Instructions:\nWhat we want to know is the exact warning or error message of the item you fixed, and a description of what you did, also as specific as possible.\nDescribe your experience below. Push this blog post to your blog-9 repo. Make sure the front matter check passes.\nWhich error or warning did you fix? … and how?"
  },
  {
    "objectID": "blog-2023/Blog-9-submissions/Sabrenar/index.html#prompt",
    "href": "blog-2023/Blog-9-submissions/Sabrenar/index.html#prompt",
    "title": "Package Errors and Warnings",
    "section": "Prompt:",
    "text": "Prompt:\nFix one of the problems in one of our community packages at https://github.com/Stat585-at-ISU/lab-3-all-all-for-one-and-one-for-all, and write about it."
  },
  {
    "objectID": "blog-2023/Blog-9-submissions/Sabrenar/index.html#instructions",
    "href": "blog-2023/Blog-9-submissions/Sabrenar/index.html#instructions",
    "title": "Package Errors and Warnings",
    "section": "Instructions:",
    "text": "Instructions:\nWhat we want to know is the exact warning or error message of the item you fixed, and a description of what you did, also as specific as possible.\nThe exact warning message: Warning message: Expected 2 pieces. Missing pieces filled with NA in 50 rows [1, 2, 3, 4, 5, 32, 33, 34, 35, 36, 63, 64, 65, 66, 67, 94, 95, 96, 97, 98, …]. I referenced the separate function’s documentation. Since the warning from a result from not finding 2 pieces for the separate function, I found the parameter that controls what the function does if it does not find the expected number of pieces. I then edited the line using the separate function such that the function now has a fill parameter that does not give a warning on default.\nDescribe your experience below. Push this blog post to your blog-9 repo. Make sure the front matter check passes.\nFixing these errors was straight-forward since I knew where the errors were coming from. I have used the separate function frequently so I recognized the warning message.\nWhich error or warning did you fix? … and how?\nPlease see the above answer."
  },
  {
    "objectID": "blog-2023/Blog-9-submissions/luobo119/index.html#prompt",
    "href": "blog-2023/Blog-9-submissions/luobo119/index.html#prompt",
    "title": "Problems in Building the R Package",
    "section": "Prompt:",
    "text": "Prompt:\nFix one of the problems in one of our community packages at https://github.com/Stat585-at-ISU/lab-3-all-all-for-one-and-one-for-all, and write about it."
  },
  {
    "objectID": "blog-2023/Blog-9-submissions/luobo119/index.html#instructions",
    "href": "blog-2023/Blog-9-submissions/luobo119/index.html#instructions",
    "title": "Problems in Building the R Package",
    "section": "Instructions:",
    "text": "Instructions:\nWhat we want to know is the exact warning or error message of the item you fixed, and a description of what you did, also as specific as possible.\nDescribe your experience below. Push this blog post to your blog-9 repo. Make sure the front matter check passes.\nWhich error or warning did you fix? … and how?\nWarning from Team2:\n\nchecking Rd files … WARNING\nprepare_Rd: ./man/presslog_ames.Rd:18: unexpected section header ‘\\source’\nprepare_Rd: ./man/presslog_ames.Rd:21: unexpected section header ‘\\usage’\nprepare_Rd: ./man/presslog_ames.Rd:24: unexpected section header ‘\\description’\nprepare_Rd: ./man/presslog_ames.Rd:27: unexpected section header ‘\\keyword’\nprepare_Rd: ./man/presslog_ames.Rd:28: unexpected END_OF_INPUT ’ ’ checkRd: (5) presslog_ames.Rd:0-29: Must have a \\description\n\nThis warning can be fixed by adding ‘}’ in presslog_ames.R. There is one ‘}’ missing for ‘\\describe’.\n\nchecking dependencies in R code … WARNING\n‘library’ or ‘require’ calls not declared from:\n‘tabulizer’ ‘tidyverse’\n‘library’ or ‘require’ calls in package code:\n‘tabulizer’ ‘tidyverse’\nPlease use :: or requireNamespace() instead.\nSee section ‘Suggested packages’ in the ‘Writing R Extensions’ manual.\n\nAdding ‘@importFrom tabulizer extract_tables’ and deleting ‘library(’tidyverse’)’ and ‘library(’tabulizer’)’ in the function in pdf_to_tbl.R."
  },
  {
    "objectID": "blog-2023/Blog-9-submissions/AArabio/index.html",
    "href": "blog-2023/Blog-9-submissions/AArabio/index.html",
    "title": "Fun with errors",
    "section": "",
    "text": "I was having a difficult time reconfigurating/rebuilding the all in this together - for some reason the project that I cloned stopped communicating with github and I have been working to reclone it but unfortunately it was not working … will continue to try tomorrow -"
  },
  {
    "objectID": "blog-2023/Blog-9-submissions/AArabio/index.html#prompt",
    "href": "blog-2023/Blog-9-submissions/AArabio/index.html#prompt",
    "title": "Fun with errors",
    "section": "Prompt:",
    "text": "Prompt:\nFix one of the problems in one of our community packages at https://github.com/Stat585-at-ISU/lab-3-all-all-for-one-and-one-for-all, and write about it."
  },
  {
    "objectID": "blog-2023/Blog-9-submissions/AArabio/index.html#instructions",
    "href": "blog-2023/Blog-9-submissions/AArabio/index.html#instructions",
    "title": "Fun with errors",
    "section": "Instructions:",
    "text": "Instructions:\nWhat we want to know is the exact warning or error message of the item you fixed, and a description of what you did, also as specific as possible.\nDescribe your experience below. Push this blog post to your blog-9 repo. Make sure the front matter check passes.\nWhich error or warning did you fix? … and how?"
  },
  {
    "objectID": "blog-2023/Blog-9-submissions/Starwiiin/index.html#prompt",
    "href": "blog-2023/Blog-9-submissions/Starwiiin/index.html#prompt",
    "title": "Errors and warnings in packages",
    "section": "Prompt:",
    "text": "Prompt:\nFix one of the problems in one of our community packages at https://github.com/Stat585-at-ISU/lab-3-all-all-for-one-and-one-for-all, and write about it."
  },
  {
    "objectID": "blog-2023/Blog-9-submissions/Starwiiin/index.html#instructions",
    "href": "blog-2023/Blog-9-submissions/Starwiiin/index.html#instructions",
    "title": "Errors and warnings in packages",
    "section": "Instructions:",
    "text": "Instructions:\nWhat we want to know is the exact warning or error message of the item you fixed, and a description of what you did, also as specific as possible.\nDescribe your experience below. Push this blog post to your blog-9 repo. Make sure the front matter check passes.\nWhich error or warning did you fix? … and how?\nParvin’s answer: I have been working on “Team6” package for this blog. Errors that I could address are as follows:\nget_pd_presslog: no visible global function definition for ‘download.file’ pd_to_tbl: no visible global function definition for ‘extract_tables’ pd_to_tbl: no visible binding for global variable ‘one_page’ pd_to_tbl: no visible global function definition for ‘write_csv’ pd_to_tbl: no visible global function definition for ‘year’ pd_to_tbl: no visible global function definition for ‘month’ pd_to_tbl: no visible global function definition for ‘mday’\nI added “ImportFrom utils download.file”, “ImportFrom readr write_csv”, “ImportFrom tabulizer extract_tables”, “ImportFrom lubridate year mday month” to the “get_pd_presslog” and “pd_to_tbl” and also to the description file. I used the “document()” and “check()” to fix the problems and check if the error is gone. In this way, I could solve the above errors. For the error related to the ‘one_page’, I added the “one_page = NULL” and it helped to address the error."
  },
  {
    "objectID": "blog-2023/Blog-3-submissions/xyzyc/ZhouYingchao.html",
    "href": "blog-2023/Blog-3-submissions/xyzyc/ZhouYingchao.html",
    "title": "Building a Book",
    "section": "",
    "text": "The goal of this week’s blog is to document what you are doing when things do not go according to plan.\nSimilar to previous exercises, we have a specific use case in mind: we want to build a book from a github repository.\nWhat happens in practice usually, is that we run into some problems. So your real task turns into that of a bug-hunter and fixer. Luckily, you have a community (the class discussion board) who might be able to help you.\n\n\nBuild the html version of the 2nd edition for Hadley Wickham’s book Advanced R Programming from a github repository.\nSteps:\n\nClone the repository https://github.com/hadley/adv-r.\nOpen the R project in the repository in RStudio.\nActivate the Build tab (by default in the top right panel). Click on the Build Book button.\nThe book will be available in html format as index.html\n\nDeliverable (1): what is the last word in chapter 15? - You don’t have to answer this question, if things don’t work.\n\n\n\nErrors happen, they are frustrating, but if we learn something from them, we can turn them into valuable experiences.\n\ncheck the Questions and Answers forum in Canvas whether there is a solution available for your problem.\n\nNo.\n\nif the above document does (not yet) include your question, document the error you encounter (be as concise and specific as you can at the same time)\n\nI can not compile the book in blog 3. The error I get is caused by line 106 of Control-flow.Rmd.\nIn Control-flow.Rmd, the author demonstrates what are the invalid inputs to an if statement. We know usually the condition should be a single TRUE or FALSE. But there is an exception:\nIn line 101, the author sets Sys.setenv(\"_R_CHECK_LENGTH_1_CONDITION_\" = \"false\") to allow an if statement to take a condition more than length 1. I run Sys.getenv() to make sure _R_CHECK_LENGTH_1_CONDITION_ is indeed set to \"false\".\nIn line 106, the author writes if (c(TRUE, FALSE)) 1 and says this should generate a warning message but not an error. However, now R generates an error “the condition has length > 1” and does not compile Control-flow.Rmd, and therefore fail to compile the book.\n\nif the Question and Answers forum does (not yet) include a solution, describe one approach on how you tried to solve the problem (and how this did not work).\n\nI added error = TRUE in the chunk options so the compilation does not stop at error so the book can be built.\n\nsubmit the description of your problem in Canvas at Discussions > Questions and Answers. Write the paragraph in the mindset that you want to get help from somebody, and you try to describe the problem you are encountering.\nExtra points (1 pt for the first suggested working solution): post a solution to one of the problems in the Questions and Answers forum (your own does not count!).\n\nDeliverable (2): Write a paragraph on the biggest problem you encountered when you were building the book, (and how you managed to solve it.)\nAnother big problem I have is a .sty file is missing for Latex. By clicking on “Build Book” button, the default output is a pdf file. Later I found index.Rmd file and knitted it into index.html.\nSubmit to your repo and you are done!"
  },
  {
    "objectID": "blog-2023/Blog-3-submissions/kundan7kumar/KumarKundan.html",
    "href": "blog-2023/Blog-3-submissions/kundan7kumar/KumarKundan.html",
    "title": "Building a Book",
    "section": "",
    "text": "The goal of this week’s blog is to document what you are doing when things do not go according to plan.\nSimilar to previous exercises, we have a specific use case in mind: we want to build a book from a github repository.\nWhat happens in practice usually, is that we run into some problems. So your real task turns into that of a bug-hunter and fixer. Luckily, you have a community (the class discussion board) who might be able to help you.\n\n\nBuild the html version of the 2nd edition for Hadley Wickham’s book Advanced R Programming from a github repository.\nSteps:\n\nClone the repository https://github.com/hadley/adv-r.\nOpen the R project in the repository in RStudio.\nActivate the Build tab (by default in the top right panel). Click on the Build Book button.\nThe book will be available in html format as index.html\n\nDeliverable (1): what is the last word in chapter 15? - You don’t have to answer this question, if things don’t work.\nSolution From Chapter 15,\nLast Line is Define a length method for the Person class.\nLast word is class\n\n\n\nI am able to build bookdown as a html version but unable to process as pdf.\nEven for html version,\nI had many issue but figured out mostly from internet as well from canvas discussion group. For multiple package issue, i searched on the Google an figured it out.\nMoreover,One of the issue was\n“Quitting from lines 106-107 (Control-flow.Rmd) Error in if (c(TRUE, FALSE)) 1 : the condition has length > 1 Calls: local … withVisible -> eval_with_user_handlers -> eval -> eval”\nI found the solution like ‘Setting error=TRUE’ after going through the canvas discussion. The discussion page was quite helpful in building the bookdown as a html.\nSecondly, I am unable to generate pdf after building the solution. i didn’t find the any solution which work for me on canvas and also from the internet.I posted the question on the canvas discussion page.\nI am getting error like:\n“Error: LaTeX failed to compile _main.tex. See. https://yihui.org/tinytex/r/#debugging for debugging tips. See _main.log. for more info. Execution halted. ”\nHere are few steps i tried:\n\ni followed the link: https://yihui.org/tinytex/r/#debugging.\n\ninstalled tinytex.\ninstlled pandoc.\nchecked pdflatex, xlelatex is installed on the system.\ncheck few other packages but none of them works.\n\n\n\n\n\n\n\nDeliverable (2): Write a paragraph on the biggest problem you encountered when you were building the book, (and how you managed to solve it.)\nSolution There are multiple issues,i have faced while building the bookdown. Firstly, I have to install all the packages required for the bookdown. Moreover, during building as bookdown::bs4_book, i faced few challenges like setting error=True to control.rmd file and also set registerS3method(“wrap”, …) to registerS3method(“sew”, …) in common.R file. I found the solution from the canvas discussion , it was really helpful and able to build bookdown as html version.\nOnce html version was build, i tried building as pdf file but unable to get success. I tried multiple things which is listed above .the biggest challenge was converting tex file to pdf ,it seems some system issue to install Miktex but even after installing ,it didn’t work. I am unable to fix (bookdown as pdf) yet."
  },
  {
    "objectID": "blog-2023/Blog-3-submissions/anyeshar/RayAnyesha.html",
    "href": "blog-2023/Blog-3-submissions/anyeshar/RayAnyesha.html",
    "title": "Building a Book",
    "section": "",
    "text": "The goal of this week’s blog is to document what you are doing when things do not go according to plan.\nSimilar to previous exercises, we have a specific use case in mind: we want to build a book from a github repository.\nWhat happens in practice usually, is that we run into some problems. So your real task turns into that of a bug-hunter and fixer. Luckily, you have a community (the class discussion board) who might be able to help you.\n\n\nBuild the html version of the 2nd edition for Hadley Wickham’s book Advanced R Programming from a github repository.\nSteps:\n\nClone the repository https://github.com/hadley/adv-r.\nOpen the R project in the repository in RStudio.\nActivate the Build tab (by default in the top right panel). Click on the Build Book button.\nThe book will be available in html format as index.html\n\nDeliverable (1): what is the last word in chapter 15? - You don’t have to answer this question, if things don’t work. The last word is “class”.\nDeliverable (2): Write a paragraph on the biggest problem you encountered when you were building the book, (and how you managed to solve it.) The biggest problem was figuring out what was going wrong. Everytime I tried to build the book, it gave me the following error: “Error in get(genname, envir = envir) : object ‘wrap’ not found”. When I googled this issue, it seemed like it was an intalling packages error. It also made me realize there were many packaes the book was using that I didn’t have installed. I went through each markdown in the repository and installed any packages that were required. Then I googled what the srap function was a part of and found that it was a part of the Kmisc package. When I went to install that, it said I needed Rtools. The hardest part of building this book was the amount of packages it needed and figuring out which packegaes those were. However, after all that, it said Kmisc was not available for my version of R. However, on the Q and A in class someone posted a solution and I switched wrap to sew and was able to get further. I had a second error that was also addressed in the Q and A and set error=true so it would continue to run. Another issue was the emoji file called “emo” instead of “emoji”. I ended up finding that function and it said emo and ji instead of emoji so I changed that. Then there were many issues with the md files being missing, and I was not able to fix those. ."
  },
  {
    "objectID": "blog-2023/Blog-3-submissions/Landon-Getting/index.html",
    "href": "blog-2023/Blog-3-submissions/Landon-Getting/index.html",
    "title": "Book Building is Backbreaking",
    "section": "",
    "text": "The last word in Chapter 15 is ‘class’!"
  },
  {
    "objectID": "blog-2023/Blog-3-submissions/Landon-Getting/index.html#deliverable-2---biggest-problem",
    "href": "blog-2023/Blog-3-submissions/Landon-Getting/index.html#deliverable-2---biggest-problem",
    "title": "Book Building is Backbreaking",
    "section": "Deliverable 2 - Biggest Problem:",
    "text": "Deliverable 2 - Biggest Problem:\nAlthough I encountered many issues in building Hadley’s book, the biggest problem was getting the .pdf file to build. I received the following error after successfully building the .html file and attempting to build the .pdf file:\nLaTeX failed to compile _main.tex\nI read the post by Motahareh Kashanian in the class Canvas forum and determined that my installation of MiKTeX may not be helpful in solving the error. I uninstalled MiKTeX and utilized the following commands from tinytex website to install tinytex:\ninstall.packages('tinytex')\ntinytex::install_tinytex()\nNext, I experienced the most frustrating error of the entire build process; font failure. I received a variety of errors indicating that the inconsolata font could not be found. One of my Lab #1 group members (shoutout Logan) suggested installing the font via Google Fonts. After the font was installed, I found this article which stated that the preamble.tex document needed ‘inconsolata’ to be lowercase rather than ‘Inconsolata’ to be found. Finally, I changed the fallback font to Arial since I could not find a free install for Andale Mono. After these changes, the book built correctly into a .pdf file! Best feeling ever!"
  },
  {
    "objectID": "blog-2023/Blog-3-submissions/Hiiiua/HuaMuxin.html",
    "href": "blog-2023/Blog-3-submissions/Hiiiua/HuaMuxin.html",
    "title": "Building a Book",
    "section": "",
    "text": "The goal of this week’s blog is to document what you are doing when things do not go according to plan.\nSimilar to previous exercises, we have a specific use case in mind: we want to build a book from a github repository.\nWhat happens in practice usually, is that we run into some problems. So your real task turns into that of a bug-hunter and fixer. Luckily, you have a community (the class discussion board) who might be able to help you.\n\n\nBuild the html version of the 2nd edition for Hadley Wickham’s book Advanced R Programming from a github repository.\nSteps:\n\nClone the repository https://github.com/hadley/adv-r.\nOpen the R project in the repository in RStudio.\nActivate the Build tab (by default in the top right panel). Click on the Build Book button.\nThe book will be available in html format as index.html\n\nDeliverable (1): what is the last word in chapter 15? - You don’t have to answer this question, if things don’t work.\nI got the word pseudo-class.\n\n\n\nErrors happen, they are frustrating, but if we learn something from them, we can turn them into valuable experiences.\n\ncheck the Questions and Answers forum in Canvas whether there is a solution available for your problem.\nif the above document does (not yet) include your question, document the error you encounter (be as concise and specific as you can at the same time)\nif the Question and Answers forum does (not yet) include a solution, describe one approach on how you tried to solve the problem (and how this did not work).\nsubmit the description of your problem in Canvas at Discussions > Questions and Answers. Write the paragraph in the mindset that you want to get help from somebody, and you try to describe the problem you are encountering.\nExtra points (1 pt for the first suggested working solution): post a solution to one of the problems in the Questions and Answers forum (your own does not count!).\n\nDeliverable (2): Write a paragraph on the biggest problem you encountered when you were building the book, (and how you managed to solve it.)\nI got most of the problem of package not found, so the most reasonable way to do is install these packages, for the most of time, it worked well.\nHowever, there were two problems took more efforts.\nThe first one is Error in if (c(TRUE, FALSE)) 1 : the condition has length > 1 Calls: local … withVisible -> eval_with_user_handlers -> eval -> eval. This Error was very specific that this is an error came from the file Control-flow.Rmd. I went straight to this file and spotted the chunk raising the error. I noticed the chunks nearby have similar code expect they specified Error = TRUE. I tried to add this command to the chunk and it just worked! The second peoblem was more tricky. I got dev.control() called without an open graphics device https://github.com/brentthorne/posterdown/issues/42. There was also some complaining about emo not installed. I was trying to solve it by installing it. Turned out there was no matching library for R version. I searched google to find I should install things from github. But the trickt part is that devtool should be the ideal way to do that, but my R wouldn’t let me to do so and kept asking me to restart R session. Eventually this is solved by installing and running remotes with rejecting R session restart request.\nSubmit to your repo and you are done!"
  },
  {
    "objectID": "blog-2023/Blog-3-submissions/mattkav49/Matt.Kavanaugh.html",
    "href": "blog-2023/Blog-3-submissions/mattkav49/Matt.Kavanaugh.html",
    "title": "Building a Book",
    "section": "",
    "text": "The goal of this week’s blog is to document what you are doing when things do not go according to plan.\nSimilar to previous exercises, we have a specific use case in mind: we want to build a book from a github repository.\nWhat happens in practice usually, is that we run into some problems. So your real task turns into that of a bug-hunter and fixer. Luckily, you have a community (the class discussion board) who might be able to help you.\n\n\nBuild the html version of the 2nd edition for Hadley Wickham’s book Advanced R Programming from a github repository.\nSteps:\n\nClone the repository https://github.com/hadley/adv-r.\nOpen the R project in the repository in RStudio.\nActivate the Build tab (by default in the top right panel). Click on the Build Book button.\nThe book will be available in html format as index.html\n\nDeliverable (1): what is the last word in chapter 15? - You don’t have to answer this question, if things don’t work.\n\nThe last word in Chapter 15 is under the second question of the Exercises section, and is the word “class”.\n\n\n\n\nErrors happen, they are frustrating, but if we learn something from them, we can turn them into valuable experiences.\n\ncheck the Questions and Answers forum in Canvas whether there is a solution available for your problem.\nif the above document does (not yet) include your question, document the error you encounter (be as concise and specific as you can at the same time)\nif the Question and Answers forum does (not yet) include a solution, describe one approach on how you tried to solve the problem (and how this did not work).\nsubmit the description of your problem in Canvas at Discussions > Questions and Answers. Write the paragraph in the mindset that you want to get help from somebody, and you try to describe the problem you are encountering.\nExtra points (1 pt for the first suggested working solution): post a solution to one of the problems in the Questions and Answers forum (your own does not count!).\n\nDeliverable (2): Write a paragraph on the biggest problem you encountered when you were building the book, (and how you managed to solve it.)\nWhen building the book, the biggest issue I came across was discovering that I needed to install so many additional packages and files in order for the book to compile. I discovered that the version of “tinytex” installed was out of date, and I needed to install the one which was compatible with my current version of R. I consulted Sudesh’s solution on the discussion forum, when he suggested to try uninstalling and installing tinytex using the “tinytex::(un)install_tidytex()” function. Also, other packages such as “zeallot” were not installed, and I had to search for each of these packages and install them as new errors occurred. I was able to search for the necessary packages and install them using the “install.packages()” command.\nAdditionally, I had to replace a couple of functions that were no longer operational in current versions of R. For instance, the knitr package was particularly difficult to work with, as the wrap command which was being used by the common.R file ceased to exist as of the version released last summer. I consulted the discussion board for help, and surely enough, there was a suggested answer to my problem provided by Yichuan. Then, I investigated the linked Github repository for more information. As it turns out, I initially went in to replace the “wrap” command with “sew”, as had been suggested on our discussion board as well as on the Common.R Github page. However, as it turned out, an error persisted when attempting to compile the common.R file. Lines 56-61 of that file featured code that would display an error message in the event that the “wrap” command malfunctioned. However, I had replaced each “wrap” with “sew” throughout those lines, and this file would not compile until I changed the error code commands back to “wrap”. It took a good bit of playing around to figure that one out, and I ended up doing so by running a few lines of code at a time throughout the enitre script until I figured out where things were going wrong. Eventually, I narrowed it down to the lines mentioned above, and I was able to fix the problem. Overall, it was a rewarding experience to encounter issues and become stronger at debugging code as well as being able to consult the help of others when it became necessary.\nYou can write your experience directly into the README.Rmd file. Just make sure that you change the yaml at the top: change the author at the top, and give your post a new title (don’t change the category :))\nCommit and push to your repo and you are done!"
  },
  {
    "objectID": "blog-2023/Blog-3-submissions/charlestbonk/index.html",
    "href": "blog-2023/Blog-3-submissions/charlestbonk/index.html",
    "title": "Bipity-Bopity-Book?",
    "section": "",
    "text": "The goal of this week’s blog is to document what you are doing when things do not go according to plan.\nSimilar to previous exercises, we have a specific use case in mind: we want to build a book from a github repository.\nWhat happens in practice usually, is that we run into some problems. So your real task turns into that of a bug-hunter and fixer. Luckily, you have a community (the class discussion board) who might be able to help you.\n\n\nBuild the html version of the 2nd edition for Hadley Wickham’s book Advanced R Programming from a github repository.\nSteps:\n\nClone the repository https://github.com/hadley/adv-r.\nOpen the R project in the repository in RStudio.\nActivate the Build tab (by default in the top right panel). Click on the Build Book button.\nThe book will be available in html format as index.html\n\nDeliverable (1): what is the last word in chapter 15? - You don’t have to answer this question, if things don’t work. - Haha so the book is not working locally, throwing Error in get(genname, envir = envir) : object 'wrap' not found Calls: local ... withVisible -> eval -> eval -> registerS3method -> get.\n\n\n\nErrors happen, they are frustrating, but if we learn something from them, we can turn them into valuable experiences.\n\ncheck the Questions and Answers forum in Canvas whether there is a solution available for your problem.\nif the above document does (not yet) include your question, document the error you encounter (be as concise and specific as you can at the same time)\nif the Question and Answers forum does (not yet) include a solution, describe one approach on how you tried to solve the problem (and how this did not work).\nsubmit the description of your problem in Canvas at Discussions > Questions and Answers. Write the paragraph in the mindset that you want to get help from somebody, and you try to describe the problem you are encountering.\nExtra points (1 pt for the first suggested working solution): post a solution to one of the problems in the Questions and Answers forum (your own does not count!).\n\nDeliverable (2): Write a paragraph on the biggest problem you encountered when you were building the book, (and how you managed to solve it.) - So the biggest problem is that it doesn’t build correctly. My knitr works, the pdf generation outside of building works. Someone had talked about changing “wrap” to “sew” and it did actually do some building. It built for over 10 minutes before uh oh, another error. Thankfully, Heike said that it isn’t going to work, so I have significantly less to be stressed about. The lesson to learn: Make sure that if you write a book, try to update it as R and its packages update, and if you can’t, try to make it as timeless and resilient as possible, that way it won’t break as easily in the future.\nYou can write your experience directly into the README.Rmd file. Just make sure that you change the yaml at the top: change the author at the top, and give your post a new title (don’t change the category :))\nCommit and push to your repo and you are done!"
  },
  {
    "objectID": "blog-2023/Blog-3-submissions/TWiedRW/index.html",
    "href": "blog-2023/Blog-3-submissions/TWiedRW/index.html",
    "title": "Building a book",
    "section": "",
    "text": "The goal of this week’s blog is to document what you are doing when things do not go according to plan.\nSimilar to previous exercises, we have a specific use case in mind: we want to build a book from a github repository.\nWhat happens in practice usually, is that we run into some problems. So your real task turns into that of a bug-hunter and fixer. Luckily, you have a community (the class discussion board) who might be able to help you.\n\n\nBuild the html version of the 2nd edition for Hadley Wickham’s book Advanced R Programming from a github repository.\nSteps:\n\nClone the repository https://github.com/hadley/adv-r.\nOpen the R project in the repository in RStudio.\nActivate the Build tab (by default in the top right panel). Click on the Build Book button.\nThe book will be available in html format as index.html\n\nDeliverable (1): what is the last word in chapter 15? - You don’t have to answer this question, if things don’t work.\nThis did not work for my computer.\n\n\n\nErrors happen, they are frustrating, but if we learn something from them, we can turn them into valuable experiences.\n\ncheck the Questions and Answers forum in Canvas whether there is a solution available for your problem.\nif the above document does (not yet) include your question, document the error you encounter (be as concise and specific as you can at the same time)\nif the Question and Answers forum does (not yet) include a solution, describe one approach on how you tried to solve the problem (and how this did not work).\nsubmit the description of your problem in Canvas at Discussions > Questions and Answers. Write the paragraph in the mindset that you want to get help from somebody, and you try to describe the problem you are encountering.\nExtra points (1 pt for the first suggested working solution): post a solution to one of the problems in the Questions and Answers forum (your own does not count!).\n\nDeliverable (2): Write a paragraph on the biggest problem you encountered when you were building the book, (and how you managed to solve it.)\nThe biggest problem for building the book was the object wrap was missing from Introduction.Rmd. This caused the book to not compile. The error message returned Quitting from lines 4-5 (Introduction.Rmd). This line from the particular Rmd file is source(\"common.R\"), which I suspect has two possible causes. The first is a reference to the function error_wrap, which appears to be a custom function from somewhere else inside the project directory (does not appear in the R help files). There was also a call from registerS3method that uses wrap, so the error might also occur from here. Since I am not sure where wrap is needed, this is where my solution to fixing the problem stops."
  },
  {
    "objectID": "blog-2023/Blog-3-submissions/charchit/ShuklaCharchit.html",
    "href": "blog-2023/Blog-3-submissions/charchit/ShuklaCharchit.html",
    "title": "Building a Book",
    "section": "",
    "text": "The goal of this week’s blog is to document what you are doing when things do not go according to plan.\nSimilar to previous exercises, we have a specific use case in mind: we want to build a book from a github repository.\nWhat happens in practice usually, is that we run into some problems. So your real task turns into that of a bug-hunter and fixer. Luckily, you have a community (the class discussion board) who might be able to help you.\n\n\nBuild the html version of the 2nd edition for Hadley Wickham’s book Advanced R Programming from a github repository.\nSteps:\n\nClone the repository https://github.com/hadley/adv-r.\nOpen the R project in the repository in RStudio.\nActivate the Build tab (by default in the top right panel). Click on the Build Book button.\nThe book will be available in html format as index.html\n\nDeliverable (1): what is the last word in chapter 15? - You don’t have to answer this question, if things don’t work.\nhtml: psuedo-class pdf: class before Exercises: packages\n\n\n\nErrors happen, they are frustrating, but if we learn something from them, we can turn them into valuable experiences.\n\ncheck the Questions and Answers forum in Canvas whether there is a solution available for your problem.\nif the above document does (not yet) include your question, document the error you encounter (be as concise and specific as you can at the same time)\nif the Question and Answers forum does (not yet) include a solution, describe one approach on how you tried to solve the problem (and how this did not work).\nsubmit the description of your problem in Canvas at Discussions > Questions and Answers. Write the paragraph in the mindset that you want to get help from somebody, and you try to describe the problem you are encountering.\nExtra points (1 pt for the first suggested working solution): post a solution to one of the problems in the Questions and Answers forum (your own does not count!).\n\nDeliverable (2): Write a paragraph on the biggest problem you encountered when you were building the book, (and how you managed to solve it.)\nI have coded before many times (not in R) and have fairly good idea how to “debug” or problem solve the coding problems. I got stuck multiple times for problems and I just read the type of error, googled if anybody else had the same problem and tried to solve it. The biggest problem was probably about .tex files. Because it was not related to Rstudio and more to Latex, I had to google in Latex community how to solve it. I solved it using examples from both community.rstudio.com and tex.stackexchange.com. Yihui book was also helpful in understanding how the Rstudio works.\nSubmit to your repo and you are done!"
  },
  {
    "objectID": "blog-2023/Blog-3-submissions/kellynay/index.html",
    "href": "blog-2023/Blog-3-submissions/kellynay/index.html",
    "title": "Rendering a book using ‘bookdown’",
    "section": "",
    "text": "The goal of this week’s blog is to document what you are doing when things do not go according to plan.\nSimilar to previous exercises, we have a specific use case in mind: we want to build a book from a github repository.\nWhat happens in practice usually, is that we run into some problems. So your real task turns into that of a bug-hunter and fixer. Luckily, you have a community (the class discussion board) who might be able to help you.\n\n\nBuild the html version of the 2nd edition for Hadley Wickham’s book Advanced R Programming from a github repository.\nSteps:\n\nClone the repository https://github.com/hadley/adv-r.\nOpen the R project in the repository in RStudio.\nActivate the Build tab (by default in the top right panel). Click on the Build Book button.\nThe book will be available in html format as index.html\n\nDeliverable (1): what is the last word in chapter 15? - You don’t have to answer this question, if things don’t work.\nAnswer: “pseudo-class” is the last word of Chapter 15. I obtained this answer by rendering the book into HTML format.\nDeliverable (2): Write a paragraph on the biggest problem you encountered when you were building the book, (and how you managed to solve it.)\nThe biggest problem was knitting the book to pdf. I tried two LaTeX distributions (MiKTex and TinyTeX) and read several responses to similar questions on Stack Overflow and the Posit Community. Following the solutions, I installed, uninstalled and updated packages, and set the PATH by editing the system environment variables; however the error “LaTeX failed to compile _main.tex” persisted. Unfortunately I did not find a solution for this problem, but by opening a new Rmarkdown file, I typed Sys.which(“pdflatex”) and RStudio found the Tinytex package installed. I also successfully knitted a pdf document using this new file. Thus, there must be something wrong in the book script."
  },
  {
    "objectID": "blog-2023/Blog-3-submissions/drbradford12/index.html",
    "href": "blog-2023/Blog-3-submissions/drbradford12/index.html",
    "title": "Reading a Chapter in adv-r",
    "section": "",
    "text": "The goal of this week’s blog is to document what you are doing when things do not go according to plan.\nSimilar to previous exercises, we have a specific use case in mind: we want to build a book from a github repository.\nWhat happens in practice usually, is that we run into some problems. So your real task turns into that of a bug-hunter and fixer. Luckily, you have a community (the class discussion board) who might be able to help you.\n\n\nBuild the html version of the 2nd edition for Hadley Wickham’s book Advanced R Programming from a github repository.\nSteps:\n\nClone the repository https://github.com/hadley/adv-r.\nOpen the R project in the repository in RStudio.\nActivate the Build tab (by default in the top right panel). Click on the Build Book button.\nThe book will be available in html format as index.html\n\nDeliverable (1): what is the last word in chapter 15? - You don’t have to answer this question, if things don’t work.\nDenise’s Answer:\nThe last word in chapter 15 is Python, while this is the last word in the exercise but I believe that the last word in the chapter before the exercise is update, this doesn’t include code in the last parts of the chapter.\n\n\n\nErrors happen, they are frustrating, but if we learn something from them, we can turn them into valuable experiences.\n\ncheck the Questions and Answers forum in Canvas whether there is a solution available for your problem.\nif the above document does (not yet) include your question, document the error you encounter (be as concise and specific as you can at the same time)\nif the Question and Answers forum does (not yet) include a solution, describe one approach on how you tried to solve the problem (and how this did not work).\nsubmit the description of your problem in Canvas at Discussions > Questions and Answers. Write the paragraph in the mindset that you want to get help from somebody, and you try to describe the problem you are encountering.\nExtra points (1 pt for the first suggested working solution): post a solution to one of the problems in the Questions and Answers forum (your own does not count!).\n\nDeliverable (2): Write a paragraph on the biggest problem you encountered when you were building the book, (and how you managed to solve it.)\nDenise’s Answer: The biggest problem that I encountered when trying to build the book was the following error:\n---\nQuitting from lines 4-5 (Introduction.Rmd) \nError in get(genname, envir = envir) : object 'wrap' not found\nCalls: local ... withVisible -> eval -> eval -> registerS3method -> get\nExecution halted\nError in Rscript_render(f, render_args, render_meta, add1, add2) : \n  Failed to compile Introduction.Rmd\nCalls: local ... <Anonymous> -> render_new_session -> Rscript_render\nExecution halted\nError: bookdown::render_book() failed to render the output format 'bookdown::bs4_book'.\nExecution halted\n---\nThe first few attempts to solve the problem was to look for the errors that were being displayed in the Build window. Following a few unsuccessful google searchs, I decided to look further into the displayed method. The message is having an issue in the Introduction.Rmd looking for a missing wrap object. I added the following webshot::install_phantomjs( force = TRUE), which was not helpful in building the book. The situation was in the libraries that were needed in the packages in order to make sure that the information complied. Lastly, I decided to complete the following to get the bookdown to work\nYou can write your experience directly into the README.Rmd file. Just make sure that you change the yaml at the top: change the author at the top, and give your post a new title (don’t change the category :))\nCommit and push to your repo and you are done!"
  },
  {
    "objectID": "blog-2023/Blog-3-submissions/HarunCelikOtto/index.html",
    "href": "blog-2023/Blog-3-submissions/HarunCelikOtto/index.html",
    "title": "Error Fixing Process",
    "section": "",
    "text": "The goal of this week’s blog is to document what you are doing when things do not go according to plan.\nSimilar to previous exercises, we have a specific use case in mind: we want to build a book from a github repository.\nWhat happens in practice usually, is that we run into some problems. So your real task turns into that of a bug-hunter and fixer. Luckily, you have a community (the class discussion board) who might be able to help you.\n\n\nBuild the html version of the 2nd edition for Hadley Wickham’s book Advanced R Programming from a github repository.\nSteps:\n\nClone the repository https://github.com/hadley/adv-r.\nOpen the R project in the repository in RStudio.\nActivate the Build tab (by default in the top right panel). Click on the Build Book button.\nThe book will be available in html format as index.html\n\nDeliverable (1): what is the last word in chapter 15? - You don’t have to answer this question, if things don’t work.\n\n\n\nErrors happen, they are frustrating, but if we learn something from them, we can turn them into valuable experiences.\n\ncheck the Questions and Answers forum in Canvas whether there is a solution available for your problem.\nif the above document does (not yet) include your question, document the error you encounter (be as concise and specific as you can at the same time)\nif the Question and Answers forum does (not yet) include a solution, describe one approach on how you tried to solve the problem (and how this did not work).\nsubmit the description of your problem in Canvas at Discussions > Questions and Answers. Write the paragraph in the mindset that you want to get help from somebody, and you try to describe the problem you are encountering.\nExtra points (1 pt for the first suggested working solution): post a solution to one of the problems in the Questions and Answers forum (your own does not count!).\n\nDeliverable (2): Write a paragraph on the biggest problem you encountered when you were building the book, (and how you managed to solve it.)\nYou can write your experience directly into the README.Rmd file. Just make sure that you change the yaml at the top: change the author at the top, and give your post a new title (don’t change the category :))\nCommit and push to your repo and you are done!\nANSWER SECTION\nLAST WORD\nThe last word in Chapter 15 is class in the sentence, Define a length method for the Person class.\nPROCESS:\nUnfortunately, I was unable to compile the pdf book, but I was able to get the bs4 version! Here was the process I followed to working through the errors.\nI was able to copy the repository into a local folder on my PC and open up all the files without an issue. I ran into a problem initially because I didn’t have the library(bookdown) package. As I was trying to download the package, I came across the error\nWARNING: Rtools is required to build R packages but is not currently installed. Please download and install the appropriate version of Rtools before proceeding:\nWhich I tried to overcome with a clean install of R once again. This unfortunately did not fix the error that I had and so I ran install.packages(\"Rtools\") to be greeted with another error.\nWarning in install.packages :\n  package ‘Rtools’ is not available for this version of R\nAt which point I did a run around forums on “community.rstudio” to find that I had to download Rtools from the Cran project. I am still unsure of why I need Rtools given that the documentation for Rtools43 indicates that “Moreover, online build services are available to check and build R packages for Windows, for which again one does not need to install Rtools43 locally.”\nInstalling Rtools43 did not make a noticeable difference, though I think this was because I actually needed the Rtools40 instead. However, I was now able to download the bookdown package and could see it in my packages list in Rstudio to start compiling.\nOnce I ran the compile, I saw that I had the same issue as everyone else regarding the ‘wrap’ argument in the registerS3method() argument which I then changed and re-compiled. I ran into an error about a package called lobstr which I did not have so I installed that package as well and the compiler continued.\nI came across an error regarding a package called emo that I did not have and followed the suggestion on the discussions forum to use devtools to install it. At this point in the console, I was asked to install Rtools40 which I realized might have been the correct version to install since my Rtools43 installation did not help here. I installed Rtools40 and followed Landon’s suggestion in the Canvas Discussions to add it to my PATH.\nI was able to successfully install emo and recompiled. I then ran into another error about not having the package sloop and ran an install on that. I followed the same procedure for package zeallot, bench, and ggbeeswarm. After this, the compiler ran without error for longer than 5 minutes to tweak the files that were generated from the first processing of the knit. The following error then came about.\nError: LaTeX failed to compile _main.tex. See https://yihui.org/tinytex/r/#debugging for debugging tips. See _main.log for more info.\nExecution halted\nError: bookdown::render_book() failed to render the output format 'bookdown::pdf_book'.\nExecution halted\nKnowing it was the _main.tex file, I tried to check where the error might be and I found within my error log the following code.\n2023-02-11 13:58:26,032-0600 INFO  xelatex - starting with command line: C:\\Users\\harun\\AppData\\Local\\Programs\\MIKTEX~1.9\\miktex\\bin\\x64\\xelatex.exe -halt-on-error -interaction=batchmode _main.tex\n2023-02-11 13:58:26,046-0600 INFO  xelatex - allowing known shell commands\n2023-02-11 13:58:26,046-0600 INFO  xelatex - enabling input (output) from (to) processes\n2023-02-11 13:58:26,062-0600 INFO  xelatex - going to create file: xelatex.fmt\n2023-02-11 13:58:30,355-0600 FATAL xelatex - GUI framework cannot be initialized.\n2023-02-11 13:58:30,355-0600 FATAL xelatex - Info: \n2023-02-11 13:58:30,355-0600 FATAL xelatex - Source: Libraries\\MiKTeX\\UI\\Qt\\mikuiqt.cpp\n2023-02-11 13:58:30,355-0600 FATAL xelatex - Line: 77\n2023-02-11 13:58:30,356-0600 INFO  xelatex - finishing with exit code 1\nLine 77 of _main.tex has the code:\nlibrary(calc)\nI’m not LateX savvy enough to understand what’s going on here but the former error in Rstudio indicates that the problem is with the pdf_book format of the build and this seems to be confirmed reading through the discussions on Canvas. I could not find the problem within the specified tex file to overcome the compiling issue.\nAs a workaround suggested by a classmate, I decided to run the bookdown::bs4_book build to see if I could at least get that working. It compiled without error and I was able to submit the deliverable through that format instead."
  },
  {
    "objectID": "blog-2023/Blog-3-submissions/valeriehan6/HanValerie.html",
    "href": "blog-2023/Blog-3-submissions/valeriehan6/HanValerie.html",
    "title": "Building a Book",
    "section": "",
    "text": "The goal of this week’s blog is to document what you are doing when things do not go according to plan.\nSimilar to previous exercises, we have a specific use case in mind: we want to build a book from a github repository.\nWhat happens in practice usually, is that we run into some problems. So your real task turns into that of a bug-hunter and fixer. Luckily, you have a community (the class discussion board) who might be able to help you.\n\n\nBuild the html version of the 2nd edition for Hadley Wickham’s book Advanced R Programming from a github repository.\nSteps:\n\nClone the repository https://github.com/hadley/adv-r.\nOpen the R project in the repository in RStudio.\nActivate the Build tab (by default in the top right panel). Click on the Build Book button.\nThe book will be available in html format as index.html\n\nDeliverable (1): what is the last word in chapter 15? - You don’t have to answer this question, if things don’t work.\nThe last word in chapter 15 is “class.” The last word in chapter 15 before the exercises is “packages.”\n\n\n\nErrors happen, they are frustrating, but if we learn something from them, we can turn them into valuable experiences.\n\ncheck the Questions and Answers forum in Canvas whether there is a solution available for your problem.\nif the above document does (not yet) include your question, document the error you encounter (be as concise and specific as you can at the same time)\nif the Question and Answers forum does (not yet) include a solution, describe one approach on how you tried to solve the problem (and how this did not work).\nsubmit the description of your problem in Canvas at Discussions > Questions and Answers. Write the paragraph in the mindset that you want to get help from somebody, and you try to describe the problem you are encountering.\nExtra points (1 pt for the first suggested working solution): post a solution to one of the problems in the Questions and Answers forum (your own does not count!).\n\nDeliverable (2): Write a paragraph on the biggest problem you encountered when you were building the book, (and how you managed to solve it.)\nI was lucky not to run into any huge problems building the book. The biggest problem was an error involving the emo package. Unlike the other missing packages, it couldn’t be installed with install.packages(\"emo\"). However, through a quick Google search of the error returned from the install.packages(\"emo\") command, I found a https://stackoverflow.com/questions/25721884/how-should-i-deal-with-package-xxx-is-not-available-for-r-version-x-y-z-wa asking about a similar error. A helpful answer informed me that this error could be because the package is not in CRAN, so I decided to google the package. This led me to a Github repo for the package with instructions on how to install it: devtools::install_github(\"hadley/emo\").\nSubmit to your repo and you are done!"
  },
  {
    "objectID": "blog-2023/Blog-3-submissions/IanParzyszek/index.html",
    "href": "blog-2023/Blog-3-submissions/IanParzyszek/index.html",
    "title": "Title of your post",
    "section": "",
    "text": "The goal of this week’s blog is to document what you are doing when things do not go according to plan.\nSimilar to previous exercises, we have a specific use case in mind: we want to build a book from a github repository.\nWhat happens in practice usually, is that we run into some problems. So your real task turns into that of a bug-hunter and fixer. Luckily, you have a community (the class discussion board) who might be able to help you.\n\n\nBuild the html version of the 2nd edition for Hadley Wickham’s book Advanced R Programming from a github repository.\nSteps:\n\nClone the repository https://github.com/hadley/adv-r.\nOpen the R project in the repository in RStudio.\nActivate the Build tab (by default in the top right panel). Click on the Build Book button.\nThe book will be available in html format as index.html\n\nDeliverable (1): what is the last word in chapter 15? - You don’t have to answer this question, if things don’t work.\n\n\n\nErrors happen, they are frustrating, but if we learn something from them, we can turn them into valuable experiences.\n\ncheck the Questions and Answers forum in Canvas whether there is a solution available for your problem.\nif the above document does (not yet) include your question, document the error you encounter (be as concise and specific as you can at the same time)\nif the Question and Answers forum does (not yet) include a solution, describe one approach on how you tried to solve the problem (and how this did not work).\nsubmit the description of your problem in Canvas at Discussions > Questions and Answers. Write the paragraph in the mindset that you want to get help from somebody, and you try to describe the problem you are encountering.\nExtra points (1 pt for the first suggested working solution): post a solution to one of the problems in the Questions and Answers forum (your own does not count!).\n\nDeliverable (2): Write a paragraph on the biggest problem you encountered when you were building the book, (and how you managed to solve it.)\nYou can write your experience directly into the README.Rmd file. Just make sure that you change the yaml at the top: change the author at the top, and give your post a new title (don’t change the category :))\nCommit and push to your repo and you are done!"
  },
  {
    "objectID": "blog-2023/Blog-3-submissions/loganjohnson0/JohnsonLogan.html",
    "href": "blog-2023/Blog-3-submissions/loganjohnson0/JohnsonLogan.html",
    "title": "Building a Book",
    "section": "",
    "text": "The goal of this week’s blog is to document what you are doing when things do not go according to plan.\nSimilar to previous exercises, we have a specific use case in mind: we want to build a book from a github repository.\nWhat happens in practice usually, is that we run into some problems. So your real task turns into that of a bug-hunter and fixer. Luckily, you have a community (the class discussion board) who might be able to help you.\n\n\nBuild the html version of the 2nd edition for Hadley Wickham’s book Advanced R Programming from a github repository.\nSteps:\n\nClone the repository https://github.com/hadley/adv-r.\nOpen the R project in the repository in RStudio.\nActivate the Build tab (by default in the top right panel). Click on the Build Book button.\nThe book will be available in html format as index.html\n\nDeliverable (1): what is the last word in chapter 15? - You don’t have to answer this question, if things don’t work.\n\n\n\nThe last word in chapter 15 in both the PDF and HTML versions that I generated was “person.”\n\n\n\nErrors happen, they are frustrating, but if we learn something from them, we can turn them into valuable experiences.\n\ncheck the Questions and Answers forum in Canvas whether there is a solution available for your problem.\nif the above document does (not yet) include your question, document the error you encounter (be as concise and specific as you can at the same time)\nif the Question and Answers forum does (not yet) include a solution, describe one approach on how you tried to solve the problem (and how this did not work).\nsubmit the description of your problem in Canvas at Discussions > Questions and Answers. Write the paragraph in the mindset that you want to get help from somebody, and you try to describe the problem you are encountering.\nExtra points (1 pt for the first suggested working solution): post a solution to one of the problems in the Questions and Answers forum (your own does not count!).\n\nDeliverable (2): Write a paragraph on the biggest problem you encountered when you were building the book, (and how you managed to solve it.)\n\n\n\nThe whole process of downloading the repository was easy, despite the sheer number of files that are included with the process. Some challenges that I faced included many errors while trying to create the book. Some of the errors I faced included:\n\nError due to “___ package not found”\nError: C stack usage 7970272 is too close to the limit\nPackage fontspec Error: The font “Inconsolata” cannot be found\nBookdown: ! LaTeX Error: Command \\href undefined\n\nIt was easy to solve those issues with packages not found. I simply downloaded the necessary package called out in the error messages. I had no issues with this issue.\nThe error with “C stack usage too close to the limit” was a confusing error for me. I wasn’t able to find a clear answer online anywhere. The issue seems to stem from computer memory issues and the issue of a recursive function that is large. Essentially to solve this, I restarted the RStudio session and then the issue seemed to resolve itself. I only faced it a time or two.\nAs simple as the missing “Inconsolata” font seemed to me, I spent a frustrating amount of time trying to figure out how to resolve this issue. I first tried to find a way to download the “fontspec” package with is in CTAN and not CRAN. My inexperience with LaTeX also didn’t help in this instance. I downloaded the package “tinytex.” This seemed to help some issues, but didn’t solve the specific font issue. I ultimately realized that I simply needed to download the font from Google Fonts. That was a simple, yet frustratingly long issue.\nLastly, the LaTeX Error: Command \\href undefined lead me to the GitHub respostory of Yihui Xie for bookdown. The specific code and changes were made to a specific LaTeX file. I was able to find this same type of file in Hadley’s advr repository. I made a change locally by adding “\n” before the issue of “LaTeX Error: Command \\href undefined.” After this final change, the book was able to render with no issues.\nSubmit to your repo and you are done!"
  },
  {
    "objectID": "blog-2023/Blog-3-submissions/Atefeha1995/index.html",
    "href": "blog-2023/Blog-3-submissions/Atefeha1995/index.html",
    "title": "I finally built a book",
    "section": "",
    "text": "The goal of this week’s blog is to document what you are doing when things do not go according to plan.\nSimilar to previous exercises, we have a specific use case in mind: we want to build a book from a github repository.\nWhat happens in practice usually, is that we run into some problems. So your real task turns into that of a bug-hunter and fixer. Luckily, you have a community (the class discussion board) who might be able to help you.\n\n\nBuild the html version of the 2nd edition for Hadley Wickham’s book Advanced R Programming from a github repository.\nSteps:\n\nClone the repository https://github.com/hadley/adv-r.\nOpen the R project in the repository in RStudio.\nActivate the Build tab (by default in the top right panel). Click on the Build Book button.\nThe book will be available in html format as index.html\n\nDeliverable (1): what is the last word in chapter 15? - You don’t have to answer this question, if things don’t work.\nClass is the last word on chapter 15.\n\n\n\nErrors happen, they are frustrating, but if we learn something from them, we can turn them into valuable experiences.\n\ncheck the Questions and Answers forum in Canvas whether there is a solution available for your problem.\nif the above document does (not yet) include your question, document the error you encounter (be as concise and specific as you can at the same time)\nif the Question and Answers forum does (not yet) include a solution, describe one approach on how you tried to solve the problem (and how this did not work).\nsubmit the description of your problem in Canvas at Discussions > Questions and Answers. Write the paragraph in the mindset that you want to get help from somebody, and you try to describe the problem you are encountering.\nExtra points (1 pt for the first suggested working solution): post a solution to one of the problems in the Questions and Answers forum (your own does not count!).\n\nDeliverable (2): Write a paragraph on the biggest problem you encountered when you were building the book, (and how you managed to solve it.)\nMy biggest problem when I was building this book was the error below:\nError: bookdown::render_book() failed to render the output format ‘bookdown::pdf_book’\nFrom the beginning, whenever I encountered an error, I searched for it on the internet and the discussion board in Canvas. I found the answer to all my questions except this last one. But I couldn’t find the answer to this error using the internet or Canvas. To my knowledge, the book can not be built in pdf format. So, I needed to change the output format, but I was not sure how. I started trying different things in order to change the output format; I searched for it, and finally, I was able to choose bookdown::bs4_book from the Build Book tab in the upright corner of R studio. I was finally able to build the book in HTML format, and I am so happy about it. Generally, that was a great experience for me to build a book from a repo in R studio.\nYou can write your experience directly into the README.Rmd file. Just make sure that you change the yaml at the top: change the author at the top, and give your post a new title (don’t change the category :))\nCommit and push to your repo and you are done!"
  },
  {
    "objectID": "blog-2023/Blog-3-submissions/anphan0828/index.html",
    "href": "blog-2023/Blog-3-submissions/anphan0828/index.html",
    "title": "Building a Book",
    "section": "",
    "text": "What we want: build a book\nBuild the html version of the 2nd edition for Hadley Wickham’s book Advanced R Programming from a github repository.\nDeliverable (1): what is the last word in chapter 15? - You don’t have to answer this question, if things don’t work.\nAfter struggling with so many errors, I was able to build a book under two formats: html (index.html) and pdf (_main.pdf). Surprisingly, chapter 15 ends differently for these two formats.\n\nFor main.pdf: the last sentence is exercise number 2 of section 15.6.3 “Define a length method for the Person class.” (attached image _main.pdf.png)\nFor index.html: the last sentence looks like a footnote (or description, or citation) numbered 81 “The S4 ANY pseudo-class plays the same role as the S3 default pseudo-class.” (attached image index.html.pdf) I think this was not added for compiling in the pdf format.\n\n\n\nThings that did not work:\nDeliverable (2): Write a paragraph on the biggest problem you encountered when you were building the book, (and how you managed to solve it.).\nI decided to describe the most frustrating problems I faced:\n\nA bunch of packages that were not installed kept interrupting the render process (e.g., htmltools, bookdown, cli, even Rcpp). I tried to install each and every package when required. Eventually, I found a smarter solution to install all required packages automatically.The script filters for library files in the project and auto-installs them almost perfectly.\n\nQuitting from lines 4-5 (Introduction.Rmd) Error in get(genname, envir = envir) : object ‘wrap’ not found. For this, I tried looking at the code chunk, then consulted the Q&A in Canvas, and changed “wrap” to “sew”.\nQuitting from lines 106-107 (Control-flow.Rmd) Error in if (c(TRUE, FALSE)) 1 : the condition has length > 1. We receive an error message because we passed a vector to the if() statement, instead of a warning. At first, I commented that line out (in Control-flow.Rmd) for a quick solution. Then I switched to a more appropriate approach as suggested on Canvas, that is setting error=TRUE for that specific chunk. This option let me continue rendering the book (do not stop on error) as well as show the error on purpose in the book.\nSome packages are “not available for this version of R”. I was using R 4.2.1 on a department PC at this point, which I cannot update R by myself (only certain versions of software are available on Software Center) so I had to find an alternative solution. I installed package emo from source by cloning Hadley’s repo into the local repo:\n\n$ git clone --recurse-submodules https://github.com/hadley/emo.git\n\n# install.packages(\"emo2\",repos=NULL,type=\"source\")\nlibrary(emo)\n\nThis is another way to install packages that are not on CRAN.\n\nQuitting from lines 183-185 (Quotation.Rmd) Error in file(con, “w”) : cannot open the connection. This occurred multiple times (I found other classmates also faced the same problem), I decided to rebuild without changing anything and it worked.\nThe last error: Error: LaTeX failed to compile main.tex. See https://yihui.org/tinytex/r/#debugging for debugging tips. which took me a lot of time. After installing, re-installing, uninstalling desperately, I went back to read the error details more closely, and figured that some fonts are missing, so the tinytex package is not the main problem. I was working on Ubuntu then, so I decided to install two fonts that were missing (Inconsolata, Andale Mono, found in preamble.tex) from the terminal and refreshed the cache to update new fonts:\n\n\n$ sudo apt-get install fonts-inconsolata -y\n$ sudo apt-get install ttf-mscorefonts-installer\n$ sudo fc-cache -fv\nOne last TeX error was solved by adding \\usepackage{hyperref} in preamble.tex following Yihui’s solution.\nAnd there we have it, the book has been successfully built entirely from R, with the help of LaTeX and some Cpp code. Now the errors feel less frustrating to deal with, I guess I have encountered around 10% of all possible errors 😄 🙌 🎉 🎉!"
  },
  {
    "objectID": "blog-2023/Blog-3-submissions/hardtme/HardtMarieBlog3.html",
    "href": "blog-2023/Blog-3-submissions/hardtme/HardtMarieBlog3.html",
    "title": "Adventures in Book Building",
    "section": "",
    "text": "The goal of this week’s blog is to document what you are doing when things do not go according to plan.\nSimilar to previous exercises, we have a specific use case in mind: we want to build a book from a github repository.\nWhat happens in practice usually, is that we run into some problems. So your real task turns into that of a bug-hunter and fixer. Luckily, you have a community (the class discussion board) who might be able to help you.\n\n\nBuild the html version of the 2nd edition for Hadley Wickham’s book Advanced R Programming from a github repository.\nSteps:\n\nClone the repository https://github.com/hadley/adv-r.\nOpen the R project in the repository in RStudio.\nActivate the Build tab (by default in the top right panel). Click on the Build Book button.\nThe book will be available in html format as index.html\n\nDeliverable (1): what is the last word in chapter 15? - You don’t have to answer this question, if things don’t work.\nIf we don’t count the exercises, the last word in chapter 15 is “packages.” If we do count the exercises, the last word is “class.”\nDeliverable (2): Write a paragraph on the biggest problem you encountered when you were building the book, (and how you managed to solve it.)\nMy journey to building the book started with installing the bookdown and downlist packages. The biggest problem I encountered was the following error message soon after initiating the build: Error in get(genname, envir = envir) : object 'wrap' not found. Luckily for me, a classmate experienced the same issue and posted a solution on the Questions and Answers discussion board for STAT 585. I implemented my classmate’s solution (registerS3method(\"sew\", ...) instead of registerS3method(\"wrap\", ... on line 45 of the common.R file), and the error went away. After fixing this error, the only problems I had involved installing some more necessary packages to build the book. These packages included: lobstr, emo (from Hadley Wickham’s GitHub via devtools), sloop, RSQLite, zeallot, bench, and beeswarm."
  },
  {
    "objectID": "blog-2023/Blog-3-submissions/santos-cl/dosSantosCaio.html",
    "href": "blog-2023/Blog-3-submissions/santos-cl/dosSantosCaio.html",
    "title": "Building a Book",
    "section": "",
    "text": "The last word on chapter 15 was: Class"
  },
  {
    "objectID": "blog-2023/Blog-3-submissions/santos-cl/dosSantosCaio.html#biggest-problems-i-had-while-building-the-book",
    "href": "blog-2023/Blog-3-submissions/santos-cl/dosSantosCaio.html#biggest-problems-i-had-while-building-the-book",
    "title": "Building a Book",
    "section": "Biggest problems I had while building the book",
    "text": "Biggest problems I had while building the book\nI thought the biggest problems I would have would be related to installing several libraries. Then, I kept track of all the libraries that R asked me to install in order to knit the book: bookdown, htmltools, lobstr, emo, sloop, zeallot, bench, ggbeeswarm, and tinyTex. However, I had the biggest problem with a self-brought upon complication of storing my scripts in Box. I usually do this as an extra layer of protection against losing my code. The bookdown package was not able to find some of the files every now and then. In special, bookdown had a problem with ga_script.html. It was as if the existed and not at the same time. Eventually, I fixed it by cloning the repository straight to my machine instead of the cloud."
  },
  {
    "objectID": "blog-2023/Blog-3-submissions/sudi007/SudeshBhagat.html",
    "href": "blog-2023/Blog-3-submissions/sudi007/SudeshBhagat.html",
    "title": "Building a Book",
    "section": "",
    "text": "The goal of this week’s blog is to document what you are doing when things do not go according to plan.\nSimilar to previous exercises, we have a specific use case in mind: we want to build a book from a github repository.\nWhat happens in practice usually, is that we run into some problems. So your real task turns into that of a bug-hunter and fixer. Luckily, you have a community (the class discussion board) who might be able to help you.\n\n\nBuild the html version of the 2nd edition for Hadley Wickham’s book Advanced R Programming from a github repository.\nSteps:\n\nClone the repository https://github.com/hadley/adv-r.\nOpen the R project in the repository in RStudio.\nActivate the Build tab (by default in the top right panel). Click on the Build Book button.\nThe book will be available in html format as index.html\n\nDeliverable (1): what is the last word in chapter 15? - You don’t have to answer this question, if things don’t work.\nThe Last word in chapter 15 is pseudo-class.The sentence reads as follows “The S4 any pseudo-class plays the same role as the S3 default pseudo-cLass”\n\n\n\nErrors happen, they are frustrating, but if we learn something from them, we can turn them into valuable experiences.\n\ncheck the Questions and Answers forum in Canvas whether there is a solution available for your problem.\n\nI was encountering an error while building the book. I had posted this challenge I was facing on the Question and Answers forum in Canvas. I received a solution to it. My classmate, Motahareh Kashanian, suggested that Rtools need to updated. Landon Getting further added to this suggestion by offering the path to solve the issue.\n\nif the above document does (not yet) include your question, document the error you encounter (be as concise and specific as you can at the same time)\n\nMy question on Canvas is as follows:I am facing the following error as shown below and have installed all necessary packages, but I cannot figure out what I am missing. Any guidance will be appreciated.\nIn system(cmd) : ‘make’ not found Quitting from lines 77-84 (Rcpp.Rmd) Error in sourceCpp(code = code, env = env, rebuild = rebuild, cacheDir = cacheDir, : Error 1 occurred building shared library. Calls: local … eval_with_user_handlers -> eval -> eval -> cppFunction -> sourceCpp\n\nif the Question and Answers forum does (not yet) include a solution, describe one approach on how you tried to solve the problem (and how this did not work).\n\nI found a solution for my error from the question and Answers forum. I have already stated the solution I received above.\n\nsubmit the description of your problem in Canvas at Discussions > Questions and Answers. Write the paragraph in the mindset that you want to get help from somebody, and you try to describe the problem you are encountering.\n\nI am trying to build a book in R. However, while building it, I face the following error. I have installed all the necessary packages. But I cannot figure out the reason for the error. A screenshot of the error is posted below. Any guidance will be appreciated\n\nExtra points (1 pt for the first suggested working solution): post a solution to one of the problems in the Questions and Answers forum (your own does not count!).\n\nI offered a solution to one of the questions posted on the Question and Answer forum. One of my classmates was facing a challenge in terms of opening the URL. They had posted the error they were facing on the Question and Answer forum as follows:I offered a solution to this error by suggesting that they try to uninstall and install from RGUI. This suggestion was based on my own experience where I had faced a similar problem and the solution that I offered had worked for me. #install #tinytex::install_tinytex() # to uninstall TinyTeX, run #tinytex::uninstall_tinytex()\nDeliverable (2): Write a paragraph on the biggest problem you encountered when you were building the book, (and how you managed to solve it.)\nMy biggest challenge while trying to build the book was the installation of a particular type of font called inconsolata. This font was required for the PDF file to be knnited. As I didn’t know how to solve this problem, I turned to StackOverflow in search for a solution and I found one there. According to the solution suggested on StackOverflow, to use this font in Windows, I was first required to install this font on my system. I did that by downloading the .tff file of the font from Google Fonts. Thereafter, I set it as a default font for R graphics. In order to do that I used the windowsFonts function from the grDevices package. Once the font was installed, my issue was resolved and I could continue to build the book. \nSubmit to your repo and you are done!"
  },
  {
    "objectID": "blog-2023/Blog-3-submissions/motinaaa/index.html",
    "href": "blog-2023/Blog-3-submissions/motinaaa/index.html",
    "title": "Drawning in ERRORS",
    "section": "",
    "text": "The goal of this week’s blog is to document what you are doing when things do not go according to plan.\nSimilar to previous exercises, we have a specific use case in mind: we want to build a book from a github repository.\nWhat happens in practice usually, is that we run into some problems. So your real task turns into that of a bug-hunter and fixer. Luckily, you have a community (the class discussion board) who might be able to help you.\n\n\nBuild the html version of the 2nd edition for Hadley Wickham’s book Advanced R Programming from a github repository.\nSteps:\n\nClone the repository https://github.com/hadley/adv-r.\nOpen the R project in the repository in RStudio.\nActivate the Build tab (by default in the top right panel). Click on the Build Book button.\nThe book will be available in html format as index.html\n\nDeliverable (1): what is the last word in chapter 15? - You don’t have to answer this question, if things don’t work.\nIt took forever to compile, but I finally got the HTML version to work!\nThe last word in chapter 15? CLASS! IT IS CLASS!\n\n\n\nErrors happen, they are frustrating, but if we learn something from them, we can turn them into valuable experiences.\n\ncheck the Questions and Answers forum in Canvas whether there is a solution available for your problem.\nif the above document does (not yet) include your question, document the error you encounter (be as concise and specific as you can at the same time)\nif the Question and Answers forum does (not yet) include a solution, describe one approach on how you tried to solve the problem (and how this did not work).\nsubmit the description of your problem in Canvas at Discussions > Questions and Answers. Write the paragraph in the mindset that you want to get help from somebody, and you try to describe the problem you are encountering.\nExtra points (1 pt for the first suggested working solution): post a solution to one of the problems in the Questions and Answers forum (your own does not count!).\n\nDeliverable (2): Write a paragraph on the biggest problem you encountered when you were building the book, (and how you managed to solve it.)\n\nBuilding the book has been a pain! :))\nThe first error I got was “Failed to load Cairo DLL” in R, which is because I use. MacOS. According to CRAN, it’s related to XQuartz since it’s not part of OS X anymore. I installed XQuartz and basically all Cairo problems are fixed.\nThe next error was object ‘wrap’ not found!\nI fixed the error by changing “wrap” to “sew” in the registerS3method() function in common.R.\nIn the meantime, I installed a bunch of packages to get going! :))\nAfter that, I get to a big one! Error in if (c(TRUE, FALSE)) 1 : the condition has length > 1\nIt turns out the behavior described is now the default (as of R 4.2.0).In other words, the command “if (c(TRUE, FALSE)) 1” will fail no matter what condition is set. To fix this, I just set error=TRUE in the addressed code chunk!\nAgain, there was a bunch of missing packages! :))\nAt this point it was taking almost 15-20 minutes to compile the book, and I ended up getting an error saying **LaTeX failed to compile _main.tex.**\nI tried updating tinytex, but I got the same error! I installed tlmgr to install packages, but it didn’t work! As I write this I’m trying options(tinytex.verbose = TRUE) to see if it fixes the error. I’ll let you know how it goes!\n\n. . . .\n\nHey, it’s been a while! My PDF version wouldn’t compile, but I made it work with HTML! I’m still trying to fix the LaTex error! :)\n\nYou can write your experience directly into the README.Rmd file. Just make sure that you change the yaml at the top: change the author at the top, and give your post a new title (don’t change the category :))\nCommit and push to your repo and you are done!"
  },
  {
    "objectID": "blog-2023/Blog-3-submissions/maxwellskinner2002/index.html",
    "href": "blog-2023/Blog-3-submissions/maxwellskinner2002/index.html",
    "title": "Title of your post",
    "section": "",
    "text": "The goal of this week’s blog is to document what you are doing when things do not go according to plan.\nSimilar to previous exercises, we have a specific use case in mind: we want to build a book from a github repository.\nWhat happens in practice usually, is that we run into some problems. So your real task turns into that of a bug-hunter and fixer. Luckily, you have a community (the class discussion board) who might be able to help you.\n\n\nBuild the html version of the 2nd edition for Hadley Wickham’s book Advanced R Programming from a github repository.\nSteps:\n\nClone the repository https://github.com/hadley/adv-r.\nOpen the R project in the repository in RStudio.\nActivate the Build tab (by default in the top right panel). Click on the Build Book button.\nThe book will be available in html format as index.html\n\nDeliverable (1): what is the last word in chapter 15? - You don’t have to answer this question, if things don’t work.\n\n\n\nErrors happen, they are frustrating, but if we learn something from them, we can turn them into valuable experiences.\n\ncheck the Questions and Answers forum in Canvas whether there is a solution available for your problem.\nif the above document does (not yet) include your question, document the error you encounter (be as concise and specific as you can at the same time)\nif the Question and Answers forum does (not yet) include a solution, describe one approach on how you tried to solve the problem (and how this did not work).\nsubmit the description of your problem in Canvas at Discussions > Questions and Answers. Write the paragraph in the mindset that you want to get help from somebody, and you try to describe the problem you are encountering.\nExtra points (1 pt for the first suggested working solution): post a solution to one of the problems in the Questions and Answers forum (your own does not count!).\n\nDeliverable (2): Write a paragraph on the biggest problem you encountered when you were building the book, (and how you managed to solve it.)\nYou can write your experience directly into the README.Rmd file. Just make sure that you change the yaml at the top: change the author at the top, and give your post a new title (don’t change the category :))\nCommit and push to your repo and you are done!"
  },
  {
    "objectID": "blog-2023/Blog-3-submissions/Sabrenar/index.html",
    "href": "blog-2023/Blog-3-submissions/Sabrenar/index.html",
    "title": "Building a book with R’s bookdown",
    "section": "",
    "text": "The goal of this week’s blog is to document what you are doing when things do not go according to plan.\nSimilar to previous exercises, we have a specific use case in mind: we want to build a book from a github repository.\nWhat happens in practice usually, is that we run into some problems. So your real task turns into that of a bug-hunter and fixer. Luckily, you have a community (the class discussion board) who might be able to help you.\n\n\nBuild the html version of the 2nd edition for Hadley Wickham’s book Advanced R Programming from a github repository.\nSteps:\n\nClone the repository https://github.com/hadley/adv-r.\nOpen the R project in the repository in RStudio.\nActivate the Build tab (by default in the top right panel). Click on the Build Book button.\nThe book will be available in html format as index.html\n\nDeliverable (1): what is the last word in chapter 15? - You don’t have to answer this question, if things don’t work.\nThe last word in chapter 15 is pseudo-class.\n\n\n\nErrors happen, they are frustrating, but if we learn something from them, we can turn them into valuable experiences.\n\ncheck the Questions and Answers forum in Canvas whether there is a solution available for your problem.\nif the above document does (not yet) include your question, document the error you encounter (be as concise and specific as you can at the same time)\nif the Question and Answers forum does (not yet) include a solution, describe one approach on how you tried to solve the problem (and how this did not work).\nsubmit the description of your problem in Canvas at Discussions > Questions and Answers. Write the paragraph in the mindset that you want to get help from somebody, and you try to describe the problem you are encountering.\nExtra points (1 pt for the first suggested working solution): post a solution to one of the problems in the Questions and Answers forum (your own does not count!).\n\nDeliverable (2): Write a paragraph on the biggest problem you encountered when you were building the book, (and how you managed to solve it.)\nThe biggest problem I encountered in building the html book was just needing a variety of packages not already installed. These errors were solved by installing the necessary packages. However, when not specifying the output for the build book command, the largest obstacle is LaTeX failed to compile main.tex. Re-installing tinytex and trying to obtain a larger error message with the options function both failed. This error appears to be a major problem since the traditional debugging methods are not resolving the error. If it was absolutely necessary to obtain a pdf version of the bookdown, then I would first try to obtain the pdf version of a different book to see if it is an issue with the system or with the book I am trying to obtain. Then I would debug either the book or the package depending on the results of the first part. Yet, if it was not necessary to obtain a pdf version of the bookdown, then I would select “bookdown::bs4_book” or “bookdown::gitbook” in order to obtain the html version of the bookdown.\nYou can write your experience directly into the README.Rmd file. Just make sure that you change the yaml at the top: change the author at the top, and give your post a new title (don’t change the category :))\nCommit and push to your repo and you are done!"
  },
  {
    "objectID": "blog-2023/Blog-3-submissions/luobo119/index.html",
    "href": "blog-2023/Blog-3-submissions/luobo119/index.html",
    "title": "Experience of building a book",
    "section": "",
    "text": "The goal of this week’s blog is to document what you are doing when things do not go according to plan.\nSimilar to previous exercises, we have a specific use case in mind: we want to build a book from a github repository.\nWhat happens in practice usually, is that we run into some problems. So your real task turns into that of a bug-hunter and fixer. Luckily, you have a community (the class discussion board) who might be able to help you.\n\n\nBuild the html version of the 2nd edition for Hadley Wickham’s book Advanced R Programming from a github repository.\nSteps:\n\nClone the repository https://github.com/hadley/adv-r.\nOpen the R project in the repository in RStudio.\nActivate the Build tab (by default in the top right panel). Click on the Build Book button.\nThe book will be available in html format as index.html\n\nDeliverable (1): what is the last word in chapter 15? - You don’t have to answer this question, if things don’t work.\nAnswer: Last word in chapter 15 is class in index.html or pseudo-class if references included.\n\n\n\nErrors happen, they are frustrating, but if we learn something from them, we can turn them into valuable experiences.\n\ncheck the Questions and Answers forum in Canvas whether there is a solution available for your problem.\nif the above document does (not yet) include your question, document the error you encounter (be as concise and specific as you can at the same time)\nif the Question and Answers forum does (not yet) include a solution, describe one approach on how you tried to solve the problem (and how this did not work).\nsubmit the description of your problem in Canvas at Discussions > Questions and Answers. Write the paragraph in the mindset that you want to get help from somebody, and you try to describe the problem you are encountering.\nExtra points (1 pt for the first suggested working solution): post a solution to one of the problems in the Questions and Answers forum (your own does not count!).\n\nDeliverable (2): Write a paragraph on the biggest problem you encountered when you were building the book, (and how you managed to solve it.)\nThe biggest problem is that it is hard to find what is wrong when I have the error ‘dev.control() called without an open graphics device’ because it does not point to any specific file that might contain the problem. I found someone had the same issue in one GitHub post, and one person commented that there might be some missing pieces in the package ‘Cairo’. I followed his instructions and solved the problem.\nAccording to my experience in building the book, we need to update and install all the packages used first. Then I still encountered some errors before I could successfully compile the book. I’d like to record all the problems I encountered and my solutions here.\n\nError in get(genname, envir = envir) : object ‘wrap’ not found\nCalls: local … withVisible -> eval -> eval -> registerS3method -> get\n\nThe error is from ‘common.R’ file ‘registerS3method’ function. Because for knitr 1.40, knitr:::wrap() has been removed, and knitr::sew() is used instead.\nUsing registerS3method(“sew”, …) instead of registerS3method(“sew”, …).\n\nError in if (c(TRUE, FALSE)) 1 : the condition has length > 1\n\nThe error is from ‘Control-flow.Rmd’ file.\nShowing the errors without stopping R by adding chunk option ‘error=TRUE’\n\nError in dev.control(displaylist = if (record) “enable” else “inhibit”) :\ndev.control() called without an open graphics device\nCalls: local … call_block -> block_exec -> eng_r -> chunk_device -> dev.control\n\n\nThis is because for mac, XQuartz is missing for package ‘Cairo’.\nDownloading ‘Quartz X11’ and re-install ‘Cairo’. (https://github.com/brentthorne/posterdown/issues/42)\n\nPackage fontspec Error: The font “Inconsolata” cannot be found.\n\nInstalling the font by using\nbrew tap homebrew/cask-fonts\nbrew install –cask font-Inconsolata\n\nLaTeX Error: Command \\href undefined.\n\nAdding ‘\\usepackage{hyperref}’ in ‘latex/preamble.tex’.\n\n\nAppendix:\n\nhttps://github.com/hadley/r-pkgs/blob/main/common.R\n\nhttps://github.com/statcomputing/compiling-advanced-r-beili0022\n\nhttps://github.com/yihui/bookdown-crc/commit/683e5fbd87478240c84cbebaf04058dd685090c8"
  },
  {
    "objectID": "blog-2023/Blog-3-submissions/AArabio/ArabioAlexandra.html",
    "href": "blog-2023/Blog-3-submissions/AArabio/ArabioAlexandra.html",
    "title": "Building a Book",
    "section": "",
    "text": "The goal of this week’s blog is to document what you are doing when things do not go according to plan.\nSimilar to previous exercises, we have a specific use case in mind: we want to build a book from a github repository.\nWhat happens in practice usually, is that we run into some problems. So your real task turns into that of a bug-hunter and fixer. Luckily, you have a community (the class discussion board) who might be able to help you.\n\n\nBuild the html version of the 2nd edition for Hadley Wickham’s book Advanced R Programming from a github repository.\nSteps:\n\nClone the repository https://github.com/hadley/adv-r.\nOpen the R project in the repository in RStudio.\nActivate the Build tab (by default in the top right panel). Click on the Build Book button.\nThe book will be available in html format as index.html\n\nDeliverable (1): what is the last word in chapter 15? - You don’t have to answer this question, if things don’t work.\n“15.6.3 Exercises What would a full setOldClass() definition look like for an ordered factor (i.e. add slots and prototype the definition above)?\nDefine a length method for the Person class.” … The last word in chapter 15 is ‘class’.\n\n\n\nErrors happen, they are frustrating, but if we learn something from them, we can turn them into valuable experiences.\n\ncheck the Questions and Answers forum in Canvas whether there is a solution available for your problem.\nif the above document does (not yet) include your question, document the error you encounter (be as concise and specific as you can at the same time)\nif the Question and Answers forum does (not yet) include a solution, describe one approach on how you tried to solve the problem (and how this did not work).\nsubmit the description of your problem in Canvas at Discussions > Questions and Answers. Write the paragraph in the mindset that you want to get help from somebody, and you try to describe the problem you are encountering.\nExtra points (1 pt for the first suggested working solution): post a solution to one of the problems in the Questions and Answers forum (your own does not count!).\n\nDeliverable (2): Write a paragraph on the biggest problem you encountered when you were building the book, (and how you managed to solve it.)\nOf the problems that I encountered when building the book, the biggest problem I had may likely have been one of the smallest… not having required packages downloaded. I encountered similar errors to others from the class through the building process but was able to trace them back and fix them quickly and without much issue. The error messages were helpful and made it easy for me to find where the issues were occurring in the various markdown files. What I found the most challenging for myself was feeling like everything was working and I had fixed everything just for the process to fail again due to not having a package that was being pulled from the library. This was of course easily fixed through downloading the package it was looking for, but it was more of an annoyance than anything else. Following through this blog and being able to successfully build the book myself was encouraging though and I now feel that I am more knowledgeable for when errors may appear in my own projects in the future. I have more experience now using search engines and asking proper questions to my peers if issues present themselves in the future.\nSubmit to your repo and you are done!"
  },
  {
    "objectID": "blog-2023/Blog-3-submissions/Starwiiin/index.html",
    "href": "blog-2023/Blog-3-submissions/Starwiiin/index.html",
    "title": "Building a book",
    "section": "",
    "text": "The goal of this week’s blog is to document what you are doing when things do not go according to plan.\nSimilar to previous exercises, we have a specific use case in mind: we want to build a book from a github repository.\nWhat happens in practice usually, is that we run into some problems. So your real task turns into that of a bug-hunter and fixer. Luckily, you have a community (the class discussion board) who might be able to help you.\n\n\nBuild the html version of the 2nd edition for Hadley Wickham’s book Advanced R Programming from a github repository.\nSteps:\n\nClone the repository https://github.com/hadley/adv-r.\nOpen the R project in the repository in RStudio.\nActivate the Build tab (by default in the top right panel). Click on the Build Book button.\nThe book will be available in html format as index.html\n\nDeliverable (1): what is the last word in chapter 15? - You don’t have to answer this question, if things don’t work.\nParvin’s answer: Unfortunately, I could not get the PDF of the book, but I could get the html file. The reason that I could not get the PDF was an error related to “Inconsolata” font and I could solve it.\n\n\n\nErrors happen, they are frustrating, but if we learn something from them, we can turn them into valuable experiences.\n\ncheck the Questions and Answers forum in Canvas whether there is a solution available for your problem.\nif the above document does (not yet) include your question, document the error you encounter (be as concise and specific as you can at the same time)\nif the Question and Answers forum does (not yet) include a solution, describe one approach on how you tried to solve the problem (and how this did not work).\nsubmit the description of your problem in Canvas at Discussions > Questions and Answers. Write the paragraph in the mindset that you want to get help from somebody, and you try to describe the problem you are encountering.\nExtra points (1 pt for the first suggested working solution): post a solution to one of the problems in the Questions and Answers forum (your own does not count!).\n\nDeliverable (2): Write a paragraph on the biggest problem you encountered when you were building the book, (and how you managed to solve it.)\nParvin’s answer: I faced with multiple errors as follows; 1) An error about the length of “if (c(TRUE, FALSE)) 1”, that I solved it using the suggestion in the Discussion page on canvas that was adding “error = True” to the R chunk. 2) I got several errors about the package installation and I solved them by installing the packages. 3) I got a couple of errors related to the Latex, and I solved them using the instruction provided in the discussion for the tinytex and It worked. 4) Finally, I got an error that I could not solve it and it was “cannot find Inconsolata.mf.”. I tried to add the fint but it did not work. I could get the index.html but I did not get the PDF. You can write your experience directly into the README.Rmd file. Just make sure that you change the yaml at the top: change the author at the top, and give your post a new title (don’t change the category :))\nCommit and push to your repo and you are done!"
  },
  {
    "objectID": "blog-2023/Blog-6-submissions/xyzyc/index.html",
    "href": "blog-2023/Blog-6-submissions/xyzyc/index.html",
    "title": "renv package",
    "section": "",
    "text": "What happens when we change the Rmd file and commit?\nIn Blog 5 you had the first exposure to Github Actions. We just checked frontmatter compliance (as we do for this round). You see that we have added a second action - here, we are converting the Rmarkdown document to a markdown file by running render_rmarkdown on Github. This action passes successfully for this document. We want to do something similar for blog #4.\nNow start reading …\nRead the vignette Introduction to renv for the renv R package by Kevin Ushey.\nThen do:\n\nInstall the R package renv on your local machine.\nIn the project for blog 4, initialize the workflow used by the renv package.\nAdd all dependencies to the environment (implicitly by installing all the dependencies or explicitly by listing dependencies in a DESCRIPTION file).\nAdd the renv folder to your blog 4 repository, and push the changes.\nIs the github action working? Read any potential error messages in the workflow and try to fix things. Make sure to check stackoverflow for help, don’t forget our Discussion board!\n\nWrite a blog post addressing the following questions:\n\nWhat is the idea of the renv package?\n\nrenv packages is for managing the dependencies of a project. By using it we can easily save the R version and dependent packages version and restore the environment in the future. This helps with reproducibility of the project.\n\nIn 50 to 100 words describe your experience working with renv. What went well? What did not go so well?\n\nI tested 8 rounds to get things right. In the render-rmarkdown.yaml generated by usethis package, setup-r, setup-renv and setup-pandoc are in v1, and I get error which says fail to install R as well as other warnings. After I updated these to v2, I started getting error saying there is no package called rmarkdown, which turned out to be caused by not pushing renv.lock to my repo.\nSubmit this blog post to your blog-6 repo."
  },
  {
    "objectID": "blog-2023/Blog-6-submissions/kundan7kumar/index.html",
    "href": "blog-2023/Blog-6-submissions/kundan7kumar/index.html",
    "title": "renv R package",
    "section": "",
    "text": "In Blog 5 you had the first exposure to Github Actions. We just checked frontmatter compliance (as we do for this round). You see that we have added a second action - here, we are converting the Rmarkdown document to a markdown file by running render_rmarkdown on Github. This action passes successfully for this document. We want to do something similar for blog #4.\nNow start reading …\nRead the vignette Introduction to renv for the renv R package by Kevin Ushey.\nThen do:\n\nInstall the R package renv on your local machine.\nIn the project for blog 4, initialize the workflow used by the renv package.\nAdd all dependencies to the environment (implicitly by installing all the depepndencies or explicilty by listing dependencies in a DESCRIPTION file).\nAdd the renv folder to your blog 4 repository, and push the changes.\nIs the github action working? Read any potential error messages in the workflow and try to fix things. Make sure to check stackoverflow for help, don’t forget our Discussion board!\n\nWrite a blog post addressing the following questions:\n\nWhat is the idea of the renv package?.\n\nSolution:.\nThe renv package is designed to create a reproducible and consistent environment for R projects. It helps in managing the package dependencies in the project. It helps to isolate and manage the R packages in the project, which can easily be reproduced even if packages are updated or changed over time. It is an effective solution to the common problem of package dependency management in R projects like conda, pipenv in python. It is a great tool for project management.\n\nIn 50 to 100 words describe your experience working with renv. What went well? What did not go so well?\n\nSolution: It was a good learning experience; I was not aware renv earlier. The good point of the renv package is that it is easier to manage R package and its dependencies within a project. It will help to make the project reproducible and consistent across different environments.\nWhat went well:.\n\nInstall using install.packages(“renv”) and then initialize the workflow with renv::init() . It will create renv folder automatically. I pushed the renv changes to blog4 github.\nWe can use renv::snapshot() to save the project’s package environment and renv::restore() to restore . It will help in reproducibility.\nThe package lockfile generated by renv made it easy to share my project with others, as they could simply restore the package environment using renv::restore().\n\nWhat did not go well:.\nI found that it is easy to create renv environment, I did easily by installing packages using install.packages(“renv”) and initialize it. I think that it is a great tool for managing projects. I didn’t find any issue till now.\nSubmit this blog post to your blog-6 repo."
  },
  {
    "objectID": "blog-2023/Blog-6-submissions/anyeshar/index.html",
    "href": "blog-2023/Blog-6-submissions/anyeshar/index.html",
    "title": "renv blog",
    "section": "",
    "text": "What happens when we change the Rmd file and commit?\nIn Blog 5 you had the first exposure to Github Actions. We just checked frontmatter compliance (as we do for this round). You see that we have added a second action - here, we are converting the Rmarkdown document to a markdown file by running render_rmarkdown on Github. This action passes successfully for this document. We want to do something similar for blog #4.\nNow start reading …\nRead the vignette Introduction to renv for the renv R package by Kevin Ushey.\nThen do:\n\nInstall the R package renv on your local machine.\nIn the project for blog 4, initialize the workflow used by the renv package.\nAdd all dependencies to the environment (implicitly by installing all the depepndencies or explicilty by listing dependencies in a DESCRIPTION file).\nAdd the renv folder to your blog 4 repository, and push the changes.\nIs the github action working? Read any potential error messages in the workflow and try to fix things. Make sure to check stackoverflow for help, don’t forget our Discussion board! The first test in 1c did not work, but after adding the renv folder it did work.\n\nWrite a blog post addressing the following questions:\n\nWhat is the idea of the renv package?\n\nThe renv package is a good way to manage your local R library. It helps to make projects more reporducible by saving your project when you specify. From my understanding you load renv, work in your project as normal, and then you’re ready, you save it. Unlike regular saving it saves information like packages used and paths.\n\nIn 50 to 100 words describe your experience working with renv. What went well? What did not go so well?\n\nFor blog 4, I did not have any issues (at least so far). I was easily able to install the package and use it. Where I ran into issues was when we created a test r package in class. I was not able to build my package. When I googled my error, I found that the issue was that I had installed renv to my regular library and not the specific project library which was causing problems. After I deleted it, I was able to build the test package."
  },
  {
    "objectID": "blog-2023/Blog-6-submissions/Landon-Getting/index.html#what-is-the-idea-of-the-renv-package",
    "href": "blog-2023/Blog-6-submissions/Landon-Getting/index.html#what-is-the-idea-of-the-renv-package",
    "title": "Exploring renv",
    "section": "What is the idea of the renv package?",
    "text": "What is the idea of the renv package?\nThe renv package helps to alleviate pain with package management. Prior to renv, I just relied on my globally installed packages in every project, script, and .Rmd file via library(). This left me prone to package verison conflicts and reproducibility issues. With renv, I can create separate project libraries that contain the correct versions and packages for that specific project. These package libraries are shared along with the project so that other users are explicitly informed of the necessary dependencies. This is especially useful when combined with package development and distribution."
  },
  {
    "objectID": "blog-2023/Blog-6-submissions/Landon-Getting/index.html#what-is-your-experience-with-renv-what-went-well-what-did-not-go-so-well",
    "href": "blog-2023/Blog-6-submissions/Landon-Getting/index.html#what-is-your-experience-with-renv-what-went-well-what-did-not-go-so-well",
    "title": "Exploring renv",
    "section": "What is your experience with renv? What went well? What did not go so well?",
    "text": "What is your experience with renv? What went well? What did not go so well?\nI had an overall positive experience with renv. I installed the package without any issues and the general workflow commands (renv::init() and renv:snapchat()) worked as well. Prior to utilizing the package, I watched this short video from one of the package maintainers at Posit (RStudio at the time). It helped explain the motivations for renv and an overview of the usual workflow for the package. I would recommend watching!"
  },
  {
    "objectID": "blog-2023/Blog-6-submissions/Hiiiua/index.html",
    "href": "blog-2023/Blog-6-submissions/Hiiiua/index.html",
    "title": "More on reproducibility",
    "section": "",
    "text": "What happens when we change the Rmd file and commit?\nIn Blog 5 you had the first exposure to Github Actions. We just checked frontmatter compliance (as we do for this round). You see that we have added a second action - here, we are converting the Rmarkdown document to a markdown file by running render_rmarkdown on Github. This action passes successfully for this document. We want to do something similar for blog #4.\nNow start reading …\nRead the vignette Introduction to renv for the renv R package by Kevin Ushey.\nThen do:\n\nInstall the R package renv on your local machine.\nIn the project for blog 4, initialize the workflow used by the renv package.\nAdd all dependencies to the environment (implicitly by installing all the depepndencies or explicilty by listing dependencies in a DESCRIPTION file).\nAdd the renv folder to your blog 4 repository, and push the changes.\nIs the github action working? Read any potential error messages in the workflow and try to fix things. Make sure to check stackoverflow for help, don’t forget our Discussion board!\n\nWrite a blog post addressing the following questions:\n\nWhat is the idea of the renv package? renv package is an effort to manage R dependency in terms of project. It creates project specific R dependencies by initializing command and keeps track of version upgrades and new installations by snapshot. In such a way, it is easier for developer to trace and reset if needed. It’s also easier for anyone accesses the code to reproduce.\nIn 50 to 100 words describe your experience working with renv. What went well? What did not go so well? Installing renv was smooth and initializing was convenient to keep track of all the dependencies, except the render-rmarkdown kept complaining about there is no package called rmarkdown. I searched stackflow, one of the answers mentioned “making sure rmarkdown is included in .lock file’. I went to the lock file but couldn’t find rmarkdown, which I’m sure I have installed it and took a snapshot. I check the status by renv::status() finding there were packages upgraded haven’t been recorded, one of them was rmarkdown, so I did snapshot again, touched little on README.Rmd to trigger github action and pushed it with updated .lock file, passed the action eventually.\n\nSubmit this blog post to your blog-6 repo."
  },
  {
    "objectID": "blog-2023/Blog-6-submissions/charlestbonk/index.html",
    "href": "blog-2023/Blog-6-submissions/charlestbonk/index.html",
    "title": "Stat 585",
    "section": "",
    "text": "What happens when we change the Rmd file and commit?\nIn Blog 5 you had the first exposure to Github Actions. We just checked frontmatter compliance (as we do for this round). You see that we have added a second action - here, we are converting the Rmarkdown document to a markdown file by running render_rmarkdown on Github. This action passes successfully for this document. We want to do something similar for blog #4.\nNow start reading …\nRead the vignette Introduction to renv for the renv R package by Kevin Ushey.\nThen do:\n\nInstall the R package renv on your local machine.\nIn the project for blog 4, initialize the workflow used by the renv package.\nAdd all dependencies to the environment (implicitly by installing all the depepndencies or explicilty by listing dependencies in a DESCRIPTION file).\nAdd the renv folder to your blog 4 repository, and push the changes.\nIs the github action working? Read any potential error messages in the workflow and try to fix things. Make sure to check stackoverflow for help, don’t forget our Discussion board!\n\nWrite a blog post addressing the following questions:\n\nWhat is the idea of the renv package?\nIn 50 to 100 words describe your experience working with renv. What went well? What did not go so well?\n\nSubmit this blog post to your blog-6 repo."
  },
  {
    "objectID": "blog-2023/Blog-6-submissions/TWiedRW/index.html",
    "href": "blog-2023/Blog-6-submissions/TWiedRW/index.html",
    "title": "Blog 6",
    "section": "",
    "text": "The idea behind renv is to save the dependencies in R projects. This includes the packages, versions, and package sources (CRAN or other) to help make research more reproducible. For example, I know that stats::aggregate() function had a recent syntax update that caused instructional notes for STAT 801A to be outdated. If this function was used in a project before, there is a chance that it would now give errors. renv allows the capability to save the state of the packages used, so it would be easier for others to see and use the same versions of the packages when others look at the project and not have to worry about incompatible versions of package dependencies.\nWhen working with renv for Blog 4, I did not encounter any issues. Initializing and saving the state was easy with the necessary functions. The only surprising thing was how many dependencies were in my blog post, but I do suppose that packages in the tidyverse have a number of dependencies."
  },
  {
    "objectID": "blog-2023/Blog-6-submissions/charchit/index.html",
    "href": "blog-2023/Blog-6-submissions/charchit/index.html",
    "title": "Renv",
    "section": "",
    "text": "What happens when we change the Rmd file and commit?\nIn Blog 5 you had the first exposure to Github Actions. We just checked frontmatter compliance (as we do for this round). You see that we have added a second action - here, we are converting the Rmarkdown document to a markdown file by running render_rmarkdown on Github. This action passes successfully for this document. We want to do something similar for blog #4.\nNow start reading …\nRead the vignette Introduction to renv for the renv R package by Kevin Ushey.\nThen do:\n\nInstall the R package renv on your local machine.\nIn the project for blog 4, initialize the workflow used by the renv package.\nAdd all dependencies to the environment (implicitly by installing all the depepndencies or explicilty by listing dependencies in a DESCRIPTION file).\nAdd the renv folder to your blog 4 repository, and push the changes.\nIs the github action working? Read any potential error messages in the workflow and try to fix things. Make sure to check stackoverflow for help, don’t forget our Discussion board!\n\nWrite a blog post addressing the following questions:\n\nWhat is the idea of the renv package?\n\nRenv package help to create, manage, and share environments in R. In python programming environments were always hard to create in my experience. I need to set a path and every time if there is a new project I usually create another environment. Renv seems pretty useful in reproducing the the environment for the R projects.It could help in collaborating very well. In one of my project in python I need to transfer all of my files and code at the end of the project to the company who is funding my project. Package like renv can help me do it better. I will look for it in python so I can share my environment with the company’s computer.\n\nIn 50 to 100 words describe your experience working with renv. What went well? What did not go so well? I could not try this blog as much as I wanted to. My time and health constraints were not really favorable but I will try it during the weekend. Even though the Renv package is designed to offer collaboration tool it took me a while to get familiar with it and setup on my computer. I will try to use on my lab computer and laptop to see if I can reproduce my env…\n\nSubmit this blog post to your blog-6 repo."
  },
  {
    "objectID": "blog-2023/Blog-6-submissions/kellynay/index.html",
    "href": "blog-2023/Blog-6-submissions/kellynay/index.html",
    "title": "Renv package overview",
    "section": "",
    "text": "What happens when we change the Rmd file and commit?\nIn Blog 5 you had the first exposure to Github Actions. We just checked frontmatter compliance (as we do for this round). You see that we have added a second action - here, we are converting the Rmarkdown document to a markdown file by running render_rmarkdown on Github. This action passes successfully for this document. We want to do something similar for blog #4.\nNow start reading …\nRead the vignette Introduction to renv for the renv R package by Kevin Ushey.\nThen do:\n\nInstall the R package renv on your local machine.\nIn the project for blog 4, initialize the workflow used by the renv package.\nAdd all dependencies to the environment (implicitly by installing all the depepndencies or explicilty by listing dependencies in a DESCRIPTION file).\nAdd the renv folder to your blog 4 repository, and push the changes.\nIs the github action working? Read any potential error messages in the workflow and try to fix things. Make sure to check stackoverflow for help, don’t forget our Discussion board!\n\nWrite a blog post addressing the following questions:\n\nWhat is the idea of the renv package?\n\nHelps with managing R project’s dependencies as well managing packages (installing or removing), so that our existing workflows function as they did before. This package represents a robust, stable replacement for the Packrat package.\n\nIn 50 to 100 words describe your experience working with renv. What went well? What did not go so well?\n\nFollowing the workflow went well and the “renv” package was created successfully. All the required packages to run the code for Blog 4 also installed and updated as expected.\nTroubleshooting the error “Error: install of package”curl” failed [error code 1]” took some time. To fix this I needed to install the “libcurl4-openssl-dev” package, but most of the answers indicated the command “sudo apt install libcurl4-openssl-dev”. To use “sudo” I needed the Ubuntu aplication installed as well.\nI also followed all the steps on this link: https://www.cyberciti.biz/faq/how-to-install-curl-command-on-a-ubuntu-linux/"
  },
  {
    "objectID": "blog-2023/Blog-6-submissions/drbradford12/index.html",
    "href": "blog-2023/Blog-6-submissions/drbradford12/index.html",
    "title": "Stat 585",
    "section": "",
    "text": "What happens when we change the Rmd file and commit?\nIn Blog 5 you had the first exposure to Github Actions. We just checked frontmatter compliance (as we do for this round). You see that we have added a second action - here, we are converting the Rmarkdown document to a markdown file by running render_rmarkdown on Github. This action passes successfully for this document. We want to do something similar for blog #4.\nNow start reading …\nRead the vignette Introduction to renv for the renv R package by Kevin Ushey.\nThen do:\n\nInstall the R package renv on your local machine.\nIn the project for blog 4, initialize the workflow used by the renv package.\nAdd all dependencies to the environment (implicitly by installing all the depepndencies or explicilty by listing dependencies in a DESCRIPTION file).\nAdd the renv folder to your blog 4 repository, and push the changes.\nIs the github action working? Read any potential error messages in the workflow and try to fix things. Make sure to check stackoverflow for help, don’t forget our Discussion board!\n\nWrite a blog post addressing the following questions:\n\nWhat is the idea of the renv package?\n\nDenise’s Answer:\nThe idea of the renv package is a tool for managing packages in R that helps with managing dependencies, making projects repeatable, and working together on R projects. It lets users set up and manage separate environments for each project. These environments have all the R packages and versions needed to run the project. This keeps packages and versions from getting in the way of each other, which can lead to errors.\n\nIn 50 to 100 words describe your experience working with renv. What went well? What did not go so well?\n\nDenise’s Answer:\n\nThe Good:\n\nSince I will be working more in Python during the class, it may be useful to show that renv in R works with Python environments (https://cran.r-project.org/web/packages/renv/vignettes/python.html). It’s great to know that we can do this when completing a project that may need both Python and R elements.\n\nThe Bad:\n\nIf we wanted to reproduce the same actions in Python, one will need to have a Linux computer. The following is from a beta package (https://pypi.org/project/renv/) that may be used for a similiar outcome in R. I can’t be completely sure since I work with a Mac.\nSubmit this blog post to your blog-6 repo."
  },
  {
    "objectID": "blog-2023/Blog-6-submissions/HarunCelikOtto/index.html",
    "href": "blog-2023/Blog-6-submissions/HarunCelikOtto/index.html",
    "title": "Split-Apply-Combine Post",
    "section": "",
    "text": "What happens when we change the Rmd file and commit?\nIn Blog 5 you had the first exposure to Github Actions. We just checked frontmatter compliance (as we do for this round). You see that we have added a second action - here, we are converting the Rmarkdown document to a markdown file by running render_rmarkdown on Github. This action passes successfully for this document. We want to do something similar for blog #4.\nNow start reading …\nRead the vignette Introduction to renv for the renv R package by Kevin Ushey.\nThen do:\n\nInstall the R package renv on your local machine.\nIn the project for blog 4, initialize the workflow used by the renv package.\nAdd all dependencies to the environment (implicitly by installing all the depepndencies or explicilty by listing dependencies in a DESCRIPTION file).\nAdd the renv folder to your blog 4 repository, and push the changes.\nIs the github action working? Read any potential error messages in the workflow and try to fix things. Make sure to check stackoverflow for help, don’t forget our Discussion board!\n\nWrite a blog post addressing the following questions:\n\nWhat is the idea of the renv package?\n\nThe renv package is used in R to manage the dependencies a project will have during its development and operation. renv essentially works as a way to support the reproducibility of projects by tracking version control histories for the packages used in an R project. What I found to be the most useful in the documentation was how R libraries worked without renv and with renv. Based on this information it makes sense to use renv in every R project that has a longtitudinal lifespan since tracking packages and errors often associated with older versions of packages is an important element to debugging.\n\nIn 50 to 100 words describe your experience working with renv. What went well? What did not go so well?\n\nInitializing with renv was not very difficult. I think the real trouble for me is that I don’t find the layout of what renv produces to be very intuitive so I had difficulties with adding all the dependencies to the environment. I first called a renv::snapshot() and followed that with renv::dependencies() but I’m not entirely sure that it did what I expected it to, I don’t have a solid enough understanding to even be able to verify in all honesty.\nSubmit this blog post to your blog-6 repo."
  },
  {
    "objectID": "blog-2023/Blog-6-submissions/valeriehan6/index.html",
    "href": "blog-2023/Blog-6-submissions/valeriehan6/index.html",
    "title": "renv",
    "section": "",
    "text": "What happens when we change the Rmd file and commit?\nIn Blog 5 you had the first exposure to Github Actions. We just checked frontmatter compliance (as we do for this round). You see that we have added a second action - here, we are converting the Rmarkdown document to a markdown file by running render_rmarkdown on Github. This action passes successfully for this document. We want to do something similar for blog #4.\nNow start reading …\nRead the vignette Introduction to renv for the renv R package by Kevin Ushey.\nThen do:\n\nInstall the R package renv on your local machine.\n\n1b. Go to your blog 4 repo, and run the command usethis::use_github_action(\"render-rmarkdown.yaml\") This creates the file render-rmarkdown.yaml inside the folder .github/workflows in your repo. Add it to the repository and push it.\n1c. Optional - but maybe educational: make a change to your Rmd file with the blog post (just a small change), and push it. Then go to your github site and watch the render-rmarkdown action fail.\n\nIn the project for blog 4, initialize the workflow used by the renv package.\nAdd all dependencies to the environment (implicitly by installing all the depepndencies or explicilty by listing dependencies in a DESCRIPTION file).\nAdd the renv folder to your blog 4 repository, and push the changes.\nIs the github action working? Read any potential error messages in the workflow and try to fix things. Make sure to check stackoverflow for help, don’t forget our Discussion board!\n\nWrite a blog post addressing the following questions:\n\nWhat is the idea of the renv package?\n\nThe renv package helps with one piece of reproducibility by recording the versions of R and packages that our project is running on. It also can make it easier to reinstall the version of those packages for a specific project that has had its versions recorded using renv.\n\nIn 50 to 100 words describe your experience working with renv. What went well? What did not go so well?\n\nIt was really cool to be able to run just a couple functions to record version numbers of R and the packages my project was dependent on. There were a lot of debugging along the way, though. Lessons learned: make sure to add renv.lock to the git repo, and try a newer version of a package if you get an error like Error: install of package 'stringi' failed [error code 1]. In general, the downside of using renv was that the error messages were not as informative as I would’ve liked, there weren’t really stackoverflow posts addressing my errors, and the vignette for the package could’ve been more informative about troubleshooting/error messages.\nSubmit this blog post to your blog-6 repo."
  },
  {
    "objectID": "blog-2023/Blog-6-submissions/IanParzyszek/index.html",
    "href": "blog-2023/Blog-6-submissions/IanParzyszek/index.html",
    "title": "Learning Renv",
    "section": "",
    "text": "library(knitr)\nlibrary(rmarkdown)\n\n\n\n  \nWhat happens when we change the Rmd file and commit?\nIn Blog 5 you had the first exposure to Github Actions. We just checked frontmatter compliance (as we do for this round). You see that we have added a second action - here, we are converting the Rmarkdown document to a markdown file by running render_rmarkdown on Github. This action passes successfully for this document. We want to do something similar for blog #4.\nNow start reading …\nRead the vignette Introduction to renv for the renv R package by Kevin Ushey.\nThen do:\n\nInstall the R package renv on your local machine.\nIn the project for blog 4, initialize the workflow used by the renv package.\nAdd all dependencies to the environment (implicitly by installing all the depepndencies or explicilty by listing dependencies in a DESCRIPTION file).\nAdd the renv folder to your blog 4 repository, and push the changes.\nIs the github action working? Read any potential error messages in the workflow and try to fix things. Make sure to check stackoverflow for help, don’t forget our Discussion board!\n\nWrite a blog post addressing the following questions:\n\nWhat is the idea of the renv package?\nIn 50 to 100 words describe your experience working with renv. What went well? What did not go so well?\n\nSubmit this blog post to your blog-6 repo.\n\nThe idea of the renv package is to help with reproducibility in terms of making sure you or anyone who uses your work knows what packages you are using and what versions of them you are using. And then it will help the user find out where to download those packages as well.\nHonestly, everything went very smoothly. After downloading ‘renv’ I played around a little bit with a couple of the functions and then I was able to find out what packages were being used in my blog 4 project. Then after that I manually made a Description file for the package dependencies."
  },
  {
    "objectID": "blog-2023/Blog-6-submissions/loganjohnson0/index.html",
    "href": "blog-2023/Blog-6-submissions/loganjohnson0/index.html",
    "title": "‘renv’ Package and Data Reproducibility",
    "section": "",
    "text": "What happens when we change the Rmd file and commit?\nIn Blog 5 you had the first exposure to Github Actions. We just checked frontmatter compliance (as we do for this round). You see that we have added a second action - here, we are converting the Rmarkdown document to a markdown file by running render_rmarkdown on Github. This action passes successfully for this document. We want to do something similar for blog #4.\nNow start reading …\nRead the vignette Introduction to renv for the renv R package by Kevin Ushey.\nThen do:\n\nInstall the R package renv on your local machine.\nIn the project for blog 4, initialize the workflow used by the renv package.\nAdd all dependencies to the environment (implicitly by installing all the depepndencies or explicilty by listing dependencies in a DESCRIPTION file).\nAdd the renv folder to your blog 4 repository, and push the changes.\nIs the github action working? Read any potential error messages in the workflow and try to fix things. Make sure to check stackoverflow for help, don’t forget our Discussion board!\n\nWrite a blog post addressing the following questions:\n\nWhat is the idea of the renv package?\n\nThe renv package allows you to create different R libraries of different packages. Essentially, this allows one to designate the specific package version that is used in the workflow. This way, any new updates or changes can be ignored because renv creates a project specific library of packages and calls specific version of packages to avoid any changes that may break or cause errors with previous code.\n\nIn 50 to 100 words describe your experience working with renv. What went well? What did not go so well?\n\nI think this package is a beneficial package. I think it helps to save the version associated with the code as often times with various updates, the package version number is likely to be the last thing that might be remembered when working on the project. I had an easy time getting it to work. A challenge was understanding what exactly the package was doing, what the files it was saving were, and how to add packages to the local library and work with that. I also had issues with getting the GitHub Actions render-rmarkdown to run successfully. I installed the “curl” through command line to get “libcurl” working.\nSubmit this blog post to your blog-6 repo."
  },
  {
    "objectID": "blog-2023/Blog-6-submissions/Atefeha1995/index.html",
    "href": "blog-2023/Blog-6-submissions/Atefeha1995/index.html",
    "title": "Working with ‘renv’ package",
    "section": "",
    "text": "What happens when we change the Rmd file and commit?\nIn Blog 5 you had the first exposure to Github Actions. We just checked frontmatter compliance (as we do for this round). You see that we have added a second action - here, we are converting the Rmarkdown document to a markdown file by running render_rmarkdown on Github. This action passes successfully for this document. We want to do something similar for blog #4.\nNow start reading …\nRead the vignette Introduction to renv for the renv R package by Kevin Ushey.\nThen do:\n\nInstall the R package renv on your local machine.\nIn the project for blog 4, initialize the workflow used by the renv package.\nAdd all dependencies to the environment (implicitly by installing all the depepndencies or explicilty by listing dependencies in a DESCRIPTION file).\nAdd the renv folder to your blog 4 repository, and push the changes.\nIs the github action working? Read any potential error messages in the workflow and try to fix things. Make sure to check stackoverflow for help, don’t forget our Discussion board!\n\nWrite a blog post addressing the following questions:\n\nWhat is the idea of the renv package?\n\nThe “renv” package, in my opinion, makes it easier for us to handle our projects. Each project’s specific details and packages will be managed individually by it. Using the “init()” function, which will make a copy of the local project with all the packages, we must first initialize a workflow. Then, “hydrate()” and “dependency()” functions can find and install all additional requirements. We will have a project-local environment with a private R library once we have completed these tasks. Anytime we wish to leave, we can take snapshots of the project and store its current condition together with all of its packages. In other words, “renv” package is a robust way that makes our projects reproducible.\n\nIn 50 to 100 words describe your experience working with renv. What went well? What did not go so well?\n\nAfter a few tries, I succeeded in completing the stages. Initially, because I didn’t utilize the hydrate function to install the dependencies, the GitHub action wasn’t working. As I returned to the manual, I discovered my error. The GitHub activity worked for me after running the hydrate function, and everything was in place. It appears that my project is now available on GitHub in a version that has all necessary dependencies and packages and can be restored by other users.\nSubmit this blog post to your blog-6 repo."
  },
  {
    "objectID": "blog-2023/Blog-6-submissions/hardtme/index.html",
    "href": "blog-2023/Blog-6-submissions/hardtme/index.html",
    "title": "Exploring renv",
    "section": "",
    "text": "What happens when we change the Rmd file and commit?\nIn Blog 5 you had the first exposure to Github Actions. We just checked frontmatter compliance (as we do for this round). You see that we have added a second action - here, we are converting the Rmarkdown document to a markdown file by running render_rmarkdown on Github. This action passes successfully for this document. We want to do something similar for blog #4.\nNow start reading …\nRead the vignette Introduction to renv for the renv R package by Kevin Ushey.\nThen do:\n\nInstall the R package renv on your local machine.\nIn the project for blog 4, initialize the workflow used by the renv package.\nAdd all dependencies to the environment (implicitly by installing all the dependencies or explicitly by listing dependencies in a DESCRIPTION file).\nAdd the renv folder to your blog 4 repository, and push the changes.\nIs the github action working? Read any potential error messages in the workflow and try to fix things. Make sure to check stackoverflow for help, don’t forget our Discussion board!\n\nWrite a blog post addressing the following questions:\n\nWhat is the idea of the renv package?\n\nThe idea of the renv package is to help with reproducibility by keeping track of what your R environment looks like as you work. The renv package saves all of the packages you install within your R project along with their versions. This means that you can be sure that if you leave your work and come back to it later, you can recreate an identical R environment to the one you were using before. This helps to ensure that you can reproduce your results as they were previously.\n\nIn 50 to 100 words describe your experience working with renv. What went well? What did not go so well?\n\nI was initially confused about whether the R code for implementing renv should be included in my RMarkdown. After learning the code was not needed, the next hurdle for me was which renv files should be committed to GitHub. Then I learned I needed to commit the renv folder and the lockfile. The last hurdle to be overcome was the R version in the lockfile. I use R 4.1.2, but GitHub uses R 4.2.2. I changed the R version in the lockfile to 4.2.2, and after not rendering at first, the RMarkdown file then rendered properly after another commit later."
  },
  {
    "objectID": "blog-2023/Blog-6-submissions/santos-cl/index.html",
    "href": "blog-2023/Blog-6-submissions/santos-cl/index.html",
    "title": "R env",
    "section": "",
    "text": "What happens when we change the Rmd file and commit?\nIn Blog 5 you had the first exposure to Github Actions. We just checked frontmatter compliance (as we do for this round). You see that we have added a second action - here, we are converting the Rmarkdown document to a markdown file by running render_rmarkdown on Github. This action passes successfully for this document. We want to do something similar for blog #4.\nNow start reading …\nRead the vignette Introduction to renv for the renv R package by Kevin Ushey.\nThen do:\n\nInstall the R package renv on your local machine.\nIn the project for blog 4, initialize the workflow used by the renv package.\nAdd all dependencies to the environment (implicitly by installing all the depepndencies or explicilty by listing dependencies in a DESCRIPTION file).\nAdd the renv folder to your blog 4 repository, and push the changes.\nIs the github action working? Read any potential error messages in the workflow and try to fix things. Make sure to check stackoverflow for help, don’t forget our Discussion board!\n\nWrite a blog post addressing the following questions:\n\nWhat is the idea of the renv package?\nIn 50 to 100 words describe your experience working with renv. What went well? What did not go so well?\n\nSubmit this blog post to your blog-6 repo.\n\nThe idea behind the renv package\nThe package was designed to allow R users to manage their project dependencies. This allows users to manage their r packages separately for each project, improving reproducibility and reliability of the code. The renv package allows users to lock the versions of their dependencies for each project, decreasing the chances of a script crashing after updating a package. Other languages, such as Python, have similar frameworks of virtual environment.\n\n\nMy experience with renv\nOverall, it was quick and easy to set up. The renv.lock file contains all the dependency versions that need to be recorded. When initializing the environment, the renv package checks the dependencies and sets up a folder for the project libraries. I believe this will make code much more reproducible."
  },
  {
    "objectID": "blog-2023/Blog-6-submissions/sudi007/index.html",
    "href": "blog-2023/Blog-6-submissions/sudi007/index.html",
    "title": "Github Actions",
    "section": "",
    "text": "What happens when we change the Rmd file and commit?\nIn Blog 5 you had the first exposure to Github Actions. We just checked frontmatter compliance (as we do for this round). You see that we have added a second action - here, we are converting the Rmarkdown document to a markdown file by running render_rmarkdown on Github. This action passes successfully for this document. We want to do something similar for blog #4.\nNow start reading …\nRead the vignette Introduction to renv for the renv R package by Kevin Ushey.\nThen do:\n\nInstall the R package renv on your local machine.\n\n\n##install.packages(\"renv\")\n\n\nIn the project for blog 4, initialize the workflow used by the renv package.\n\n\n##work flow initialization \n#library(renv)\n#renv::init()\n\n\nAdd all dependencies to the environment (implicitly by installing all the depepndencies or explicilty by listing dependencies in a DESCRIPTION file).\n\n\n##Necessary package for blog 4\n#renv::install(\"plyr\")\n#renv::install(\"dplyr\")\n\n\nAdd the renv folder to your blog 4 repository, and push the changes.\n\n\n#Add the renv folder to blog four git \n\n\nIs the github action working? Read any potential error messages in the workflow and try to fix things. Make sure to check stackoverflow for help, don’t forget our Discussion board!\n\nWrite a blog post addressing the following questions:\n\nWhat is the idea of the renv package?\n\nThe renv package for R is a package management tool that aids in the reproducibility of R projects. Renv’s goal is to provide an isolated environment for each R project with all the required R packages and their dependencies. This helps to ensure that the R code in the project executes consistently regardless of the machine or the environment in which it is run.renv has various features that can assist in reaching this goal. It enables the construction of a project-specific R package library separate from the global R library. This ensures that the packages used in one project do not conflict with those used in another. It also tracks and manages the versions of packages used in each project. This is significant because different versions of a package can behave differently, and knowing which version was used to get a specific result is critical. Project collaboration is easier with renv as it enables the building of a lock file with the precise versions of all the packages used in the project. The renv package aims to create a uniform, reproducible environment for R projects that simplifies managing dependencies and sharing code with others. As a package management tool, renv is a package that helps reproduce R projects. With this package, each R project and its associated constituents operate in seclusion, ensuring consistency across machines and environments. This is achieved through the characteristic features of renv. This package creates a library that is specific to the project, which is different from the global R library. In addition, renv also tracks and manages the versions of the different packages. Project collaboration is easier with renv as it enables the building of a lock file with the precise versions of all the packages used in the project.\n\nIn 50 to 100 words describe your experience working with renv. What went well? What did not go so well?\n\nWorking with the renv package was a smooth experience as I only installed the necessary packages in my environment before creating the renv folder. These necessary packages were  installed while the rmakrdown was rendering. I made sure that I was able to knit the document in my local machine before I rendered it on the git. I did not receive any errors. \nSubmit this blog post to your blog-6 repo.\n \n\n---\nauthor: \"Sudesh Bhagat\"\ntitle: \"Github Actions\"\ndate: \"2023-03-02\"\ncategories:\"Github Actions\"\n---"
  },
  {
    "objectID": "blog-2023/Blog-6-submissions/gnbltrn/index.html",
    "href": "blog-2023/Blog-6-submissions/gnbltrn/index.html",
    "title": "Stat 585",
    "section": "",
    "text": "What happens when we change the Rmd file and commit?\nIn Blog 5 you had the first exposure to Github Actions. We just checked frontmatter compliance (as we do for this round). You see that we have added a second action - here, we are converting the Rmarkdown document to a markdown file by running render_rmarkdown on Github. This action passes successfully for this document. We want to do something similar for blog #4.\nNow start reading …\nRead the vignette Introduction to renv for the renv R package by Kevin Ushey.\nThen do:\n\nInstall the R package renv on your local machine.\nIn the project for blog 4, initialize the workflow used by the renv package.\nAdd all dependencies to the environment (implicitly by installing all the depepndencies or explicilty by listing dependencies in a DESCRIPTION file).\nAdd the renv folder to your blog 4 repository, and push the changes.\nIs the github action working? Read any potential error messages in the workflow and try to fix things. Make sure to check stackoverflow for help, don’t forget our Discussion board!\n\nWrite a blog post addressing the following questions:\n\nWhat is the idea of the renv package?\nIn 50 to 100 words describe your experience working with renv. What went well? What did not go so well?\n\nSubmit this blog post to your blog-6 repo."
  },
  {
    "objectID": "blog-2023/Blog-6-submissions/motinaaa/index.html",
    "href": "blog-2023/Blog-6-submissions/motinaaa/index.html",
    "title": "Badge is Coool!",
    "section": "",
    "text": "What happens when we change the Rmd file and commit?\nIn Blog 5 you had the first exposure to Github Actions. We just checked frontmatter compliance (as we do for this round). You see that we have added a second action - here, we are converting the Rmarkdown document to a markdown file by running render_rmarkdown on Github. This action passes successfully for this document. We want to do something similar for blog #4.\nNow start reading …\nRead the vignette Introduction to renv for the renv R package by Kevin Ushey.\nThen do:\n\nInstall the R package renv on your local machine.\nIn the project for blog 4, initialize the workflow used by the renv package.\nAdd all dependencies to the environment (implicitly by installing all the depepndencies or explicilty by listing dependencies in a DESCRIPTION file).\nAdd the renv folder to your blog 4 repository, and push the changes.\nIs the github action working? Read any potential error messages in the workflow and try to fix things. Make sure to check stackoverflow for help, don’t forget our Discussion board!\n\nYes! It’s working :)\nWrite a blog post addressing the following questions:\n\nWhat is the idea of the renv package?\n\nR package dependencies are easier to manage and reproducible environments are easier to create with the renv package. The use of renv means you will spend less time worrying about package version mismatches and more time developing or analyzing.\n\nIn 50 to 100 words describe your experience working with renv. What went well? What did not go so well?\n\nBefore I pushed the changes to my blog4 repo, I did a few things to make sure everything was in order.\nFirst, I hit up “renv::init()” to get my R environment all set up for this project.\nThen I called “renv::dependencies” to make sure all my package dependencies were good to go.\nAfter that, I hit up “renv::snapshot()” to save my project library in case I needed to roll back my updates.\nNext, I added “check-yaml.yaml” to my workflow folder because the badge code shows the status of the workflow defined in my “.github/workflows” directory. I also added “schema.json” and “schema.yaml” to my “.github” folder and copied and pasted the ymal and json code from blog 5.\nThat’s when I spotted a problem: the ymal in the read.rmd file for blog 4 was messed up. The dates weren’t in quotation marks ““, and the categories were spelled like”category.” So, I fixed those issues and pushed everything up to my repo. Easy peasy! I followed the same process for blog 6, and now both badges are showing “passing.”\nSubmit this blog post to your blog-6 repo."
  },
  {
    "objectID": "blog-2023/Blog-6-submissions/maxwellskinner2002/index.html",
    "href": "blog-2023/Blog-6-submissions/maxwellskinner2002/index.html",
    "title": "Stat 585",
    "section": "",
    "text": "What happens when we change the Rmd file and commit?\nIn Blog 5 you had the first exposure to Github Actions. We just checked frontmatter compliance (as we do for this round). You see that we have added a second action - here, we are converting the Rmarkdown document to a markdown file by running render_rmarkdown on Github. This action passes successfully for this document. We want to do something similar for blog #4.\nNow start reading …\nRead the vignette Introduction to renv for the renv R package by Kevin Ushey.\nThen do:\n\nInstall the R package renv on your local machine.\nIn the project for blog 4, initialize the workflow used by the renv package.\nAdd all dependencies to the environment (implicitly by installing all the depepndencies or explicilty by listing dependencies in a DESCRIPTION file).\nAdd the renv folder to your blog 4 repository, and push the changes.\nIs the github action working? Read any potential error messages in the workflow and try to fix things. Make sure to check stackoverflow for help, don’t forget our Discussion board!\n\nWrite a blog post addressing the following questions:\n\nWhat is the idea of the renv package?\nIn 50 to 100 words describe your experience working with renv. What went well? What did not go so well?\n\nSubmit this blog post to your blog-6 repo."
  },
  {
    "objectID": "blog-2023/Blog-6-submissions/Sabrenar/index.html",
    "href": "blog-2023/Blog-6-submissions/Sabrenar/index.html",
    "title": "Reproducibility",
    "section": "",
    "text": "What happens when we change the Rmd file and commit?\nIn Blog 5 you had the first exposure to Github Actions. We just checked frontmatter compliance (as we do for this round). You see that we have added a second action - here, we are converting the Rmarkdown document to a markdown file by running render_rmarkdown on Github. This action passes successfully for this document. We want to do something similar for blog #4.\nNow start reading …\nRead the vignette Introduction to renv for the renv R package by Kevin Ushey.\nThen do:\n\nInstall the R package renv on your local machine.\nIn the project for blog 4, initialize the workflow used by the renv package.\nAdd all dependencies to the environment (implicitly by installing all the depepndencies or explicilty by listing dependencies in a DESCRIPTION file).\nAdd the renv folder to your blog 4 repository, and push the changes.\nIs the github action working? Read any potential error messages in the workflow and try to fix things. Make sure to check stackoverflow for help, don’t forget our Discussion board!\n\nWrite a blog post addressing the following questions:\n\nWhat is the idea of the renv package?\n\nThe renv package is designed to store library paths to all of a projects’ necessary R packages and their dependencies. As such, it saves a list of all R packages’ versions being used in a project. Having all version numbers for a project’s required packages and dependencies is extremely helpful for reproducibility.\n\nIn 50 to 100 words describe your experience working with renv. What went well? What did not go so well?\n\nI have used renv in my personal projects and have not had an issue with it before. However, when trying to use renv and github together, I have not been successful. Within Rstudio, renv installed correctly and initialized correctly. Yet, the renv directory does not appear to push correctly to the global Github repo. As such, when trying to render the Rmarkdown, it fails when loading the first package.\nSubmit this blog post to your blog-6 repo."
  },
  {
    "objectID": "blog-2023/Blog-6-submissions/luobo119/index.html",
    "href": "blog-2023/Blog-6-submissions/luobo119/index.html",
    "title": "renv package",
    "section": "",
    "text": "What happens when we change the Rmd file and commit?\nIn Blog 5 you had the first exposure to Github Actions. We just checked frontmatter compliance (as we do for this round). You see that we have added a second action - here, we are converting the Rmarkdown document to a markdown file by running render_rmarkdown on Github. This action passes successfully for this document. We want to do something similar for blog #4.\nNow start reading …\nRead the vignette Introduction to renv for the renv R package by Kevin Ushey.\nThen do:\n\nInstall the R package renv on your local machine.\nIn the project for blog 4, initialize the workflow used by the renv package.\nAdd all dependencies to the environment (implicitly by installing all the depepndencies or explicilty by listing dependencies in a DESCRIPTION file).\nAdd the renv folder to your blog 4 repository, and push the changes.\nIs the github action working? Read any potential error messages in the workflow and try to fix things. Make sure to check stackoverflow for help, don’t forget our Discussion board!\n\nWrite a blog post addressing the following questions:\n\nWhat is the idea of the renv package?\n\n‘renv’ package is a tool to help create project-local libraries. It records all packages used in the project and also saved the states of these libraries. It isolates the project library from the system environment, which makes packages used in the project reproducible. By using the ‘snapshot’ function, the state of the project’s library will be saved in a lockfile. By using ‘restore’, the state of the project’s library can be restored.\n\nIn 50 to 100 words describe your experience working with renv. What went well? What did not go so well?\n\nBy following the workflow in ‘renv’ package website, I could successfully create ‘renv’ folder and see the dependencies used in blog 4 in the ‘renv.lock’ file. I run into problems when I try to figure out whether packages ‘dplyr’ and ‘plyr’ are recorded by using renv, but it turns out that they are automatically recorded by using ‘renv::snapshot()’, and many other base R packages I didn’t know I used have also been recorded."
  },
  {
    "objectID": "blog-2023/Blog-6-submissions/AArabio/index.html",
    "href": "blog-2023/Blog-6-submissions/AArabio/index.html",
    "title": "title :)",
    "section": "",
    "text": "What happens when we change the Rmd file and commit?\nIn Blog 5 you had the first exposure to Github Actions. We just checked frontmatter compliance (as we do for this round). You see that we have added a second action - here, we are converting the Rmarkdown document to a markdown file by running render_rmarkdown on Github. This action passes successfully for this document. We want to do something similar for blog #4.\nNow start reading …\nRead the vignette Introduction to renv for the renv R package by Kevin Ushey.\nThen do:\n\nInstall the R package renv on your local machine.\nIn the project for blog 4, initialize the workflow used by the renv package.\nAdd all dependencies to the environment (implicitly by installing all the depepndencies or explicilty by listing dependencies in a DESCRIPTION file).\nAdd the renv folder to your blog 4 repository, and push the changes.\nIs the github action working? Read any potential error messages in the workflow and try to fix things. Make sure to check stackoverflow for help, don’t forget our Discussion board!\n\nWrite a blog post addressing the following questions:\n\nWhat is the idea of the renv package?\n\n“The renv package is a new effort to bring project-local R dependency management to your projects. The goal is for renv to be a robust, stable replacement for the Packrat package, with fewer surprises and better default behaviors.\nUnderlying the philosophy of renv is that any of your existing workflows should just work as they did before – renv helps manage library paths (and other project-specific state) to help isolate your project’s R dependencies, and the existing tools you’ve used for managing R packages (e.g. install.packages(), remove.packages()) should work as they did before.”\nThis essentially is telling us that the idea of renv is to work as a better controlled and more sturdy dependency management system. The overall goal seems to present itself as being able to integrate renv into current workflow to better keep track of dependencies and packages.\n\nIn 50 to 100 words describe your experience working with renv. What went well? What did not go so well?\n\nI was hesitant to begin working the renv and having error messages produce… it is discouraging when things come back as failed or not working as you would likeI understand that renv may come in handy when trying make packages that will be able to stand alone and help to sort of isolate working environments, but I have not yet been able to figure out exactly how to implement it."
  },
  {
    "objectID": "blog-2023/Blog-6-submissions/Starwiiin/index.html",
    "href": "blog-2023/Blog-6-submissions/Starwiiin/index.html",
    "title": "More on reproducibility…",
    "section": "",
    "text": "What happens when we change the Rmd file and commit?\nIn Blog 5 you had the first exposure to Github Actions. We just checked frontmatter compliance (as we do for this round). You see that we have added a second action - here, we are converting the Rmarkdown document to a markdown file by running render_rmarkdown on Github. This action passes successfully for this document. We want to do something similar for blog #4.\nNow start reading …\nRead the vignette Introduction to renv for the renv R package by Kevin Ushey.\nThen do:\n\nInstall the R package renv on your local machine.\nIn the project for blog 4, initialize the workflow used by the renv package.\nAdd all dependencies to the environment (implicitly by installing all the depepndencies or explicilty by listing dependencies in a DESCRIPTION file).\nAdd the renv folder to your blog 4 repository, and push the changes.\nIs the github action working? Read any potential error messages in the workflow and try to fix things. Make sure to check stackoverflow for help, don’t forget our Discussion board!\n\nWrite a blog post addressing the following questions:\n\nWhat is the idea of the renv package? Parvin’s answer: renv package is an useful package to install, update and manage packages in various projects in a more robust way. In the other words, using renv, we can update/install packages in a specific project without any changes in the packages in the other projects. This advantage is useful to prevent conflicts when we work on the other projects;it means that other projects do not break (it is like a private library and environment). Furthermore, renv provides the ability to reproduce the previous versions of our work. In summary, renv provides a better management in projects individually.\nIn 50 to 100 words describe your experience working with renv. What went well? What did not go so well? Parvin’s answer: My experience with renv package was smooth, fortunately. Using the instruction in the “Introduction to renv” I could get it done with a few number of committing. In the first rounds, I forgot to use “hydrate()” function and it did not work, but when I read the instruction again, I did the process again, step by step and I called the hydrate and it worked!\n\nSubmit this blog post to your blog-6 repo."
  },
  {
    "objectID": "blog-2023/Blog-1-submissions/xyzyc/ZhouYingchao.html",
    "href": "blog-2023/Blog-1-submissions/xyzyc/ZhouYingchao.html",
    "title": "Asking Good Questions",
    "section": "",
    "text": "Asking good questions is a valuable skill to have - asking questions in an online setting is both easier and harder than asking questions in person: we can prepare to ask a question but we are also expected to prepare. The links posted here give some advice on how to ask good questions:\n\nstackoverflow’s Asking a good question\nR’s Posting guidelines\nminimal complete verifiable example, minimal reproducible example\n\nFollow these links and read through the advice given, then\n\nPick at least one question from stackoverflow or the R help and answer it.\n\nWrite a blog post answering the following questions:\n\nDocument which question you answered (link to your answer).\n\nI answered one question from stackoverflow about plotting data with longitude and latitude on a map. Here is the link: https://stackoverflow.com/questions/75228497/how-can-i-plot-a-map-using-ggplot2-that-includes-the-latitude-and-longitude-of-t/75229784#75229784\n\nRelate your experience of answering the question to your reading. \n\nome questions I see on stackoverflow are long and messy, with many code chunks and I feel hard to read and understand them. Although the titles seem not too difficult, after clicking in, I gave up reading them. Giving a minimal reproducible example can really make it much easier for answerers.\n\nInstructions to follow."
  },
  {
    "objectID": "blog-2023/Blog-1-submissions/kundan7kumar/KumarKundan.html",
    "href": "blog-2023/Blog-1-submissions/kundan7kumar/KumarKundan.html",
    "title": "Asking Good Questions",
    "section": "",
    "text": "Pick at least one question from stackoverflow or the R help and answer it.\n\nWrite a blog post answering the following questions:\nI have asked a question about how to detect objects in a video using python. Please find the Link\nMoreover, I have answered on question in R, in which i plotted a pie chart.Please find the Link\n\nDocument which question you answered (link to your answer).\n\nI have answered a question how to create Pie chart legend with multiple lines of text in R. User is facing an issue that multiple lines of text will out of legend. Please find the Link\nI have explored the the package ‘ggplot2’ and ‘ggrepel’ and finally plotted the pie chart in which multiple lines of text are within the legend.\n\nRelate your experience of answering the question to your reading. \n\nAs the start, i was just plotting it seems fine to me, but seems i didn’t understand the problem well. I was only using the basic R functionality for plotting the pie chart and i literally struggle alot.\nAfter understanding the problem well, i explored the R packages and implemented the code successfully and plotted the pie chart along the legend precisely. It is a great learning curve for me and hopefully enhanced my skill a bit."
  },
  {
    "objectID": "blog-2023/Blog-1-submissions/anyeshar/RayAnyesha.html",
    "href": "blog-2023/Blog-1-submissions/anyeshar/RayAnyesha.html",
    "title": "Asking Good Questions",
    "section": "",
    "text": "Asking good questions is a valuable skill to have - asking questions in an online setting is both easier and harder than asking questions in person: we can prepare to ask a question but we are also expected to prepare. The links posted here give some advice on how to ask good questions:\n\nstackoverflow’s Asking a good question\nR’s Posting guidelines\nminimal complete verifiable example, minimal reproducible example\n\nFollow these links and read through the advice given, then\n\nPick at least one question from stackoverflow or the R help and answer it.\n\nWrite a blog post answering the following questions:\n\nDocument which question you answered (link to your answer). https://stackoverflow.com/questions/75204993/merge-two-csv-files-based-on-row-information/75205639#75205639\nRelate your experience of answering the question to your reading. \n\nBased on my reading there are a couple things that we should do when asking a question: - Make sure your question is on-topic and suitable for this site - Search, and research - Write a title that summarizes the specific problem - Introduce the problem before you post any code - Help others reproduce the problem - Include all relevant tags - Proofread before posting - Respond to feedback after posting -(From https://stackoverflow.com/help/how-to-ask)\nThe question I answered would not be considered a good question. While the question was on topic and had an appropriate title, it was not researched and not reproducible. The question was about merging two csv files, and I am sure that question has already been asked before. Also, they gave a description of the data, but it was not very detailed. I answered the question based on what I assumed the data looked like, but the question could have been more descriptive. From looking around on Stack Exchange, it is more difficult than you think to ask a good question.\n\nInstructions to follow."
  },
  {
    "objectID": "blog-2023/Blog-1-submissions/Landon-Getting/GettingLandon.html",
    "href": "blog-2023/Blog-1-submissions/Landon-Getting/GettingLandon.html",
    "title": "Asking Good Questions",
    "section": "",
    "text": "Asking good questions is a valuable skill to have - asking questions in an online setting is both easier and harder than asking questions in person: we can prepare to ask a question but we are also expected to prepare. The links posted here give some advice on how to ask good questions:\n\nstackoverflow’s Asking a good question\nR’s Posting guidelines\nminimal complete verifiable example, minimal reproducible example\n\nFollow these links and read through the advice given, then\n\nPick at least one question from stackoverflow or the R help and answer it.\n\nWrite a blog post answering the following questions:\n\nDocument which question you answered (link to your answer).\nRelate your experience of answering the question to your reading.\n\n\nInstructions to follow."
  },
  {
    "objectID": "blog-2023/Blog-1-submissions/Landon-Getting/GettingLandon.html#blog-post---landon-getting",
    "href": "blog-2023/Blog-1-submissions/Landon-Getting/GettingLandon.html#blog-post---landon-getting",
    "title": "Asking Good Questions",
    "section": "Blog Post - Landon Getting",
    "text": "Blog Post - Landon Getting\nWhile trying to identify a question to answer, I was surprised at the rate of response to most of the posted questions on StackOverflow. Many of the trivial, popular, or generic questions were answered in around 20 minutes. By the time I was done crafting my response, there had already been an accepted answer. However, I went back a few days and found an interesting unanswered question. I answered “How to plot the effects of various explanatory variables on the response variable” on StackOverflow.\nPlotting data in many dimensions can be a difficult task and it made sense why this question was unanswered. In my limited experience, there is not a widely accepted and general method for this type of visual. I did some ‘search and research’ as suggested in “How do I ask a good question?” and came up wanting more - as the author of the question likely did. I think the author could have been more precise with their title. Something along the lines of “Plotting Effect of Predictors in MLR on Response Variable?” However, the post was overall short and to the point. I also would have liked to see some data provided to help generate examples. I created a quick shiny app to show how an interactive solution may be useful in addition to a simple column graph for relative comparison of the effects."
  },
  {
    "objectID": "blog-2023/Blog-1-submissions/Hiiiua/HuaMuxin.html",
    "href": "blog-2023/Blog-1-submissions/Hiiiua/HuaMuxin.html",
    "title": "Asking Good Questions",
    "section": "",
    "text": "Asking good questions is a valuable skill to have - asking questions in an online setting is both easier and harder than asking questions in person: we can prepare to ask a question but we are also expected to prepare. The links posted here give some advice on how to ask good questions:\n\nstackoverflow’s Asking a good question\nR’s Posting guidelines\nminimal complete verifiable example, minimal reproducible example\n\nFollow these links and read through the advice given, then\n\nPick at least one question from stackoverflow or the R help and answer it.\n\nWrite a blog post answering the following questions:\n\nDocument which question you answered (link to your answer).\n\nhttps://stackoverflow.com/questions/75344221/how-to-combine-2-lists-in-equal-parts/75363707#75363707\n\nRelate your experience of answering the question to your reading.\n\nI chose a question specifically about merging list. The author nicely and clearly stated the problem. According to “How do I ask a good question” in stackoverflow, it does very good on help others reproduce the problem, because the author gave example of how the results should look like, that makes the problem comprehensible. The author also didn’t specify the language to solve the problem, which looks more like asking for help in “logic” behind the question rather than limiting to “getting the answer”. This should be inspiring to the ones need such help."
  },
  {
    "objectID": "blog-2023/Blog-1-submissions/mattkav49/KavanaughMatt.html",
    "href": "blog-2023/Blog-1-submissions/mattkav49/KavanaughMatt.html",
    "title": "Asking Good Questions",
    "section": "",
    "text": "Asking good questions is a valuable skill to have - asking questions in an online setting is both easier and harder than asking questions in person: we can prepare to ask a question but we are also expected to prepare. The links posted here give some advice on how to ask good questions:\n\nstackoverflow’s Asking a good question\nR’s Posting guidelines\nminimal complete verifiable example, minimal reproducible example\n\nFollow these links and read through the advice given, then\n\nPick at least one question from stackoverflow or the R help and answer it.\n\nWrite a blog post answering the following questions:\n\nDocument which question you answered (link to your answer).\n\nI answered the following question on StackOverflow: https://stackoverflow.com/questions/75239069/error-matrix-must-have-equal-dimensions-despite-seemingly-equal-dimensions/75239932#75239932\n\nRelate your experience of answering the question to your reading. \n\nWhen answering this question, I took advantage of what the asker did provide in terms of a of a minimal, reproducible example. The asker provided a sufficient amount of code that was necessary to answer the question. This code was also very well organized and grouped into small chunks. The included code was also relevant to the issue at hand, and extraneous details were omitted. As a result, I was able to test out similar code myself with a sample program to determine whether my solution was plausible. Additionally, I was able to compare my solution with related questions and answers presented by other StackOverflow users. However, the asker did not provide the specific R package they used to fit their model. Hence, I was unable to know for sure whether the issue was related to the data in their test matrix or if it was instead an issue with the way they were using a certain package. The question only included small amounts of code and a brief description of the issue. Additionally, no comments were included for the code that was included, which made it difficult to understand all lines of code with this package that I was seemingly unfamiliar with. Fortunately, the problem appeared to be quite self-explanatory and required few additional details. When answering the question, I asked for additional clarification on the R package that they used so that myself or another user can provide a more detailed solution (if my solution does not solve their issue). The problem should then be easily solved by another user who has a greater degree of familiarity with the associated package.\n\nInstructions to follow."
  },
  {
    "objectID": "blog-2023/Blog-1-submissions/charlestbonk/BonkCharlie.html",
    "href": "blog-2023/Blog-1-submissions/charlestbonk/BonkCharlie.html",
    "title": "Asking Good Questions",
    "section": "",
    "text": "Asking good questions is a valuable skill to have - asking questions in an online setting is both easier and harder than asking questions in person: we can prepare to ask a question but we are also expected to prepare. The links posted here give some advice on how to ask good questions:\n\nstackoverflow’s Asking a good question\nR’s Posting guidelines\nminimal complete verifiable example, minimal reproducible example\n\nFollow these links and read through the advice given, then\n\nPick at least one question from stackoverflow or the R help and answer it.\n\n\nOkay, so I looked at all of the R questions and even with my relatively decent knowledge of R, I have no idea the back end of things and I thought I could maybe answer a question on R on MacOS since I have dealed with a lot of issues, but I got super anxious and scared about answering any of the questions, so I just went to a LaTeX question (which is still kind of R adjacent becuase maybe they are working in a .qmd file?) and answered it.\n\nWrite a blog post answering the following questions:\n\nDocument which question you answered (link to your answer).\n\n\nLink to my answer\n\n\nRelate your experience of answering the question to your reading. \n\n\nOne thing about the question that I answered is that the answer to it is really easy to find online. Like, I’m not sure if the user looked elsewhere before asking on StackOverflow. Simply Googling “How to remove the numbering before a section in LaTeX” pulls up an Overleaf site with the answer. So if I were that person, I would have first looked elsewhere.\nThe question asker also could have done a little better with include all relevant code in order to answer their solution. They included just the part that was giving them trouble, when a document class and some of the packages being used would have been helpful. I assumed they were working on an article as it is the most common, but the answer should apply across all classes.\nIf I could talk to them face-to-face, I would have pointed them to other sources (i.e. Overleaf) for most of their questions, since their documentation is really good for quick-access LaTeX questions. If they were also working in somehting like R with a Quarto document, I know Quarto’s website also has a plethora of knowledge.\nOne thing the readings did not tell you is that answering on StackOverflow is SO SCARY like I haven’t been as stressed out about anything before. Like, what is too little to add? Is saying that `{python} ` (without the space) is another way to quickly access Python in a .Rmd document, when someone already spoke about the code you can run in a R session with the ‘reticulate’ package? Also I was and still am afraid that I made a mistake with my answer and it is wrong or not what they needed and then my answer will get down-voted to the deepest depths.\nI’m just too timid to ask questions on StackOverflow, but also too timid to answer them.\n\n\nInstructions to follow."
  },
  {
    "objectID": "blog-2023/Blog-1-submissions/TWiedRW/WiederichTyler.html",
    "href": "blog-2023/Blog-1-submissions/TWiedRW/WiederichTyler.html",
    "title": "Asking Good Questions",
    "section": "",
    "text": "Asking good questions is a valuable skill to have - asking questions in an online setting is both easier and harder than asking questions in person: we can prepare to ask a question but we are also expected to prepare. The links posted here give some advice on how to ask good questions:\n\nstackoverflow’s Asking a good question\nR’s Posting guidelines\nminimal complete verifiable example, minimal reproducible example\n\nFollow these links and read through the advice given, then\n\nPick at least one question from stackoverflow or the R help and answer it.\n\nWrite a blog post answering the following questions:\n\nDocument which question you answered (link to your answer).\n\nhttps://stackoverflow.com/questions/75197974/got-stuck-while-changing-data-format-from-wide-to-long/75242594#75242594\n\nRelate your experience of answering the question to your reading. \n\nThe problem I submitted an answer for ended up being a lot easier than what everybody else was thinking. In this case, the author needed to get data from a wide format into a long format. The author provided code for the process, but did not include code for a sample dataset. This did not allow me to fully test to see if my solution worked, but the problem was within the syntax. The author was inputting a list of countries to melt with reshape2 and was missing a couple of commas. The error could be reproduced with c(\"Var1\" \"Var2). I also provided a recommendation to use the pivot_longer() function to simplify the amount of typing (and potential typing errors).\n\nMinimal: the code provide was quite basic, but included all columns necessary for their particular problem. However, this was actually needed in this case to solve their problem.\nComplete: author did not provide the dataset, so I could not reproduce the problem directly\nReproducible: a similar syntax error gave the same result on my computer, so the problem was reproducible with my suspicion of the problem.\n\n\nInstructions to follow."
  },
  {
    "objectID": "blog-2023/Blog-1-submissions/charchit/ShuklaCharchit.html",
    "href": "blog-2023/Blog-1-submissions/charchit/ShuklaCharchit.html",
    "title": "Asking Good Questions",
    "section": "",
    "text": "Asking good questions is a valuable skill to have - asking questions in an online setting is both easier and harder than asking questions in person: we can prepare to ask a question but we are also expected to prepare. The links posted here give some advice on how to ask good questions:\n\nstackoverflow’s Asking a good question\nR’s Posting guidelines\nminimal complete verifiable example, minimal reproducible example\n\nFollow these links and read through the advice given, then\n\nPick at least one question from stackoverflow or the R help and answer it.\n\nWrite a blog post answering the following questions:\nHow to install rstudio with conda\nConvert NumPy array to Python list\n\nDocument which question you answered (link to your answer).\n\nhttps://stackoverflow.com/questions/75228559/how-to-install-rstudio-with-conda/75254070#75254070\nhttps://stackoverflow.com/questions/1966207/convert-numpy-array-to-python-list/75254352#75254352\n\nRelate your experience of answering the question to your reading. \n\nI picked the newest questions people were asking on the stackoverflow to check my knowledge and try to answer them. A lot of the people were following the rules as described in the reading. However, there were some which were not following and posting the minimal reproducible example or researching the questions if they were already answered.\nI learned another thing during this assignment. I created the account recently and I was not allowed to comment if I do not have more than 50 reputation on the stackoverflow. Which seems like a good system for preventing the new fake/spam accounts. Stackoverflow seems like a helpful community to ask questions. There were other highly active questions which I was not allowed to answer due to similar reason as having a low reputation.\nThe second question I answered was on python as we discussed in the class. Python community seems way larger than the R community and more developed. However, the questions seemed more organized and following the guidelines of the stackoverflow to ask a good question.\n\nInstructions to follow."
  },
  {
    "objectID": "blog-2023/Blog-1-submissions/kellynay/NascimentoThompson_Kelly.html",
    "href": "blog-2023/Blog-1-submissions/kellynay/NascimentoThompson_Kelly.html",
    "title": "Asking Good Questions",
    "section": "",
    "text": "Asking good questions is a valuable skill to have - asking questions in an online setting is both easier and harder than asking questions in person: we can prepare to ask a question but we are also expected to prepare. The links posted here give some advice on how to ask good questions:\n\nstackoverflow’s Asking a good question\nR’s Posting guidelines\nminimal complete verifiable example, minimal reproducible example\n\nFollow these links and read through the advice given, then\n\nPick at least one question from stackoverflow or the R help and answer it.\n\nWrite a blog post answering the following questions:\n\nDocument which question you answered (link to your answer).\n\nQuestion: Cannot plot a histogram from a Pandas data frame\nAnswer: First, you need to import the Histogram class from the Matplotlib library.\nimport matplotlib.pyplot as plt\nThen, you can use the plot() method which will accept a dataframe column as an argument.\nplt.hist(df[‘column’], color=‘blue’, edgecolor=‘black’, bins=int(45/1))\nSource: https://vitalflux.com/histogram-plots-using-matplotlib-pandas-python/\nLink: (https://stackoverflow.com/a/75250948/21082634)\n\nRelate your experience of answering the question to your reading. \n\nThe reading “Asking Good Questions” from the stack overflow platform outlined the importance of summarizing the problem in the title, writing some introductory text before posting code, and helping others reproduce the problem by posting reprex, mcve, and mwe codes.\nThe question I answered to on stack overflow had a good title “Cannot plot a histogram from a Pandas data frame”, but the user did not provide example code to reproduce the problem. He provided some ways he tried to solve the problem with methods applied, but I can not tell if he imported the correct packages to run the code or what the output would of his problem will look like due to the lack of example code.\nHis question seemed easy to find an answer online, thus, some “Search and Research”could have easily solved his problem. I found an article discussing his problem and linked it in my answer."
  },
  {
    "objectID": "blog-2023/Blog-1-submissions/drbradford12/BradfordDenise.html",
    "href": "blog-2023/Blog-1-submissions/drbradford12/BradfordDenise.html",
    "title": "Asking Good Questions",
    "section": "",
    "text": "R Help Community Question\nThe actual question from R Help Community: Make dynamic inputs related to each other?\nIm trying to make an application, and one functionality I would like is to have inputs that dynamically update each other!\nto explain this a bit further, I would like to have a functionality where you can have a raw value, a percentile, and a letter grade, and that all 3 show up on the original page of inputs!\nso when you put in the input for the raw value, it will show the letter grade and the percentile on that same page dynamically, and when you put in the percentile it will update the raw value and letter grade on that page\nideally I could do this with the grade as well (so an A will correspond to a 93rd percentile value, an A- to a 90th percentile value, and putting that in, in a dropdown sense, would update the Raw value and letter grade on the same page to those corresponding values)\njust wondering how I could go about this?!\nMy answer My response could be much clearer if I made an example for every possible outcome of using the UI Dynamically but the previous response linked to the Mastering Shiny R book, chapter 10. As chapter 10 may have been the starting place, suggesting Chapter 15 was at an attempt to allow the user to understand more about the UI being reactive when changed. Or in the event that the UI is not what they were actually looking for in their response to their question.\nPros: - The person asked a question that was important and specific to Shiny. - The person knows enough to be detailed in the outcome\nCons: - The person who posted the question failed to ask a question that was specific with an example. As a result, it would be hard to make the best recommendation. - We don’t know what the data look like"
  },
  {
    "objectID": "blog-2023/Blog-1-submissions/HarunCelikOtto/HarunCelik.html",
    "href": "blog-2023/Blog-1-submissions/HarunCelikOtto/HarunCelik.html",
    "title": "Asking Good Questions",
    "section": "",
    "text": "Asking good questions is a valuable skill to have - asking questions in an online setting is both easier and harder than asking questions in person: we can prepare to ask a question but we are also expected to prepare. The links posted here give some advice on how to ask good questions:\n\nstackoverflow’s Asking a good question\nR’s Posting guidelines\nminimal complete verifiable example, minimal reproducible example\n\nFollow these links and read through the advice given, then\n\nPick at least one question from stackoverflow or the R help and answer it.\n\nWrite a blog post answering the following questions:\n\nDocument which question you answered (link to your answer).\nRelate your experience of answering the question to your reading. \n\n\nInstructions to follow.\nHarun’s Blog\nI chose to answer a question from StackOverflow because I have used the forum as a resource plenty of times in the past but never contributed. The question I answered was this one about using a list of variables in a loop in R. My username is HarunCelikOtto and is chronologically the second answer to the question.\nI think that after reading the advice by Stack Overflow’s “How do I ask a good question?” I came to better understand why I had trouble understanding the question that the user posted on the forum. While the inquirer added some example code about what data they were working with, they didn’t elaborate on the outcome that was expected of the corrected code. For this reason, another user and myself had to assume what the intended output had to be. While the user may find my answer helpful, maybe it isn’t exactly the result that they want because the objective was unclear. Looking through questions, I’ve come to the realization after this activity that only a good question can elicit a good response."
  },
  {
    "objectID": "blog-2023/Blog-1-submissions/HaomingWang123/WangHaoming.html",
    "href": "blog-2023/Blog-1-submissions/HaomingWang123/WangHaoming.html",
    "title": "Asking Good Questions",
    "section": "",
    "text": "Asking good questions is a valuable skill to have - asking questions in an online setting is both easier and harder than asking questions in person: we can prepare to ask a question but we are also expected to prepare. The links posted here give some advice on how to ask good questions:\n\nstackoverflow’s Asking a good question\nR’s Posting guidelines\nminimal complete verifiable example, minimal reproducible example\n\nFollow these links and read through the advice given, then\n\nPick at least one question from stackoverflow or the R help and answer it.\n\nWrite a blog post answering the following questions:\n\nDocument which question you answered (link to your answer).\n\n\nI chose a question from stackoverflow, and it asked how to plot two graphs in one plot.\nThe link to this page on stackoverflow is [https://stackoverflow.com/questions/2564258/plot-two-graphs-in-same-plot-in-r]\nWhen I saw this question, the first solution that comes into my mind is to use ggplot2 package to draw the plot because we can add as many layers as we want on the original plot using all geom_ functions.\nHere is an example:\n\n\nlibrary(ggplot2)\n# create an arbitrary integer array x\nx <- c(-3, -2, -1, 0, 1, 2, 3)\n# create two arbitrary functions y1 and y2\ny1 <- 2*x + 2\ny2 <- sin(x)\n# form a data frame used for ggplot\nmy.df <- data.frame(x)\nggplot(data = my.df, mapping = aes(x, y1, y2)) +\n  geom_line(aes(y=y1), colour = \"blue\") +\n  geom_line(aes(y=y2), colour = \"red\")\n\n\n\n\n\nRelate your experience of answering the question to your reading. \n\n\nAfter I read the instruction “How do I ask a good question” on stackoverflow, I start entering some key words to search for relevent questions that others have ever asked. I typed “r” and “plot” because this is something that I have some knowledge of and I might be able to answer some questions about plotting in R. Then, I located the question that I answered above which is a relatively easy question. By reading the title of this question, I could easily get what they want to know, and based on my knowledge of R and ggplot2 package, it is easy for me to come up with an illustration that used ggplot() and geom_line() to plot multiple lines in the same plot. After I finished my solution, I came back to the stackoverflow page and read through others’ solutions. It turned out that there are many different ways of drawing two graphs in the same plot that I have not used before. Their ideas really helped me and provided me with more tools in my future R experience.\n\n\nInstructions to follow."
  },
  {
    "objectID": "blog-2023/Blog-1-submissions/valeriehan6/ValerieHan.html",
    "href": "blog-2023/Blog-1-submissions/valeriehan6/ValerieHan.html",
    "title": "Asking Good Questions",
    "section": "",
    "text": "Asking good questions is a valuable skill to have - asking questions in an online setting is both easier and harder than asking questions in person: we can prepare to ask a question but we are also expected to prepare. The links posted here give some advice on how to ask good questions:\n\nstackoverflow’s Asking a good question\nR’s Posting guidelines\nminimal complete verifiable example, minimal reproducible example\n\nFollow these links and read through the advice given, then\n\nPick at least one question from stackoverflow or the R help and answer it.\n\nWrite a blog post answering the following questions:\n\nDocument which question you answered (link to your answer).\n\nhttps://stackoverflow.com/questions/75241167/looping-through-r-dataframe-columns/75241265#75241265\n\nRelate your experience of answering the question to your reading. \n\nChoosing a question to answer and actually trying to answer it helped me understand how important a minimal reproducible example is. I also appreciated the informative titles of questions. Both helped me quickly assess if a question was something I could solve using my own experience and made me want to answer their questions more, making clear to me why the readings have such guidelines for posting questions.\nThe question I chose to answer was relatively simple with only 6 lines of code. However, when trying to answer their question, I realized that their example was not reproducible for others because they didn’t include a dataset that corresponded to their variable in the code. I ended up creating my own little example to try to understand what their issue was. In doing so, I also realized that, as the readings said, making a minimal reproducible example isn’t always that hard and that trying to make one can help you think through your bug as well.\n\nInstructions to follow."
  },
  {
    "objectID": "blog-2023/Blog-1-submissions/IanParzyszek/ParzyszekIan.html",
    "href": "blog-2023/Blog-1-submissions/IanParzyszek/ParzyszekIan.html",
    "title": "Asking Good Questions",
    "section": "",
    "text": "https://stackoverflow.com/questions/75254510/using-dplyr-correctly-to-combine-shared-values-of-a-row-to-a-new-column-of-a-tab/75254534#75254534\nIt would have been nice if this individual had included some code or an example they wanted to have answered. I was not 100% confident on what this person was asking, but if I interpreted it correctly it should give them a good start."
  },
  {
    "objectID": "blog-2023/Blog-1-submissions/loganjohnson0/JohnsonLogan.html",
    "href": "blog-2023/Blog-1-submissions/loganjohnson0/JohnsonLogan.html",
    "title": "Asking Good Questions",
    "section": "",
    "text": "Asking good questions is a valuable skill to have - asking questions in an online setting is both easier and harder than asking questions in person: we can prepare to ask a question but we are also expected to prepare. The links posted here give some advice on how to ask good questions:\n\nstackoverflow’s Asking a good question\nR’s Posting guidelines\nminimal complete verifiable example, minimal reproducible example\n\nFollow these links and read through the advice given, then\n\nPick at least one question from stackoverflow or the R help and answer it.\n\nWrite a blog post answering the following questions:\n\nDocument which question you answered (link to your answer).\n\nThe question that I chose was related to graphing data and the ability to use ggplot2 to visualize this data. The link to the post is included here. The question did not provide an example of their data or any code they had been working with.\n\nRelate your experience of answering the question to your reading. \n\nIn reading the examples of asking a good question on stackoverflow and the other links provided, it is clear that you must include a sufficient amount of background on the question you are asking. This can be an overview of the question you have, some example of the data, and some of the code that you have been using. In the example that I had, there was none of this. The person had 3 sentences and vagely described their problem. I did my best to answer their question, provide a link to ggplot2 cheat sheets, and provide some potential examples.\n\nInstructions to follow."
  },
  {
    "objectID": "blog-2023/Blog-1-submissions/Atefeha1995/Anisi.Atefeh.html",
    "href": "blog-2023/Blog-1-submissions/Atefeha1995/Anisi.Atefeh.html",
    "title": "Asking Good Questions",
    "section": "",
    "text": "Asking good questions is a valuable skill to have - asking questions in an online setting is both easier and harder than asking questions in person: we can prepare to ask a question but we are also expected to prepare. The links posted here give some advice on how to ask good questions:\n\nstackoverflow’s Asking a good question\nR’s Posting guidelines\nminimal complete verifiable example, minimal reproducible example\n\nFollow these links and read through the advice given, then\n\nPick at least one question from stackoverflow or the R help and answer it.\n\nWrite a blog post answering the following questions:\n\nDocument which question you answered (link to your answer).\n\nI answered one question in StackOverflow, here is the link to the question.\nMy StackOverflow profile is Atefeha1995.\n\nRelate your experience of answering the question to your reading. \n\nThis is the first time I am working on the StackOverflow website. Based on my reading, the questions and answers on this website need to follow special instructions. I tried to answer a question that I know the answer to while making sure that:\n\nMy answer is short, complete, and clear.\nI followed the StackOverflow structure for writing.\nMy answer and code are reproducible.\nI included the code sample regarding the required code formatting, etc.\n\n\nInstructions to follow."
  },
  {
    "objectID": "blog-2023/Blog-1-submissions/anphan0828/PhanAn.html",
    "href": "blog-2023/Blog-1-submissions/anphan0828/PhanAn.html",
    "title": "Asking Good Questions",
    "section": "",
    "text": "Asking good questions is a valuable skill to have - asking questions in an online setting is both easier and harder than asking questions in person: we can prepare to ask a question but we are also expected to prepare. The links posted here give some advice on how to ask good questions:\n\nstackoverflow’s Asking a good question\nR’s Posting guidelines\nminimal complete verifiable example, minimal reproducible example\n\nFollow these links and read through the advice given, then\n\nPick at least one question from stackoverflow or the R help and answer it.\n\nWrite a blog post answering the following questions: Using If /Else Statement Operator in Pandas/Python The problem was introduced before code was given (as related from ‘asking a good question’ guide). The author was having trouble with conditionally filling his/her new column in a dataframe. He/she used an anonymous function (lambda) to add values as desired.\n\nDocument which question you answered (link to your answer). Link to my answer\nRelate your experience of answering the question to your reading. \n\nThe question was straightforward and details of the output were described in many scenarios. It “includes just enough code to allow others to reproduce the problem” (as posted in the ‘minimal complete verifiable example’ guide). Because of that, I guessed that they accidentally assign values to the same cell in the dataframe, which seemed suspicious.\nI thought that the conditions should be structured in an if-elif-else instead of two separate if-else commands. I double checked the correct if-elif-else structure of an anonymous function and found a StackOverflow post on that. Next, I tried to explain the issue he/she was having and propose a solution as well as the link to the original answer on StackOverflow. Eventually, I rewrote the code in his/her context to make sure they understand my point.\nIt was my first time ever answering a StackOverflow question. I am not sure if the author figured it out yet (there was no update up to when I submitted this homework) but I feel good for being a part of an awesome community that helped me a lot during my first year. Thank you for the meaningful homework!\n\nInstructions to follow."
  },
  {
    "objectID": "blog-2023/Blog-1-submissions/hardtme/HardtMarie.html",
    "href": "blog-2023/Blog-1-submissions/hardtme/HardtMarie.html",
    "title": "Asking Good Questions",
    "section": "",
    "text": "Asking good questions is a valuable skill to have - asking questions in an online setting is both easier and harder than asking questions in person: we can prepare to ask a question but we are also expected to prepare. The links posted here give some advice on how to ask good questions:\n\nstackoverflow’s Asking a good question\nR’s Posting guidelines\nminimal complete verifiable example, minimal reproducible example\n\nFollow these links and read through the advice given, then\n\nPick at least one question from stackoverflow or the R help and answer it.\n\nWrite a blog post answering the following questions:\n\nDocument which question you answered (link to your answer).\nRelate your experience of answering the question to your reading. \n\n\nInstructions to follow.\nI answered this question from stackoverflow: https://stackoverflow.com/questions/75245310/change-colors-in-bar-chart-in-r-to-other-colors/75250501#75250501\nThe original poster (OP) of the question I answered was having trouble getting a bar plot created using ggplot2 to look the way they wanted. It was very helpful that the OP provided their code with the question. However, the OP’s code used a dataset that was not built into R and the OP did not include code to create the dataset for the plot. This broke one of the guidelines for minimal reproducible examples. Fortunately, the requested plot was simple enough that I could recreate the issue using the built-in iris dataset in R. The problem turned out to be that the OP wanted to use the fill aesthetic to change the color of the bars on the plot via scale_fill_manual but did not have anything mapped to the fill aesthetic. In my answer, I provided an example very similar to the OP’s code, except I used the iris dataset with the variable Species mapped to the x aesthetic to define the bars and also mapped Species to the fill aesthetic so I could use scale_fill_manual to change the colors of the bars."
  },
  {
    "objectID": "blog-2023/Blog-1-submissions/santos-cl/dosSantosCaio.html",
    "href": "blog-2023/Blog-1-submissions/santos-cl/dosSantosCaio.html",
    "title": "Asking Good Questions",
    "section": "",
    "text": "It seemed like the Stack Overflow user Jamie was having some trouble calculating the distance between a hospital in Fresno, CA (119.85 °W, 36.84° N) and the home location of several patients.\nJamie had a data frame with the geographical coordinates of city in which the hospital patients lived and wanted to calculate the geographical distance that each patient traveled.\nJamie provided the geographical coordinates of the hospital\n\nLatitude: 36.840\n\nLongitude: -119.850\n\nIn addition, Jamie also provided the an example data frame\n\nstructure(list(major_city = c(\"Mountain View\", \"Watsonville\", \"Honolulu\", \"Los Altos\", \"Morgan Hill\", \"Fulton\", \"Oak Grove\", \"Port Kent\", \"Bedford\", \"San Jose\"), \n\nlatitude = c(37.39, 36.9, 21.31, 37.36, 37.1, 43.3, 36.69, 44.526, NA, 37.27),\n\nlongitude = c(-122.07, -121.7, -157.85, -122.15, -121.7, -76.4, -87.44, -73.409, NA, -121.84)), \nrow.names = c(NA, -10L), class = c(\"data.table\", \"data.frame\"), \n.internal.selfref = <pointer: 0x7f98af80bae0>, index = integer(0))\n\nI provided an answer using the apply function. The idea was to apply a function rowwise which returned the distance from the hospital to the home location of each patient.\n\ndf <- data.frame(major_city = c(\"Mountain View\",\"Watsonville\", \"Honolulu\", \"Los Altos\", \"Morgan Hill\", \"Fulton\", \"Oak Grove\", \"Port Kent\", \"Bedford\", \"San Jose\"),\n                 latitude = c(37.39, 36.9, 21.31, 37.36, 37.1, 43.3, 36.69, 44.526, NA, 37.27),\n                 longitude = c(-122.07, -121.7, -157.85, -122.15, -121.7, -76.4, -87.44, -73.409, NA, -121.84))\n\ndf$distance_m <- apply(df, MARGIN = 1, function(x) {\n  geosphere::distGeo(as.numeric(c(x['longitude'], x['latitude'])),\n                     c(-119.85, 36.84)) \n  })\n\ndf$distance_km <- df$distance_m / 1000\n\nThe ouput provided the distance for all rows in the data frame\n\n      major_city latitude longitude distance_m distance_km\n1  Mountain View   37.390  -122.070   206527.4    206.5274\n2    Watsonville   36.900  -121.700   165083.2    165.0832\n3       Honolulu   21.310  -157.850  4045683.3   4045.6833\n4      Los Altos   37.360  -122.150   212440.1    212.4401\n5    Morgan Hill   37.100  -121.700   167241.2    167.2412\n6         Fulton   43.300   -76.400  3731976.3   3731.9763\n7      Oak Grove   36.690   -87.440  2879678.0   2879.6780\n8      Port Kent   44.526   -73.409  3962114.4   3962.1144\n9        Bedford       NA        NA         NA          NA\n10      San Jose   37.270  -121.840   183321.3    183.3213"
  },
  {
    "objectID": "blog-2023/Blog-1-submissions/santos-cl/dosSantosCaio.html#my-experience",
    "href": "blog-2023/Blog-1-submissions/santos-cl/dosSantosCaio.html#my-experience",
    "title": "Asking Good Questions",
    "section": "MY EXPERIENCE",
    "text": "MY EXPERIENCE\nThis was my first time answering questions on Stack Overflow. This question in specific was good because the poster provided a minimal reproducible example. When I was looking for questions to answer, I saw several questions that could not be answered because they did not provide examples. Overall, it was a pleasant experience, being able to provide answers to a community that has greatly helped me when I taking my first steps towards learning R."
  },
  {
    "objectID": "blog-2023/Blog-1-submissions/sudi007/SudeshBhagat.html",
    "href": "blog-2023/Blog-1-submissions/sudi007/SudeshBhagat.html",
    "title": "Asking Good Questions",
    "section": "",
    "text": "Asking good questions is a valuable skill to have - asking questions in an online setting is both easier and harder than asking questions in person: we can prepare to ask a question but we are also expected to prepare. The links posted here give some advice on how to ask good questions:\n\nstackoverflow’s Asking a good question\nR’s Posting guidelines\nminimal complete verifiable example, minimal reproducible example\n\nFollow these links and read through the advice given, then\n\nPick at least one question from stackoverflow or the R help and answer it. After reading the content on both the links, the question I chose to answer was from Stackoverflow(https://stackoverflow.com/questions/61086231/writing-a-for-loop-in-r-for-knn-method-with-cross-validation?noredirect=1#comment108075908_61086231) and R help(https://community.rstudio.com/t/converting-factor-variable-into-numeric/158479).\n\nWrite a blog post answering the following questions:\n\nDocument which question you answered (link to your answer). After reading the content on both the links, the question I chose to answer was from Stackoverflow(https://stackoverflow.com/questions/61086231/writing-a-for-loop-in-r-for-knn-method-with-cross-validation?noredirect=1#comment108075908_61086231) and R help(https://community.rstudio.com/t/converting-factor-variable-into-numeric/158479). The link to my answer to the questions I answered is already provided in the first part as well as here and here. My ID for the question and answer on Stackoverflow(https://stackoverflow.com/questions/61086231/writing-a-for-loop-in-r-for-knn-method-with-cross-validation?noredirect=1#comment108075908_61086231) is user13073332 whereas on R help is Sudi. I had asked this question on Stackoverflow and I landed up answering it, following a discussion about it on Stackoverflow. As a result, my answer is also provided under the question\nRelate your experience of answering the question to your reading. \n\nMy experience of answering the question based on the reading. When I had answered this question, I was not aware of the correct way to ask questions. Based on the readings, the question asked meets the first criterion for a good question, which is that the question should be on topic and suitable to the Stackoverflow website.The portal Stackoverflow invites questions about programming and the question asked met this requirement. The second requirement is to research and search the existing set of questions to ensure that the question you intend to ask is not duplicated. Although the questioner (which, in this case, was me) had researched and searched the existing set of questions to look for a suitable answer, there is no proof provided to indicate that the question was not repeated/duplicated. The questioner had not linked any seemingly similar questions on this topic existing on the portal. It could also be that there were no such questions. Thereafter, another requirement is that the title of the question summarizes the specific problem faced by the researcher. This condition is not met by the questioner as the title could appear a vague and ambiguous to those attempting to answer the question, although the question itself carries some details, if not all. This is why the person attempting to answer this question asked counterquestions for further clarification. While offering clarification to the question, I stumbled upon the answer myself and answered it on the portal as user13073332. With this experience of asking and answering questions, I learned the importance of providing all possible details required to answer the questions satisfactorily. A question that is clear begets answers whereas one that is unclear only invites further questions. I would also like to link another question I had answered on R help. In this case, the questioner was not me but I had provided the answer under the name “Sudi”.\nThe title of the question is not clear to the extent that there is no indication that it may be a question related to R as required by the guidelines of the portal. However, the person asking the question provides all the required information as part of the question, albeit leaving room for grammatical correction. No vignettes or code demonstrations were provided. The questioner did not allude to other similar questions on the portal or their search about such questions. As I was the second person answering this question, I had help in the form of the answer from the person who had attempted the question before me. Their answer had code information, which was useful while providing an answer.\n\nInstructions to follow."
  },
  {
    "objectID": "blog-2023/Blog-1-submissions/gnbltrn/BeltranGino.html",
    "href": "blog-2023/Blog-1-submissions/gnbltrn/BeltranGino.html",
    "title": "Asking Good Questions",
    "section": "",
    "text": "Answering a question was hard for me, given my limited experience with R and programing. Instead, I focused on evaluating the quality of the question and found one that needed some guidance–based on the materials we read in class about asking good questions. A student had copied and pasted a homework, which contained multiple questions about a data set. My response was aimed at suggesting the question needed to be more specific to get the help needed. Link to my response https://stackoverflow.com/questions/75254300/uic-assignment-need-help-please-let-me-know-how-to-do-them/75254399#75254399\nSome else had just answered the same question, and included a link with specific guidance for students seeking help for homework (see link below). I read this resource and found it very informative, which made me contemplate the other side of every question… the answer. I realized my answer was perhaps too simple. I also realized that a good answer can be recycled and used many times and it becomes a guideline.\nAsking about homework link https://meta.stackoverflow.com/questions/334822/how-do-i-ask-and-answer-homework-questions\nThanks, Gino"
  },
  {
    "objectID": "blog-2023/Blog-1-submissions/gnbltrn/BeltranGino.html#prompt",
    "href": "blog-2023/Blog-1-submissions/gnbltrn/BeltranGino.html#prompt",
    "title": "Asking Good Questions",
    "section": "Prompt:",
    "text": "Prompt:\nAsking good questions is a valuable skill to have - asking questions in an online setting is both easier and harder than asking questions in person: we can prepare to ask a question but we are also expected to prepare. The links posted here give some advice on how to ask good questions:\n\nstackoverflow’s Asking a good question\nR’s Posting guidelines\nminimal complete verifiable example, minimal reproducible example\n\nFollow these links and read through the advice given, then\n\nPick at least one question from stackoverflow or the R help and answer it.\n\nWrite a blog post answering the following questions:\n\nDocument which question you answered (link to your answer).\nRelate your experience of answering the question to your reading. \n\n\nInstructions to follow."
  },
  {
    "objectID": "blog-2023/Blog-1-submissions/motinaaa/KashanianMotahareh.html",
    "href": "blog-2023/Blog-1-submissions/motinaaa/KashanianMotahareh.html",
    "title": "Asking Good Questions",
    "section": "",
    "text": "Asking good questions is a valuable skill to have - asking questions in an online setting is both easier and harder than asking questions in person: we can prepare to ask a question but we are also expected to prepare. The links posted here give some advice on how to ask good questions:\n\nstackoverflow’s Asking a good question\nR’s Posting guidelines\nminimal complete verifiable example, minimal reproducible example\n\nFollow these links and read through the advice given, then\n\nPick at least one question from stackoverflow or the R help and answer it.\n\nWrite a blog post answering the following questions:\n\nDocument which question you answered (link to your answer).\n\nBelow is the link to one of the questions I answered on StackOverflow (https://stackoverflow.com/questions/74797820/find-value-in-matrix-starting-from-two-columns-value/75253008#75253008)\n\nRelate your experience of answering the question to your reading. \n\nMy attempt was to answer a question to which I knew the answer. To be honest, finding a question that I can answer has been challenging! It took me most of my time to find a question :)\nIn answering the question, I tried to be clear, concise, and complete. According to StackOverflow’s structure, I provided reproducible code and a formatted answer.\n\nInstructions to follow."
  },
  {
    "objectID": "blog-2023/Blog-1-submissions/Sabrenar/RutledgeSabrena.html",
    "href": "blog-2023/Blog-1-submissions/Sabrenar/RutledgeSabrena.html",
    "title": "Asking Good Questions",
    "section": "",
    "text": "Asking good questions is a valuable skill to have - asking questions in an online setting is both easier and harder than asking questions in person: we can prepare to ask a question but we are also expected to prepare. The links posted here give some advice on how to ask good questions:\n\nstackoverflow’s Asking a good question\nR’s Posting guidelines\nminimal complete verifiable example, minimal reproducible example\n\nFollow these links and read through the advice given, then\n\nPick at least one question from stackoverflow or the R help and answer it.\n\nWrite a blog post answering the following questions:\n\nDocument which question you answered (link to your answer). I answered the question linked below: (https://stackoverflow.com/questions/75248261/cant-install-packages-in-r) https://stackoverflow.com/questions/75248261/cant-install-packages-in-r/75251062#75251062\nRelate your experience of answering the question to your reading. \n\nI chose an installation issue question, where the person asking was having issues installing a specific package. Answering the question I chose was rather straight-forward, since the answer to their question was hidden in the midst of their error message. According to stackoverflow’s Asking a good question page, authors should “explain how [they] encountered the problem [they are] trying to solve, and any difficulties that have prevented [them] from solving it [themselves].” Yet, the author of this particular question appears to only have attemptted installing twice before giving up. They go on to say “Any package I try to install raises the same issue,” which cannot be true since the error message is specific to the package and its dependencies. As such, I’m not sure if their question was helpful to resolving their issue, since there seemed to issues with not having admin rights that was complicating the installation process. In conclusion, I don’t think this question should have been posted on StackOverflow and should have been directed to the author’s IT department.\n\nInstructions to follow."
  },
  {
    "objectID": "blog-2023/Blog-1-submissions/luobo119/YichuanBai.html",
    "href": "blog-2023/Blog-1-submissions/luobo119/YichuanBai.html",
    "title": "Asking Good Questions",
    "section": "",
    "text": "Asking good questions is a valuable skill to have - asking questions in an online setting is both easier and harder than asking questions in person: we can prepare to ask a question but we are also expected to prepare. The links posted here give some advice on how to ask good questions:\n\nstackoverflow’s Asking a good question\nR’s Posting guidelines\nminimal complete verifiable example, minimal reproducible example\n\nFollow these links and read through the advice given, then\n\nPick at least one question from stackoverflow or the R help and answer it.\n\nWrite a blog post answering the following questions:\n\nDocument which question you answered (link to your answer).\nRelate your experience of answering the question to your reading."
  },
  {
    "objectID": "blog-2023/Blog-1-submissions/AArabio/ArabioAlexandra.html",
    "href": "blog-2023/Blog-1-submissions/AArabio/ArabioAlexandra.html",
    "title": "Asking Good Questions",
    "section": "",
    "text": "Asking good questions is a valuable skill to have - asking questions in an online setting is both easier and harder than asking questions in person: we can prepare to ask a question but we are also expected to prepare. The links posted here give some advice on how to ask good questions:\n\nstackoverflow’s Asking a good question\nR’s Posting guidelines\nminimal complete verifiable example, minimal reproducible example\n\nFollow these links and read through the advice given, then\n\nPick at least one question from stackoverflow or the R help and answer it.\n\nWrite a blog post answering the following questions:\n\nDocument which question you answered (link to your answer).\n\nLink to question\nAnswer: Once using the plot function you are building the base for your figure. To be able to add to that initial figure you can use the lines() function or the points() to add any addition data information to that plot.\nGiven your data, you could use the following code to accomplish your task.\n`{r} x <- seq(-2, 2, 0.05) y1 <- pnorm(x) y2 <- pnorm(x, 1, 1) plot(x, y1, type = “l”, col = “red”) plot(x, y2, type = “l”, col = “green”)\nplot(x, y1, type = “l”, col = “red”) + lines(x, y2, type = “l”, col = “green”) ``` This will produce the following figure.\n\n\nRelate your experience of answering the question to your reading. \n\nFrom the Stack Overflow ‘How do I ask a good question?’, it discussed how it is easier to provide answers to questions when they are summarized, specific, and reproducible. Because of this, I kpet these in mind when searching for questions to answer. I found a question that was to the point in what they needed to accomplish and provided simple data to work with as an example. Following the advice from Stack overflow ‘How to create a Minimal, Reproducible Example’ I started from scratch on my own device and broke the question into simple, traceable steps.\n\nInstructions to follow."
  },
  {
    "objectID": "blog-2023/Blog-1-submissions/Starwiiin/MohammadiarvejehParvin.html",
    "href": "blog-2023/Blog-1-submissions/Starwiiin/MohammadiarvejehParvin.html",
    "title": "Asking Good Questions",
    "section": "",
    "text": "Asking good questions is a valuable skill to have - asking questions in an online setting is both easier and harder than asking questions in person: we can prepare to ask a question but we are also expected to prepare. The links posted here give some advice on how to ask good questions:\n\nstackoverflow’s Asking a good question\nR’s Posting guidelines\nminimal complete verifiable example, minimal reproducible example\n\nFollow these links and read through the advice given, then\n\nPick at least one question from stackoverflow or the R help and answer it.\n\nWrite a blog post answering the following questions:\n\nDocument which question you answered (link to your answer).\nRelate your experience of answering the question to your reading. \n\n\nInstructions to follow."
  },
  {
    "objectID": "blog-2023/Blog-8-submissions/xyzyc/index.html#prompt",
    "href": "blog-2023/Blog-8-submissions/xyzyc/index.html#prompt",
    "title": "Simple personal website",
    "section": "Prompt:",
    "text": "Prompt:\nGitHub is an incredibly useful tool for project management and collaboration. It also has several useful features for professional promotion: you can host your own site on github using GitHub pages, describe yourself using a GitHub developer profile, and even use resume.github.io to generate a resume summary of your activity on GitHub (you must opt-in by starring the project page).\nposit and the associated package infrastructure provide multiple ways to generate websites using Quarto (or Rmarkdown). You can complete this assignment using one of the two options detailed in Prompt 8\nDescribe your experience creating your website below. Don’t forget to link to your website! Push this blog post to your blog-8 repo. Make sure that all of the checks are passing.\nHow did building your own website go?\nMy website address: Yingchao’s website\nI followed Yihui’s documentation and built the website by rmarkdown. The process is very smooth. The structure can be specified in index.Rmd and the different tabs are generated by different .Rmd files in the project directory."
  },
  {
    "objectID": "blog-2023/Blog-8-submissions/kundan7kumar/index.html#prompt",
    "href": "blog-2023/Blog-8-submissions/kundan7kumar/index.html#prompt",
    "title": "Personal Website",
    "section": "Prompt:",
    "text": "Prompt:\nGitHub is an incredibly useful tool for project management and collaboration. It also has several useful features for professional promotion: you can host your own site on github using GitHub pages, describe yourself using a GitHub developer profile, and even use resume.github.io to generate a resume summary of your activity on GitHub (you must opt-in by starring the project page).\nposit and the associated package infrastructure provide multiple ways to generate websites using Quarto (or Rmarkdown). You can complete this assignment using one of the two options detailed in Prompt 8\nDescribe your experience creating your website below. Don’t forget to link to your website! Push this blog post to your blog-8 repo. Make sure that all of the checks are passing. Link:\nSolution: It has been a great experience in creating websites and publish on GitHub. I have learnt a lot how “rmd” and “qmd” file works and how continuous integration help projects to build and host. It also helped me to learn yaml file and how it works.\nPersonal Website using Jekyll: https://kundan7kumar.github.io/\nBook down Website for statistical notes: https://kundan7kumar.github.io/statistics-analysis/\nFor this Blog, I have created another blogging website using Quarto:\nQuarto-Website: https://kundan7kumar.github.io/datascience-blog/\nHow did building your own website go?\nIt went well and able to deploy successfully."
  },
  {
    "objectID": "blog-2023/Blog-8-submissions/anyeshar/index.html",
    "href": "blog-2023/Blog-8-submissions/anyeshar/index.html",
    "title": "Website Blog",
    "section": "",
    "text": "GitHub is an incredibly useful tool for project management and collaboration. It also has several useful features for professional promotion: you can host your own site on github using GitHub pages, describe yourself using a GitHub developer profile, and even use resume.github.io to generate a resume summary of your activity on GitHub (you must opt-in by starring the project page).\nposit and the associated package infrastructure provide multiple ways to generate websites using Quarto (or Rmarkdown). You can complete this assignment using one of the two options detailed in Prompt 8\nDescribe your experience creating your website below. Don’t forget to link to your website! Push this blog post to your blog-8 repo. Make sure that all of the checks are passing.\nHow did building your own website go?\nIt went okay. The actual building of the websit was fine, however it was very difficult to push the changes. The sites_libs folder did not want to push. I finally was able to through the terminal. Also, I was confused as to how we get to the website."
  },
  {
    "objectID": "blog-2023/Blog-8-submissions/Landon-Getting/index.html",
    "href": "blog-2023/Blog-8-submissions/Landon-Getting/index.html",
    "title": "Becoming a Website Engineer",
    "section": "",
    "text": "How did building your own website go?\nView my website!\nBuilding the website went relatively smoothly! However, I had a few minor issues.\nFirst, I had trouble staging my files to be committed. I originally thought this was due to the new RStudio update. However, I reinstalled the latest RStudio version, restarted my computer, restarted my RStudio several times, and finally found success. I cannot replicate the problem so it may be tough to solve.\nI also had an issue where a page was not building the correctly named .html file. I developed a page called shiny.Rmd to display a Shiny App project. A file called “Shiny.html” is generated when the website it built. It is not recognized by the _site.yml file since it is expecting “shiny.html”. I manually changed the file name after building to achieve success. I could not determine why this problem was occurring."
  },
  {
    "objectID": "blog-2023/Blog-8-submissions/Hiiiua/index.html#prompt",
    "href": "blog-2023/Blog-8-submissions/Hiiiua/index.html#prompt",
    "title": "Github Page",
    "section": "Prompt:",
    "text": "Prompt:\nGitHub is an incredibly useful tool for project management and collaboration. It also has several useful features for professional promotion: you can host your own site on github using GitHub pages, describe yourself using a GitHub developer profile, and even use resume.github.io to generate a resume summary of your activity on GitHub (you must opt-in by starring the project page).\nposit and the associated package infrastructure provide multiple ways to generate websites using Quarto (or Rmarkdown). You can complete this assignment using one of the two options detailed in Prompt 8\nDescribe your experience creating your website below. Don’t forget to link to your website! Push this blog post to your blog-8 repo. Make sure that all of the checks are passing.\nMy answer I have done this when I took STAT 850, but we didn’t cover yaml and header structure. This time I found a nice template to add icons for contact, github, blog and etc. There’s no doubt the website looks neater than before. I’ll share two finding of mine in this github page revisit activity.\nGithub page is a nice way to share the README file with keeping repo code private. There is always a time I make a nice repo of a project, but I don’t want to or I can’t share my code yet while I want to shout out to the world about how great is my project, github page is my good friend in this case.\nI didn’t know why I need to wait for some time to see my update after refreshing the github.io page two years ago, because I didn’t know what does github action do. It was also difficult to tell I failed see the updated webpage because incorrect rendering or just wrong syntax in README. I remember it took me a morning to redo the page tab over and over again because I can’t find the link in the io page, but turned out it was a little syntax in Rmd file and I passed the workflow. Now I can differentiate by looking at the green check or red cross under the action tab, and I can change default md output to html in yaml to fix the rendering problem.\nhttps://hiiiua.github.io/\nHow did building your own website go?"
  },
  {
    "objectID": "blog-2023/Blog-8-submissions/charchit/index.html#prompt",
    "href": "blog-2023/Blog-8-submissions/charchit/index.html#prompt",
    "title": "Building website",
    "section": "Prompt:",
    "text": "Prompt:\nGitHub is an incredibly useful tool for project management and collaboration. It also has several useful features for professional promotion: you can host your own site on github using GitHub pages, describe yourself using a GitHub developer profile, and even use resume.github.io to generate a resume summary of your activity on GitHub (you must opt-in by starring the project page).\nposit and the associated package infrastructure provide multiple ways to generate websites using Quarto (or Rmarkdown). You can complete this assignment using one of the two options detailed in Prompt 8\nDescribe your experience creating your website below. Don’t forget to link to your website! Push this blog post to your blog-8 repo. Make sure that all of the checks are passing.\nHow did building your own website go?\nIt was good. I enjoyed working with github. It was fairly easy to build a website on github. However, creating a good website seems a bit challenging. There needs to be a human element which people would like to interact with and easy to use.I found a lot of tutorials on youtube about it too. I will most likely use it to publish my work in the future when I am close to graduation. Thanks for introducing this in the class."
  },
  {
    "objectID": "blog-2023/Blog-8-submissions/kellynay/index.html#prompt",
    "href": "blog-2023/Blog-8-submissions/kellynay/index.html#prompt",
    "title": "Building a Website",
    "section": "Prompt:",
    "text": "Prompt:\nGitHub is an incredibly useful tool for project management and collaboration. It also has several useful features for professional promotion: you can host your own site on github using GitHub pages, describe yourself using a GitHub developer profile, and even use resume.github.io to generate a resume summary of your activity on GitHub (you must opt-in by starring the project page).\nposit and the associated package infrastructure provide multiple ways to generate websites using Quarto (or Rmarkdown). You can complete this assignment using one of the two options detailed in Prompt 8\nDescribe your experience creating your website below. Don’t forget to link to your website! Push this blog post to your blog-8 repo. Make sure that all of the checks are passing.\nHow did building your own website go?\nBuilding the website was fun and quite easy until I had to commit and push all the files required. There was a yellow question mark beside the site_libs folder and I tried clicking on it to get the check mark, so I could commit and push.\nI kept getting the following error message:\nAnother git process seems to be running in this repository, e.g. an editor opened by ‘git commit’. Please make sure all processes are terminated then try again. If it still fails, a git process may have crashed in this repository earlier: remove the file manually to continue. Updating 8130468..b4ecf64\nSo I went on my repo and added the files via upload. My website has three pages: Home, Volunteering Experiences, R Favorite Packages.\nIn these pages I linked my student bios in different research and professional development projects that I am involved. I also mentioned Volunteer Experience and packages that I have enjoyed working with or packages that I see value for future work.\nHere is the link: https://github.com/kellynay/kellynay.github.io"
  },
  {
    "objectID": "blog-2023/Blog-8-submissions/drbradford12/index.html#prompt",
    "href": "blog-2023/Blog-8-submissions/drbradford12/index.html#prompt",
    "title": "My professional self",
    "section": "Prompt:",
    "text": "Prompt:\nGitHub is an incredibly useful tool for project management and collaboration. It also has several useful features for professional promotion: you can host your own site on github using GitHub pages, describe yourself using a GitHub developer profile, and even use resume.github.io to generate a resume summary of your activity on GitHub (you must opt-in by starring the project page).\nposit and the associated package infrastructure provide multiple ways to generate websites using Quarto (or Rmarkdown). You can complete this assignment using one of the two options detailed in Prompt 8\nDescribe your experience creating your website below. Don’t forget to link to your website! Push this blog post to your blog-8 repo. Make sure that all of the checks are passing.\nHow did building your own website go?\nDenise’s Answer:\nTo be honest, I have had a github pages since last year during SDSS presentation. I’ve made some changes to the webpage like the landing page during this blog post. I wanted to be clear that this was some thing that I was not new to the publishing github pages. I would like to make more changes when I have the time.\nDenise’s Github Pages\nTo finally answer the question, initially, this process was MUCH EASIER than creating a blogdown website, which I also did last year. Unfortunately, I’m not great with Netlify. As a result, it has not been publicly updated and removed from all of my lines of communication."
  },
  {
    "objectID": "blog-2023/Blog-8-submissions/HarunCelikOtto/index.html#prompt",
    "href": "blog-2023/Blog-8-submissions/HarunCelikOtto/index.html#prompt",
    "title": "Harun’s Quarto Blog Page",
    "section": "Prompt:",
    "text": "Prompt:\nGitHub is an incredibly useful tool for project management and collaboration. It also has several useful features for professional promotion: you can host your own site on github using GitHub pages, describe yourself using a GitHub developer profile, and even use resume.github.io to generate a resume summary of your activity on GitHub (you must opt-in by starring the project page).\nposit and the associated package infrastructure provide multiple ways to generate websites using Quarto (or Rmarkdown). You can complete this assignment using one of the two options detailed in Prompt 8\nDescribe your experience creating your website below. Don’t forget to link to your website! Push this blog post to your blog-8 repo. Make sure that all of the checks are passing.\nHow did building your own website go?\nHistorical Mapping\nI decided to build a Quarto Blog to document the work that I want to do for the projects related to historical maps. Quarto’s layout is pretty straight-forward so I didn’t run into any problems with creating the posts that are on the webpage. I did try to change the css styling of the page a little bit with a new navbar but definitely struggled with trying to find the right place to put in the new html styles. In publishing to the Github Pages, I first decided I would try to work with the quarto publish command but didn’t really understand what the purpose of change the source branch to the gh-pages was so I opted for the docs method instead which was quite easy. It is still a little scary that you could accidentally push the rest of your code with your docs to the repository by accident but I suppose there are .gitignore files for a reason."
  },
  {
    "objectID": "blog-2023/Blog-8-submissions/valeriehan6/index.html#prompt",
    "href": "blog-2023/Blog-8-submissions/valeriehan6/index.html#prompt",
    "title": "Building a website",
    "section": "Prompt:",
    "text": "Prompt:\nGitHub is an incredibly useful tool for project management and collaboration. It also has several useful features for professional promotion: you can host your own site on github using GitHub pages, describe yourself using a GitHub developer profile, and even use resume.github.io to generate a resume summary of your activity on GitHub (you must opt-in by starring the project page).\nposit and the associated package infrastructure provide multiple ways to generate websites using Quarto (or Rmarkdown). You can complete this assignment using one of the two options detailed in Prompt 8\nDescribe your experience creating your website below. Don’t forget to link to your website! Push this blog post to your blog-8 repo. Make sure that all of the checks are passing.\nHow did building your own website go?\nHere’s my website: https://valeriehan6.github.io/.\nI chose to use Quarto. The website building itself wasn’t too bad since it felt pretty similar to RMarkdown and the changes I made to the layout were straightforward. However, I got frustrated when I was trying to figure out how to publish the website from Github. The rendering to docs method did not work for me. I tried re-organizing my file structure to get it to work and added .nojekyll files in each layer just to see if it wasn’t checking it in the git root directory, but it still only displayed the default page generated from the README.md file. I then tried the other method of publishing. Luckily, that method worked after only minor debugging."
  },
  {
    "objectID": "blog-2023/Blog-8-submissions/IanParzyszek/index.html#prompt",
    "href": "blog-2023/Blog-8-submissions/IanParzyszek/index.html#prompt",
    "title": "Ian and Remmys Website",
    "section": "Prompt:",
    "text": "Prompt:\nGitHub is an incredibly useful tool for project management and collaboration. It also has several useful features for professional promotion: you can host your own site on github using GitHub pages, describe yourself using a GitHub developer profile, and even use resume.github.io to generate a resume summary of your activity on GitHub (you must opt-in by starring the project page).\nposit and the associated package infrastructure provide multiple ways to generate websites using Quarto (or Rmarkdown). You can complete this assignment using one of the two options detailed in Prompt 8\nDescribe your experience creating your website below. Don’t forget to link to your website! Push this blog post to your blog-8 repo. Make sure that all of the checks are passing.\nHow did building your own website go?\nBuilding my webiste was fun! I was able to add some photos and hace some fun with it. I for the life of me was having trouble attatching things like my CV or my email for whatever reasaon. However, following some instructions online I was able to make it about my pet! So I had some fun with it, it is pretty basic and not very interactive, but everytime I tried to add something I would get an error about certain characters not beign allowed in the column/row. And it seemed that all the answers onstack overflow or similar websites only helped that persons speciic code. I still do not know what the root porblem is .\nIanParzyszek.github.io/index.html"
  },
  {
    "objectID": "blog-2023/Blog-8-submissions/loganjohnson0/index.html#prompt",
    "href": "blog-2023/Blog-8-submissions/loganjohnson0/index.html#prompt",
    "title": "Building my own website",
    "section": "Prompt:",
    "text": "Prompt:\nGitHub is an incredibly useful tool for project management and collaboration. It also has several useful features for professional promotion: you can host your own site on github using GitHub pages, describe yourself using a GitHub developer profile, and even use resume.github.io to generate a resume summary of your activity on GitHub (you must opt-in by starring the project page).\nposit and the associated package infrastructure provide multiple ways to generate websites using Quarto (or Rmarkdown). You can complete this assignment using one of the two options detailed in Prompt 8\nDescribe your experience creating your website below. Don’t forget to link to your website! Push this blog post to your blog-8 repo. Make sure that all of the checks are passing.\nHow did building your own website go?\nI genuinely found this activity to be very exciting. I have always wanted to have my own website but I have never fully understood all of the behind the scenes type work that has to go into it. I also thought that in order to have a website that I would have to pay for a domain name or pay for the service of hosting the website. Blog 8 gave me the information needed to begin to develop my own website. I was able to use the Quarto documents online to help guide me through the process of hosting a website, some of the modifications I could make to my website, and connecting the Quarto project to GitHub pages. It was all a very easy process.\nI also took to the Quarto Gallery to see some example websites. From these examples, I was able to identify some of the structure that I was looking to incorporate into my website. I also modified some of the color of my page using a .scss file. I’m not certain if I used that file correctly or not because according to GitHub, 98% of my website is coded in SCSS. I’m still learning more about the different styling and language of HTML and CSS, so maybe in the future I can modify those files better than incorporating the SCSS file. Maybe it doesn’t matter either way, but I’m hoping to learn more about the styling.\nOverall, I was impressed with the ease of use of creating the website. There are many different ways to modify the website and make it unique to each use case that a user might have. I think it also has a nice standard format that makes it consistent. I imagine it is easy to really add even more customization into the website beyond my current knowledge of the system. Some goals I have for my website would be to include an additional section for potentially a blog, an area for packages or other relevant things related to my research, and adjusting the styling and being more creative with that. I also aim to incorporate different pictures into the website or a page showcasing tweets or retweets of mine (I am working on being active on academic twitter)."
  },
  {
    "objectID": "blog-2023/Blog-8-submissions/Atefeha1995/index.html#prompt",
    "href": "blog-2023/Blog-8-submissions/Atefeha1995/index.html#prompt",
    "title": "My professional self",
    "section": "Prompt:",
    "text": "Prompt:\nGitHub is an incredibly useful tool for project management and collaboration. It also has several useful features for professional promotion: you can host your own site on github using GitHub pages, describe yourself using a GitHub developer profile, and even use resume.github.io to generate a resume summary of your activity on GitHub (you must opt-in by starring the project page).\nposit and the associated package infrastructure provide multiple ways to generate websites using Quarto (or Rmarkdown). You can complete this assignment using one of the two options detailed in Prompt 8\nDescribe your experience creating your website below. Don’t forget to link to your website! Push this blog post to your blog-8 repo. Make sure that all of the checks are passing.\nHow did building your own website go?\nBuilding a website was really interesting to me. I thought that it should be very complicated, but when I started it was much easier than what I thought. I chose to build my website using Rmarkdown. It was very straight forward, but I experienced a few minor problems during the process. One of them happened when I wanted to push the required initial document to the GitHub. I had some difficulties pushing the site_libs; I finally uploaded this file on my repo manually. Here is the link to my website.:) I am really excited about it, and I am going to make my website more complete and more beautiful."
  },
  {
    "objectID": "blog-2023/Blog-8-submissions/anphan0828/index.html#prompt",
    "href": "blog-2023/Blog-8-submissions/anphan0828/index.html#prompt",
    "title": "Let’s RMarkdown that Site",
    "section": "Prompt:",
    "text": "Prompt:\nGitHub is an incredibly useful tool for project management and collaboration. It also has several useful features for professional promotion: you can host your own site on github using GitHub pages, describe yourself using a GitHub developer profile, and even use resume.github.io to generate a resume summary of your activity on GitHub (you must opt-in by starring the project page).\nposit and the associated package infrastructure provide multiple ways to generate websites using Quarto (or Rmarkdown). You can complete this assignment using one of the two options detailed in Prompt 8\nDescribe your experience creating your website below. Don’t forget to link to your website! Push this blog post to your blog-8 repo. Make sure that all of the checks are passing.\nHow did building your own website go? I chose the Simple RMarkdown Site option. Here is my website.\nI was able to create a minimal website using just a few commands (I did not know building a website was that fast and simple). I am planning to add some details to it following the instruction at https://bookdown.org/yihui/rmarkdown/rmarkdown-site.html.\nI added two pages about Research and Teaching, as those are the two things that occupy me 24/7. I had fun adding details into the website, the more things added the more I want it to look nice. I will probably go back and decorate it when I have time. Now I realize all the fancy websites are just code behind the scene, but effort and creativity are what make them look fancy.\nI noticed that the website is not updated immediately after I push changes to the GitHub repo, it usually takes 1-2 minutes to fully reflect the changes. I freaked out at first when the website did not change accordingly to my code. Other than that, I have no trouble rendering the site and passing the checks.\nSomehow the Frontmatter check does not work for my repo anymore, seems like I have to pay for something:\nFrontmatter JSON Schema Validator The job was not started because recent account payments have failed or your spending limit needs to be increased. Please check the ‘Billing & plans’ section in your settings."
  },
  {
    "objectID": "blog-2023/Blog-8-submissions/hardtme/index.html",
    "href": "blog-2023/Blog-8-submissions/hardtme/index.html",
    "title": "Adventures in Website Building",
    "section": "",
    "text": "How did building your own website go?\nI made my website using a simple RMarkdown site. Since I intend this website to be a professional website, I added pages about my research interests, teaching experiences, and working experiences. The biggest surprise I had during the website process was that changes to the website were not immediately visible after committing and pushing them to the repository. I refreshed my website multiple times, and the changes eventually appeared. It turned out that a GitHub action needed to run in order for the changes to be visible, and this took a few moments after each commit. In retrospect, this makes sense, but it was surprising for me after I added the first additional page to my website.\nFor me, the most time-consuming part of the process was choosing the theme for my website since RMarkdown includes multiple themes for HTML documents. I started out changing the theme in the _site.yml file, committing and pushing to the repository, and waiting for the changes to be applied so I could see if I liked how the theme looked. I later figured out that I could change the theme in the _site.yml file and then locally knit one of the RMarkdown documents to see what the resulting webpage would look like. This sped things up, and I settled on the cerulean theme because I liked that it incorporated color, unlike most of the other themes.\nHere is a link to my website: hardtme.github.io."
  },
  {
    "objectID": "blog-2023/Blog-8-submissions/santos-cl/index.html",
    "href": "blog-2023/Blog-8-submissions/santos-cl/index.html",
    "title": "What should I include? What should I not?",
    "section": "",
    "text": "Frontmatter check"
  },
  {
    "objectID": "blog-2023/Blog-8-submissions/santos-cl/index.html#prompt",
    "href": "blog-2023/Blog-8-submissions/santos-cl/index.html#prompt",
    "title": "What should I include? What should I not?",
    "section": "Prompt:",
    "text": "Prompt:\nGitHub is an incredibly useful tool for project management and collaboration. It also has several useful features for professional promotion: you can host your own site on github using GitHub pages, describe yourself using a GitHub developer profile, and even use resume.github.io to generate a resume summary of your activity on GitHub (you must opt-in by starring the project page).\nposit and the associated package infrastructure provide multiple ways to generate websites using Quarto (or Rmarkdown). You can complete this assignment using one of the two options detailed in Prompt 8\nDescribe your experience creating your website below. Don’t forget to link to your website! Push this blog post to your blog-8 repo. Make sure that all of the checks are passing.\nHow did building your own website go?\nThis week, we were tasked with building our own website and it was an interesting task. I have been meaning to build it for sometime but it has alway been put in the back burner because other tasks took priority over it. I am glad I finally had a push to do it. Thankfully, I could count on GitHub pages to help with this task. The fact that we can upload a website the general structure to a GitHub repository and GitHub will build a webpage and deploy it, is fascinating. This removes a lot of the complications that come from bulding websites, as we often have the answer questions such as: “Where I am going to host this?”; “Should I configure a database for this website?”; and “How do I configure a server?”.\nNot everything went well though, I had a hard time figuring out how to build the website using Jeckyll. I was able to find several Jeckyll templates but I failed to understand how to use them in GitHub. Eventually, I gave up on Jeckyll. I have had some previous experience building websites using HTML, CSS, and JavaScript so I decided to move forward with that. Overall, I had a fun time writing about myself in a professional website. The hardest part was figuring out what should I include and what should I not. Finally, I have opted for a simple layout that communicates all the information I believe a future employer would be interested. The website contains a very simple layout with the following sections:\n\n\n\n\n\n\n\nSection\nDescription\n\n\n\n\nWelcome\nBrief description of my activities nowadays.\n\n\nProfile\nProfile picture and links to social media and curriculum vitae.\n\n\nResearch Interests\nResearch topics I am fascinated about.\n\n\nEducation\nUniversities I have attended.\n\n\nSoftware\n1 software I have published…\n\n\nPublications\nPeer-reviewed publications"
  },
  {
    "objectID": "blog-2023/Blog-8-submissions/sudi007/index.html#prompt",
    "href": "blog-2023/Blog-8-submissions/sudi007/index.html#prompt",
    "title": "My professional self",
    "section": "Prompt:",
    "text": "Prompt:\nGitHub is an incredibly useful tool for project management and collaboration. It also has several useful features for professional promotion: you can host your own site on github using GitHub pages, describe yourself using a GitHub developer profile, and even use resume.github.io to generate a resume summary of your activity on GitHub (you must opt-in by starring the project page).\nposit and the associated package infrastructure provide multiple ways to generate websites using Quarto (or Rmarkdown). You can complete this assignment using one of the two options detailed in Prompt 8\nDescribe your experience creating your website below. Don’t forget to link to your website! Push this blog post to your blog-8 repo. Make sure that all of the checks are passing.\nHow did building your own website go? First of all, I created a layout of the website and chose my color scheme using Quarto. Thereafter, I created the homepage and inserted an image there. Instead of a dedicated “contact me” page, I added icons of my social media pages and linked them. Formatting the content on this page was easy. I could play around with the different levels of the title to add structure to my content. I was also able to add bullets and other punctuation. I could add pages to my website and also select their layout. I had the option to add images on the other pages as well, although I chose to not add any. Overall, I could see the value R-studio brings in developing professional looking websites. Here is the link to the website :https://sudi007.github.io/"
  },
  {
    "objectID": "blog-2023/Blog-8-submissions/motinaaa/index.html#prompt",
    "href": "blog-2023/Blog-8-submissions/motinaaa/index.html#prompt",
    "title": "Welcome to the Club!",
    "section": "Prompt:",
    "text": "Prompt:\nGitHub is an incredibly useful tool for project management and collaboration. It also has several useful features for professional promotion: you can host your own site on github using GitHub pages, describe yourself using a GitHub developer profile, and even use resume.github.io to generate a resume summary of your activity on GitHub (you must opt-in by starring the project page).\nposit and the associated package infrastructure provide multiple ways to generate websites using Quarto (or Rmarkdown). You can complete this assignment using one of the two options detailed in Prompt 8\nDescribe your experience creating your website below. Don’t forget to link to your website! Push this blog post to your blog-8 repo. Make sure that all of the checks are passing.\nHow did building your own website go?\ncreating my website with Quarto in R was actually pretty sweet! I had a lot of fun with it, and it was a smooth ride for the most part. Although, I gotta admit, I did run into some trouble with this ERROR: YAMLException: bad indentation of a mapping entry. But, hey, I figured it out and moved on!\nThe toughest part for me was figuring out what to write about myself. It’s not easy to talk about yourself, you know what I mean? I spent a lot of time trying to come up with the right words, and I still don’t know if I got it exactly right.\nI’m also obsessed with design and colors and themes, so that part was a blast. I spent way too much time trying to decide on the right colors and themes. And even then, I’m still not sure if I made the right choice! I just can’t help myself.\nOverall, though, I really enjoyed creating my website with Quarto in R. I was so into it that I didn’t even realize how much time had passed. It was a rewarding and engaging experience, and I’m thrilled with how my website turned out :) Here is the link: [https://motinaaa.github.io]"
  },
  {
    "objectID": "blog-2023/Blog-8-submissions/Sabrenar/index.html#prompt",
    "href": "blog-2023/Blog-8-submissions/Sabrenar/index.html#prompt",
    "title": "Creating a Website",
    "section": "Prompt:",
    "text": "Prompt:\nGitHub is an incredibly useful tool for project management and collaboration. It also has several useful features for professional promotion: you can host your own site on github using GitHub pages, describe yourself using a GitHub developer profile, and even use resume.github.io to generate a resume summary of your activity on GitHub (you must opt-in by starring the project page).\nposit and the associated package infrastructure provide multiple ways to generate websites using Quarto (or Rmarkdown). You can complete this assignment using one of the two options detailed in Prompt 8\nDescribe your experience creating your website below. Don’t forget to link to your website! Push this blog post to your blog-8 repo. Make sure that all of the checks are passing.\nHow did building your own website go?\nThe biggest issue I had with creating this website was the lack of documentation. The theme would not update unless it was on the *_site.yml* file despite the individual Rmarkdown files having options for theme. Changing the layout for the pages is cumbersome since the html coding is needed within the Rmarkdown, which is not explicitly mentioned in any documentation. After troubleshooting theme display issues, I encountered several issues with connection between the github repo and the website. At one time both the Rmarkdown and the website rendered successfully, but in order to get matching layout and theme between the Rmarkdown render and the website display, I created a css file. Adding this file caused a 404 error when accessing the website, but no issues in the Rmarkdown render. I investigated the errors and found a connection issue with github triggered by bug #3345 github bug report website connection (gtritchie. “R Markdown Website Published with Source to RSConnect from Viewer Has Wrong Type · Issue #3345 · RSTUDIO/Rstudio.” GitHub, August 20, 2018. https://github.com/rstudio/rstudio/issues/3345. ). The error implies that github cannot find the index.html file, which does not make sense since it is present on the main directory of the github repo. Overall I found the experience to be tedious and annoying."
  },
  {
    "objectID": "blog-2023/Blog-8-submissions/luobo119/index.html#prompt",
    "href": "blog-2023/Blog-8-submissions/luobo119/index.html#prompt",
    "title": "Website Generation",
    "section": "Prompt:",
    "text": "Prompt:\nGitHub is an incredibly useful tool for project management and collaboration. It also has several useful features for professional promotion: you can host your own site on github using GitHub pages, describe yourself using a GitHub developer profile, and even use resume.github.io to generate a resume summary of your activity on GitHub (you must opt-in by starring the project page).\nposit and the associated package infrastructure provide multiple ways to generate websites using Quarto (or Rmarkdown). You can complete this assignment using one of the two options detailed in Prompt 8\nDescribe your experience creating your website below. Don’t forget to link to your website! Push this blog post to your blog-8 repo. Make sure that all of the checks are passing.\nHow did building your own website go?\nWebsite Link: https://luobo119.github.io/\nI use Quarto to build my website. Quarto is a very powerful tool to build a website. It’s very convenient to add content to the website, add links to other websites, and modify the structure of the website. I tried a sidebar navigator and it works well. Publishing the website to GitHub is a little bit confusing, but the description of the methods is detailed on Quarto website."
  },
  {
    "objectID": "blog-2023/Blog-8-submissions/AArabio/index.html#prompt",
    "href": "blog-2023/Blog-8-submissions/AArabio/index.html#prompt",
    "title": "All About Ally",
    "section": "Prompt:",
    "text": "Prompt:\nGitHub is an incredibly useful tool for project management and collaboration. It also has several useful features for professional promotion: you can host your own site on github using GitHub pages, describe yourself using a GitHub developer profile, and even use resume.github.io to generate a resume summary of your activity on GitHub (you must opt-in by starring the project page).\nposit and the associated package infrastructure provide multiple ways to generate websites using Quarto (or Rmarkdown). You can complete this assignment using one of the two options detailed in Prompt 8\nDescribe your experience creating your website below. Don’t forget to link to your website! Push this blog post to your blog-8 repo. Make sure that all of the checks are passing.\nHow did building your own website go?\nThrough the process of building my website, I found that there are more complicated ways to accomplish a relatively simple task. I was able to use markdown to create a website domain that was useable and loadable… but I could not figure out how to begin the process of building a website from scratch. The site that I had created was entirely blank. By using quarto, I was able to generate the website much easier. There was already a built in template using the creation of a new project blog. From there I was able to make a few changes such as replacing the default photo with my own and altering the set up a little bit.\nNow that the website is up and working I am able to add posts and make changes as I continue working on new projects and taking on new adventures. I look forward to making more alterations to the website as the semester goes along to be able to make it unique to myself."
  },
  {
    "objectID": "blog-2023/Blog-8-submissions/Starwiiin/index.html#prompt",
    "href": "blog-2023/Blog-8-submissions/Starwiiin/index.html#prompt",
    "title": "My Website",
    "section": "Prompt:",
    "text": "Prompt:\nGitHub is an incredibly useful tool for project management and collaboration. It also has several useful features for professional promotion: you can host your own site on github using GitHub pages, describe yourself using a GitHub developer profile, and even use resume.github.io to generate a resume summary of your activity on GitHub (you must opt-in by starring the project page).\nposit and the associated package infrastructure provide multiple ways to generate websites using Quarto (or Rmarkdown). You can complete this assignment using one of the two options detailed in Prompt 8\nDescribe your experience creating your website below. Don’t forget to link to your website! Push this blog post to your blog-8 repo. Make sure that all of the checks are passing.\nHow did building your own website go?\nParvin’s answer: I made the website using simple Rmarkdown site creating “_site.yml”, other pages, and rendering went pretty well. I had a challenge regarding the setting (main branch and docs), and pushing changes to the Github. I needed to arrange the setting and push the changes manually and it worked finally."
  },
  {
    "objectID": "blog-2023/Blog-10-submissions/xyzyc/index.html",
    "href": "blog-2023/Blog-10-submissions/xyzyc/index.html",
    "title": "Web scraping etiquette …",
    "section": "",
    "text": "With great power comes great responsibility - a large part of the web is based on data and services that scrape those data. Now that we start to apply scraping mechanisms, we need to think about how to apply those skills without becoming a burden to the internet society.\nFind sources on ethical web scraping - some readings that might help you get started with that are:\n\nJames Densmore\nR package polite\nJAMI @ EMPIRICAL\n\nAfter reading through some of the ethics essays write a blog post addressing the following questions:\n\nWhat are your main three takeaways for ethical web scraping? - Give examples, or cite your sources.\n\nFrom James Densmore and polite:\n\nDo not become a burden to the website one is scraping from. If there is a public API containing the desired data, then scraping does not need to happen. After bow to the host and get permission first, only nod is needed in the following process.\nBe open about the scraper’s identity by providing a user agent string and respond to the web owner’s contact.\nRespect the PI of the website. Only keep the data necessary to the project, and do not pass it as if the scraper owns it. Give credit to the website.\n\n\nWhat is a ROBOTS.TXT file? Identify one instance and explain what it allows/prevents.\n\nFrom JAMI @ EMPIRICAL: A ROBOTS.txt file indicates the web-crawling software where it is allowed (or not allowed) within the website. This is part of the Robots Exclusion Protocol (REP) which are a group of web standards created as a way to regulate how robots crawl the web.\nI checked the robots.txt file for overleaf.\n# robots.txt for https://www.sharelatex.com/\n\nUser-agent: *\nDisallow: /project/*\nDisallow: /github/repos/*\nDisallow: /recurly.com\nDisallow: /user/password/set\nAllow: /\n\nUser-Agent: AhrefsBot\nDisallow: /\n\nUser-Agent: XoviBot\nDisallow: /\n\nUser-Agent: RankSonicBot\nDisallow: /\n\nUser-Agent: SMTBot\nDisallow: /\nIt prevents all users (if not logged in I guess) from accessing the pages of projects, github repos, recurly.com and setting password page. It also disallows AhrefsBot, XoviBot, RankSonicBot and SMTBot from visiting the overleaf website.\n\nIdentify a website that you would like to scrape (or one an example from class) and implement a scrape using the polite package.\n\nI want to scrape the wikipedia for hummingbirds to retrieve the scientific classification of humming birds.\n\nlibrary(polite)\nlibrary(rvest)\nlibrary(purrr)\n\nsession <- bow(\"https://en.wikipedia.org/wiki/Hummingbird\", force = TRUE)\nresult <- scrape(session)\n\ninfo <- result %>% \n  html_elements(xpath = '//table[@class=\"infobox biota\"]') %>%\n  html_table()\n\ninfo[[1]]\n\n# A tibble: 13 × 2\n   HummingbirdTemporal range: Rupelian 30–0 Ma \\nPreꞒ\\nꞒ\\nO\\nS\\nD\\nC\\n…¹ Hummi…²\n   <chr>                                                                 <chr>  \n 1 \"\"                                                                    \"\"     \n 2 \"Four hummingbirdsfrom Trinidad and Tobago\"                           \"Four …\n 3 \"Scientific classification\"                                           \"Scien…\n 4 \"Kingdom:\"                                                            \"Anima…\n 5 \"Phylum:\"                                                             \"Chord…\n 6 \"Class:\"                                                              \"Aves\" \n 7 \"Clade:\"                                                              \"Stris…\n 8 \"Order:\"                                                              \"Apodi…\n 9 \"Family:\"                                                             \"Troch…\n10 \"Type genus\"                                                          \"Type …\n11 \"TrochilusLinnaeus, 1758\"                                             \"Troch…\n12 \"Subfamilies\"                                                         \"Subfa…\n13 \"†EurotrochilusFlorisuginaePhaethornithinaePolytminaeLesbiinaePatago… \"†Euro…\n# … with abbreviated variable names\n#   ¹​`HummingbirdTemporal range: Rupelian 30–0 Ma \\nPreꞒ\\nꞒ\\nO\\nS\\nD\\nC\\nP\\nT\\nJ\\nK\\nPg\\nN`,\n#   ²​`HummingbirdTemporal range: Rupelian 30–0 Ma \\nPreꞒ\\nꞒ\\nO\\nS\\nD\\nC\\nP\\nT\\nJ\\nK\\nPg\\nN`\n\n\nInstructions:\nSubmit to your repo. Make sure that all of the github actions pass (check menu item Actions - all of the actions should have green checks)"
  },
  {
    "objectID": "blog-2023/Blog-10-submissions/kundan7kumar/index.html",
    "href": "blog-2023/Blog-10-submissions/kundan7kumar/index.html",
    "title": "Web scraping",
    "section": "",
    "text": "With great power comes great responsibility - a large part of the web is based on data and services that scrape those data. Now that we start to apply scraping mechanisms, we need to think about how to apply those skills without becoming a burden to the internet society.\nFind sources on ethical web scraping - some readings that might help you get started with that are:\n\nJames Densmore\nR package polite\nJAMI @ EMPIRICAL\n\nAfter reading through some of the ethics essays write a blog post addressing the following questions:\n\nWhat are your main three takeaways for ethical web scraping? - Give examples, or cite your sources.\n\nSolution: The major takeaway for ethical web scraping :\n\nBefore any web-Scarping, it is important to check the website’s terms of use and robots.txt file to ensure you are not violating any rules.\nWeb-Scarping should not collect sensitive or private information without the consent of the website owner or the individuals concerned. It should follow data privacy and intellectual property like copyrighted material rights.\nWeb-scraping should not cause undue load on the website’s server or disrupt its performance. It limits the rate at which requests are made to the website’s server.\n\nReferences:\n\nwebsite’s terms of use and robots.txt: https://developers.google.com/search/docs/crawling-indexing/robots/intro and https://techcrunch.com/2022/04/18/web-scraping-legal-court/?guccounter=1\nData privacy laws and web scraping: https://www.fieldfisher.com/en/services/privacy-security-and-information/privacy-security-and-information-law-blog/data-scraping-considering-the-privacy-issues\nLimit request rate: https://blog.cloudflare.com/advanced-rate-limiting/\n\n\nWhat is a ROBOTS.TXT file? Identify one instance and explain what it allows/prevents.\n\nSolution: A robots.txt file is placed on a website’s server, instructing web crawlers how to crawl and index its pages. It is a plain text file specifying which parts of the website the web crawlers are allowed or not to access.\nAn example of a robots.txt file looks like this:\nUser-agent: *\nDisallow: /wp-admin/\nAllow: /wp-admin/admin-ajax.php\nReferences: Check for the complete robots.txt: https://kinsta.com/robots.txt\nThe User-agent: * line indicates what rules apply to all web-crawler. The Disallow lines specify directories or pages not to be accessed by the bots, while Allow lines allow the bot to access pages or directories by it.\nThis Disallow help to prevent the bot from crawling a page with sensitive information.\n\nIdentify a website that you would like to scrape (or one an example from class) and implement a scrape using the polite package.\n\nSolution: We are doing web-scrape for Active Civil Service List data, which consists of all candidate which passed the exam.\nhttps://data.cityofnewyork.us/City-Government/Civil-Service-List-Active-/vx8i-nprf\n\nlibrary(polite)\nlibrary(rvest)\nlibrary(httr)\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(ggplot2)\n\npolite_GET <- politely(httr::GET,verbose = TRUE)\nres <- polite_GET(\"https://data.cityofnewyork.us/resource/vx8i-nprf.json\")\n\nFetching robots.txt\n\n\nrt_robotstxt_http_getter: normal http get\n\n\n\nNew copy robots.txt was fetched from https://data.cityofnewyork.us/robots.txt\n\n\nTotal of 1 crawl delay rule(s) defined for this host.\n\n\nYour rate will be set to 1 request every 5 second(s).\n\n\nPausing... \n\n\nScraping: https://data.cityofnewyork.us/resource/vx8i-nprf.json\n\n\nSetting useragent: polite R (4.2.1 x86_64-pc-linux-gnu x86_64 linux-gnu) bot\n\n#res\ndf <- jsonlite::fromJSON(rawToChar(res$content))\nhead(df)\n\n  exam_no list_no first_name last_name adj_fa list_title_code\n1    0162 875.000    JENELLE    FRASER  78.00           10001\n2    0162 876.000        AML  METRYOSE  78.00           10001\n3    0162 877.000    YAHAIRA   ALMONTE  78.00           10001\n4    0162 878.000    CHI SUN      CHOW  77.00           10001\n5    0162 879.000     RACHEL    CANCEL  77.00           10001\n6    0162 880.000    FARHANA     AKTER  76.00           10001\n            list_title_desc group_no list_agency_code list_agency_desc\n1 ADMINISTRATIVE ACCOUNTANT      000              000 OPEN COMPETITIVE\n2 ADMINISTRATIVE ACCOUNTANT      000              000 OPEN COMPETITIVE\n3 ADMINISTRATIVE ACCOUNTANT      000              000 OPEN COMPETITIVE\n4 ADMINISTRATIVE ACCOUNTANT      000              000 OPEN COMPETITIVE\n5 ADMINISTRATIVE ACCOUNTANT      000              000 OPEN COMPETITIVE\n6 ADMINISTRATIVE ACCOUNTANT      000              000 OPEN COMPETITIVE\n           published_date        established_date        anniversary_date   mi\n1 2021-05-26T00:00:00.000 2021-07-28T00:00:00.000 2025-07-28T00:00:00.000 <NA>\n2 2021-05-26T00:00:00.000 2021-07-28T00:00:00.000 2025-07-28T00:00:00.000    T\n3 2021-05-26T00:00:00.000 2021-07-28T00:00:00.000 2025-07-28T00:00:00.000 <NA>\n4 2021-05-26T00:00:00.000 2021-07-28T00:00:00.000 2025-07-28T00:00:00.000 <NA>\n5 2021-05-26T00:00:00.000 2021-07-28T00:00:00.000 2025-07-28T00:00:00.000 <NA>\n6 2021-05-26T00:00:00.000 2021-07-28T00:00:00.000 2025-07-28T00:00:00.000 <NA>\n  veteran_credit sibling_lgy_credit\n1           <NA>               <NA>\n2           <NA>               <NA>\n3           <NA>               <NA>\n4           <NA>               <NA>\n5           <NA>               <NA>\n6           <NA>               <NA>\n\n\nTotal Candidate passed for different agency\n\ndf_grouped <- df %>%\n  group_by(list_agency_desc) %>%\n  summarize(total_person = n())\n\ndf_grouped\n\n# A tibble: 9 × 2\n  list_agency_desc                       total_person\n  <chr>                                         <int>\n1 ADMINISTRATION FOR CHILDREN'S SERVICES            2\n2 DEPARTMENT OF CITY PLANNING                       1\n3 DEPARTMENT OF EDUCATION                          25\n4 HRA/DEPARTMENT OF SOCIAL SERVICES                 4\n5 NYC EMPLOYEES' RETIREMENT SYSTEM                  5\n6 OFFICE OF THE COMPTROLLER                        19\n7 OPEN COMPETITIVE                                932\n8 POLICE DEPARTMENT                                 9\n9 TEACHERS' RETIREMENT SYSTEM                       3\n\n\nInstructions:\nSubmit to your repo. Make sure that all of the github actions pass (check menu item Actions - all of the actions should have green checks)"
  },
  {
    "objectID": "blog-2023/Blog-10-submissions/anyeshar/index.html",
    "href": "blog-2023/Blog-10-submissions/anyeshar/index.html",
    "title": "Web scraping Blog.",
    "section": "",
    "text": "With great power comes great responsibility - a large part of the web is based on data and services that scrape those data. Now that we start to apply scraping mechanisms, we need to think about how to apply those skills without becoming a burden to the internet society.\nFind sources on ethical web scraping - some readings that might help you get started with that are:\n\nJames Densmore\nR package polite\nJAMI @ EMPIRICAL\n\nAfter reading through some of the ethics essays write a blog post addressing the following questions:\n\nWhat are your main three takeaways for ethical web scraping? - Give examples, or cite your sources. One thing that comes up often is that if the site has an API, it is important to use that instead of scraping. (Ethics in Web Scraping and A Guide to Ethical Web Scraping). Also, it is important to not use too much data, or do it during less busy times. We also want to follow the terms and conditions rules, and ask for premission if it is not specified. (A Guide to Ethical Web Scraping)\nWhat is a ROBOTS.TXT file? Identify one instance and explain what it allows/prevents. A ROBOTS.TXT file is what tells the web crawling software where it is allowed on the website. I think an example of this would be if Google had a link to a website that had information on particular people in a study. Maybe they had a file with user names and the robots.txt file would say that the web crawler could not access that folder with the user names.\nIdentify a website that you would like to scrape (or one an example from class) and implement a scrape using the polite package. I think it would be interesting to web scrape Goodreads. It is a website that has book titles, authors and ratings.\n\nInstructions:\nSubmit to your repo. Make sure that all of the github actions pass (check menu item Actions - all of the actions should have green checks)"
  },
  {
    "objectID": "blog-2023/Blog-10-submissions/Landon-Getting/index.html",
    "href": "blog-2023/Blog-10-submissions/Landon-Getting/index.html",
    "title": "Being kind to Wikipedia",
    "section": "",
    "text": "With great power comes great responsibility - a large part of the web is based on data and services that scrape those data. Now that we start to apply scraping mechanisms, we need to think about how to apply those skills without becoming a burden to the internet society.\nFind sources on ethical web scraping - some readings that might help you get started with that are:\n\nJames Densmore\nR package polite\nJAMI @ EMPIRICAL\n\nAfter reading through some of the ethics essays write a blog post addressing the following questions:\n\nWhat are your main three takeaways for ethical web scraping? - Give examples, or cite your sources.\nPrior to the reading, I was not aware of User Agent strings or robot.txt files. I think these two concepts, along with public APIs, are important to understand as an ethical web scraper. Despite using packages like rvest and Python’s Beautiful Soup in the past, I had never encountered the need for a User Agent string or interaction with a robots.txt file. James Densmore did a great job outlining these topics in his towardsdatascience article. If everyone introduced themselves to the site owners via a User Agent string, checked what the house rules were via the robot.txt file, and utilized public API’s when available, site owners might be less likely to dissuade scrapping.\nWhat is a ROBOTS.TXT file? Identify one instance and explain what it allows/prevents.\nThe ROBOT.txt can prevent scrappers from accessing data whether that is a web page, media file, or resource files. In a informative article by Google, the search giant explains how website owners use robot.txt to indicate which URLs they would like crawled by Google and to avoid too much traffic.\nIdentify a website that you would like to scrape (or one an example from class) and implement a scrape using the polite package.\nI utilized the polite package to scrap information on notable table tennis players from Wikipedia.\n\nFirst, I started by using bow() to introduce myself to the page.\n\nlibrary(polite)\nlibrary(rvest)\n\nsession <- bow(\"https://en.wikipedia.org/wiki/Table_tennis\")\n\nNext, I let the scrape() function know that I had properly introduced myself and passed the result to html_nodes() to get the table I was looking for by specifying the class. I passed the html to the html_table() function to nicely parse it into appealing R terms for me. Finally, I printed my object and reflected on how much I like Wikipedia.\n\nresult <- scrape(session) |>\n  html_nodes(\".wikitable\") |>\n  html_table()\n\nresult\n\n[[1]]\n# A tibble: 11 × 7\n   Name            Gender Nationality `Times won`    `Times won`   Times…¹ ``   \n   <chr>           <chr>  <chr>       <chr>          <chr>         <chr>   <chr>\n 1 Name            Gender Nationality Olympics       World Champi… World … \"\"   \n 2 Jan-Ove Waldner Male   Sweden      1 (1992)       2 (1989, 199… 1 (199… \"[76…\n 3 Deng Yaping     Female China       2 (1992, 1996) 3 (1991, 199… 1 (199… \"[77…\n 4 Liu Guoliang    Male   China       1 (1996)       1 (1999)      1 (199… \"[78…\n 5 Wang Nan        Female China       1 (2000)       3 (1999, 200… 4 (199… \"[79…\n 6 Kong Linghui    Male   China       1 (2000)       1 (1995)      1 (199… \"[80…\n 7 Zhang Yining    Female China       2 (2004, 2008) 2 (2005, 200… 4 (200… \"[81…\n 8 Zhang Jike      Male   China       1 (2012)       2 (2011, 201… 2 (201… \"[82…\n 9 Li Xiaoxia      Female China       1 (2012)       1 (2013)      1 (200… \"[83…\n10 Ding Ning       Female China       1 (2016)       3 (2011, 201… 2 (201… \"[84…\n11 Ma Long         Male   China       2 (2016, 2020) 3 (2015, 201… 2 (201…  <NA>\n# … with abbreviated variable name ¹​`Times won`"
  },
  {
    "objectID": "blog-2023/Blog-10-submissions/Hiiiua/index.html",
    "href": "blog-2023/Blog-10-submissions/Hiiiua/index.html",
    "title": "Web scraping etiquette …",
    "section": "",
    "text": "With great power comes great responsibility - a large part of the web is based on data and services that scrape those data. Now that we start to apply scraping mechanisms, we need to think about how to apply those skills without becoming a burden to the internet society.\nFind sources on ethical web scraping - some readings that might help you get started with that are:\n\nJames Densmore\nR package polite\nJAMI @ EMPIRICAL\n\nAfter reading through some of the ethics essays write a blog post addressing the following questions:\n\nWhat are your main three takeaways for ethical web scraping? - Give examples, or cite your sources.\n\nMy takeaways are from both side: being respectful and grateful when scraping, and being open to ethical scrapers when being an owner.\nTo me, scraping is like making a cold call: it takes two to make the deal. Visitors should leave the customer alone if there’s a “No soliciting”. If no such a sign, visitors need to knock on the door before getting in. After getting in, visitors are responsible for identifying themselves, following the instructions from the owner, being polite, and saying thanks before leaving. These correspond to access APIs if there’s any, reasonably request data, respect rules and data, showing gratitude.\nOn the other hand, the owner can make rules or signs to avoid confusion. If the owner decides to start a conversation, respecting the visitors’ follow rules, explain why he needs the visitors to leave if there’s any situation. These correspond to considering public APIs, allowing ethical scrapers, and reaching out to scrapers before blocking.\n\nWhat is a ROBOTS.TXT file? Identify one instance and explain what it allows/prevents.\nA robots.txt file tells scrappers which URLs can be accessed. Here’s a line of robots.txt.\n\nUser-agent: Googlebot\nDisallow: /nogooglebot/\n\n\nThe user agent named Googlebot is not allowed to crawl any URL that starts with https://example.com/nogooglebot/.\n\nUser-agent: *\nAllow: /\n\nAbove lines mean all user agent are allowed to crawl the entire site.\nIdentify a website that you would like to scrape (or one an example from class) and implement a scrape using the polite package.\n\nlibrary(polite)\nlibrary(rvest)\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nurl <- \"https://en.wikipedia.org/wiki/AFC_Asian_Cup_records_and_statistics\"\nsession <- bow(url, user_agent = \"hiiiua blog-10 assignment\")\n\nsection <- scrape(session) %>% html_nodes(\"#mw-content-text > div.mw-parser-output > table:nth-child(5)\")\n\nsection %>% html_table()\n\n[[1]]\n# A tibble: 19 × 6\n    Year `Host(s)`                           Winners     Winni…¹ Top s…² Best …³\n   <int> <chr>                               <chr>       <chr>   <chr>   <chr>  \n 1  1956 Hong Kong                           South Korea Kim Su… Nahum … —      \n 2  1960 South Korea                         South Korea Kim Yo… Cho Yo… —      \n 3  1964 Israel                              Israel      Yosef … Inder … —      \n 4  1968 Iran                                Iran        Mahmou… Homayo… —      \n 5  1972 Thailand                            Iran        Mohamm… Hossei… Ebrahi…\n 6  1976 Iran                                Iran        Heshma… Gholam… Ali Pa…\n 7  1980 Kuwait                              Kuwait      Carlos… Behtas… —      \n 8  1984 Singapore                           Saudi Arab… Khalil… Jia Xi… Jia Xi…\n 9  1988 Qatar                               Saudi Arab… Carlos… Lee Ta… Kim Jo…\n10  1992 Japan                               Japan       Hans O… Fahad … Kazuyo…\n11  1996 United Arab Emirates                Saudi Arab… Nelo V… Ali Da… Khodad…\n12  2000 Lebanon                             Japan       Philip… Lee Do… Hirosh…\n13  2004 China                               Japan       Zico    A'ala … Shunsu…\n14  2007 Indonesia Malaysia Thailand Vietnam Iraq        Jorvan… Younis… Younis…\n15  2011 Qatar                               Japan       Albert… Koo Ja… Keisuk…\n16  2015 Australia                           Australia   Ange P… Ali Ma… Massim…\n17  2019 United Arab Emirates                Qatar       Félix … Almoez… Almoez…\n18  2023 Qatar                               TBD         TBD     TBD     TBD    \n19  2027 Saudi Arabia                        TBD         TBD     TBD     TBD    \n# … with abbreviated variable names ¹​`Winning coach`, ²​`Top scorer(s) (goals)`,\n#   ³​`Best player award`\n\n\nInstructions:\nSubmit to your repo. Make sure that all of the github actions pass (check menu item Actions - all of the actions should have green checks)"
  },
  {
    "objectID": "blog-2023/Blog-10-submissions/TWiedRW/index.html",
    "href": "blog-2023/Blog-10-submissions/TWiedRW/index.html",
    "title": "Web scraping etiquette …",
    "section": "",
    "text": "With great power comes great responsibility - a large part of the web is based on data and services that scrape those data. Now that we start to apply scraping mechanisms, we need to think about how to apply those skills without becoming a burden to the internet society.\nFind sources on ethical web scraping - some readings that might help you get started with that are:\n\nJames Densmore\nR package polite\nJAMI @ EMPIRICAL\n\nAfter reading through some of the ethics essays write a blog post addressing the following questions:\n\nWhat are your main three takeaways for ethical web scraping? - Give examples, or cite your sources.\nWhat is a ROBOTS.TXT file? Identify one instance and explain what it allows/prevents.\nIdentify a website that you would like to scrape (or one an example from class) and implement a scrape using the polite package.\n\nInstructions:\nSubmit to your repo. Make sure that all of the github actions pass (check menu item Actions - all of the actions should have green checks)"
  },
  {
    "objectID": "blog-2023/Blog-10-submissions/charchit/index.html",
    "href": "blog-2023/Blog-10-submissions/charchit/index.html",
    "title": "Web scraping",
    "section": "",
    "text": "The json schema for this blog is different in the announcement than the schema on the github. Let me know if you want me to change it."
  },
  {
    "objectID": "blog-2023/Blog-10-submissions/charchit/index.html#prompt",
    "href": "blog-2023/Blog-10-submissions/charchit/index.html#prompt",
    "title": "Web scraping",
    "section": "Prompt:",
    "text": "Prompt:\nWith great power comes great responsibility - a large part of the web is based on data and services that scrape those data. Now that we start to apply scraping mechanisms, we need to think about how to apply those skills without becoming a burden to the internet society.\nFind sources on ethical web scraping - some readings that might help you get started with that are:\n\nJames Densmore\nR package polite\nJAMI @ EMPIRICAL\n\nAfter reading through some of the ethics essays write a blog post addressing the following questions:\n\nWhat are your main three takeaways for ethical web scraping? - Give examples, or cite your sources.\n\nMy main takeaways from the ethical web scraping is that it takes resources to build and maintain website and we should respect the robot.txt file and their terms of services.\nBow and scrape: Basically we should also obtain consent if we are going to use their content and give them the credit.\nIt would be nice to provide some value in return if we can. Also, we should respect the data privacy and try to use only the content which is necessary for the work or hobby we are doing. Anything else is best to be not stored on our computer.\n\nWhat is a ROBOTS.TXT file? Identify one instance and explain what it allows/prevents.\n\nRobot.txt file is use to instruct the web robot how to crawl (find stuff on) the web. It communicate what parts of the site are accessible and what actions are allowed. It is usually at the root of a website.\nBelow is the example from gooogle search central:\n” User-agent: Googlebot Disallow: /nogooglebot/\nUser-agent: * Allow: /\nSitemap: https://www.example.com/sitemap.xml ”\nThe above file is stopping an agent named “Googlebot” to crawl any URL that starts with xyz.com/nogooglebot/ but everyone else is allowed.\nRobots.txt is usually a guideline and some users do not seem to follow that online.\n\nIdentify a website that you would like to scrape (or one an example from class) and implement a scrape using the polite package.\n\nFirst example is just from the second link of this rmd file as a first try for this blog.\n\nlibrary(polite)\nlibrary(rvest)\nsession <- bow(\"https://www.cheese.com/by_type\", force = TRUE)\nresult <- scrape(session, query=list(t=\"semi-soft\", per_page=100)) %>%\n  html_node(\"#main-body\") %>% \n  html_nodes(\"h3\") %>% \n  html_text()\nhead(result)\n\n[1] \"3-Cheese Italian Blend\"  \"Abbaye de Citeaux\"      \n[3] \"Abbaye du Mont des Cats\" \"Adelost\"                \n[5] \"ADL Brick Cheese\"        \"Ailsa Craig\"            \n\n\n\nlibrary(janitor)\n\n\nAttaching package: 'janitor'\n\n\nThe following objects are masked from 'package:stats':\n\n    chisq.test, fisher.test\n\nsession <- bow(\"https://en.wikipedia.org/wiki/List_of_national_independence_days\", force = TRUE)\nind_html <-\n  polite::scrape(session) %>%\n  rvest::html_nodes(\"table.wikitable\") %>% \n  rvest::html_table(fill = TRUE)\n\nind_tab <- \n  ind_html[[1]] %>% \n  clean_names()\nind_tab\n\n# A tibble: 202 × 6\n   country             name_of_holiday           date_…¹ year_…² indep…³ event…⁴\n   <chr>               <chr>                     <chr>   <chr>   <chr>   <chr>  \n 1 Afghanistan         Afghan Independence Day … 19 Aug… 1919    United… \"Anglo…\n 2 Albania             Flag Day (Dita e Flamuri… 28 Nov… 1912    Ottoma… \"Alban…\n 3 Algeria             Independence Day          5 July  1962    France  \"Alger…\n 4 Angola              Independence Day          11 Nov… 1975    Portug… \"The A…\n 5 Antigua and Barbuda Independence Day          1 Nove… 1981    United… \"The e…\n 6 Argentina           Independence Day          9 July  1816[8] Spanis… \"Argen…\n 7 Armenia             Republic Day              28 May  1918[9] Russia… \"Decla…\n 8 Armenia             Independence Day          21 Sep… 1991    Soviet… \"1991 …\n 9 Azerbaijan          Independence Day          28 May  1918    Russia… \"Decla…\n10 Azerbaijan          Independendence Restorat… 18 Oct… 1991[1… Soviet… \"Adopt…\n# … with 192 more rows, and abbreviated variable names ¹​date_of_holiday,\n#   ²​year_of_event, ³​independence_from, ⁴​event_commemorated_and_notes\n\n\nInstructions:\nSubmit to your repo. Make sure that all of the github actions pass (check menu item Actions - all of the actions should have green checks)"
  },
  {
    "objectID": "blog-2023/Blog-10-submissions/kellynay/index.html",
    "href": "blog-2023/Blog-10-submissions/kellynay/index.html",
    "title": "Reflections on Ethical Web Scraping",
    "section": "",
    "text": "With great power comes great responsibility - a large part of the web is based on data and services that scrape those data. Now that we start to apply scraping mechanisms, we need to think about how to apply those skills without becoming a burden to the internet society.\nFind sources on ethical web scraping - some readings that might help you get started with that are:\n\nJames Densmore\nR package polite\nJAMI @ EMPIRICAL\n\nAfter reading through some of the ethics essays write a blog post addressing the following questions:\n\nWhat are your main three takeaways for ethical web scraping? - Give examples, or cite your sources.\n\n\nEthics and law regarding web data scraping are not same thing and each of them have their own complexity and level of importance as stated by James Densmore, 2017.Another important point brought up is that people scraping data and those providing data have not agreed on basic principles of ethical web scrapping.\nA common point on both articles from James Densmore and JAMI @ EMPIRICAL is that if a data source has an API, we should definitely use it because then we will avoid scraping and will gather the data according to the publisher’s rules.\nReturn value to data owners from where we scrape information from is another ethical principle and we can do so by referencing where the data came from, so their website can receive some traffic. We can also recognize website’s value by citing them in articles or posts.\n\n\nWhat is a ROBOTS.TXT file? Identify one instance and explain what it allows/prevents.\n\n\nThey are part of the Robots Exclusion Protocol (REP) and they regulate what is allowed or not when conducting data web scrapping. This text file provides instructions for search engine robots how to scrape and index pages on websites.\nExample: Blocking a folder. In some cases, website owners want to block a certain area of the website and give access to the rest. To do so, website owners create a admin area allowing only admins with a login to make content changes on their page. They do not want bots looking into this admin folder, so they block it by doing:\n  User-agent: *\n  Disallow: /admin/\nBy doing this, the bots will not access the admin folder.\nSource: https://pagedart.com/blog/robots-txt-file-example/\n\n\nIdentify a website that you would like to scrape (or one an example from class) and implement a scrape using the polite package.\n\n\n# Types of cheese from Brazil\nlibrary(polite)\nlibrary(rvest)\n\nsession <- bow(\"https://www.cheese.com/by_country/?per_page=20&c=BR#top\", force = TRUE)\nresult <- scrape(session, query=list(t=\"Brazil\", per_page=20)) %>%\n  html_node(\"#main-body\") %>% \n  html_nodes(\"h3\") %>% \n  html_text()\nresult\n\n[1] \"Canastra cheese\" \"Catupiry\"        \"Coalho\"          \"Colony cheese\"  \n[5] \"Minas cheese\"    \"Queijo do serro\" \"Requeson\""
  },
  {
    "objectID": "blog-2023/Blog-10-submissions/drbradford12/index.html",
    "href": "blog-2023/Blog-10-submissions/drbradford12/index.html",
    "title": "Web scraping etiquette …",
    "section": "",
    "text": "With great power comes great responsibility - a large part of the web is based on data and services that scrape those data. Now that we start to apply scraping mechanisms, we need to think about how to apply those skills without becoming a burden to the internet society.\nFind sources on ethical web scraping - some readings that might help you get started with that are:\n\nJames Densmore\nR package polite\nJAMI @ EMPIRICAL\n\nAfter reading through some of the ethics essays write a blog post addressing the following questions:\n\nWhat are your main three takeaways for ethical web scraping? - Give examples, or cite your sources.\nWhat is a ROBOTS.TXT file? Identify one instance and explain what it allows/prevents.\nIdentify a website that you would like to scrape (or one an example from class) and implement a scrape using the polite package.\n\nInstructions:\nSubmit to your repo. Make sure that all of the github actions pass (check menu item Actions - all of the actions should have green checks)"
  },
  {
    "objectID": "blog-2023/Blog-10-submissions/HarunCelikOtto/index.html",
    "href": "blog-2023/Blog-10-submissions/HarunCelikOtto/index.html",
    "title": "Web Scraping",
    "section": "",
    "text": "With great power comes great responsibility - a large part of the web is based on data and services that scrape those data. Now that we start to apply scraping mechanisms, we need to think about how to apply those skills without becoming a burden to the internet society.\nFind sources on ethical web scraping - some readings that might help you get started with that are:\n\nJames Densmore\nR package polite\nJAMI @ EMPIRICAL\n\nAfter reading through some of the ethics essays write a blog post addressing the following questions:\n\nWhat are your main three takeaways for ethical web scraping? - Give examples, or cite your sources.\n\n\nBoth readings discussed the importance of using an API first. I had thought of this from the side of the scraper but rarely from the side of the page owner and found it useful to be thinking about as I go on developing tools. I’m convinced that with any online platform that I would like to host should have a more serious contemplation about the development of APIs for public or quasi-public access.\nThe topic of identification was also interesting since I’ve mostly used APIs that used keys instead of direct pulls off the web. While I’ve asked for personal permission and cited the material I took from a web-scraping portion of a project, I don’t recall adding my name and information for the person to keep record of in the future. I’ll certainly be more mindful of it now.\nMy third takeaway, which is less direct, relates to the approach of the authors in these articles. They say the word ‘ethics’ but what they really describe are scraping etiquette. I think deeper engagement with the ethics of scraping is necessary so that guiding principles can uniformly be set in place. While I found the blogs to be useful, I am still left with questions about the moral systems behind scraping and how these values could shape the future of scraping practice and legality.\n\n\nWhat is a ROBOTS.TXT file? Identify one instance and explain what it allows/prevents.\n\n\nThe purpose of a ROBOTS.TXT file is to help guide incoming web traffic by directing search engine crawlers to access particular portions of your webpage. An example that I can think of might be that if you run a page which has a news feed but also a section where users are directed to a log-in portal, you would want the log-in portal to be protected from unnecessary traffic to lessen any security risks.\n\n\nIdentify a website that you would like to scrape (or one an example from class) and implement a scrape using the polite package.\n\n\nI had ambitions to build a systematic scraping method for users with access to the Historical Statistics of the United States Online Edition but didn’t do nearly as well as I thought I would. Instead, I’ll demonstrate a polite scrape with a different objective. I would like to know all the popular packages that Dr. Hofmann is working on! I want to perform a scrape that gives me just their names.\n\n\nlibrary(rvest)\nlibrary(polite)\n\n\nsession <-bow(\"https://github.com/heike\", user_agent = \"Student from STAT 585 course at ISU\")\nresult <- scrape(session) %>%\n  html_elements(\".repo\") %>% \n  html_text\n\n\n# These are Dr. Hofmann's current popular packages:\ncat(result)\n\nggparallel gglogo stat590f ggmapr rotations ggpcp\n\n\nInstructions:\nSubmit to your repo. Make sure that all of the github actions pass (check menu item Actions - all of the actions should have green checks)"
  },
  {
    "objectID": "blog-2023/Blog-10-submissions/valeriehan6/index.html",
    "href": "blog-2023/Blog-10-submissions/valeriehan6/index.html",
    "title": "Web scraping etiquette …",
    "section": "",
    "text": "With great power comes great responsibility - a large part of the web is based on data and services that scrape those data. Now that we start to apply scraping mechanisms, we need to think about how to apply those skills without becoming a burden to the internet society.\nFind sources on ethical web scraping - some readings that might help you get started with that are:\n\nJames Densmore\nR package polite\nJAMI @ EMPIRICAL\n\nAfter reading through some of the ethics essays write a blog post addressing the following questions:\n\nWhat are your main three takeaways for ethical web scraping? - Give examples, or cite your sources.\n\nMy main takeaways are James Densmore and JAMI @ EMPIRICAL. In general, try to be kind to one another. Don’t harm the website you’re scraping. 1) Respect the website’s guidelines: use a public API instead if available, respect the robots.txt file if the website has one, and respect the terms and conditions of the site. 2) Give credit where it’s due: if you scrape data and write something about it, make sure to credit the source of the data. 3) Don’t overload the site: space out requests and try to send requests during off-peak hours.\n\nWhat is a ROBOTS.TXT file? Identify one instance and explain what it allows/prevents.\n\nA robots.txt file tells the web-crawling software where it is allowed to go on the website (JAMI @ EMPIRICAL). For example, websites can use it to tell search engines like Google which pages should be crawled to understand the website and what search results it should appear in Introduction to robots.txt. Note that while the robots.txt file tells web crawlers where they are allowed to go, they don’t actually enforce those rules themselves.\n\nIdentify a website that you would like to scrape (or one an example from class) and implement a scrape using the polite package.\n\nI scraped from https://www.nytimes.com/elections/2016/results/massachusetts.\n\nlibrary(polite)\nlibrary(rvest)\n\n\n# similar to example from class\nurl <- \"https://www.nytimes.com/elections/2016/results/massachusetts\"\nsession <- bow(url)\nhtml <- scrape(session)\ntables <- html %>% html_table()\n\n# tables %>% purrr::map(.f = pillar::glimpse)\n\nma_results <- tables[[2]] %>% dplyr::mutate(\n  Trump  = readr::parse_number(Trump),\n  Clinton = readr::parse_number(Clinton)\n)\nma_results\n\n# A tibble: 351 × 3\n   `Vote by town` Clinton Trump\n   <chr>            <dbl> <dbl>\n 1 Boston          221093 38087\n 2 Worcester        43084 17732\n 3 Springfield      40341 11231\n 4 Cambridge        46563  3323\n 5 Newton           36463  7764\n 6 Quincy           25477 13321\n 7 Somerville       33740  4128\n 8 Lowell           23555 10584\n 9 Brockton         25593  8801\n10 Lynn             22164  9311\n# … with 341 more rows\n\n\nInstructions:\nSubmit to your repo. Make sure that all of the github actions pass (check menu item Actions - all of the actions should have green checks)"
  },
  {
    "objectID": "blog-2023/Blog-10-submissions/IanParzyszek/index.html",
    "href": "blog-2023/Blog-10-submissions/IanParzyszek/index.html",
    "title": "Web scraping etiquette …",
    "section": "",
    "text": "With great power comes great responsibility - a large part of the web is based on data and services that scrape those data. Now that we start to apply scraping mechanisms, we need to think about how to apply those skills without becoming a burden to the internet society.\nFind sources on ethical web scraping - some readings that might help you get started with that are:\n\nJames Densmore\nR package polite\nJAMI @ EMPIRICAL\n\nAfter reading through some of the ethics essays write a blog post addressing the following questions:\n\nWhat are your main three takeaways for ethical web scraping? - Give examples, or cite your sources.\n\nOne of the first things I was unaware of was that webscraping can be a burden on the server. I did not think it was anymore cumbersome for the server than just visiting the website, but because this is not the case good practice is to conduct scraping during non-busy times.\nAnother good practice is to identify yourself. The websites owner may see some unusual activity, so it can be a good idea to give a string in your code to identify yourself, and maybe also let them know your intentions.\nLastly, you should give back to the website owner and give them credit. If you are using their data, cite their website/article. This will help give their website some more traffic.\nI got these takeaways from :JAMI @ EMPIRICAL\n\nWhat is a ROBOTS.TXT file? Identify one instance and explain what it allows/prevents.\n\nA ROBOTS.TXT files is put in place to put limitations on what crawlers can access on their website. An example would be including a ROBOTS.TXT file to limit the amount of information a search engine can search on your website and include in their results. Sometimes you may want GOOGLE to avoid including PDFs or pictures, so you could include a ROBOTS.TXT file to prevent this.\n\nIdentify a website that you would like to scrape (or one an example from class) and implement a scrape using the polite package.\n\nInstructions:\nSubmit to your repo. Make sure that all of the github actions pass (check menu item Actions - all of the actions should have green checks)\n\nlibrary(polite)\nlibrary(rvest)\nsession <-  bow(\"https://www.avca.org/polls/diii-men/2023/03-28-23.html\")\nscrape(session) %>%\n  html_table()\n\nNo encoding supplied: defaulting to UTF-8.\n\n\n[[1]]\n# A tibble: 15 × 5\n   Rank  `School (First-Place Votes Adjusted)` Total Points Adj…¹ Record Previ…²\n   <chr> <chr>                                              <int> <chr>    <int>\n 1 1     Stevens [20]                                         342 26-2         1\n 2 2     Vassar [3]                                           325 17-1         2\n 3 3     Juniata                                              294 22-2         3\n 4 4     Springfield                                          276 20-2         4\n 5 5     Messiah                                              251 20-2         5\n 6 6     North Central (IL)                                   217 18-3         7\n 7 T-7   NYU                                                  171 12-6         9\n 8 T-7   SUNY New Paltz                                       171 18-8        11\n 9 9     Carthage                                             168 14-5         6\n10 10    Southern Virginia                                    167 13-2        10\n11 11    St John Fisher                                       135 19-6         8\n12 12    Wentworth                                             64 18-6        13\n13 13    Nazareth                                              58 20-5        14\n14 14    Marymount                                             56 17-5        12\n15 15    Rutgers-Newark                                        31 11-5        15\n# … with abbreviated variable names ¹​`Total Points Adjusted`, ²​`Previous Rank`\n\n#Here is the Division 3 Men's Volleyball National Rankings...Messiah University is ranked 5! Go Falcons!!!!!"
  },
  {
    "objectID": "blog-2023/Blog-10-submissions/loganjohnson0/index.html",
    "href": "blog-2023/Blog-10-submissions/loganjohnson0/index.html",
    "title": "Web scraping etiquette …",
    "section": "",
    "text": "With great power comes great responsibility - a large part of the web is based on data and services that scrape those data. Now that we start to apply scraping mechanisms, we need to think about how to apply those skills without becoming a burden to the internet society.\nFind sources on ethical web scraping - some readings that might help you get started with that are:\n\nJames Densmore\nR package polite\nJAMI @ EMPIRICAL\n\nAfter reading through some of the ethics essays write a blog post addressing the following questions:\n\nWhat are your main three takeaways for ethical web scraping? - Give examples, or cite your sources.\nWhat is a ROBOTS.TXT file? Identify one instance and explain what it allows/prevents.\nIdentify a website that you would like to scrape (or one an example from class) and implement a scrape using the polite package.\n\nInstructions:\nSubmit to your repo. Make sure that all of the github actions pass (check menu item Actions - all of the actions should have green checks)"
  },
  {
    "objectID": "blog-2023/Blog-10-submissions/Atefeha1995/index.html",
    "href": "blog-2023/Blog-10-submissions/Atefeha1995/index.html",
    "title": "Web scraping etiquette …",
    "section": "",
    "text": "With great power comes great responsibility - a large part of the web is based on data and services that scrape those data. Now that we start to apply scraping mechanisms, we need to think about how to apply those skills without becoming a burden to the internet society.\nFind sources on ethical web scraping - some readings that might help you get started with that are:\n\nJames Densmore\nR package polite\nJAMI @ EMPIRICAL\n\nAfter reading through some of the ethics essays write a blog post addressing the following questions:\n\nWhat are your main three takeaways for ethical web scraping? - Give examples, or cite your sources.\n\nFrom my perspective, the following are some key considerations for ethical online scraping:\n\nRespect the terms of service of the website: It’s crucial to check the terms of service of any website before scraping to make sure that scraping is permitted. Some websites may expressly forbid scraping or demand that you get consent before doing so.\nAvoid interfering with how the website functions: You shouldn’t disrupt or harm the website in any manner with your scraping activity. This includes not sending too many requests to the site’s servers or doing the scrapping process during non-peak hours.\nAvoid scraping sensitive data, such as personal identifying information, financial information, or health information, to protect people’s privacy.\n\nBeing respectful of the websites you are scraping and the people or organizations whose data you are gathering is, in general, a requirement for ethical web scraping. It is crucial to be open and honest about your objectives and to abstain from any behavior that can endanger the website or specific people.\n\nWhat is a ROBOTS.TXT file? Identify one instance and explain what it allows/prevents.\n\nA robots.txt file, found at the root of a website, tells web robots whether pages or parts of the website should be crawled. It is a plain text file that is open to the public and offers instructions for web robots.\nFor example, suppose a website contains sensitive information that should not be available to search engines, including financial data or users’ personal information. In that case, the website owner can make a robots.txt file and include a directive to forbid search engines from accessing that part. For instance, if the robots.txt file has the directive \"Disallow: /sensitive-data/,\" search engine bots won’t be able to crawl the “sensitive-data” part of the website.\nBut, a website owner may also utilize the robots.txt file to provide the particular search engine bots access to particular pages or parts of the website. For instance, the robots.txt directive \"Allow: /blog/\" added to the website’s code will let web crawlers access the “/blog/” area.\n\nIdentify a website that you would like to scrape (or one an example from class) and implement a scrape using the polite package.\n\nI used the polite package to scrape a sample website. The base URL of the website was https://www.metacritic.com/ and the specific path I checked was /movie/ponyo. Then I looked for the director of the movie, and I got what I wanted.\n\nlibrary(polite)\nlibrary(rvest)\n\n\nmc_bow <- bow(\n  url = \"https://www.metacritic.com/\",  # base URL\n  user_agent = \"A Anisi\",  # identify ourselves\n  force = TRUE\n)\n\n\nsession <- nod(\n  bow = mc_bow,\n  path = \"/movie/ponyo\"\n)\n\n\nscraped_page <- scrape(session)\n\n\nnode_result <- html_nodes(\n  scraped_page, \n  css = \".director span\"\n)\n\n\ntext_result <- html_text(node_result)\ntext_result\n\n[1] \"Director:\"      \"Hayao Miyazaki\"\n\n\nInstructions:\nSubmit to your repo. Make sure that all of the github actions pass (check menu item Actions - all of the actions should have green checks)"
  },
  {
    "objectID": "blog-2023/Blog-10-submissions/anphan0828/index.html",
    "href": "blog-2023/Blog-10-submissions/anphan0828/index.html",
    "title": "Web scraping etiquette …",
    "section": "",
    "text": "With great power comes great responsibility - a large part of the web is based on data and services that scrape those data. Now that we start to apply scraping mechanisms, we need to think about how to apply those skills without becoming a burden to the internet society.\nFind sources on ethical web scraping - some readings that might help you get started with that are:\n\nJames Densmore\nR package polite\nJAMI @ EMPIRICAL\n\nAfter reading through some of the ethics essays write a blog post addressing the following questions:\n\nWhat are your main three takeaways for ethical web scraping? - Give examples, or cite your sources.\nWhat is a ROBOTS.TXT file? Identify one instance and explain what it allows/prevents.\nIdentify a website that you would like to scrape (or one an example from class) and implement a scrape using the polite package.\n\nInstructions:\nSubmit to your repo. Make sure that all of the github actions pass (check menu item Actions - all of the actions should have green checks)"
  },
  {
    "objectID": "blog-2023/Blog-10-submissions/hardtme/index.html",
    "href": "blog-2023/Blog-10-submissions/hardtme/index.html",
    "title": "Web Scraping Etiquette …",
    "section": "",
    "text": "With great power comes great responsibility - a large part of the web is based on data and services that scrape those data. Now that we start to apply scraping mechanisms, we need to think about how to apply those skills without becoming a burden to the internet society.\nFind sources on ethical web scraping - some readings that might help you get started with that are:\n\nJames Densmore\nR package polite\nJAMI @ EMPIRICAL\n\nAfter reading through some of the ethics essays write a blog post addressing the following questions:\n\nWhat are your main three takeaways for ethical web scraping? - Give examples, or cite your sources.\n\nMy three main ethical web scraping takeaways are:\n\nIf a website has an API, you should collect data via the API instead of scraping the website (James Densmore and JAMI @ EMPIRICAL).\nWhen scraping a website, you should scrape at a rate that doesn’t overload the website’s host servers or get you confused for a DDoS attack on the website (James Densmore and JAMI @ EMPIRICAL).\nYou should only scrape the data that you need and then cite/link back to the website from which you scraped the data (James Densmore and JAMI @ EMPIRICAL).\n\n\nWhat is a ROBOTS.TXT file? Identify one instance and explain what it allows/prevents.\n\nA ROBOTS.TXT file tells web scrapers what parts of a website they are allowed to access, and can disallow access to some (or all) web scrapers altogether. The vignette on polite package website links to the ROBOTS.TXT file for Bob Rudis’s blog. This file includes a crawl delay that ethical web scrapers will observe along with some impressive text art images of a Star Trek space station. It seems that all scraping of the blog is allowed as long as the crawl delay is observed. Conversely, Wikipedia has an extensive ROBOTS.TXT file that disallows many different web crawlers for various reasons, including making too many requests in too short a period of time, being associated with advertising, and more.\n\nIdentify a website that you would like to scrape (or an example from class) and implement a scrape using the polite package.\n\nI will revisit an example from class, but implement the web scrape using the polite package instead of the rvest package. I will scrape the New York Times website to acquire the 2016 election results from Oregon. I chose Oregon because I spent the summer of 2019 participating in a research experience for undergraduates (REU) program at Oregon State University in Corvallis. I will then compare the results to those obtained when we scrape the website using the rvest package.\nFirst, let’s scrape the Oregon election results using the polite package.\n\nlibrary(tidyverse)\nlibrary(polite)\nlibrary(rvest)\n\nor_url <- \"https://www.nytimes.com/elections/2016/results/oregon\"\npolite_session <- bow(or_url, force = T)\nor_scrape <- scrape(polite_session)\n\nor_tables <- or_scrape %>% html_table(fill=TRUE)\nor_tables[[2]]\n\n# A tibble: 36 × 3\n   `Vote by county` Clinton Trump \n   <chr>            <chr>   <chr> \n 1 Multnomah        292,561 67,954\n 2 Washington       153,251 83,197\n 3 Clackamas        102,095 88,392\n 4 Lane             102,753 67,141\n 5 Marion           57,788  63,377\n 6 Jackson          44,447  53,870\n 7 Deschutes        42,444  45,692\n 8 Linn             17,995  33,488\n 9 Douglas          14,096  34,582\n10 Benton           29,193  13,445\n# … with 26 more rows\n\n\nNow let’s compare the results from the polite package to those obtained using the rvest package.\n\nor_html <- read_html(or_url)\nor_tables2 <- or_html %>% html_table(fill=TRUE)\nor_tables2[[2]]\n\n# A tibble: 36 × 3\n   `Vote by county` Clinton Trump \n   <chr>            <chr>   <chr> \n 1 Multnomah        292,561 67,954\n 2 Washington       153,251 83,197\n 3 Clackamas        102,095 88,392\n 4 Lane             102,753 67,141\n 5 Marion           57,788  63,377\n 6 Jackson          44,447  53,870\n 7 Deschutes        42,444  45,692\n 8 Linn             17,995  33,488\n 9 Douglas          14,096  34,582\n10 Benton           29,193  13,445\n# … with 26 more rows\n\nall.equal(or_tables[[2]], or_tables2[[2]])\n\n[1] TRUE\n\n\nThe results from both scraping methods are the same."
  },
  {
    "objectID": "blog-2023/Blog-10-submissions/santos-cl/index.html",
    "href": "blog-2023/Blog-10-submissions/santos-cl/index.html",
    "title": "Web scraping etiquette …",
    "section": "",
    "text": "With great power comes great responsibility - a large part of the web is based on data and services that scrape those data. Now that we start to apply scraping mechanisms, we need to think about how to apply those skills without becoming a burden to the internet society.\nFind sources on ethical web scraping - some readings that might help you get started with that are:\n\nJames Densmore\nR package polite\nJAMI @ EMPIRICAL\n\nAfter reading through some of the ethics essays write a blog post addressing the following questions:\n\nWhat are your main three takeaways for ethical web scraping? - Give examples, or cite your sources.\nWhat is a ROBOTS.TXT file? Identify one instance and explain what it allows/prevents.\nIdentify a website that you would like to scrape (or one an example from class) and implement a scrape using the polite package.\n\nInstructions:\nSubmit to your repo. Make sure that all of the github actions pass (check menu item Actions - all of the actions should have green checks)"
  },
  {
    "objectID": "blog-2023/Blog-10-submissions/santos-cl/index.html#answers",
    "href": "blog-2023/Blog-10-submissions/santos-cl/index.html#answers",
    "title": "Web scraping etiquette …",
    "section": "Answers:",
    "text": "Answers:\n1 - What are your main three takeaways for ethical web scraping? - Give examples, or cite your sources.\nThere are three main takeaways related to ethical web scraping that caught my attention. The first one is to be respectful to the owner of the data one is scraping. For example, the web scraping operation might be very demanding on the server so trying to execute this operation as smoothly as possible would be my first aim. This can be done by minimizing the amount of requests sent to the server. The second aspect that caught my attention was to be also respectful to the human users of the website one is scraping. For example, the idea of web scraping only outside of peak use hours is fascinating to me. It reduces the traffic on the server and also does not interfere with the user experience. The third and last aspect that I thought was extremely interesting was the idea that, if an Application Programming Interface (API) is provided, to avoid web scraping all together. This API will most likely be more equiped to handle large requests than the website front end.\nAn example of how to apply a couple of these principles would be on how to request weather data from NASA POWER. Often I will have to send multiple requests for weather data but it is important to try and minimize the amount of requests. Let us take a look:\nIf we need to iterate over a list of locations for which we need data for multiple years, for example, there are multiple ways to do it, but some of them will be more gentle to the API server. In the following example, we can see how a simple tweak in the code can change the number of requests to the server from 62 to 2.\n\n# renv::init()\n# renv::activate()\n# renv::restore()\nlocations <- data.frame(location_name = c('Ames, IA', 'Fayetteville, AR'),\n                        latitude = c(42, 36),\n                        longitude = c(94, 94))\n\nlocations <- merge(locations, \n                   data.frame(year = 1990:2020))\n\nhead(locations)\n\n     location_name latitude longitude year\n1         Ames, IA       42        94 1990\n2 Fayetteville, AR       36        94 1990\n3         Ames, IA       42        94 1991\n4 Fayetteville, AR       36        94 1991\n5         Ames, IA       42        94 1992\n6 Fayetteville, AR       36        94 1992\n\ndim(locations)\n\n[1] 62  4\n\n\nIf we need the data for each of these locations at each one of these years, one might be inclined to do the following loop:\n\nweather_all <- data.frame()\ntime.start <- Sys.time()\nfor (i in 1:dim(locations)[1]) {\n  \n  dates <- c(sprintf('%1$s-01-01', locations$year[i]),\n             sprintf('%1$s-12-31', locations$year[i]))\n  \n  lonlat <- c(locations$longitude[i], locations$latitude[i])\n  \n  weather_ind <- nasapower::get_power(community = \"AG\", pars = c(\"T2M_MAX\", \n    \"T2M_MIN\", \"ALLSKY_SFC_SW_DWN\", \"PRECTOTCORR\", \"RH2M\", \n    \"WS2M\"), dates = dates, lonlat = lonlat, temporal_api = \"daily\")\n  \n  weather_ind$location_name <- locations$location_name[i]\n  weather_all <- rbind(weather_all, weather_ind)\n \n}\ntime.end <- Sys.time()\nprint(time.end - time.start)\n\nTime difference of 3.012721 mins\n\n\nThe previous code would have sent 62 separate requests to the NASA POWER server. The following loop will retrieve the same information but with only 3% of the requests. This example uses an API but the same principle can be applied to the front face of a website.\n\nsearch_parameters <- do.call(rbind, \n                            by(locations, locations$location_name, \n                               function(df) data.frame(df[1, c('location_name', 'longitude', 'latitude')],\n                               min_year = min(df$year), \n                               max_year = max(df$year))))\n\ntime.start <- Sys.time()\n\n\nweather_all <- data.frame()\n\nfor (i in 1:dim(search_parameters)[1]) {\n  \n  dates <- c(sprintf('%1$s-01-01', search_parameters$min_year[i]),\n             sprintf('%1$s-12-31', search_parameters$max_year[i]))\n  \n  lonlat <- c(search_parameters$longitude[i], search_parameters$latitude[i])\n  \n  weather_ind <- nasapower::get_power(community = \"AG\", pars = c(\"T2M_MAX\", \n    \"T2M_MIN\", \"ALLSKY_SFC_SW_DWN\", \"PRECTOTCORR\", \"RH2M\", \n    \"WS2M\"), dates = dates, lonlat = lonlat, temporal_api = \"daily\")\n  \n  weather_ind$location_name <- search_parameters$location_name[i]\n  weather_all <- rbind(weather_all, weather_ind)\n \n}\ntime.end <- Sys.time()\nprint(time.end - time.start)\n\nTime difference of 7.605049 secs\n\n\n2 - What is a ROBOTS.TXT file? Identify one instance and explain what it allows/prevents.\nThe robots.txt file is a file that tells bots instructions of where the bot is allowed to crawl or not. It is a convention and it is a sign of good faith to respect the robots.txt file. The file allows or disallows certain behaviors of bots. These rules can be implemented globally or for specific bots.\nAn example is the robots.txt file from https://www.iastate.edu. It specific disallows not clean URLs.\n# Paths (no clean URLs)\nDisallow: /index.php/admin/\nDisallow: /index.php/comment/reply/\nDisallow: /index.php/filter/tips\nDisallow: /index.php/node/add/\nDisallow: /index.php/search/\nDisallow: /index.php/user/password\nDisallow: /index.php/user/register\nDisallow: /index.php/user/login\nDisallow: /index.php/user/logout\nDisallow: /index.php/media/oembed\nDisallow: /index.php/*/media/oembed\n3- Identify a website that you would like to scrape (or one an example from class) and implement a scrape using the polite package.\n\nlibrary(polite)\nlibrary(rvest)\nlibrary(readr)\n\n\nAttaching package: 'readr'\n\n\nThe following object is masked from 'package:rvest':\n\n    guess_encoding\n\nsession <- bow(\"https://www.nytimes.com/elections/2016/results/iowa\", force = TRUE)\nresult <- scrape(session, query=list(t=\"semi-soft\", per_page=100))\n\ntables <- result %>% html_table(fill=TRUE)\ntables[[2]]\n\n# A tibble: 99 × 3\n   `Vote by county` Trump  Clinton\n   <chr>            <chr>  <chr>  \n 1 Polk             93,492 119,804\n 2 Linn             48,390 58,935 \n 3 Scott            39,149 40,440 \n 4 Johnson          21,044 50,200 \n 5 Black Hawk       27,476 32,233 \n 6 Story            19,458 25,709 \n 7 Dubuque          23,460 22,850 \n 8 Woodbury         24,727 16,210 \n 9 Pottawattamie    24,447 15,355 \n10 Dallas           19,339 15,701 \n# … with 89 more rows\n\nia_results <- tables[[2]] \nia_results$Trump <- with(ia_results,  parse_number(Trump))\nia_results$Clinton <- with(ia_results,  parse_number(Clinton))\n\nhead(ia_results)\n\n# A tibble: 6 × 3\n  `Vote by county` Trump Clinton\n  <chr>            <dbl>   <dbl>\n1 Polk             93492  119804\n2 Linn             48390   58935\n3 Scott            39149   40440\n4 Johnson          21044   50200\n5 Black Hawk       27476   32233\n6 Story            19458   25709\n\n\n\n# renv::snapshot()"
  },
  {
    "objectID": "blog-2023/Blog-10-submissions/sudi007/index.html",
    "href": "blog-2023/Blog-10-submissions/sudi007/index.html",
    "title": "Web scraping etiquette",
    "section": "",
    "text": "With great power comes great responsibility - a large part of the web is based on data and services that scrape those data. Now that we start to apply scraping mechanisms, we need to think about how to apply those skills without becoming a burden to the internet society.\nFind sources on ethical web scraping - some readings that might help you get started with that are:\n\nJames Densmore\nR package polite\nJAMI @ EMPIRICAL\n\nAfter reading through some of the ethics essays write a blog post addressing the following questions:\n\nWhat are your main three takeaways for ethical web scraping? - Give examples, or cite your sources.\n\nBased on the reading, Ethics in Web Scraping, the first key takeaway for ethical web scraping is that it is moral to provide a User Agent string that states the purpose of the web scraping and offers contact information. The second important takeaway is that web scraping is done to add value to the data and not duplicate it. The third important key takeaway is to always credit the original content and do not plagiarize. For example, it is ethical to include a statement on your website about how the data was sourced and how it will be utilized.\n\nWhat is a ROBOTS.TXT file? Identify one instance and explain what it allows/prevents.\n\nROBOTS.TXT file is also called the Robots Exclusion Standards. It guides the web-crawling software where it is allowed or not-allowed within the website. This file is a part of the Robots Exclusion Protocol, created to monitor and regulate how robots crawl the web. An example is the ROBOTS.TXT file of the New York Times (Ref: https://www.nytimes.com/robots.txt). This file allows twitterbot whereas disallows omgilibot, omgili and ia_achiever.\n\nIdentify a website that you would like to scrape (or one an example from class) and implement a scrape using the polite package.\n\nI have implemented polite package with other packages to scrape the web site.An example of a website considered for scraping is https://en.wikipedia.org/wiki/National_day its a website which explain about national day of different nations .A sample code using the polite package is as follows:\n\n# national day for each country \n# To clean data\nlibrary(tidyverse)\nlibrary(lubridate)\nlibrary(janitor)\n\n# To scrape data\nlibrary(rvest)\nlibrary(httr)\nlibrary(polite)\n\nurl <- \"https://en.wikipedia.org/wiki/National_day\"\nurl_bow <- polite::bow(url)\nurl_bow\n\n<polite session> https://en.wikipedia.org/wiki/National_day\n    User-agent: polite R package\n    robots.txt: 456 rules are defined for 33 bots\n   Crawl delay: 5 sec\n  The path is scrapable for this user-agent\n\nind_html <-\n  polite::scrape(url_bow) %>%  # scrape web page\n  rvest::html_nodes(\"table.wikitable\") %>% # pull out specific table\n  rvest::html_table(fill = TRUE) \nind_tab <- \n  ind_html[[1]] %>% \n  clean_names()\nind_tab\n\n# A tibble: 312 × 3\n   nation                         date        significance_of_this_date         \n   <chr>                          <chr>       <chr>                             \n 1 Acadia (Canada)                15 August   Assumption Day was preferred over…\n 2 Afghanistan                    19 August   Independence from United Kingdom …\n 3 Albania                        28 November Albanian Flag Day: Raising of the…\n 4 Alderney (British Islands)     15 December Homecoming Day, the return of the…\n 5 Algeria                        5 July      Independence Day (Algeria) in 1962\n 6 American Samoa (United States) 17 April    US Flag Day, commemorates the dat…\n 7 Andorra                        8 September Our Lady of Meritxell Day, patron…\n 8 Angola                         11 November Independence from Portugal in 1975\n 9 Anguilla (United Kingdom)      30 May      Anguilla Day; the beginning of th…\n10 Antigua and Barbuda            1 November  Independence from the United King…\n# … with 302 more rows\n\n#reference:https://en.wikipedia.org/wiki/National_day\n\nInstructions:\nSubmit to your repo. Make sure that all of the github actions pass (check menu item Actions - all of the actions should have green checks)"
  },
  {
    "objectID": "blog-2023/Blog-10-submissions/motinaaa/index.html",
    "href": "blog-2023/Blog-10-submissions/motinaaa/index.html",
    "title": "Web scraping etiquette …",
    "section": "",
    "text": "With great power comes great responsibility - a large part of the web is based on data and services that scrape those data. Now that we start to apply scraping mechanisms, we need to think about how to apply those skills without becoming a burden to the internet society.\nFind sources on ethical web scraping - some readings that might help you get started with that are:\n\nJames Densmore\nR package polite\nJAMI @ EMPIRICAL\n\nAfter reading through some of the ethics essays write a blog post addressing the following questions:\n\nWhat are your main three takeaways for ethical web scraping? - Give examples, or cite your sources. Here are three key takeaways from the article:\n\n\nUse public APIs whenever possible: Instead of scraping data directly from a website, use its API if it has it. By using an API, you’ll get the data in a structured and consistent format and you’ll reduce the website’s server load.\n\n\nRespect the website’s terms of use: When scraping data from a website, be transparent about your intentions. Providing a clear user agent string identifies you as a scraper rather than a malicious bot, requesting data at a reasonable rate, and only saving the data you need. If you keep anything, make sure you don’t pass it off as your own.\n\n\nProvide value: Instead of just taking data from a website, try to give something back. The data can be used in a way to benefit the website or its users, such as driving traffic to the site, crediting it in an article, or finding other ways to use it.\n\nSource: [James Densmore’s article “Ethics in Web Scraping”] (https://towardsdatascience.com/ethics-in-web-scraping-b96b18136f01)\n\nWhat is a ROBOTS.TXT file? Identify one instance and explain what it allows/prevents.\n\nFor robots.txt, it’s a file placed in a site’s root directory that tells web scrapers how they can crawl the site. You can allow or disallow certain web scraping activities in the file, or define how often requests should be made. The robots.txt file on Twitter, for example, doesn’t let scrapers crawl the /search and /notifications sections of the site. Therefore, web scrapers shouldn’t scrape or access these parts of the site without permission.\n\nIdentify a website that you would like to scrape (or one an example from class) and implement a scrape using the polite package.\n\n\nlibrary(polite)\nlibrary(rvest)\nlibrary(purrr)\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\n# Set the URL to scrape\nurl <- \"https://www.nytimes.com/elections/2016/results/iowa\"\n\n# Create a polite session to request permission to scrape the site\nsession <- bow(url)\n\n# Use the session to retrieve the HTML content of the page\nhtml <- scrape(session)\n\n# Extract the tables from the HTML using rvest\ntables <- html %>% html_table(fill = TRUE)\n\n# Print a summary of each table using purrr \ntables %>% purrr::map(summary) %>% head()\n\n[[1]]\n Candidate       Candidate            Party              Votes          \n Mode:logical   Length:11          Length:11          Length:11         \n NA's:11        Class :character   Class :character   Class :character  \n                Mode  :character   Mode  :character   Mode  :character  \n     Pct.                              E.V.          \n Length:11          Mode:logical   Length:11         \n Class :character   NA's:11        Class :character  \n Mode  :character                  Mode  :character  \n\n[[2]]\n Vote by county        Trump             Clinton         \n Length:99          Length:99          Length:99         \n Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character  \n\n[[3]]\n Candidate       Candidate            Party              Votes          \n Mode:logical   Length:6           Length:6           Length:6          \n NA's:6         Class :character   Class :character   Class :character  \n                Mode  :character   Mode  :character   Mode  :character  \n     Pct.                         \n Length:6           Mode:logical  \n Class :character   NA's:6        \n Mode  :character                 \n\n[[4]]\n Vote by county       Grassley            Judge          \n Length:99          Length:99          Length:99         \n Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character  \n\n[[5]]\n District\\n          Dist.    Leader                            \n Min.   :1.00              Length:4           Length:4          \n 1st Qu.:1.75              Class :character   Class :character  \n Median :2.50              Mode  :character   Mode  :character  \n Mean   :2.50                                                   \n 3rd Qu.:3.25                                                   \n Max.   :4.00                                                   \n     Rpt.                         \n Length:4           Mode:logical  \n Class :character   NA's:4        \n Mode  :character                 \n                                  \n                                  \n                                  \n\n[[6]]\n Seat\\n          Seat    Leader                                 Rpt.          \n Min.   : 2           Length:25          Length:25          Length:25         \n 1st Qu.:14           Class :character   Class :character   Class :character  \n Median :26           Mode  :character   Mode  :character   Mode  :character  \n Mean   :26                                                                   \n 3rd Qu.:38                                                                   \n Max.   :50                                                                   \n               \n Mode:logical  \n NA's:25       \n               \n               \n               \n               \n\n\nInstructions:\nSubmit to your repo. Make sure that all of the github actions pass (check menu item Actions - all of the actions should have green checks)"
  },
  {
    "objectID": "blog-2023/Blog-10-submissions/maxwellskinner2002/index.html",
    "href": "blog-2023/Blog-10-submissions/maxwellskinner2002/index.html",
    "title": "Web scraping etiquette …",
    "section": "",
    "text": "With great power comes great responsibility - a large part of the web is based on data and services that scrape those data. Now that we start to apply scraping mechanisms, we need to think about how to apply those skills without becoming a burden to the internet society.\nFind sources on ethical web scraping - some readings that might help you get started with that are:\n\nJames Densmore\nR package polite\nJAMI @ EMPIRICAL\n\nAfter reading through some of the ethics essays write a blog post addressing the following questions:\n\nWhat are your main three takeaways for ethical web scraping? - Give examples, or cite your sources.\nWhat is a ROBOTS.TXT file? Identify one instance and explain what it allows/prevents.\nIdentify a website that you would like to scrape (or one an example from class) and implement a scrape using the polite package.\n\nInstructions:\nSubmit to your repo. Make sure that all of the github actions pass (check menu item Actions - all of the actions should have green checks)"
  },
  {
    "objectID": "blog-2023/Blog-10-submissions/Sabrenar/index.html",
    "href": "blog-2023/Blog-10-submissions/Sabrenar/index.html",
    "title": "Web scraping etiquette …",
    "section": "",
    "text": "With great power comes great responsibility - a large part of the web is based on data and services that scrape those data. Now that we start to apply scraping mechanisms, we need to think about how to apply those skills without becoming a burden to the internet society.\nFind sources on ethical web scraping - some readings that might help you get started with that are:\n\nJames Densmore\nR package polite\nJAMI @ EMPIRICAL\n\nAfter reading through some of the ethics essays write a blog post addressing the following questions:\n\nWhat are your main three takeaways for ethical web scraping? - Give examples, or cite your sources. Be considerate to the page that you are web-scraping: cite the author(s) and do not claim their data as your own. (https://towardsdatascience.com/ethics-in-web-scraping-b96b18136f01) If there is an API on the website for its data, use the API to retrieve the data. (https://www.empiricaldata.org/dataladyblog/a-guide-to-ethical-web-scraping) “The three pillars of a polite session are seeking permission, taking slowly and never asking twice” (https://github.com/dmi3kno/polite)\nWhat is a ROBOTS.TXT file? Identify one instance and explain what it allows/prevents. The ROBOTS.TXT file defines what is allowed or not allowed within a website to web-crawling software (https://www.empiricaldata.org/dataladyblog/a-guide-to-ethical-web-scraping). It allows or prevents robots to access content based on the user’s specifications. There is no standard, so it is truly up to the website creater to state what is allowed (or probably more specifically NOT allowed).\nIdentify a website that you would like to scrape (or one an example from class) and implement a scrape using the polite package. Using the example on the polite package’s github: www.cheese.com I successfully installed polite and ran the below code (the basic example from the github page).\n\n\nlibrary(polite)\nlibrary(rvest)\n\nsession <- bow(\"https://www.cheese.com/by_type\", force = TRUE)\nresult <- scrape(session, query=list(t=\"semi-soft\", per_page=100)) %>%\n  html_node(\"#main-body\") %>% \n  html_nodes(\"h3\") %>% \n  html_text()\nhead(result)\n\nInstructions:\nSubmit to your repo. Make sure that all of the github actions pass (check menu item Actions - all of the actions should have green checks)"
  },
  {
    "objectID": "blog-2023/Blog-10-submissions/luobo119/index.html",
    "href": "blog-2023/Blog-10-submissions/luobo119/index.html",
    "title": "Web scraping etiquette",
    "section": "",
    "text": "With great power comes great responsibility - a large part of the web is based on data and services that scrape those data. Now that we start to apply scraping mechanisms, we need to think about how to apply those skills without becoming a burden to the internet society.\nFind sources on ethical web scraping - some readings that might help you get started with that are:\n\nJames Densmore\nR package polite\nJAMI @ EMPIRICAL\n\nAfter reading through some of the ethics essays write a blog post addressing the following questions:\n\nWhat are your main three takeaways for ethical web scraping? - Give examples, or cite your sources.\n\n\nDo the scraping off-peak hours and request the data at a reasonable rate.\nLet the website’s administrator know who you are, your intentions as well as your contact information by adding some strings in the user-agent.\nRead ROBOTS.TXT and respect their rules.\n\nReferences:\n\nhttps://www.empiricaldata.org/dataladyblog/a-guide-to-ethical-web-scraping\nhttps://towardsdatascience.com/ethics-in-web-scraping-b96b18136f01\n\n\nWhat is a ROBOTS.TXT file? Identify one instance and explain what it allows/prevents.\n\nA ROBOTS.TXT file indicates what is allowed and what is not allowed in the web crawling. It is part of the Robot Exclusion Protocol (REP).\nIn the robots.txt for https://www.costco.com, part of the file is as follows:\nUser-agent: *\nDisallow: /*?*pageSize=*\nAllow: /*?currentPage=*pageSize=*\nwhich means costco.com does not want any use-agent to crawl the url /*?*pageSize=*, but it is allowed to crawl the url /*?currentPage=*pageSize=*.\n\nIdentify a website that you would like to scrape (or one an example from class) and implement a scrape using the polite package.\n\n\nlibrary(polite)\nlibrary(rvest)\nlibrary(readr)\nlibrary(dplyr)\nsession <- bow(\"https://www.nytimes.com/elections/2016/results/iowa\", force = TRUE)\ntbl <- scrape(session) %>% html_table(fill=TRUE) \nia_results <- tbl[[2]] %>% mutate(\n  Trump  = parse_number(Trump),\n  Clinton = parse_number(Clinton)\n)\nhead(ia_results)\n\n# A tibble: 6 × 3\n  `Vote by county` Trump Clinton\n  <chr>            <dbl>   <dbl>\n1 Polk             93492  119804\n2 Linn             48390   58935\n3 Scott            39149   40440\n4 Johnson          21044   50200\n5 Black Hawk       27476   32233\n6 Story            19458   25709"
  },
  {
    "objectID": "blog-2023/Blog-10-submissions/AArabio/index.html",
    "href": "blog-2023/Blog-10-submissions/AArabio/index.html",
    "title": "Web scraping etiquette …",
    "section": "",
    "text": "With great power comes great responsibility - a large part of the web is based on data and services that scrape those data. Now that we start to apply scraping mechanisms, we need to think about how to apply those skills without becoming a burden to the internet society.\nFind sources on ethical web scraping - some readings that might help you get started with that are:\n\nJames Densmore\nR package polite\nJAMI @ EMPIRICAL\n\nAfter reading through some of the ethics essays write a blog post addressing the following questions:\n\nWhat are your main three takeaways for ethical web scraping? - Give examples, or cite your sources.\n\nMain 3 takeaways for ethical webscaping: - One of the first takeaways for ethical webscraping that I noticed when reading Jami @ EMIRICAL was that the definition of ethical may be subject in a way and may not be universially agreed upon… the reading discussed that even if on paper everything seems to be in order and appropriate, it doesn’t mean that you may be compfortable with it. You don’t always know what you’re signing and it could be dangerous. - Expanding upon my first takeaway, the reading written by James Densmore on the ethics in web scraping continued to touch on the point that one of the largest issues regarding the ethics of this practice is that not everyone is agreeing on the terms. People are typically innately selfish so what someone may think of as ethical on one end (the scraper) may differ from one on the other end (the site ownder). - The third takeaway came from reviewing the R package [polite] … This brought everything together in terms of the process of scraping not being as scary as I origionally thought. I am typically afraid of getting in trouble or doing something wrong but through the help of this package there is a more clear way of seaking permisison and introducting yourself and following the steps that were laid out in the previous two writtings.\n\nWhat is a ROBOTS.TXT file? Identify one instance and explain what it allows/prevents.\n\nAccording to Jami @ Empirical … a ROBOTS.TXT files is … “what indicates the web-crawling software where it is allowed (or not allowed) within the website. This is part of the Robots Exclusion Protocol (REP) which are a group of web standards created as a way to regulate how robots crawl the web.” … this file typically lives at the root of a site as a plain text file that provides instructions to web robots like search engine crawlers about locations within the website that robots are or are not allowed to crawl and index.\n\nIdentify a website that you would like to scrape (or one an example from class) and implement a scrape using the polite package.\n\nTo help work through some examples I utilized the following link: https://www.r-bloggers.com/2020/05/intro-to-polite-web-scraping-of-soccer-data-with-r/\nInstructions:\nSubmit to your repo. Make sure that all of the github actions pass (check menu item Actions - all of the actions should have green checks)"
  },
  {
    "objectID": "blog-2023/Blog-10-submissions/Starwiiin/index.html",
    "href": "blog-2023/Blog-10-submissions/Starwiiin/index.html",
    "title": "Web scraping etiquette …",
    "section": "",
    "text": "With great power comes great responsibility - a large part of the web is based on data and services that scrape those data. Now that we start to apply scraping mechanisms, we need to think about how to apply those skills without becoming a burden to the internet society.\nFind sources on ethical web scraping - some readings that might help you get started with that are:\n\nJames Densmore\nR package polite\nJAMI @ EMPIRICAL\n\nAfter reading through some of the ethics essays write a blog post addressing the following questions:\n\nWhat are your main three takeaways for ethical web scraping? - Give examples, or cite your sources. Parvin’s answer: 1) I will always mention and clarify my intentions by using the data that I scarp and I will not scrap the data that I do not need. For example, suppose that I scrapped data from a web, if I am analyzing the relationship between two variables including exercise and lifetime, I will mention my goal in my github and also I will not scrap the data related to the diet which I do not use it in my analysis. 2) I will always try to give the credit back to the owner of the website. For example I will mention it in the paper as the reference. 3) I will always extract data from a web to create value, new, and useful information. In the other words, I will not copy the data to put it my webpage. For example, I will use the data to run a prediction model to publish insights.\nWhat is a ROBOTS.TXT file? Identify one instance and explain what it allows/prevents. Parvin’s answer: robots.txt file which is used in the “polite” package and it should be called in the process of the web scarping to introduce the client (who will use from the data by web scarping) to the host and get the permission to scrape. Also, it helps to take the information with slower rate and the client needs to ask the permission just one time.\nIdentify a website that you would like to scrape (or one an example from class) and implement a scrape using the polite package.\n\n\nlibrary(polite)\nlibrary(rvest)\nlibrary(purrr)\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nsession = bow(\"https://www.nytimes.com/elections/2016/results/iowa\") \nhtml = scrape(session)\nhtml\n\n{html_document}\n<html lang=\"en\" itemscope=\"\" xmlns:og=\"//opengraphprotocol.org/schema/\" itemtype=\"//schema.org/NewsArticle\">\n[1] <head>\\n<title>Iowa Election Results 2016 – The New York Times</title>\\n< ...\n[2] <body class=\"eln-general-state-results eln-state-iowa\">\\n    <div id=\"she ...\n\n\n\ntables <- html %>% html_table(fill=TRUE)\ntables %>% purrr::map(glimpse)\n\nRows: 11\nColumns: 7\n$ Candidate <lgl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA\n$ Candidate <chr> \"Trump\\n            \\n            \\n              Donald J. …\n$ Party     <chr> \"Republican\\n          Rep.\", \"Democrat\\n          Dem.\", \"L…\n$ Votes     <chr> \"800,983\", \"653,669\", \"59,186\", \"19,992\", \"12,366\", \"11,479\"…\n$ Pct.      <chr> \"51.1%\", \"41.7%\", \"3.8%\", \"1.3%\", \"0.8%\", \"0.7%\", \"0.3%\", \"0…\n$ ``        <lgl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA\n$ E.V.      <chr> \"6\", \"—\", \"—\", \"—\", \"—\", \"—\", \"—\", \"—\", \"—\", \"—\", \"—\"\nRows: 99\nColumns: 3\n$ `Vote by county` <chr> \"Polk\", \"Linn\", \"Scott\", \"Johnson\", \"Black Hawk\", \"St…\n$ Trump            <chr> \"93,492\", \"48,390\", \"39,149\", \"21,044\", \"27,476\", \"19…\n$ Clinton          <chr> \"119,804\", \"58,935\", \"40,440\", \"50,200\", \"32,233\", \"2…\nRows: 6\nColumns: 6\n$ Candidate <lgl> NA, NA, NA, NA, NA, NA\n$ Candidate <chr> \"Grassley*\\n            \\n            \\n              Charle…\n$ Party     <chr> \"Republican\\n          Rep.\", \"Democrat\\n          Dem.\", \"L…\n$ Votes     <chr> \"926,007\", \"549,460\", \"41,794\", \"17,649\", \"4,441\", \"22,090\"\n$ Pct.      <chr> \"60.2%\", \"35.7%\", \"2.7%\", \"1.1%\", \"0.3%\", \"1.4%\"\n$ ``        <lgl> NA, NA, NA, NA, NA, NA\nRows: 99\nColumns: 3\n$ `Vote by county` <chr> \"Polk\", \"Linn\", \"Scott\", \"Johnson\", \"Black Hawk\", \"St…\n$ Grassley         <chr> \"118,164\", \"62,737\", \"46,415\", \"28,914\", \"33,884\", \"2…\n$ Judge            <chr> \"100,317\", \"47,635\", \"34,503\", \"42,699\", \"27,245\", \"2…\nRows: 4\nColumns: 5\n$ `District\\n          Dist.` <int> 1, 2, 3, 4\n$ Leader                      <chr> \"54%Blum*\\n      Rep.\", \"54%Loebsack*\\n   …\n$ ``                          <chr> \"46%Vernon\\n      Dem.\", \"46%Peters\\n     …\n$ Rpt.                        <chr> \"100%\", \"100%\", \"100%\", \"100%\"\n$ ``                          <lgl> NA, NA, NA, NA\nRows: 25\nColumns: 5\n$ `Seat\\n          Seat` <int> 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26,…\n$ Leader                 <chr> \"0%Feenstra*\\n      Rep.\", \"61%Guth*\\n      Rep…\n$ ``                     <chr> \"Uncontested\", \"39%Bangert\\n      Dem.\", \"17%Se…\n$ Rpt.                   <chr> \"\", \"100%\", \"100%\", \"100%\", \"100%\", \"100%\", \"10…\n$ ``                     <lgl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\nRows: 100\nColumns: 5\n$ `District\\n          Dist.` <int> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,…\n$ Leader                      <chr> \"0%Wills*\\n      Rep.\", \"0%Jones*\\n      R…\n$ ``                          <chr> \"Uncontested\", \"Uncontested\", \"19%McCoy\\n …\n$ Rpt.                        <chr> \"\", \"\", \"100%\", \"100%\", \"100%\", \"100%\", \"1…\n$ ``                          <lgl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\nRows: 3\nColumns: 5\n$ Question <chr> \"Retain Brent Appel\", \"Retain Daryl Hecht\", \"Retain Mark Cady\"\n$ Yes      <chr> \"64%Yes\", \"64%Yes\", \"65%Yes\"\n$ No       <chr> \"36%No\", \"36%No\", \"35%No\"\n$ Rpt.     <chr> \"100%\", \"100%\", \"100%\"\n$ ``       <lgl> NA, NA, NA\n\n\n[[1]]\n# A tibble: 11 × 7\n   Candidate Candidate                             Party Votes Pct.  ``    E.V. \n   <lgl>     <chr>                                 <chr> <chr> <chr> <lgl> <chr>\n 1 NA        \"Trump\\n            \\n            \\n… \"Rep… 800,… 51.1% NA    6    \n 2 NA        \"Clinton\\n            \\n            … \"Dem… 653,… 41.7% NA    —    \n 3 NA        \"Johnson\\n            \\n            … \"Lib… 59,1… 3.8%  NA    —    \n 4 NA        \"Others\\n            \\n            \\… \"Ind… 19,9… 1.3%  NA    —    \n 5 NA        \"McMullin\\n            \\n           … \"Pet… 12,3… 0.8%  NA    —    \n 6 NA        \"Stein\\n            \\n            \\n… \"Gre… 11,4… 0.7%  NA    —    \n 7 NA        \"Castle\\n            \\n            \\… \"Con… 5,335 0.3%  NA    —    \n 8 NA        \"Kahn\\n            \\n            \\n … \"Ind… 2,247 0.1%  NA    —    \n 9 NA        \"De La Fuente\\n            \\n       … \"Pet… 451   0.0%  NA    —    \n10 NA        \"La Riva\\n            \\n            … \"P.S… 323   0.0%  NA    —    \n11 NA        \"Others\\n            \\n            \\… \"\"    32,2… 2.1%  NA    —    \n\n[[2]]\n# A tibble: 99 × 3\n   `Vote by county` Trump  Clinton\n   <chr>            <chr>  <chr>  \n 1 Polk             93,492 119,804\n 2 Linn             48,390 58,935 \n 3 Scott            39,149 40,440 \n 4 Johnson          21,044 50,200 \n 5 Black Hawk       27,476 32,233 \n 6 Story            19,458 25,709 \n 7 Dubuque          23,460 22,850 \n 8 Woodbury         24,727 16,210 \n 9 Pottawattamie    24,447 15,355 \n10 Dallas           19,339 15,701 \n# … with 89 more rows\n\n[[3]]\n# A tibble: 6 × 6\n  Candidate Candidate                                    Party Votes Pct.  ``   \n  <lgl>     <chr>                                        <chr> <chr> <chr> <lgl>\n1 NA        \"Grassley*\\n            \\n            \\n   … \"Rep… 926,… 60.2% NA   \n2 NA        \"Judge\\n            \\n            \\n       … \"Dem… 549,… 35.7% NA   \n3 NA        \"Aldrich\\n            \\n            \\n     … \"Lib… 41,7… 2.7%  NA   \n4 NA        \"Hennager\\n            \\n            \\n    … \"Ind… 17,6… 1.1%  NA   \n5 NA        \"Luick-Thrams\\n            \\n            \\n… \"Pet… 4,441 0.3%  NA   \n6 NA        \"Others\\n            \\n            \\n      … \"\"    22,0… 1.4%  NA   \n\n[[4]]\n# A tibble: 99 × 3\n   `Vote by county` Grassley Judge  \n   <chr>            <chr>    <chr>  \n 1 Polk             118,164  100,317\n 2 Linn             62,737   47,635 \n 3 Scott            46,415   34,503 \n 4 Johnson          28,914   42,699 \n 5 Black Hawk       33,884   27,245 \n 6 Story            25,475   21,472 \n 7 Dubuque          27,348   19,291 \n 8 Woodbury         27,166   13,909 \n 9 Pottawattamie    25,721   12,943 \n10 Dallas           24,374   11,876 \n# … with 89 more rows\n\n[[5]]\n# A tibble: 4 × 5\n  `District\\n          Dist.` Leader                     ``          Rpt.  ``   \n                        <int> <chr>                      <chr>       <chr> <lgl>\n1                           1 \"54%Blum*\\n      Rep.\"     \"46%Vernon… 100%  NA   \n2                           2 \"54%Loebsack*\\n      Dem.\" \"46%Peters… 100%  NA   \n3                           3 \"54%Young*\\n      Rep.\"    \"40%Mowrer… 100%  NA   \n4                           4 \"61%King*\\n      Rep.\"     \"39%Weaver… 100%  NA   \n\n[[6]]\n# A tibble: 25 × 5\n   `Seat\\n          Seat` Leader                     ``              Rpt.  ``   \n                    <int> <chr>                      <chr>           <chr> <lgl>\n 1                      2 \"0%Feenstra*\\n      Rep.\"  \"Uncontested\"   \"\"    NA   \n 2                      4 \"61%Guth*\\n      Rep.\"     \"39%Bangert\\n … \"100… NA   \n 3                      6 \"83%Segebart*\\n      Rep.\" \"17%Serianni\\n… \"100… NA   \n 4                      8 \"54%Dawson\\n      Rep.\"    \"46%Gronstal*\\… \"100… NA   \n 5                     10 \"67%Chapman*\\n      Rep.\"  \"33%Paladino\\n… \"100… NA   \n 6                     12 \"78%Costello*\\n      Rep.\" \"22%Brantz\\n  … \"100… NA   \n 7                     14 \"74%Sinclair*\\n      Rep.\" \"26%Smith\\n   … \"100… NA   \n 8                     16 \"60%Boulton\\n      Dem.\"   \"35%Pryor\\n   … \"100… NA   \n 9                     18 \"0%Petersen*\\n      Dem.\"  \"Uncontested\"   \"\"    NA   \n10                     20 \"60%Zaun*\\n      Rep.\"     \"41%Hikiji\\n  … \"100… NA   \n# … with 15 more rows\n\n[[7]]\n# A tibble: 100 × 5\n   `District\\n          Dist.` Leader                    ``          Rpt.  ``   \n                         <int> <chr>                     <chr>       <chr> <lgl>\n 1                           1 \"0%Wills*\\n      Rep.\"    \"Uncontest… \"\"    NA   \n 2                           2 \"0%Jones*\\n      Rep.\"    \"Uncontest… \"\"    NA   \n 3                           3 \"81%Huseman*\\n      Rep.\" \"19%McCoy\\… \"100… NA   \n 4                           4 \"63%Wheeler\\n      Rep.\"  \"37%VanDer… \"100… NA   \n 5                           5 \"77%Holz*\\n      Rep.\"    \"23%Ritz\\n… \"100… NA   \n 6                           6 \"66%Carlin\\n      Rep.\"   \"35%Alarco… \"100… NA   \n 7                           7 \"63%Gassman*\\n      Rep.\" \"37%Grussi… \"100… NA   \n 8                           8 \"68%Baxter*\\n      Rep.\"  \"32%Paule … \"100… NA   \n 9                           9 \"57%Miller*\\n      Dem.\"  \"43%Waecht… \"100… NA   \n10                          10 \"0%Sexton*\\n      Rep.\"   \"Uncontest… \"\"    NA   \n# … with 90 more rows\n\n[[8]]\n# A tibble: 3 × 5\n  Question           Yes    No    Rpt.  ``   \n  <chr>              <chr>  <chr> <chr> <lgl>\n1 Retain Brent Appel 64%Yes 36%No 100%  NA   \n2 Retain Daryl Hecht 64%Yes 36%No 100%  NA   \n3 Retain Mark Cady   65%Yes 35%No 100%  NA   \n\n\nInstructions:\nSubmit to your repo. Make sure that all of the github actions pass (check menu item Actions - all of the actions should have green checks)"
  },
  {
    "objectID": "blog-2023/Prompts/Blog-5/Prompt.html",
    "href": "blog-2023/Prompts/Blog-5/Prompt.html",
    "title": "Ethics and Reproducibility… – Prompt 5",
    "section": "",
    "text": "In May 2015 Science retracted - without consent of the lead author - a paper on how canvassers can sway people’s opinions about gay marriage, see also: http://www.sciencemag.org/news/2015/05/science-retracts-gay-marriage-paper-without-agreement-lead-author-lacour The Science Editor-in-Chief cited as reasons for the retraction that the original survey data was not made available for independent reproduction of results, that survey incentives were misrepresented and that statements made about sponsorships turned out to be incorrect. The investigation resulting in the retraction was triggered by two Berkeley grad students who attempted to replicate the study and discovered that the data must have been faked.\nFiveThirtyEight has published an article with more details on the two Berkeley students’ work.\nMalicious changes to the data such as in the LaCour case are hard to prevent, but more rigorous checks should be built into the scientific publishing system. All too often papers have to be retracted for unintended reasons. Retraction Watch is a data base that keeps track of retracted papers (see the related Science magazine publication).\nRead the paper Ten Simple Rules for Reproducible Computational Research by Sandve et al.\nWrite a blog post addressing the questions:\n\nPick one of the papers from Retraction Watch that were retracted because of errors in the paper (you might want to pick a paper from the set of featured papers, because there are usually more details available). Describe what went wrong. Would any of the rules by Sandve et al. have helped in this situation?\nAfter reading the paper by Sandve et al. describe which rule you are most likely to follow and why, and which rule you find the hardest to follow and will likely not (be able to) follow in your future projects.\nPush your changes to your repository. Make sure that all github actions pass without an error message. You can check on that by selecting ‘Actions’ on the menu and ensure that the last item has a green checkmark."
  },
  {
    "objectID": "blog-2023/Prompts/Blog-2/Prompt.html",
    "href": "blog-2023/Prompts/Blog-2/Prompt.html",
    "title": "Happy Git with R",
    "section": "",
    "text": "git and Github are tools for helping with versioning of files in collaborative efforts as well as archiving entries for your future self. Unfortunately working with git isn’t always completely straightforward. Jenny Bryan’s book “Happy git and github with R” helps with that. The book is available from http://happygitwithr.com/. Have a look over the index and pick one of the chapters for a more in-depth read.\nWrite a blog post answering the following questions:\n\nWrite a short (100-150 words) summary of the chapter you read in-depth.\nLooking back at all of the team projects you have been involved in, describe the biggest mishap you had. Could that have been avoided using git? How?.\nGive an example of one new git feature that you learned about from Jenny Bryan’s book..\n\nTo make your blog post show up properly on this site, you have to\n\nchange the name of the file LastnameFirstname.Rmd to something else,\nchange the yaml in your Rmd file to:\n\n---\nauthor: Your Name\ndate: 2023-02-02\ncategories: \"Happy Git with R\"\ntitle: Happy Git with R\n---"
  },
  {
    "objectID": "blog-2023/Prompts/Blog-3/Prompt.html",
    "href": "blog-2023/Prompts/Blog-3/Prompt.html",
    "title": "Building a book – Prompt 3",
    "section": "",
    "text": "The goal of this week’s blog is to document what you are doing when things do not go according to plan.\nSimilar to previous exercises, we have a specific use case in mind: we want to build a book from a github repository.\nWhat happens in practice usually, is that we run into some problems. So your real task turns into that of a bug-hunter and fixer. Luckily, you have a community (the class discussion board) who might be able to help you.\n\n\nBuild the html version of the 2nd edition for Hadley Wickham’s book Advanced R Programming from a github repository.\nSteps:\n\nClone the repository https://github.com/hadley/adv-r.\nOpen the R project in the repository in RStudio.\nActivate the Build tab (by default in the top right panel). Click on the Build Book button.\nThe book will be available in html format as index.html\n\nDeliverable (1): what is the last word in chapter 15? - You don’t have to answer this question, if things don’t work.\n\n\n\nErrors happen, they are frustrating, but if we learn something from them, we can turn them into valuable experiences.\n\ncheck the Questions and Answers forum in Canvas whether there is a solution available for your problem.\nif the above document does (not yet) include your question, document the error you encounter (be as concise and specific as you can at the same time)\nif the Question and Answers forum does (not yet) include a solution, describe one approach on how you tried to solve the problem (and how this did not work).\nsubmit the description of your problem in Canvas at Discussions > Questions and Answers. Write the paragraph in the mindset that you want to get help from somebody, and you try to describe the problem you are encountering.\nExtra points (1 pt for the first suggested working solution): post a solution to one of the problems in the Questions and Answers forum (your own does not count!).\n\nDeliverable (2): Write a paragraph on the biggest problem you encountered when you were building the book, (and how you managed to solve it.)\nYou can write your experience directly into the README.Rmd file. Just make sure that you change the yaml at the top: change the author at the top, and give your post a new title (don’t change the category :))\nCommit and push to your repo and you are done!"
  },
  {
    "objectID": "blog-2023/Prompts/Blog-4/Prompt.html",
    "href": "blog-2023/Prompts/Blog-4/Prompt.html",
    "title": "The Split-Apply-Combine paradigm - Prompt 4",
    "section": "",
    "text": "The plyr package has by now been replaced by other, even faster packages, but the idea of Split, apply, combine is as relevant as ever.\nRead the paper The Split-Apply-Combine Strategy for Data Analysis by Hadley Wickham.\nWrite a blog post addressing the following questions:\n\nThe R code for the split-apply-combine paper is posted with the paper. Pick one of the examples demonstrating plyr functionality (such as dlply or ddply, …) and rewrite the example using functionality from the package dplyr. Make sure that your example works and returns identical results.\nWhich (base R) functions do you know that support the split-apply-combine strategy? In your opinion, are these sufficient? State why or why not?\nThe ChatGPT response to the prompt “Describe the split-apply-combine paradigm” is given below. Generally, the chatbot’s answers are decent. ChatGPT does have problems getting details right. Which details would you change in the response?\n\n\nThe “split-apply-combine” paradigm is a data analysis strategy used in statistics and data science to analyze grouped data. It consists of three steps:\nSplit: The data is first split into groups based on one or more variables of interest.\nApply: A specific operation or function is applied to each group of data, usually for the purpose of aggregating, summarizing, or transforming the data within each group.\nCombine: The results of the operation applied to each group are then combined and returned as a single output.\nThe split-apply-combine paradigm is particularly useful in cases where the data cannot be analyzed as a whole and instead must be analyzed in smaller, more manageable chunks. This allows for more efficient data processing and improved scalability. The paradigm is commonly implemented using tools such as the “groupby” function in the R and Python programming languages, and the “dplyr” library in R.\n\nYou can write your answers directly the README.Rmd file. Make sure that the file knits (you will need to activate any packages your use in your code chunks with a call to library(xxx), where xxx is the name of the package, such as plyr ). Commit your changes and push to your repo; add any files in the README_files directory to your repository."
  },
  {
    "objectID": "blog-2023/Prompts/Blog-8/Prompt.html",
    "href": "blog-2023/Prompts/Blog-8/Prompt.html",
    "title": "Make your own website – Prompt 8",
    "section": "",
    "text": "GitHub is an incredibly useful tool for project management and collaboration. It also has several useful features for professional promotion: you can host your own site on github using GitHub pages, describe yourself using a GitHub developer profile, and even use resume.github.io to generate a resume summary of your activity on GitHub (you must opt-in by starring the project page).\nposit and the associated package infrastructure provide multiple ways to generate websites using Quarto (or Rmarkdown). You can complete this assignment using one of two options:\n\nSimple RMarkdown websites\nFor more information about simple R Markdown websites, please read the documentation at https://bookdown.org/yihui/rmarkdown/rmarkdown-site.html. Simple R Markdown sites are not based on blogdown. They are probably good for websites with only a few Rmd documents.\nQuarto\nFor larger-scale and more sophisticated websites (such as blogs), you may want to use Quarto instead: https://quarto.org/docs/websites/."
  },
  {
    "objectID": "blog-2023/Prompts/Blog-8/Prompt.html#instructions",
    "href": "blog-2023/Prompts/Blog-8/Prompt.html#instructions",
    "title": "Make your own website – Prompt 8",
    "section": "Instructions:",
    "text": "Instructions:\n\nCreate a new GitHub repository named <your-username>.github.io (replacing “” with your GitHub username). Initialize this repo with a readme.\nSet up your website using either the Simple Markdown Site or the Quarto instructions below. If you would like to use this repository to host a blog, you may find Quarto to be a more convenient option, however, it is (just a bit) more complicated than the simple Rmarkdown site.\nWrite about you experience – and link to your new website!\n\nTo get full marks for this blog post, you should modify your site beyond the default template files, adding at least some content that is unique to you - packages you find interesting, sites you enjoy, projects you have worked on, a page with your CV, etc.\n\nSimple RMarkdown Site\n\nUse RStudio and set up a new project on your machine linked to the GitHub repository you just created.\nCreate two files in your project folder:\n\n_site.yml:\nname: \"my-website\"\noutput_dir: \".\"\nnavbar:\n  title: \"My Website\"\n  left:\n    - text: \"Home\"\n      href: index.html\nindex.Rmd\n---\ntitle: \"My Website\"\n---\n\nHello, Website!\n\nUse the commmand rmarkdown::render_site() to build your website (Or click the “Build Website” button under the Build tab in RStudio). This command will compile any R markdown document in the main project directory to HTML (even if it is not mentioned in _site.yml).\nPush your site to GitHub. In this instance, you want to include the HTML files that were rendered, the site_libs directory, the _site.yml file used to configure the build process, and the Rmd files used to render the HTML files.\nCustomize your site. Remember to use the command rmarkdown::render_site() before you push your changes so that the HTML is updated!\n\nModify _site.yml to update the header structure, add links to other files, etc.\nModify index.Rmd to add content to the landing page of your site. You might think about including a link to your CV on this page.\nAdd new Rmd files to add new pages to your site. Consider adding a page describing your favorite packages, or pages for different projects you’ve worked on.\n\n\n\n\nQuarto\n\nInstall/Update the quarto package (install.packages(\"quarto\"))\nCreate a new folder where you will store your blog and the rendered site.\nUse RStudio to create a new project inside the folder you created in step 2. Select either the Option “Quarto Website” or “Quarto Blog” as the project type.\nFollow the Quick Start instructions on https://quarto.org/docs/websites/ or https://quarto.org/docs/websites/website-blog.html to create your website.\nFor publishing your website, follow the steps described under Github Pages. You can try to build the site automatically, but fair warning: I went back to build to docs and render the site myself.\nVERY IMPORTANT. Open the “username.github.io” project. Add a text file named “.nojekyll” (the file should be empty). This tells GitHub not to build the pages with Jekyll (another rendering engine) and instead render pages built with Quarto."
  },
  {
    "objectID": "blog-2023/Prompts/Blog-8/Prompt.html#submission",
    "href": "blog-2023/Prompts/Blog-8/Prompt.html#submission",
    "title": "Make your own website – Prompt 8",
    "section": "Submission",
    "text": "Submission\nDescribe your experience the README.Rmd of the blog-8 repo. Don’t forget to link to your website! Push the blog post to your blog-8 repo. Make sure that all of the checks are passing."
  },
  {
    "objectID": "blog-2023/Prompts/Blog-6/Prompt.html",
    "href": "blog-2023/Prompts/Blog-6/Prompt.html",
    "title": "More on reproducibility… – Prompt 6",
    "section": "",
    "text": "In Blog 5 you had the first exposure to Github Actions. We just checked frontmatter compliance (as we do for this round). You see that we have added a second action - here, we are converting the Rmarkdown document to a markdown file by running render_rmarkdown on Github. This action passes successfully for this document. We want to do something similar for blog #4.\nNow start reading …\nRead the vignette Introduction to renv for the renv R package by Kevin Ushey.\nThen do:\n\nInstall the R package renv on your local machine.\n\n1b. Go to your blog 4 repo, and run the command usethis::use_github_action(\"render-rmarkdown.yaml\") This creates the file render-rmarkdown.yaml inside the folder .github/workflows in your repo. Add it to the repository and push it.\n1c. Optional - but maybe educational: make a change to your Rmd file with the blog post (just a small change), and push it. Then go to your github site and watch the render-rmarkdown action fail.\n\nIn the project for blog 4, initialize the workflow used by the renv package.\nAdd all dependencies to the environment (implicitly by installing all the dependencies or explicitly by listing dependencies in a DESCRIPTION file).\nAdd the renv folder to your blog 4 repository, and push the changes.\nIs the github action working? Read any potential error messages in the workflow and try to fix things. Make sure to check stackoverflow for help, don’t forget our Discussion board!\n\nWrite a blog post addressing the following questions:\n\nWhat is the idea of the renv package?\nIn 50 to 100 words describe your experience working with renv. What went well? What did not go so well?\n\nSubmit this blog post to your blog-6 repo.\nAdditional resources in case you get stuck: https://www.youtube.com/watch?v=GwVx_pf2uz4&ab_channel=PositPBC"
  },
  {
    "objectID": "blog-2023/Prompts/Blog-7/Prompt.html#prompt",
    "href": "blog-2023/Prompts/Blog-7/Prompt.html#prompt",
    "title": "All that legal stuff… – Prompt 7",
    "section": "Prompt:",
    "text": "Prompt:\nThe DESCRIPTION file of a package contains the package’s meta information. Most of the fields in this file are quite straight forward: author, version number, and a short package description. When you call library(help=\"<package name>\") for package <package name> you can see the contents of the DESCRIPTION file for that package (and some parts of the NAMESPACE file).\nRead through Colin Fay’s (short) book on Licensing R\nWrite a blog post addressing the following questions:\n\nUnder what license does R operate? What is the license for ggplot2?\n\n\nWhat are the dependencies of the package you made?\nRead through chapter 5.2 of Licensing R. Combine and adjust the code pieces to create the dependencies for a package that is on github rather than CRAN. (Don’t forget about the package desc.) What dependencies does the package have that you created for Lab-3? Which licenses are involved? Are all of these dependencies required? Elaborate.\nUnder which license should this blog post be published? Make sure that you are using an appropriate license. (You can change the current licenses with the help of commands from the use_license_XXX family in the usethis package)\n\n\nCan I publish an R package on CRAN under an MIT license when I have a dependency on a package that is licensed under GPL-3?\nWhen confronted with the above question, ChatGPT gave two – quite different – responses, as shown below. The main point in both responses is ‘your package may be considered derivative work’. At the specific problem of the package developed for Lab 3, what is your opinion about potential copyright infringements when releasing the package with an MIT license? Make sure to take the relevant passage in Colin Fay’s book under consideration.\nThe legal implications of publishing an R package on CRAN under an MIT license while having a dependency on a package that is licensed under GPL-3 are complex and can vary depending on the specific circumstances. It is always advisable to seek legal advice from a licensed attorney if you have any doubts or concerns about licensing issues.\n\nHowever, in general, it is possible to publish an R package on CRAN under an MIT license when you have a dependency on a package that is licensed under GPL-3. This is because the MIT license is a permissive open-source license that allows for more flexibility in how the software can be used and distributed, and it is generally considered compatible with the GPL-3 license.\n\nThat being said, if your package depends on a GPL-3-licensed package, your package may be considered a derivative work and therefore subject to the terms of the GPL-3 license. This means that if you distribute your package, you may need to also distribute the source code for your package under the GPL-3 license or a compatible license, and you may need to ensure that the requirements of the GPL-3 license are met for the entire distribution, including any dependencies.\n\nIt is also worth noting that the R community has its own guidelines and recommendations for package licensing, and it is important to comply with these guidelines if you want to publish your package on CRAN. The CRAN Repository Policy states that packages should have a \"permissive\" or \"GPL-compatible\" license, but does not explicitly require that packages use the GPL license or any other specific license.\n\nIn summary, while it is possible to publish an R package on CRAN under an MIT license while having a dependency on a package that is licensed under GPL-3, it is important to understand the implications of the different licenses and to ensure that you comply with any applicable guidelines and recommendations from the R community.\nAfter harping a bit on copyright infringement in general, ChatGPT changed its response to\nTechnically, you can publish an R package on CRAN under an MIT license when you have a dependency on a package that is licensed under GPL-3, but doing so would not be compliant with the terms of the GPL-3 license.\n\nThe GPL-3 license is a strong copyleft license that requires derivative works to be released under the same license. If your package depends on a GPL-3-licensed package, your package may be considered a derivative work and therefore must be licensed under the GPL-3 license or a compatible license.\n\nThe MIT license, on the other hand, is a permissive license that allows for more flexibility in how the software is used and distributed. However, it is not compatible with the GPL-3 license, and therefore cannot be used for derivative works of GPL-3-licensed software.\n\nPublishing an R package on CRAN under an MIT license when you have a dependency on a package that is licensed under GPL-3 would be a licensing violation, and could potentially result in legal action or other consequences. It is important to comply with the licensing requirements of all dependencies in your package to avoid any legal issues.\nThe ‘harping’ questions:\n\nIs it legal to publish an R package on CRAN under an MIT license when I have a dependency on a package that is licensed under GPL-3?\nIs it illegal to publish an R package on CRAN under an MIT license when I have a dependency on a package that is licensed under GPL-3?\nIs it a copyright infringement to publish an R package on CRAN under an MIT license when I have a dependency on a package that is licensed under GPL-3?\nCan I publish an R package on CRAN under an MIT license when I have a dependency on a package that is licensed under GPL-3 without infringing copyright?"
  },
  {
    "objectID": "blog-2023/Prompts/Blog-7/Prompt.html#submission",
    "href": "blog-2023/Prompts/Blog-7/Prompt.html#submission",
    "title": "All that legal stuff… – Prompt 7",
    "section": "Submission",
    "text": "Submission\nWrite answers to the questions directly into the file README.Rmd. Push the blog post to your blog-7 repo. Make sure that all of the checks are passing."
  },
  {
    "objectID": "blog-2023/Prompts/Blog-9/Prompt.html",
    "href": "blog-2023/Prompts/Blog-9/Prompt.html",
    "title": "Fix a thing – Prompt 9",
    "section": "",
    "text": "This blog prompt is extremely simple: fix one of the problems in one of our community packages at https://github.com/Stat585-at-ISU/lab-3-all-all-for-one-and-one-for-all, and write about it."
  },
  {
    "objectID": "blog-2023/Prompts/Blog-9/Prompt.html#instructions",
    "href": "blog-2023/Prompts/Blog-9/Prompt.html#instructions",
    "title": "Fix a thing – Prompt 9",
    "section": "Instructions:",
    "text": "Instructions:\nWhat we want to know is the exact warning or error message of the item you fixed, and a description of what you did, also as specific as possible."
  },
  {
    "objectID": "blog-2023/Prompts/Blog-9/Prompt.html#submission",
    "href": "blog-2023/Prompts/Blog-9/Prompt.html#submission",
    "title": "Fix a thing – Prompt 9",
    "section": "Submission",
    "text": "Submission\nPush the blog post to your blog-9 repo. Make sure that the yaml-front-matter check passes."
  },
  {
    "objectID": "blog-2023/Prompts/Blog-10/Prompt.html",
    "href": "blog-2023/Prompts/Blog-10/Prompt.html",
    "title": "Web scraping etiquette … – Prompt 10",
    "section": "",
    "text": "With great power comes great responsibility - a large part of the web is based on data and services that scrape those data. Now that we start to apply scraping mechanisms, we need to think about how to apply those skills without becoming a burden to the internet society.\nFind sources on ethical web scraping - some readings that might help you get started with that are:\n\nJames Densmore\nR package polite\nJAMI @ EMPIRICAL\n\nAfter reading through some of the ethics essays write a blog post addressing the following questions:\n\nWhat are your main three takeaways for ethical web scraping? - Give examples, or cite your sources.\nWhat is a ROBOTS.TXT file? Identify one instance and explain what it allows/prevents.\nIdentify a website that you would like to scrape (or one an example from class) and implement a scrape using the polite package.\n\nInstructions:\nSubmit to your repo. Make sure that all of the github actions pass (check menu item Actions - all of the actions should have green checks)"
  },
  {
    "objectID": "blog-2023/Blog-4-submissions/xyzyc/YingchaoZhou.html",
    "href": "blog-2023/Blog-4-submissions/xyzyc/YingchaoZhou.html",
    "title": "Split, apply, combine",
    "section": "",
    "text": "The plyr package has by now been replaced by other, even faster packages, but the idea of Split, apply, combine is as relevant as ever.\nRead the paper The Split-Apply-Combine Strategy for Data Analysis by Hadley Wickham.\nWrite a blog post addressing the following questions:\n\nThe R code for the split-apply-combine paper is posted with the paper. Pick one of the examples demonstrating plyr functionality (such as dlply or ddply, …) and rewrite the example using functionality from the package dplyr. Make sure that your example works and the results are identical.\nWhich (base R) functions do you know that support the split-apply-combine strategy? In your opinion, are these sufficient? State why or why not?\nThe ChatGPT response to the prompt “Describe the split-apply-combine paradigm” is given below. Generally, the chatbot’s answers are decent. ChatGPT does have problems getting details right. Which details would you change in the response?\n\n\nThe “split-apply-combine” paradigm is a data analysis strategy used in statistics and data science to analyze grouped data. It consists of three steps:\nSplit: The data is first split into groups based on one or more variables of interest.\nApply: A specific operation or function is applied to each group of data, usually for the purpose of aggregating, summarizing, or transforming the data within each group.\nCombine: The results of the operation applied to each group are then combined and returned as a single output.\nThe split-apply-combine paradigm is particularly useful in cases where the data cannot be analyzed as a whole and instead must be analyzed in smaller, more manageable chunks. This allows for more efficient data processing and improved scalability. The paradigm is commonly implemented using tools such as the “groupby” function in the R and Python programming languages, and the “dplyr” library in R.\n\nYou can write your answers directly the README.Rmd file. Make sure that the file knits (you will need to activate any packages your use in your code chunks with a call to library(xxx), where xxx is the name of the package, such as plyr ). Commit your changes and push to your repo; add any files in the README_files directory to your repository.\n\n\nI choose ddply.\nCheck out ddply first:\n\nlibrary(\"ggplot2\")\nlibrary(\"plyr\")\noptions(digits = 3)\n\n## check original baseball dataset first\nhead(baseball[,c(\"id\", \"year\")])\n#>            id year\n#> 4   ansonca01 1871\n#> 44  forceda01 1871\n#> 68  mathebo01 1871\n#> 99  startjo01 1871\n#> 102 suttoez01 1871\n#> 106 whitede01 1871\n\n\nbaseball1 <- ddply(baseball, .(id), transform, \n  cyear = year - min(year) + 1)\nhead(baseball1[,c(\"id\", \"year\", \"cyear\")])\n#>          id year cyear\n#> 1 aaronha01 1954     1\n#> 2 aaronha01 1955     2\n#> 3 aaronha01 1956     3\n#> 4 aaronha01 1957     4\n#> 5 aaronha01 1958     5\n#> 6 aaronha01 1959     6\n\nThis operation creates a new variable “cyear”, which is the year of a record minus the minimum year record for the same id, then plus 1. We also notice the records are grouped by the same id.\nWe can take a closer look for id “aaronha01” to make sure we have the right understanding:\n\nbaseball[baseball$id == \"aaronha01\",c(\"id\", \"year\")]\n#>              id year\n#> 37157 aaronha01 1954\n#> 37795 aaronha01 1955\n#> 38408 aaronha01 1956\n#> 39023 aaronha01 1957\n#> 39645 aaronha01 1958\n#> 40291 aaronha01 1959\n#> 40921 aaronha01 1960\n#> 41642 aaronha01 1961\n#> 42323 aaronha01 1962\n#> 43076 aaronha01 1963\n#> 43824 aaronha01 1964\n#> 44578 aaronha01 1965\n#> 45338 aaronha01 1966\n#> 46122 aaronha01 1967\n#> 46880 aaronha01 1968\n#> 47703 aaronha01 1969\n#> 48618 aaronha01 1970\n#> 49524 aaronha01 1971\n#> 50416 aaronha01 1972\n#> 51294 aaronha01 1973\n#> 52200 aaronha01 1974\n#> 52657 aaronha01 1975\n#> 53564 aaronha01 1976\n\n\nbaseball1[baseball1$id == \"aaronha01\",c(\"id\", \"year\", \"cyear\")]\n#>           id year cyear\n#> 1  aaronha01 1954     1\n#> 2  aaronha01 1955     2\n#> 3  aaronha01 1956     3\n#> 4  aaronha01 1957     4\n#> 5  aaronha01 1958     5\n#> 6  aaronha01 1959     6\n#> 7  aaronha01 1960     7\n#> 8  aaronha01 1961     8\n#> 9  aaronha01 1962     9\n#> 10 aaronha01 1963    10\n#> 11 aaronha01 1964    11\n#> 12 aaronha01 1965    12\n#> 13 aaronha01 1966    13\n#> 14 aaronha01 1967    14\n#> 15 aaronha01 1968    15\n#> 16 aaronha01 1969    16\n#> 17 aaronha01 1970    17\n#> 18 aaronha01 1971    18\n#> 19 aaronha01 1972    19\n#> 20 aaronha01 1973    20\n#> 21 aaronha01 1974    21\n#> 22 aaronha01 1975    22\n#> 23 aaronha01 1976    23\n\nNext we rewrite this example using dplyr:\n\nlibrary(dplyr)\n#> \n#> Attaching package: 'dplyr'\n#> The following objects are masked from 'package:plyr':\n#> \n#>     arrange, count, desc, failwith, id, mutate, rename, summarise,\n#>     summarize\n#> The following objects are masked from 'package:stats':\n#> \n#>     filter, lag\n#> The following objects are masked from 'package:base':\n#> \n#>     intersect, setdiff, setequal, union\nbaseball %>% group_by(id) %>%\n  arrange(id) %>%\n  mutate(cyear = year - min(year) + 1) -> baseball2\n\nCheck whether the two datasets are the same.\n\nbaseball1 %>% select_if(~ !any(is.na(.))) -> baseball1\nbaseball2 %>% select_if(~ !any(is.na(.))) -> baseball2\n\nsum(baseball1 != baseball2)\n#> [1] 0\n\n\n\n\nI know some functions in the “apply” family can do split-apply-combine operations, like apply, lapply, sapply. I think these are useful functions and can get a lot of work done. But sometimes they are tricky in what type of data they would take, the specification of dimension, etc. For example, lapply can take a list or vector and return a list, which takes a lot of space when the list object is large.\n\n\n\nThere is no groupby function in R. I would say SQL has a group by operator and SAS has a by operator."
  },
  {
    "objectID": "blog-2023/Blog-4-submissions/kundan7kumar/index.html",
    "href": "blog-2023/Blog-4-submissions/kundan7kumar/index.html",
    "title": "The Split-Apply-Combine Strategy for Data Analysis",
    "section": "",
    "text": "The plyr package has by now been replaced by other, even faster packages, but the idea of Split, apply, combine is as relevant as ever.\nRead the paper The Split-Apply-Combine Strategy for Data Analysis by Hadley Wickham.\nWrite a blog post addressing the following questions:\n\nThe R code for the split-apply-combine paper is posted with the paper. Pick one of the examples demonstrating plyr functionality (such as dlply or ddply, …) and rewrite the example using functionality from the package dplyr. Make sure that your example works and the results are identical.\n\nSolution: The author talks about the split-combine strategy for data analysis. This concept is similar to map -reduce technique for processing huge datasets. Split and apply is similar to map in which data is divided in the some with some criteria, while combine correspond to reduce combination of all datasets results into similar data structure and finally summarized the overall results.\nThe detailed r code for ‘dplyr’ package as below\n\nlibrary(dplyr)\n#> \n#> Attaching package: 'dplyr'\n#> The following objects are masked from 'package:stats':\n#> \n#>     filter, lag\n#> The following objects are masked from 'package:base':\n#> \n#>     intersect, setdiff, setequal, union\nlibrary(plyr)\n#> ------------------------------------------------------------------------------\n#> You have loaded plyr after dplyr - this is likely to cause problems.\n#> If you need functions from both plyr and dplyr, please load plyr first, then dplyr:\n#> library(plyr); library(dplyr)\n#> ------------------------------------------------------------------------------\n#> \n#> Attaching package: 'plyr'\n#> The following objects are masked from 'package:dplyr':\n#> \n#>     arrange, count, desc, failwith, id, mutate, rename, summarise,\n#>     summarize\nlibrary(Lahman)\nlibrary(purrr)\n#> \n#> Attaching package: 'purrr'\n#> The following object is masked from 'package:plyr':\n#> \n#>     compact\nlibrary(broom)\nlibrary(ggplot2)\n\ndata(\"baseball\",package = \"plyr\")\n \n# Now Base ball case study\nhead(baseball)\n#>            id year stint team lg  g  ab  r  h X2b X3b hr rbi sb cs bb so ibb\n#> 4   ansonca01 1871     1  RC1    25 120 29 39  11   3  0  16  6  2  2  1  NA\n#> 44  forceda01 1871     1  WS3    32 162 45 45   9   4  0  29  8  0  4  0  NA\n#> 68  mathebo01 1871     1  FW1    19  89 15 24   3   1  0  10  2  1  2  0  NA\n#> 99  startjo01 1871     1  NY2    33 161 35 58   5   1  1  34  4  2  3  0  NA\n#> 102 suttoez01 1871     1  CL1    29 128 35 45   3   7  3  23  3  1  1  0  NA\n#> 106 whitede01 1871     1  CL1    29 146 40 47   6   5  1  21  2  2  4  1  NA\n#>     hbp sh sf gidp\n#> 4    NA NA NA   NA\n#> 44   NA NA NA   NA\n#> 68   NA NA NA   NA\n#> 99   NA NA NA   NA\n#> 102  NA NA NA   NA\n#> 106  NA NA NA   NA\n\n\n# Summaries\nsummarise(baseball,nteam=length(unique(team)))\n#>   nteam\n#> 1   132\nsummarise(baseball,nplayers=length(unique(id)))\n#>   nplayers\n#> 1     1228\n\n\n# mutate and filter\nbaberuth <- filter(baseball, id == \"ruthba01\") %>%\n  mutate(cyear = year - min(year) + 1)\n \n# plot line graph\nggplot(baberuth, aes(x = cyear, y = rbi / ab)) +\n  geom_line()\n\n\n\n\n\n# Filter based on condition\nbaseball <- baseball %>%\n  filter(ab >= 25)\n \n# Adding cyear \nbaseball <- baseball %>%\n  group_by(id) %>%\n  mutate(cyear = year - min(year) + 1) %>%\n  ungroup()\n \n# fitting a Model \nmodel <- function(df) {\n  coef_df <- as.data.frame(t(coef(lm(rbi / ab ~ cyear, data = df))))\n  names(coef_df) <- c(\"intercept\", \"slope\")\n  rsq <- summary(lm(rbi / ab ~ cyear, data = df))$r.squared\n  coef_df$rsquare <- rsq\n  return(coef_df)\n}\nbmodels <- baseball %>%\n  group_by(id) %>%\n  do(model(.))\n \nbcoefs <- bind_rows(bmodels)\n \nbaseballcoef <- left_join(baseball, bcoefs, by = \"id\")\n \n# R-squared\nsubset(baseballcoef, rsquare > 0.999)$id\n#>  [1] \"lindbpa01\" \"carrocl02\" \"lindbpa01\" \"carrocl02\" \"jacksgr01\" \"jacksgr01\"\n#>  [7] \"splitpa01\" \"woodwi01\"  \"splitpa01\" \"woodwi01\"  \"bannifl01\" \"bannifl01\"\n#> [13] \"bedrost01\" \"davisma01\" \"penaal01\"  \"davisma01\" \"penaal01\"  \"bedrost01\"\n#> [19] \"powerte01\" \"cookde01\"  \"powerte01\" \"cookde01\"  \"violafr01\" \"violafr01\"\n#> [25] \"wakefti01\" \"wakefti01\" \"weathda01\" \"weathda01\" \"burbada01\" \"burbada01\"\n#> [31] \"oliveda02\" \"oliveda02\"\n \n# histogram  R-squared\nggplot(bcoefs, aes(x = rsquare)) +\n  geom_histogram(binwidth = 0.01)\n#> Warning: Removed 1 rows containing non-finite values (`stat_bin()`).\n\n\n\n\n\nWhich (base R) functions do you know that support the split-apply-combine strategy? In your opinion, are these sufficient? State why or why not?\n\nSolution: The base R functions which supports split-apply-combine.\n\nsplit() : This function splits data frame into groups based on the certain criteria.\napply() : This functions applies to rows/columns of a matrices or array.These are few apply functions.\n\ntapply() : It applies to subsets of a vector defined by one or more factors.\nsapply() : It applies to each element of a list or vector and simplifies the results into a vector or matrix.\nlapply() : It applies to each element of a list and returns a list of the same length.\n\naggregate() : This functions is used to group data by one or more variables. It is used to combine the results into a new data frame.\n\nThese functions are not sufficient to split-apply-combine strategy.These base R function that supports the split-apply-combine strategy. These base function has limited functionality and cannot be sufficient functionality to accomplish complex data manipulation. For e.g. aggregate() splits a data frame into subsets based on criteria and also used to compute a summary statistic. This is good for simpler tasks. It is not best option for more complex tasks, which requires several steps/loops and also cannot handle missing data very well, thus lead to inefficient for large data-sets.\nSo, R packages like dplyr, plyr etc provides flexible and efficient packaging for complex grouping, filtering and summarizing. These packages provides efficient and optimized code for working with large data-sets.\n\nThe ChatGPT response to the prompt “Describe the split-apply-combine paradigm” is given below. Generally, the chatbot’s answers are decent. ChatGPT does have problems getting details right. Which details would you change in the response?\n\n\nThe “split-apply-combine” paradigm is a data analysis strategy used in statistics and data science to analyze grouped data. It consists of three steps:\nSplit: The data is first split into groups based on one or more variables of interest.\nApply: A specific operation or function is applied to each group of data, usually for the purpose of aggregating, summarizing, or transforming the data within each group.\nCombine: The results of the operation applied to each group are then combined and returned as a single output.\nThe split-apply-combine paradigm is particularly useful in cases where the data cannot be analyzed as a whole and instead must be analyzed in smaller, more manageable chunks. This allows for more efficient data processing and improved scalability. The paradigm is commonly implemented using tools such as the “groupby” function in the R and Python programming languages, and the “dplyr” library in R.\n\nSolution:\nThe ChatGPT response are very basic, it didn’t have explain these three terms very well and which functions requires to perform this tasks. It can be explained better. One examples is:\n\nSplit: It divides the data into groups based on or more criteria/variables. This can be achieved by split() function or group by function.\nApply: This operation applies to each group of data separately which is used for aggregating, transforming and summarizing the data within each group. It can be done by lapply, tapply, or summarize functions.\nCombine: This operations applies to each group combined and return a single output .This can be done by functions like rbind, cbind,aggregate, or bind_rows.\n\nIn general, More detailed explanation will be helpful to understand the concepts. Moreover, Providing few examples of specific functions can be used for each step of the split-apply-combine paradigm will be really helpful.\n\nYou can write your answers directly the README.Rmd file. Make sure that the file knits (you will need to activate any packages your use in your code chunks with a call to library(xxx), where xxx is the name of the package, such as plyr ). Commit your changes and push to your repo; add any files in the README_files directory to your repository."
  },
  {
    "objectID": "blog-2023/Blog-4-submissions/anyeshar/RayAnyesha.html",
    "href": "blog-2023/Blog-4-submissions/anyeshar/RayAnyesha.html",
    "title": "plyr to dplyr",
    "section": "",
    "text": "The plyr package has by now been replaced by other, even faster packages, but the idea of Split, apply, combine is as relevant as ever.\nRead the paper The Split-Apply-Combine Strategy for Data Analysis by Hadley Wickham.\nWrite a blog post addressing the following questions:\n\nThe R code for the split-apply-combine paper is posted with the paper. Pick one of the examples demonstrating plyr functionality (such as dlply or ddply, …) and rewrite the example using functionality from the package dplyr. Make sure that your example works and the results are identical.\n\n\nlibrary(plyr)\nlibrary(dplyr)\n#> \n#> Attaching package: 'dplyr'\n#> The following objects are masked from 'package:plyr':\n#> \n#>     arrange, count, desc, failwith, id, mutate, rename, summarise,\n#>     summarize\n#> The following objects are masked from 'package:stats':\n#> \n#>     filter, lag\n#> The following objects are masked from 'package:base':\n#> \n#>     intersect, setdiff, setequal, union\n\nbaseball <- ddply(baseball, .(id), transform,\n  cyear = year - min(year) + 1)\n\n\n#using dplyr\nbaseball%>%\n  group_by(id)%>%\n  mutate(cyear = year - min(year) + 1)\n#> # A tibble: 21,699 × 23\n#> # Groups:   id [1,228]\n#>    id     year stint team  lg        g    ab     r     h   X2b   X3b    hr   rbi\n#>    <chr> <int> <int> <chr> <chr> <int> <int> <int> <int> <int> <int> <int> <int>\n#>  1 aaro…  1954     1 ML1   NL      122   468    58   131    27     6    13    69\n#>  2 aaro…  1955     1 ML1   NL      153   602   105   189    37     9    27   106\n#>  3 aaro…  1956     1 ML1   NL      153   609   106   200    34    14    26    92\n#>  4 aaro…  1957     1 ML1   NL      151   615   118   198    27     6    44   132\n#>  5 aaro…  1958     1 ML1   NL      153   601   109   196    34     4    30    95\n#>  6 aaro…  1959     1 ML1   NL      154   629   116   223    46     7    39   123\n#>  7 aaro…  1960     1 ML1   NL      153   590   102   172    20    11    40   126\n#>  8 aaro…  1961     1 ML1   NL      155   603   115   197    39    10    34   120\n#>  9 aaro…  1962     1 ML1   NL      156   592   127   191    28     6    45   128\n#> 10 aaro…  1963     1 ML1   NL      161   631   121   201    29     4    44   130\n#> # … with 21,689 more rows, and 10 more variables: sb <int>, cs <int>, bb <int>,\n#> #   so <int>, ibb <int>, hbp <int>, sh <int>, sf <int>, gidp <int>, cyear <dbl>\n\nI chose to replace the ddply function. ddply splits data frames by variables, which can be done in dplyr with group_by. mutate creates new columns that are functions of existing variables.\n\nWhich (base R) functions do you know that support the split-apply-combine strategy? In your opinion, are these sufficient? State why or why not?\n\n\nsplit()\nlapply()\nrbind()\n\nare all functions in base R. I think they work well, but maybe not as efficiently as plyr. However, I do believe they are sufficient. I use rbind and lapply() all the time.\n\nThe ChatGPT response to the prompt “Describe the split-apply-combine paradigm” is given below. Generally, the chatbot’s answers are decent. ChatGPT does have problems getting details right. Which details would you change in the response?\n\nFirst thing is, I wouldn’t say “analyze grouped data”. To me, it isn’t incorrect, just not great wording. It also missed that split-apply-combine can be used in base R and plyr. Also, it missed that it is a paradigm and therefor has many applications outside of just data cleaning and manipulation. As Hadley Wickham’s paper says, you can use it in modeling and visualization as well."
  },
  {
    "objectID": "blog-2023/Blog-4-submissions/Landon-Getting/index.html",
    "href": "blog-2023/Blog-4-submissions/Landon-Getting/index.html",
    "title": "dplyr vs plyr",
    "section": "",
    "text": "# loading in necessary libraries and data sets\nlibrary(plyr)\nlibrary(dplyr)\ndata(\"baseball\")\nRead the paper The Split-Apply-Combine Strategy for Data Analysis by Hadley Wickham."
  },
  {
    "objectID": "blog-2023/Blog-4-submissions/Landon-Getting/index.html#question-1---dplyr-and-plyr",
    "href": "blog-2023/Blog-4-submissions/Landon-Getting/index.html#question-1---dplyr-and-plyr",
    "title": "dplyr vs plyr",
    "section": "Question 1 - dplyr and plyr",
    "text": "Question 1 - dplyr and plyr\nThe R code for the split-apply-combine paper is posted with the paper. Pick one of the examples demonstrating plyr functionality (such as dlply or ddply, …) and rewrite the example using functionality from the package dplyr. Make sure that your example works and the results are identical.\nIn the baseball case study, Hadley first shows an example where we need to create a new column called “cyear” which states how long the player has been playing. Since each row represents a year, this calculation needs to be preformed for every row. He starts by using Base R functions to accomplish this operation for a single player.\n\nbaberuth <- subset(baseball, id == \"ruthba01\") # similiar to dplyr filter\n\nbaberuth <- transform(baberuth, \n                      cyear = year - min(year) + 1) # similiar to dplyr mutate\n\nbaberuth[,c(\"id\",\"year\",\"cyear\",\"rbi\")] # checking to see if it worked\n#>             id year cyear rbi\n#> 14646 ruthba01 1914     1   2\n#> 15457 ruthba01 1915     2  21\n#> 16238 ruthba01 1916     3  15\n#> 16776 ruthba01 1917     4  12\n#> 17286 ruthba01 1918     5  66\n#> 17790 ruthba01 1919     6 114\n#> 18329 ruthba01 1920     7 137\n#> 18834 ruthba01 1921     8 171\n#> 19363 ruthba01 1922     9  99\n#> 19883 ruthba01 1923    10 131\n#> 20420 ruthba01 1924    11 121\n#> 20967 ruthba01 1925    12  66\n#> 21507 ruthba01 1926    13 150\n#> 22038 ruthba01 1927    14 164\n#> 22572 ruthba01 1928    15 142\n#> 23110 ruthba01 1929    16 154\n#> 23656 ruthba01 1930    17 153\n#> 24167 ruthba01 1931    18 163\n#> 24694 ruthba01 1932    19 137\n#> 25199 ruthba01 1933    20 103\n#> 25702 ruthba01 1934    21  84\n#> 26477 ruthba01 1935    22  12\n\nNext, Hadley introduces ddply as a method to perform the calculation for each of the players for each of the years they played.\n\n# calculating how long every player has played using plyr\n# dataframe to dataframe\nbaseball_plyr <- ddply(baseball, # dataframe\n                  .(id), # split up by id\n                  transform, \n                  cyear = year - min(year) + 1) # processing function\n\nbaseball_plyr[baseball_plyr$id == \"ruthba01\",\n              c(\"id\",\"year\",\"cyear\",\"rbi\")] # checking to see if it worked\n#>             id year cyear rbi\n#> 17005 ruthba01 1914     1   2\n#> 17006 ruthba01 1915     2  21\n#> 17007 ruthba01 1916     3  15\n#> 17008 ruthba01 1917     4  12\n#> 17009 ruthba01 1918     5  66\n#> 17010 ruthba01 1919     6 114\n#> 17011 ruthba01 1920     7 137\n#> 17012 ruthba01 1921     8 171\n#> 17013 ruthba01 1922     9  99\n#> 17014 ruthba01 1923    10 131\n#> 17015 ruthba01 1924    11 121\n#> 17016 ruthba01 1925    12  66\n#> 17017 ruthba01 1926    13 150\n#> 17018 ruthba01 1927    14 164\n#> 17019 ruthba01 1928    15 142\n#> 17020 ruthba01 1929    16 154\n#> 17021 ruthba01 1930    17 153\n#> 17022 ruthba01 1931    18 163\n#> 17023 ruthba01 1932    19 137\n#> 17024 ruthba01 1933    20 103\n#> 17025 ruthba01 1934    21  84\n#> 17026 ruthba01 1935    22  12\n\nWith dplyr, I can perform this operation with mutate. Looks like it matches up with plyr!\n\n# dplyr one less line than plyr!\nbaseball_dplyr <- mutate(baseball, # dataframe to use\n                         cyear = year - min(year) + 1, # function to perform\n                         .by = id) # split by id\n\nbaseball_dplyr[baseball_dplyr$id == \"ruthba01\",\n              c(\"id\",\"year\",\"cyear\",\"rbi\")] # checking to see if it matches \n#>             id year cyear rbi\n#> 14646 ruthba01 1914     1   2\n#> 15457 ruthba01 1915     2  21\n#> 16238 ruthba01 1916     3  15\n#> 16776 ruthba01 1917     4  12\n#> 17286 ruthba01 1918     5  66\n#> 17790 ruthba01 1919     6 114\n#> 18329 ruthba01 1920     7 137\n#> 18834 ruthba01 1921     8 171\n#> 19363 ruthba01 1922     9  99\n#> 19883 ruthba01 1923    10 131\n#> 20420 ruthba01 1924    11 121\n#> 20967 ruthba01 1925    12  66\n#> 21507 ruthba01 1926    13 150\n#> 22038 ruthba01 1927    14 164\n#> 22572 ruthba01 1928    15 142\n#> 23110 ruthba01 1929    16 154\n#> 23656 ruthba01 1930    17 153\n#> 24167 ruthba01 1931    18 163\n#> 24694 ruthba01 1932    19 137\n#> 25199 ruthba01 1933    20 103\n#> 25702 ruthba01 1934    21  84\n#> 26477 ruthba01 1935    22  12"
  },
  {
    "objectID": "blog-2023/Blog-4-submissions/Landon-Getting/index.html#question-2---split-apply-combine-and-base-r",
    "href": "blog-2023/Blog-4-submissions/Landon-Getting/index.html#question-2---split-apply-combine-and-base-r",
    "title": "dplyr vs plyr",
    "section": "Question 2 - split, apply, combine and Base R",
    "text": "Question 2 - split, apply, combine and Base R\nWhich (base R) functions do you know that support the split-apply-combine strategy? In your opinion, are these sufficient? State why or why not?\nThe only Base R functions that I am familiar with that support the split-apply-combine strategy are split() and lapply(). Although I initially thought these would be adequate, Hadley makes a great point on page 4 of the paper when he discusses the lack of label continuity if utilizing the Base R functions. As demonstrated on the previous question, the plyr and dplyr functions are also nicely convenient and reduce the number of unique function calls."
  },
  {
    "objectID": "blog-2023/Blog-4-submissions/Landon-Getting/index.html#question-3---what-did-chatgpt-miss",
    "href": "blog-2023/Blog-4-submissions/Landon-Getting/index.html#question-3---what-did-chatgpt-miss",
    "title": "dplyr vs plyr",
    "section": "Question 3 - What did ChatGPT miss?",
    "text": "Question 3 - What did ChatGPT miss?\nThe ChatGPT response to the prompt “Describe the split-apply-combine paradigm” is given below. Generally, the chatbot’s answers are decent. ChatGPT does have problems getting details right. Which details would you change in the response?\n\nThe “split-apply-combine” paradigm is a data analysis strategy used in statistics and data science to analyze grouped data. It consists of three steps:\nSplit: The data is first split into groups based on one or more variables of interest.\nApply: A specific operation or function is applied to each group of data, usually for the purpose of aggregating, summarizing, or transforming the data within each group.\nCombine: The results of the operation applied to each group are then combined and returned as a single output.\nThe split-apply-combine paradigm is particularly useful in cases where the data cannot be analyzed as a whole and instead must be analyzed in smaller, more manageable chunks. This allows for more efficient data processing and improved scalability. The paradigm is commonly implemented using tools such as the “groupby” function in the R and Python programming languages, and the “dplyr” library in R.\n\nChatGPT’s definition of the ‘Split’ step is fairly short and suggests splitting based on some variables. Although this is correct, I think considering the split to be based on a conditional statement is more intuitive. This includes cases where you may need to perform a split-apply-combine (or other operations) just to create the variables necessary for a more complex split.\nIn addition, Hadley brings up an important assumption in page 2 of the paper that potentially should have been included in the closing paragraph of ChatGPT’s response:\n\n“Note that plyr makes the strong assumption that each piece of data will be processed only once and independently of all other pieces. This means that you can not use these tools when each iteration requires overlapping data (like a running mean), or it depends on the previous iteration (like in a dynamic simulation).”\n\nI think ChatGPT’s response may have been more robust if it included a short sentence on the limits or downsides of the approach in contrast to the efficiency and scaleability praise. However, it is amazing that it can provide such a response in the first place!"
  },
  {
    "objectID": "blog-2023/Blog-4-submissions/Hiiiua/index.html",
    "href": "blog-2023/Blog-4-submissions/Hiiiua/index.html",
    "title": "Split Apply Combine",
    "section": "",
    "text": "The plyr package has by now been replaced by other, even faster packages, but the idea of Split, apply, combine is as relevant as ever.\nRead the paper The Split-Apply-Combine Strategy for Data Analysis by Hadley Wickham.\nWrite a blog post addressing the following questions:\n\nThe R code for the split-apply-combine paper is posted with the paper. Pick one of the examples demonstrating plyr functionality (such as dlply or ddply, …) and rewrite the example using functionality from the package dplyr. Make sure that your example works and the results are identical.\n\n\nlibrary(plyr)\nbaseball <- baseball\nbaseball1 <- ddply(baseball, .(id), transform, cyear = year - min(year) + 1)\nhead(baseball1, 10)\n#>           id year stint team lg   g  ab   r   h X2b X3b hr rbi sb cs bb so ibb\n#> 1  aaronha01 1954     1  ML1 NL 122 468  58 131  27   6 13  69  2  2 28 39  NA\n#> 2  aaronha01 1955     1  ML1 NL 153 602 105 189  37   9 27 106  3  1 49 61   5\n#> 3  aaronha01 1956     1  ML1 NL 153 609 106 200  34  14 26  92  2  4 37 54   6\n#> 4  aaronha01 1957     1  ML1 NL 151 615 118 198  27   6 44 132  1  1 57 58  15\n#> 5  aaronha01 1958     1  ML1 NL 153 601 109 196  34   4 30  95  4  1 59 49  16\n#> 6  aaronha01 1959     1  ML1 NL 154 629 116 223  46   7 39 123  8  0 51 54  17\n#> 7  aaronha01 1960     1  ML1 NL 153 590 102 172  20  11 40 126 16  7 60 63  13\n#> 8  aaronha01 1961     1  ML1 NL 155 603 115 197  39  10 34 120 21  9 56 64  20\n#> 9  aaronha01 1962     1  ML1 NL 156 592 127 191  28   6 45 128 15  7 66 73  14\n#> 10 aaronha01 1963     1  ML1 NL 161 631 121 201  29   4 44 130 31  5 78 94  18\n#>    hbp sh sf gidp cyear\n#> 1    3  6  4   13     1\n#> 2    3  7  4   20     2\n#> 3    2  5  7   21     3\n#> 4    0  0  3   13     4\n#> 5    1  0  3   21     5\n#> 6    4  0  9   19     6\n#> 7    2  0 12    8     7\n#> 8    2  1  9   16     8\n#> 9    3  0  6   14     9\n#> 10   0  0  5   11    10\n\n\noptions(dplyr.width = Inf)\nlibrary(dplyr)\n#> \n#> Attaching package: 'dplyr'\n#> The following objects are masked from 'package:plyr':\n#> \n#>     arrange, count, desc, failwith, id, mutate, rename, summarise,\n#>     summarize\n#> The following objects are masked from 'package:stats':\n#> \n#>     filter, lag\n#> The following objects are masked from 'package:base':\n#> \n#>     intersect, setdiff, setequal, union\nbasketball2 <- baseball %>% group_by(id) %>% mutate(cyear = year-min(year)+1) %>% arrange(id)\nhead(basketball2, 10)\n#> # A tibble: 10 × 23\n#> # Groups:   id [1]\n#>    id         year stint team  lg        g    ab     r     h   X2b   X3b    hr\n#>    <chr>     <int> <int> <chr> <chr> <int> <int> <int> <int> <int> <int> <int>\n#>  1 aaronha01  1954     1 ML1   NL      122   468    58   131    27     6    13\n#>  2 aaronha01  1955     1 ML1   NL      153   602   105   189    37     9    27\n#>  3 aaronha01  1956     1 ML1   NL      153   609   106   200    34    14    26\n#>  4 aaronha01  1957     1 ML1   NL      151   615   118   198    27     6    44\n#>  5 aaronha01  1958     1 ML1   NL      153   601   109   196    34     4    30\n#>  6 aaronha01  1959     1 ML1   NL      154   629   116   223    46     7    39\n#>  7 aaronha01  1960     1 ML1   NL      153   590   102   172    20    11    40\n#>  8 aaronha01  1961     1 ML1   NL      155   603   115   197    39    10    34\n#>  9 aaronha01  1962     1 ML1   NL      156   592   127   191    28     6    45\n#> 10 aaronha01  1963     1 ML1   NL      161   631   121   201    29     4    44\n#>      rbi    sb    cs    bb    so   ibb   hbp    sh    sf  gidp cyear\n#>    <int> <int> <int> <int> <int> <int> <int> <int> <int> <int> <dbl>\n#>  1    69     2     2    28    39    NA     3     6     4    13     1\n#>  2   106     3     1    49    61     5     3     7     4    20     2\n#>  3    92     2     4    37    54     6     2     5     7    21     3\n#>  4   132     1     1    57    58    15     0     0     3    13     4\n#>  5    95     4     1    59    49    16     1     0     3    21     5\n#>  6   123     8     0    51    54    17     4     0     9    19     6\n#>  7   126    16     7    60    63    13     2     0    12     8     7\n#>  8   120    21     9    56    64    20     2     1     9    16     8\n#>  9   128    15     7    66    73    14     3     0     6    14     9\n#> 10   130    31     5    78    94    18     0     0     5    11    10\n\n\nWhich (base R) functions do you know that support the split-apply-combine strategy? In your opinion, are these sufficient? State why or why not?\nThe first function came into my mind is apply, because I can always write a function to fulfill the requirement. In terms of writing functions to complete tasks, apply is sufficient, but it’s time consuming and low efficient. It has to apply the function many times, store the result before writing it into the dataframe. Besides, users have to write function on their own, which also increases the time cost and risk of raising bugs.\nOperations in dplyr have different ways of completing tasks in terms of different objects (array, vector, list ect.). These nicely designed data structure save both time and space, which makes the split-apply-combine strategy efficiently implemented.\nThe ChatGPT response to the prompt “Describe the split-apply-combine paradigm” is given below. Generally, the chatbot’s answers are decent. ChatGPT does have problems getting details right. Which details would you change in the response?\n\n\nThe “split-apply-combine” paradigm is a data analysis strategy used in statistics and data science to analyze grouped data. It consists of three steps:\nSplit: The data is first split into groups based on one or more variables of interest.\nApply: A specific operation or function is applied to each group of data, usually for the purpose of aggregating, summarizing, or transforming the data within each group.\nCombine: The results of the operation applied to each group are then combined and returned as a single output.\nThe split-apply-combine paradigm is particularly useful in cases where the data cannot be analyzed as a whole and instead must be analyzed in smaller, more manageable chunks. This allows for more efficient data processing and improved scalability. The paradigm is commonly implemented using tools such as the “groupby” function in the R and Python programming languages, and the “dplyr” library in R.\n\nI think chatGPD got most of the part right except groupby is a function in Python does the grouping work, group_by is the function in R does the same work.\nYou can write your answers directly the README.Rmd file. Make sure that the file knits (you will need to activate any packages your use in your code chunks with a call to library(xxx), where xxx is the name of the package, such as plyr ). Commit your changes and push to your repo; add any files in the README_files directory to your repository."
  },
  {
    "objectID": "blog-2023/Blog-4-submissions/charlestbonk/index.html",
    "href": "blog-2023/Blog-4-submissions/charlestbonk/index.html",
    "title": "Title of your post",
    "section": "",
    "text": "The plyr package has by now been replaced by other, even faster packages, but the idea of Split, apply, combine is as relevant as ever.\nRead the paper The Split-Apply-Combine Strategy for Data Analysis by Hadley Wickham.\nWrite a blog post addressing the following questions:\n\nThe R code for the split-apply-combine paper is posted with the paper. Pick one of the examples demonstrating plyr functionality (such as dlply or ddply, …) and rewrite the example using functionality from the package dplyr. Make sure that your example works and the results are identical.\n\nI used the Baseball example with calculating the cyear.\n\n\n\nlibrary(tidyverse)\noptions(digits = 3)\n#options(prompt = \"R> \")\nbrightblue <- rgb(102, 204, 255, max = 255)\n\n# ----------------------------\n\n# Base ball case study ============================================\nbaberuth <- subset(plyr::baseball, id == \"ruthba01\")\nbaberuth <- transform(baberuth, cyear = year - min(year) + 1)\n\n\n# ----------------------------\n## The Original Code\nlibrary(plyr)\nbaseball.plyr <- ddply(baseball, .(id), transform, \n  cyear = year - min(year) + 1)\n## Making this a Dplyr Code\nbaseball.dplyr <- baseball%>%group_by(id)%>%mutate(cyear = year - min(year) + 1)\n\n\nWhich (base R) functions do you know that support the split-apply-combine strategy? In your opinion, are these sufficient? State why or why not?\n\nAll of the *apply() functions (like lapply(), mapply(), sapply(), etc) can help with the apply part of the split-apply-combine strategy.\nWe could also use concatination functions, like cbind() and rbind()\nWe can finally use functions like $ to separate in base R.\n\nThe ChatGPT response to the prompt “Describe the split-apply-combine paradigm” is given below. Generally, the chatbot’s answers are decent. ChatGPT does have problems getting details right. Which details would you change in the response?\n\n\nThe “split-apply-combine” paradigm is a data analysis strategy used in statistics and data science to analyze grouped data. It consists of three steps:\nSplit: The data is first split into groups based on one or more variables of interest.\nApply: A specific operation, function, or a group of functions is applied to each group of data, usually for the purpose of aggregating, summarizing, or transforming the data within each group.\nCombine: The results of the operation applied to each group are then combined and returned as a single output.\nThe split-apply-combine paradigm is particularly useful in cases where the data cannot be analyzed as a whole and instead must be analyzed in smaller, more manageable chunks. The slipt-apply-combine paradigm is also useful when the data must have multiple functions applied to one another. This allows for more efficient data processing and improved scalability. The paradigm is commonly implemented using tools such as the “group_by” function in the R and Python programming languages, and the “dplyr” library in R.\n\nYou can write your answers directly the README.Rmd file. Make sure that the file knits (you will need to activate any packages your use in your code chunks with a call to library(xxx), where xxx is the name of the package, such as plyr ). Commit your changes and push to your repo; add any files in the README_files directory to your repository."
  },
  {
    "objectID": "blog-2023/Blog-4-submissions/TWiedRW/index.html",
    "href": "blog-2023/Blog-4-submissions/TWiedRW/index.html",
    "title": "Split-apply-combine",
    "section": "",
    "text": "The plyr package has by now been replaced by other, even faster packages, but the idea of Split, apply, combine is as relevant as ever.\nRead the paper The Split-Apply-Combine Strategy for Data Analysis by Hadley Wickham.\nWrite a blog post addressing the following questions:\n1. The R code for the split-apply-combine paper is posted with the paper. Pick one of the examples demonstrating plyr functionality (such as dlply or ddply, …) and rewrite the example using functionality from the package dplyr. Make sure that your example works and the results are identical.\n\n\n#plyr approach\nlibrary(plyr)\n\n#Year with plyr\nbaberuth <- subset(baseball, id == \"ruthba01\")\nbaberuth <- transform(baberuth, cyear = year - min(year) + 1)\nbaseball <- ddply(baseball, .(id), transform,\n  cyear = year - min(year) + 1)\nbaseball_subset <- subset(baseball, ab >= 25)\n\n#Models with plyr\nmodel <- function(df) {\n lm(rbi / ab ~ cyear, data = df)\n}\nbmodels <- dlply(baseball_subset, .(id), model)\nrsq <- function(x) summary(x)$r.squared\nbcoefs <- ldply(bmodels, function(x) c(coef(x), rsquare = rsq(x)))\nnames(bcoefs)[2:3] <- c(\"intercept\", \"slope\")\nbaseballcoef <- merge(baseball_subset, bcoefs, by = \"id\")\nresults = subset(baseballcoef, rsquare > 0.999)$id\n\n\n\n#dplyr approach\nlibrary(dplyr)\n#> \n#> Attaching package: 'dplyr'\n#> The following objects are masked from 'package:plyr':\n#> \n#>     arrange, count, desc, failwith, id, mutate, rename, summarise,\n#>     summarize\n#> The following objects are masked from 'package:stats':\n#> \n#>     filter, lag\n#> The following objects are masked from 'package:base':\n#> \n#>     intersect, setdiff, setequal, union\nlibrary(purrr)\n#> \n#> Attaching package: 'purrr'\n#> The following object is masked from 'package:plyr':\n#> \n#>     compact\nlibrary(tidyr)\n\n#Year with dplyr\nbaseball2 <- baseball %>% \n  group_by(id) %>% \n  mutate(cyear2 = year - min(year) + 1)\n\n#Models with dplyr (and others)\nbaseball3 = baseball2 %>% \n  filter(ab >= 25) %>% \n  group_by(id) %>% \n  nest() %>% \n  mutate(bmodels = map(data, model),\n         bcoefs = map_dfr(bmodels, function(x)(c(coef(x), rsquare = rsq(x))))) %>% \n  unnest(bcoefs) %>%  \n  mutate(intercept = `(Intercept)`, slope = cyear) %>% \n  select(-`(Intercept)`, -cyear) %>% \n  unnest(data) %>% \n  filter(rsquare > 0.999)\n\n#Verify that the years are the same\nall(baseball$cyear == baseball2$cyear2)\n#> [1] TRUE\n\n#Verify that the players are the same\nall(baseball3$id == results)\n#> [1] TRUE\n\nFor this blog post, I chose the baseball example to work with. Getting the number of years is fairly straightforward with dplyr using the group_by function and mutate. The main differences show up when modeling the data to each player. With plyr, it first creates a list of models and then applies some functions to that list. This is not possible with dplyr alone, but it is possible with the help of tidyr (for the nest and unnest functions) and purrr (for the map function). The results come out to be the same, but plyr uses less code.\n2. Which (base R) functions do you know that support the split-apply-combine strategy? In your opinion, are these sufficient? State why or why not?\nThe base R functions that support the split-apply-combine strategy are the apply functions. I currently have found these apply functions to be sufficient and I often incorporate then whenever I can (even going as far to avoid for loops if I can help it). From the paper, it seems like the apply functions fall short when data takes more than two dimensions. They then require extra care to operate whereas the plyr functions extend the functionality of the apply functions more easily.\n3. The ChatGPT response to the prompt “Describe the split-apply-combine paradigm” is given below. Generally, the chatbot’s answers are decent. ChatGPT does have problems getting details right. Which details would you change in the response?\n\nThe “split-apply-combine” paradigm is a data analysis strategy used in statistics and data science to analyze grouped data. It consists of three steps:\nSplit: The data is first split into groups based on one or more variables of interest.\nApply: A specific operation or function is applied to each group of data, usually for the purpose of aggregating, summarizing, or transforming the data within each group.\nCombine: The results of the operation applied to each group are then combined and returned as a single output.\nThe split-apply-combine paradigm is particularly useful in cases where the data cannot be analyzed as a whole and instead must be analyzed in smaller, more manageable chunks. This allows for more efficient data processing and improved scalability. The paradigm is commonly implemented using tools such as the “groupby” function in the R and Python programming languages, and the “dplyr” library in R.\n\nI would have to say that ChatGPT is almost entirely correct, but the coding is a bit off. The groupby does not exist in R, and the tools necessary for the split-apply-combine paradigm need additional packages to use with dplyr. groupby is a simple fix by using group_by and the other useful packages are tidyr and purrr (along with plyr as another approach). In my experience of asking ChatGPT coding questions, it seems to combine different languages and/or syntaxes. Additionally, the apply step could use a little more expansion. This step could include more, such as using the data for some purpose such as modelling or graphing.\nA little off-topic, but another example of ChatGPT messing up a coding response is when I had it give me a mixed model using aov(), but used the random term syntax from lme4. It’s close, but not quite there."
  },
  {
    "objectID": "blog-2023/Blog-4-submissions/charchit/index.html",
    "href": "blog-2023/Blog-4-submissions/charchit/index.html",
    "title": "plyr and dplyr",
    "section": "",
    "text": "library(ggplot2)\nlibrary(plyr)\nlibrary(reshape)\n#> \n#> Attaching package: 'reshape'\n#> The following objects are masked from 'package:plyr':\n#> \n#>     rename, round_any\nlibrary(dplyr)\n#> \n#> Attaching package: 'dplyr'\n#> The following object is masked from 'package:reshape':\n#> \n#>     rename\n#> The following objects are masked from 'package:plyr':\n#> \n#>     arrange, count, desc, failwith, id, mutate, rename, summarise,\n#>     summarize\n#> The following objects are masked from 'package:stats':\n#> \n#>     filter, lag\n#> The following objects are masked from 'package:base':\n#> \n#>     intersect, setdiff, setequal, union\n\ndata <- baseball\n\nrbi <- ddply(baseball, .(year), summarise, mean_rbi = mean(rbi, na.rm = TRUE))\nhead(rbi)\n#>   year mean_rbi\n#> 1 1871 22.28571\n#> 2 1872 20.53846\n#> 3 1873 30.92308\n#> 4 1874 29.00000\n#> 5 1875 31.58824\n#> 6 1876 30.13333\n\n#using dplyr package\n\nb2 <- group_by(data, year)\nrbi2 <- summarize(b2,mean(rbi))\nhead(rbi2)\n#> # A tibble: 6 × 2\n#>    year `mean(rbi)`\n#>   <int>       <dbl>\n#> 1  1871        22.3\n#> 2  1872        20.5\n#> 3  1873        30.9\n#> 4  1874        29  \n#> 5  1875        31.6\n#> 6  1876        30.1"
  },
  {
    "objectID": "blog-2023/Blog-4-submissions/charchit/index.html#prompt",
    "href": "blog-2023/Blog-4-submissions/charchit/index.html#prompt",
    "title": "plyr and dplyr",
    "section": "Prompt:",
    "text": "Prompt:\nThe plyr package has by now been replaced by other, even faster packages, but the idea of Split, apply, combine is as relevant as ever.\nRead the paper The Split-Apply-Combine Strategy for Data Analysis by Hadley Wickham.\nWrite a blog post addressing the following questions:\n\nThe R code for the split-apply-combine paper is posted with the paper. Pick one of the examples demonstrating plyr functionality (such as dlply or ddply, …) and rewrite the example using functionality from the package dplyr. Make sure that your example works and the results are identical.\n\nCheck the code above.\n\nWhich (base R) functions do you know that support the split-apply-combine strategy? In your opinion, are these sufficient? State why or why not?\n\nThe base R has functions like arrange, apply which can be combined with other functions like aggregate to use the split-combine strategy or even simply data$variable to select the variable. Other base function like split, subset, cbind, rbind etc. can also be used.\nThese base functions can get the job done for simpler datasets but the users have to go through inconsistent syntax to find the solution. However, it will be very hard working with higher dimensional data and different data structures as the paper mentioned.\n\nThe ChatGPT response to the prompt “Describe the split-apply-combine paradigm” is given below. Generally, the chatbot’s answers are decent. ChatGPT does have problems getting details right. Which details would you change in the response?\n\n\nThe “split-apply-combine” paradigm is a data analysis strategy used in statistics and data science to analyze grouped data. It consists of three steps:\nSplit: The data is first split into groups based on one or more variables of interest.\nApply: A specific operation or function is applied to each group of data, usually for the purpose of aggregating, summarizing, or transforming the data within each group.\nCombine: The results of the operation applied to each group are then combined and returned as a single output.\nThe split-apply-combine paradigm is particularly useful in cases where the data cannot be analyzed as a whole and instead must be analyzed in smaller, more manageable chunks. This allows for more efficient data processing and improved scalability. The paradigm is commonly implemented using tools such as the “groupby” function in the R and Python programming languages, and the “dplyr” library in R.\n\nI think ChatGPT explained it well enough. The first thing which I caught was “groupby” function it has given as answer. Clearly, I have used above is “group_by” but ChatGPT mentioned it confidently in the quotation marks that it will be “groupby”. In python as far as I know, the library is pandas. So, that does not seem right in the response above.\nI will be interested in hearing other students thoughts on this and what I mistakes I did not catch in the ChatGPT response.\nYou can write your answers directly the README.Rmd file. Make sure that the file knits (you will need to activate any packages your use in your code chunks with a call to library(xxx), where xxx is the name of the package, such as plyr ). Commit your changes and push to your repo; add any files in the README_files directory to your repository."
  },
  {
    "objectID": "blog-2023/Blog-4-submissions/kellynay/index.html",
    "href": "blog-2023/Blog-4-submissions/kellynay/index.html",
    "title": "Testing the ‘dplyr’ functionality",
    "section": "",
    "text": "The plyr package has by now been replaced by other, even faster packages, but the idea of Split, apply, combine is as relevant as ever.\nRead the paper The Split-Apply-Combine Strategy for Data Analysis by Hadley Wickham.\nWrite a blog post addressing the following questions:\n\nThe R code for the split-apply-combine paper is posted with the paper. Pick one of the examples demonstrating plyr functionality (such as dlply or ddply, …) and rewrite the example using functionality from the package dplyr. Make sure that your example works and the results are identical.\n\n#Case study Baseball: #Example page 14:\n\n# Using \"plyr\" package\n\nlibrary(\"plyr\")\n# Get performance of a batter over his career\n# Calculate \"career year\"\n\nbaberuth <- subset(baseball, id == \"ruthba01\")\nbaberuth_plyr <- transform(baberuth, cyear = year - min(year) + 1)\n\n# Do the same for all players\n\nbaseball_all <- ddply(baseball, .(id), transform,\n    cyear = year - min(year) + 1)\n\n#Example page 14:\n\n# Using \"dplyr\" package\nlibrary(\"tidyr\")\nlibrary(\"dplyr\")\n#> \n#> Attaching package: 'dplyr'\n#> The following objects are masked from 'package:plyr':\n#> \n#>     arrange, count, desc, failwith, id, mutate, rename, summarise,\n#>     summarize\n#> The following objects are masked from 'package:stats':\n#> \n#>     filter, lag\n#> The following objects are masked from 'package:base':\n#> \n#>     intersect, setdiff, setequal, union\n\n# Calculate \"career year\"\n\nbaberuth <- filter(baseball, id == \"ruthba01\")\nbaberuth_dplyr <- mutate(baberuth, cyear = year - min(year) + 1)\n\n# Do the same for all players\n\nbaseball <- baseball %>% group_by(id) %>%\n  mutate(cyear = year - min(year) + 1) %>%\n  arrange(baseball$id) %>% ungroup(id)\n\n\nWhich (base R) functions do you know that support the split-apply-combine strategy? In your opinion, are these sufficient? State why or why not?\n\nNested loops or the apply family of functions, however they present some disadvantages.\nNested loops: A disadvantage is that there is lots of book-keeping code because the array size is hard coded in several places and output structures need to be created before filling them with data.\nApply family of functions - apply(), lapply(), mapply(): These simplify the task, but the process to go from a 2d array of models to 3d array of residuals is not straightforward.\nFor data frames: The split-apply-combine strategy can be achieved as follows: Split: split() Apply: lapply() Combine: rbind()\nThe major complication is giving appropriate labels to the data because types of label will depend on the output data structure (i.e arrays = dimnames and data frames = additional columns). For this reason, mapply() is needed to match source data to extract informative labels.\n\nThe ChatGPT response to the prompt “Describe the split-apply-combine paradigm” is given below. Generally, the chatbot’s answers are decent. ChatGPT does have problems getting details right. Which details would you change in the response?\n\n\nThe “split-apply-combine” paradigm is a data analysis strategy used in statistics and data science to analyze grouped data. It consists of three steps:\nSplit: The data is first split into groups based on one or more variables of interest.\nApply: A specific operation or function is applied to each group of data, usually for the purpose of aggregating, summarizing, or transforming the data within each group.\nCombine: The results of the operation applied to each group are then combined and returned as a single output.\nThe split-apply-combine paradigm is particularly useful in cases where the data cannot be analyzed as a whole and instead must be analyzed in smaller, more manageable chunks. This allows for more efficient data processing and improved scalability. The paradigm is commonly implemented using tools such as the “groupby” function in the R and Python programming languages, and the “dplyr” library in R.\n\nThe term “analyze grouped data” seems too general to describe the split-apply-combine strategy. Even though the following bullet points describe each of the steps individually, it would be ideal to have an introductory sentence similar to what is shown in the paper from Hadley Wickman.\nI would change it this way: “The ’split-apply-combine” paradigm is a data analysis strategy used in statistics and data science to break up a larger data set into manageable pieces, operate on each piece independently, and then put all the pieces back together.”\nPerhaps the “apply” step is a little wordy. I would change it to “calculate summary statistics on each data group.”\nThe final paragraph looks correct for concluding sentences and explains why this strategy is useful in data science. Since ChatGPT mentioned the “groupby” function, it would be necessary to add the five key functions from the “dplyr” library: filter(), arrange(), select(), mutate(), and summarise()."
  },
  {
    "objectID": "blog-2023/Blog-4-submissions/drbradford12/index.html",
    "href": "blog-2023/Blog-4-submissions/drbradford12/index.html",
    "title": "Blog post 4 - Split-Apply-Combine",
    "section": "",
    "text": "The plyr package has by now been replaced by other, even faster packages, but the idea of Split, apply, combine is as relevant as ever.\nRead the paper The Split-Apply-Combine Strategy for Data Analysis by Hadley Wickham.\nWrite a blog post addressing the following questions:\n\nThe R code for the split-apply-combine paper is posted with the paper. Pick one of the examples demonstrating plyr functionality (such as dlply or ddply, …) and rewrite the example using functionality from the package dplyr. Make sure that your example works and the results are identical.\n\n\ndata(\"baseball\")\nsubset_baseball <- baseball %>% filter(year > 2000)\n\n#plyr example\nplyr::ddply(subset_baseball, .(team, lg), \n            summarise, hbp = mean(hbp, na.rm = TRUE), \n            year = max(year) ) %>% \n  head()\n#>   team lg       hbp year\n#> 1  ANA AL 0.1818182 2004\n#> 2  ARI NL 1.7846154 2007\n#> 3  ATL NL 1.4583333 2007\n#> 4  BAL AL 1.9189189 2007\n#> 5  BOS AL 1.2878788 2007\n#> 6  CHA AL 2.3513514 2007\n\n#dplyr example\nsubset_baseball %>% \n  group_by(team,lg) %>% \n dplyr::do(mean = mean(.$hbp, na.rm = TRUE),\n           year = max(.$year)) %>% \n  unnest() %>%\n  head()\n#> # A tibble: 6 × 4\n#>   team  lg     mean  year\n#>   <chr> <chr> <dbl> <int>\n#> 1 ANA   AL    0.182  2004\n#> 2 ARI   NL    1.78   2007\n#> 3 ATL   NL    1.46   2007\n#> 4 BAL   AL    1.92   2007\n#> 5 BOS   AL    1.29   2007\n#> 6 CHA   AL    2.35   2007\n\n\nfrom pybaseball import batting_stats_range\nimport numpy as np\n\nsubset_baseball = batting_stats_range('2008-05-01', '2010-11-08')\nsubset_baseball.head()\n\nsubset_baseball.groupby(['Tm','Lev']).agg({'HBP': 'mean', 'OBP': 'max'}).head()\n\n\nWhich (base R) functions do you know that support the split-apply-combine strategy? In your opinion, are these sufficient? State why or why not?\nFunctions that support the split-apply-combine strategy in base R such as: by(), do.call(),reshape(),aggregate(),subset(). In my opinion, I believe that some of these functions are sufficient (like subset()) when looking at a larger dataset, it will be useful to see what the data look like without knowing what the actual table contents.\nThe ChatGPT response to the prompt “Describe the split-apply-combine paradigm” is given below. Generally, the chatbot’s answers are decent. ChatGPT does have problems getting details right. Which details would you change in the response?\n\n\nThe “split-apply-combine” paradigm is a data analysis strategy used in statistics and data science to analyze grouped data. It consists of three steps:\nSplit: The data is first split into groups based on one or more variables of interest.\nApply: A specific operation or function is applied to each group of data, usually for the purpose of aggregating, summarizing, or transforming the data within each group.\nCombine: The results of the operation applied to each group are then combined and returned as a single output.\nThe split-apply-combine paradigm is particularly useful in cases where the data cannot be analyzed as a whole and instead must be analyzed in smaller, more manageable chunks. This allows for more efficient data processing and improved scalability. The paradigm is commonly implemented using tools such as the “groupby” function in the R and Python programming languages, and the “dplyr” library in R.\n\n“…cases where the data cannot be analyzed as a whole and instead must be analyzed in smaller, more manageable chunks.” The details that I would not completely agree with this statement for the fact that the split-apply-combine method can be perform other functional things that are useful. We can use the functionality to explore the data when we have a large dataset. This method could be used to combine data that are similar from different data sources, for example state related outcomes.\nYou can write your answers directly the README.Rmd file. Make sure that the file knits (you will need to activate any packages your use in your code chunks with a call to library(xxx), where xxx is the name of the package, such as plyr ). Commit your changes and push to your repo; add any files in the README_files directory to your repository."
  },
  {
    "objectID": "blog-2023/Blog-4-submissions/fveneri/index.html",
    "href": "blog-2023/Blog-4-submissions/fveneri/index.html",
    "title": "Title of your post",
    "section": "",
    "text": "The plyr package has by now been replaced by other, even faster packages, but the idea of Split, apply, combine is as relevant as ever.\nRead the paper The Split-Apply-Combine Strategy for Data Analysis by Hadley Wickham.\nWrite a blog post addressing the following questions:\n\nThe R code for the split-apply-combine paper is posted with the paper. Pick one of the examples demonstrating plyr functionality (such as dlply or ddply, …) and rewrite the example using functionality from the package dplyr. Make sure that your example works and the results are identical.\nWhich (base R) functions do you know that support the split-apply-combine strategy? In your opinion, are these sufficient? State why or why not?\nThe ChatGPT response to the prompt “Describe the split-apply-combine paradigm” is given below. Generally, the chatbot’s answers are decent. ChatGPT does have problems getting details right. Which details would you change in the response?\n\n\nThe “split-apply-combine” paradigm is a data analysis strategy used in statistics and data science to analyze grouped data. It consists of three steps:\nSplit: The data is first split into groups based on one or more variables of interest.\nApply: A specific operation or function is applied to each group of data, usually for the purpose of aggregating, summarizing, or transforming the data within each group.\nCombine: The results of the operation applied to each group are then combined and returned as a single output.\nThe split-apply-combine paradigm is particularly useful in cases where the data cannot be analyzed as a whole and instead must be analyzed in smaller, more manageable chunks. This allows for more efficient data processing and improved scalability. The paradigm is commonly implemented using tools such as the “groupby” function in the R and Python programming languages, and the “dplyr” library in R.\n\nYou can write your answers directly the README.Rmd file. Make sure that the file knits (you will need to activate any packages your use in your code chunks with a call to library(xxx), where xxx is the name of the package, such as plyr ). Commit your changes and push to your repo; add any files in the README_files directory to your repository."
  },
  {
    "objectID": "blog-2023/Blog-4-submissions/HarunCelikOtto/index.html",
    "href": "blog-2023/Blog-4-submissions/HarunCelikOtto/index.html",
    "title": "Split-Apply-Combine Post",
    "section": "",
    "text": "The plyr package has by now been replaced by other, even faster packages, but the idea of Split, apply, combine is as relevant as ever.\nRead the paper The Split-Apply-Combine Strategy for Data Analysis by Hadley Wickham.\nWrite a blog post addressing the following questions:\n\nThe R code for the split-apply-combine paper is posted with the paper. Pick one of the examples demonstrating plyr functionality (such as dlply or ddply, …) and rewrite the example using functionality from the package dplyr. Make sure that your example works and the results are identical.\nWhich (base R) functions do you know that support the split-apply-combine strategy? In your opinion, are these sufficient? State why or why not?\nThe ChatGPT response to the prompt “Describe the split-apply-combine paradigm” is given below. Generally, the chatbot’s answers are decent. ChatGPT does have problems getting details right. Which details would you change in the response?\n\n\nThe “split-apply-combine” paradigm is a data analysis strategy used in statistics and data science to analyze grouped data. It consists of three steps:\nSplit: The data is first split into groups based on one or more variables of interest.\nApply: A specific operation or function is applied to each group of data, usually for the purpose of aggregating, summarizing, or transforming the data within each group.\nCombine: The results of the operation applied to each group are then combined and returned as a single output.\nThe split-apply-combine paradigm is particularly useful in cases where the data cannot be analyzed as a whole and instead must be analyzed in smaller, more manageable chunks. This allows for more efficient data processing and improved scalability. The paradigm is commonly implemented using tools such as the “groupby” function in the R and Python programming languages, and the “dplyr” library in R.\n\nYou can write your answers directly the README.Rmd file. Make sure that the file knits (you will need to activate any packages your use in your code chunks with a call to library(xxx), where xxx is the name of the package, such as plyr ). Commit your changes and push to your repo; add any files in the README_files directory to your repository.\n#Answers"
  },
  {
    "objectID": "blog-2023/Blog-4-submissions/HarunCelikOtto/index.html#question-one",
    "href": "blog-2023/Blog-4-submissions/HarunCelikOtto/index.html#question-one",
    "title": "Split-Apply-Combine Post",
    "section": "Question One",
    "text": "Question One\n\nCode Selection\nI wanted to work with a simple example from Hadley Wickham’s code so that I could better understand in detail what was happening. For this reason, I chose to work with a chunk of code that used ddply to first group_by the column $id, and then to create a new column called $cyear using a base R transform() function.\n\n\nHere is the original code in plyr:\n\nlibrary(\"ggplot2\")\nlibrary(\"plyr\")\noptions(digits = 3)\noptions(prompt = \"R> \")\n\n\n#Changed variable name to baseball_plyr\nbaseball_plyr <- ddply(baseball, .(id), transform, \n  cyear = year - min(year) + 1)\nhead(baseball_plyr)\n#>          id year stint team lg   g  ab   r   h X2b X3b hr rbi sb cs bb so ibb\n#> 1 aaronha01 1954     1  ML1 NL 122 468  58 131  27   6 13  69  2  2 28 39  NA\n#> 2 aaronha01 1955     1  ML1 NL 153 602 105 189  37   9 27 106  3  1 49 61   5\n#> 3 aaronha01 1956     1  ML1 NL 153 609 106 200  34  14 26  92  2  4 37 54   6\n#> 4 aaronha01 1957     1  ML1 NL 151 615 118 198  27   6 44 132  1  1 57 58  15\n#> 5 aaronha01 1958     1  ML1 NL 153 601 109 196  34   4 30  95  4  1 59 49  16\n#> 6 aaronha01 1959     1  ML1 NL 154 629 116 223  46   7 39 123  8  0 51 54  17\n#>   hbp sh sf gidp cyear\n#> 1   3  6  4   13     1\n#> 2   3  7  4   20     2\n#> 3   2  5  7   21     3\n#> 4   0  0  3   13     4\n#> 5   1  0  3   21     5\n#> 6   4  0  9   19     6\n\nHere is the output replicated in dplyr:\n\nlibrary(dplyr)\n\n\nbaseball_dplyr <- baseball %>%\n  group_by(id) %>%\n  mutate(cyear = year - min(year) + 1)\nhead(baseball_dplyr)\n#> # A tibble: 6 × 23\n#> # Groups:   id [6]\n#>   id      year stint team  lg        g    ab     r     h   X2b   X3b    hr   rbi\n#>   <chr>  <int> <int> <chr> <chr> <int> <int> <int> <int> <int> <int> <int> <int>\n#> 1 anson…  1871     1 RC1   \"\"       25   120    29    39    11     3     0    16\n#> 2 force…  1871     1 WS3   \"\"       32   162    45    45     9     4     0    29\n#> 3 mathe…  1871     1 FW1   \"\"       19    89    15    24     3     1     0    10\n#> 4 start…  1871     1 NY2   \"\"       33   161    35    58     5     1     1    34\n#> 5 sutto…  1871     1 CL1   \"\"       29   128    35    45     3     7     3    23\n#> 6 white…  1871     1 CL1   \"\"       29   146    40    47     6     5     1    21\n#> # … with 10 more variables: sb <int>, cs <int>, bb <int>, so <int>, ibb <int>,\n#> #   hbp <int>, sh <int>, sf <int>, gidp <int>, cyear <dbl>\n\n\n\nDiscussion\nIn both cases, the input and output is a data frame. While the code is less intuitive to understand at first glance in ddply the input/output formats are represented easier through the dd notation. Both codes group by $id and create a new column that is called $cyear with the cumulative year of a player’s career. The dplyr package makes use of the pipeline operator %>% to streamline the process of split-apply-combine whereas ddply looks more similar to how the apply functions take care of this paradigm in base r. One interesting difference that I never paid attention to before was that the str() function produces different results because of the group_by() function in dplyr. It looks like the group_by() function creates nested structures when calling str() on the data frame."
  },
  {
    "objectID": "blog-2023/Blog-4-submissions/HarunCelikOtto/index.html#question-two",
    "href": "blog-2023/Blog-4-submissions/HarunCelikOtto/index.html#question-two",
    "title": "Split-Apply-Combine Post",
    "section": "Question Two",
    "text": "Question Two\n\nDiscussion\nUntil recently, I wasn’t following the differences between base r and the tidyverse so the only base function I am aware of that follows this split-apply-combine paradigm are the apply functions.\n\nby(baseball$g, baseball$id, mean) |>\n  head()\n#> baseball$id\n#> aaronha01 abernte02 adairje01 adamsba01 adamsbo03 adcocjo01 \n#>     143.4      40.1      77.7      25.4      85.4     115.2\n\nThe code above uses by which serves as a wrapper for tapply and while it does calculate the mean of $g by $id, the information of the output is not as detailed as when run with the dplyr functions. I also found it difficult to work with the syntax of the new base pipe |> operator despite it serving a similar functionality to the more widely utilized magrittr pipe operator."
  },
  {
    "objectID": "blog-2023/Blog-4-submissions/HarunCelikOtto/index.html#question-three",
    "href": "blog-2023/Blog-4-submissions/HarunCelikOtto/index.html#question-three",
    "title": "Split-Apply-Combine Post",
    "section": "Question Three",
    "text": "Question Three\nThroughout the article, Hadley Wickham demonstrates the importance of working with the split-apply-combine paradigm efficiently. This is something that ChatGPT did not pick up on in their answer. The answer from the AI for instance doesn’t mention that in the “split” section, memory-saving methods, like the ones introduced by plyr, are an important process of working through the paradigm. The AI also doesn’t discuss the limitations of the split-apply-combine method. An important limitation to the paradigm, especially through use of plyr is that “each piece of data [is] processed only once and independently of all other pieces” (Wickham, 2011). This is an important element of the paradigm that separates it from advanced looping functions.\nI have to admit that ChatGPT’s answer is surprisingly concise even if it is a little generalized. It would be interesting to see how it answers more particular questions about the paradigm like, “what are the limitations of the split-apply-combine paradigm?”"
  },
  {
    "objectID": "blog-2023/Blog-4-submissions/valeriehan6/index.html",
    "href": "blog-2023/Blog-4-submissions/valeriehan6/index.html",
    "title": "The Split-Apply-Combine Strategy",
    "section": "",
    "text": "The plyr package has by now been replaced by other, even faster packages, but the idea of Split, apply, combine is as relevant as ever.\nRead the paper The Split-Apply-Combine Strategy for Data Analysis by Hadley Wickham.\nWrite a blog post addressing the following questions:\n\nThe R code for the split-apply-combine paper is posted with the paper. Pick one of the examples demonstrating plyr functionality (such as dlply or ddply, …) and rewrite the example using functionality from the package dplyr. Make sure that your example works and the results are identical.\n\n\nlibrary(plyr)\nbaseball1 <- ddply(baseball, .(id), transform, \n  cyear = year - min(year) + 1)\n\n\nlibrary(dplyr)\n#> \n#> Attaching package: 'dplyr'\n#> The following objects are masked from 'package:plyr':\n#> \n#>     arrange, count, desc, failwith, id, mutate, rename, summarise,\n#>     summarize\n#> The following objects are masked from 'package:stats':\n#> \n#>     filter, lag\n#> The following objects are masked from 'package:base':\n#> \n#>     intersect, setdiff, setequal, union\nbaseball2 <- baseball %>%\n  group_by(id) %>%\n  mutate(cyear = year - min(year) + 1) %>%\n  arrange(id) %>%\n  as.data.frame()\n\nidentical(baseball1, baseball2)\n#> [1] TRUE\n\n\nWhich (base R) functions do you know that support the split-apply-combine strategy? In your opinion, are these sufficient? State why or why not?\n\nWith a dataframe df with a column col1, you can subset by value val1 of col1 with df[df$col1 == val1, ]. You could then do whatever procedure you wanted on that subsetted dataframe. There’s also the apply functions in base R (or a for loop), which would allow you to apply the same procedure to multiple values and combine the values. However, I don’t believe the base R functions are sufficient. The split-apply-combine strategy is so common in data analysis that it shouldn’t take so many (not super readable) lines of code to accomplish it. The functions in dplyr are much more intuitive to code with and understand, reducing the cognitive load.\n\nThe ChatGPT response to the prompt “Describe the split-apply-combine paradigm” is given below. Generally, the chatbot’s answers are decent. ChatGPT does have problems getting details right. Which details would you change in the response?\n\n\nThe “split-apply-combine” paradigm is a data analysis strategy used in statistics and data science to analyze grouped data. It consists of three steps:\nSplit: The data is first split into groups based on one or more variables of interest.\nApply: A specific operation or function is applied to each group of data, usually for the purpose of aggregating, summarizing, or transforming the data within each group.\nCombine: The results of the operation applied to each group are then combined and returned as a single output.\nThe split-apply-combine paradigm is particularly useful in cases where the data cannot be analyzed as a whole and instead must be analyzed in smaller, more manageable chunks. This allows for more efficient data processing and improved scalability. The paradigm is commonly implemented using tools such as the “groupby” function in the R and Python programming languages, and the “dplyr” library in R.\n\nOne important thing that the answer doesn’t mention is that the operations on each group must be assumed to be independent. In addition, the last paragraph has a few misleading details. The data usually can be analyzed as a whole, but analyzing by group gives us different information than analyzing as a whole. In addition, the paradigm is not so much useful in runtime efficiency/scalability but rather in reducing the cognitive load for certain common data analysis tasks (which can increase efficiency in writing/understanding code). The last sentence would also be more accurate as: The paradigm is implemented using tools such as the group_by and groupby functions in the dplyr and pandas libraries in the R and Python programming languages, respectively.\nYou can write your answers directly the README.Rmd file. Make sure that the file knits (you will need to activate any packages your use in your code chunks with a call to library(xxx), where xxx is the name of the package, such as plyr ). Commit your changes and push to your repo; add any files in the README_files directory to your repository."
  },
  {
    "objectID": "blog-2023/Blog-4-submissions/IanParzyszek/Getting.to.know.dplyr.html",
    "href": "blog-2023/Blog-4-submissions/IanParzyszek/Getting.to.know.dplyr.html",
    "title": "Getting familiar with dpylr",
    "section": "",
    "text": "The plyr package has by now been replaced by other, even faster packages, but the idea of Split, apply, combine is as relevant as ever.\nRead the paper The Split-Apply-Combine Strategy for Data Analysis by Hadley Wickham.\nWrite a blog post addressing the following questions:\n\nThe R code for the split-apply-combine paper is posted with the paper. Pick one of the examples demonstrating plyr functionality (such as dlply or ddply, …) and rewrite the example using functionality from the package dplyr. Make sure that your example works and the results are identical.\n\n\nlibrary(\"plyr\")\nlibrary(\"dplyr\")\n#> \n#> Attaching package: 'dplyr'\n#> The following objects are masked from 'package:plyr':\n#> \n#>     arrange, count, desc, failwith, id, mutate, rename, summarise,\n#>     summarize\n#> The following objects are masked from 'package:stats':\n#> \n#>     filter, lag\n#> The following objects are masked from 'package:base':\n#> \n#>     intersect, setdiff, setequal, union\n\n\n#This chunk calculates the year they are on for that year\nbaseball_plyr <- ddply(baseball, .(id), transform, \n  cyear = year - min(year) + 1)\nbaseball_plyr\n#>             id year stint team lg   g  ab   r   h X2b X3b hr rbi  sb cs  bb  so\n#> 1    aaronha01 1954     1  ML1 NL 122 468  58 131  27   6 13  69   2  2  28  39\n#> 2    aaronha01 1955     1  ML1 NL 153 602 105 189  37   9 27 106   3  1  49  61\n#> 3    aaronha01 1956     1  ML1 NL 153 609 106 200  34  14 26  92   2  4  37  54\n#> 4    aaronha01 1957     1  ML1 NL 151 615 118 198  27   6 44 132   1  1  57  58\n#> 5    aaronha01 1958     1  ML1 NL 153 601 109 196  34   4 30  95   4  1  59  49\n#> 6    aaronha01 1959     1  ML1 NL 154 629 116 223  46   7 39 123   8  0  51  54\n#> 7    aaronha01 1960     1  ML1 NL 153 590 102 172  20  11 40 126  16  7  60  63\n#> 8    aaronha01 1961     1  ML1 NL 155 603 115 197  39  10 34 120  21  9  56  64\n#> 9    aaronha01 1962     1  ML1 NL 156 592 127 191  28   6 45 128  15  7  66  73\n#> 10   aaronha01 1963     1  ML1 NL 161 631 121 201  29   4 44 130  31  5  78  94\n#> 11   aaronha01 1964     1  ML1 NL 145 570 103 187  30   2 24  95  22  4  62  46\n#> 12   aaronha01 1965     1  ML1 NL 150 570 109 181  40   1 32  89  24  4  60  81\n#> 13   aaronha01 1966     1  ATL NL 158 603 117 168  23   1 44 127  21  3  76  96\n#> 14   aaronha01 1967     1  ATL NL 155 600 113 184  37   3 39 109  17  6  63  97\n#> 15   aaronha01 1968     1  ATL NL 160 606  84 174  33   4 29  86  28  5  64  62\n#> 16   aaronha01 1969     1  ATL NL 147 547 100 164  30   3 44  97   9 10  87  47\n#> 17   aaronha01 1970     1  ATL NL 150 516 103 154  26   1 38 118   9  0  74  63\n#> 18   aaronha01 1971     1  ATL NL 139 495  95 162  22   3 47 118   1  1  71  58\n#> 19   aaronha01 1972     1  ATL NL 129 449  75 119  10   0 34  77   4  0  92  55\n#> 20   aaronha01 1973     1  ATL NL 120 392  84 118  12   1 40  96   1  1  68  51\n#> 21   aaronha01 1974     1  ATL NL 112 340  47  91  16   0 20  69   1  0  39  29\n#> 22   aaronha01 1975     1  ML4 AL 137 465  45 109  16   2 12  60   0  1  70  51\n#> 23   aaronha01 1976     1  ML4 AL  85 271  22  62   8   0 10  35   0  1  35  38\n#> 24   abernte02 1955     1  WS1 AL  40  26   1   4   0   0  0   0   0  0   0   6\n#> 25   abernte02 1956     1  WS1 AL   5  11   1   2   0   0  0   1   0  0   0   5\n#> 26   abernte02 1957     1  WS1 AL  26  24   3   4   1   0  0   1   0  0   1   5\n#> 27   abernte02 1960     1  WS1 AL   2   1   1   1   0   0  0   0   0  0   0   0\n#> 28   abernte02 1963     1  CLE AL  43   5   1   2   1   0  0   0   0  0   1   2\n#> 29   abernte02 1964     1  CLE AL  53   6   0   0   0   0  0   0   0  0   0   3\n#> 30   abernte02 1965     1  CHN NL  84  18   1   3   0   0  0   2   0  0   0   7\n#> 31   abernte02 1966     1  CHN NL  20   4   0   0   0   0  0   0   0  0   0   2\n#> 32   abernte02 1966     2  ATL NL  38   8   0   2   0   0  0   0   0  0   1   3\n#> 33   abernte02 1967     1  CIN NL  70  17   0   1   0   0  0   2   0  0   0  10\n#> 34   abernte02 1968     1  CIN NL  78  17   2   0   0   0  0   0   0  0   3  12\n#> 35   abernte02 1969     1  CHN NL  56   8   1   2   1   0  0   1   0  0   0   2\n#> 36   abernte02 1970     3  KCA AL  36  14   1   3   0   0  0   2   0  0   0   5\n#> 37   abernte02 1970     1  CHN NL  11   0   0   0   0   0  0   0   0  0   0   0\n#> 38   abernte02 1970     2  SLN NL  11   3   0   0   0   0  0   0   0  0   0   2\n#> 39   abernte02 1971     1  KCA AL  63  13   0   1   0   0  0   0   0  0   0   7\n#> 40   abernte02 1972     1  KCA AL  45   6   0   0   0   0  0   0   0  0   0   3\n#> 41   adairje01 1958     1  BAL AL  11  19   1   2   0   0  0   0   0  0   1   7\n#> 42   adairje01 1959     1  BAL AL  12  35   3  11   0   1  0   2   0  0   1   5\n#> 43   adairje01 1960     1  BAL AL   3   5   1   1   0   0  1   1   0  0   0   0\n#> 44   adairje01 1961     1  BAL AL 133 386  41 102  21   1  9  37   5  2  35  51\n#> 45   adairje01 1962     1  BAL AL 139 538  67 153  29   4 11  48   7  7  27  77\n#> 46   adairje01 1963     1  BAL AL 109 382  34  87  21   3  6  30   3  3   9  51\n#> 47   adairje01 1964     1  BAL AL 155 569  56 141  20   3  9  47   3  2  28  72\n#> 48   adairje01 1965     1  BAL AL 157 582  51 151  26   3  7  66   6  4  35  65\n#> 49   adairje01 1966     1  BAL AL  17  52   3  15   1   0  0   3   0  0   4   8\n#> 50   adairje01 1966     2  CHA AL 105 370  27  90  18   2  4  36   3  2  17  44\n#> 51   adairje01 1967     1  CHA AL  28  98   6  20   4   0  0   9   0  1   4  17\n#> 52   adairje01 1967     2  BOS AL  89 316  41  92  13   1  3  26   1  4  13  35\n#> 53   adairje01 1968     1  BOS AL  74 208  18  45   1   0  2  12   0  0   9  28\n#> 54   adairje01 1969     1  KCA AL 126 432  29 108   9   1  5  48   1  3  20  36\n#> 55   adairje01 1970     1  KCA AL   7  27   0   4   0   0  0   1   0  1   5   3\n#> 56   adamsba01 1906     1  SLN NL   1   1   0   0   0   0  0   0   0 NA   0  NA\n#> 57   adamsba01 1907     1  PIT NL   4   7   1   2   0   0  0   0   0 NA   0  NA\n#> 58   adamsba01 1909     1  PIT NL  25  39   0   2   0   1  0   1   0 NA   2  NA\n#> 59   adamsba01 1910     1  PIT NL  34  83   9  16   3   0  0   6   0 NA   9  23\n#> 60   adamsba01 1911     1  PIT NL  40 103   9  26   5   1  0  10   0 NA   3  17\n#> 61   adamsba01 1912     1  PIT NL  28  53   5  12   3   1  0   3   0 NA   8   9\n#> 62   adamsba01 1913     1  PIT NL  43 114  13  33   6   2  0  13   0 NA   1  16\n#> 63   adamsba01 1914     1  PIT NL  40  97   8  16   0   2  1   4   0 NA   3  29\n#> 64   adamsba01 1915     1  PIT NL  40  85   4  12   1   0  0   7   0 NA   4  14\n#> 65   adamsba01 1916     1  PIT NL  16  22   1   6   0   1  0   2   0 NA   2   1\n#> 66   adamsba01 1918     1  PIT NL   3   9   0   3   0   1  0   0   0 NA   0   3\n#> 67   adamsba01 1919     1  PIT NL  34  92   2  17   2   1  0   4   0 NA   6  13\n#> 68   adamsba01 1920     1  PIT NL  35  89   4  13   0   0  1   3   0  0   1  18\n#> 69   adamsba01 1921     1  PIT NL  25  63   7  16   2   4  0   6   1  0   1   7\n#> 70   adamsba01 1922     1  PIT NL  27  56   6  16   2   0  1   6   0  0   4   7\n#> 71   adamsba01 1923     1  PIT NL  26  55   5  15   5   1  0   8   0  1   6  13\n#> 72   adamsba01 1924     1  PIT NL   9  11   1   2   1   0  0   1   0  0   0   1\n#> 73   adamsba01 1925     1  PIT NL  33  31   3   7   1   0  0   1   0  0   3   6\n#> 74   adamsba01 1926     1  PIT NL  19   9   1   2   0   0  0   0   0 NA   0   0\n#> 75   adamsbo03 1946     1  CIN NL  94 311  35  76  13   3  4  24  16 NA  18  32\n#> 76   adamsbo03 1947     1  CIN NL  81 217  39  59  11   2  4  20   9 NA  25  23\n#> 77   adamsbo03 1948     1  CIN NL  87 262  33  78  20   3  1  21   6 NA  25  23\n#> 78   adamsbo03 1949     1  CIN NL 107 277  32  70  16   2  0  25   4 NA  26  36\n#> 79   adamsbo03 1950     1  CIN NL 115 348  57  98  21   8  3  25   7 NA  43  29\n#> 80   adamsbo03 1951     1  CIN NL 125 403  57 107  12   5  5  24   4 10  43  40\n#> 81   adamsbo03 1952     1  CIN NL 154 637  85 180  25   4  6  48  11  9  49  67\n#> 82   adamsbo03 1953     1  CIN NL 150 607  99 167  14   6  8  49   3  2  58  67\n#> 83   adamsbo03 1954     1  CIN NL 110 390  69 105  25   6  3  23   2  5  55  46\n#> 84   adamsbo03 1955     2  CHA AL  28  21   8   2   0   1  0   3   0  0   4   4\n#> 85   adamsbo03 1955     1  CIN NL  64 150  23  41  11   2  2  20   2  0  20  21\n#> 86   adamsbo03 1956     1  BAL AL  41 111  19  25   6   1  0   7   1  1  25  15\n#> 87   adamsbo03 1957     1  CHN NL  60 187  21  47  10   2  1  10   0  3  17  28\n#> 88   adamsbo03 1958     1  CHN NL  62  96  14  27   4   4  0   4   2  0   6  15\n#> 89   adamsbo03 1959     1  CHN NL   3   2   0   0   0   0  0   0   0  0   0   1\n#> 90   adcocjo01 1950     1  CIN NL 102 372  46 109  16   1  8  55   2 NA  24  24\n#> 91   adcocjo01 1951     1  CIN NL 113 395  40  96  16   4 10  47   1  2  24  29\n#> 92   adcocjo01 1952     1  CIN NL 117 378  43 105  22   4 13  52   1  4  23  38\n#> 93   adcocjo01 1953     1  ML1 NL 157 590  71 168  33   6 18  80   3  2  42  82\n#> 94   adcocjo01 1954     1  ML1 NL 133 500  73 154  27   5 23  87   1  4  44  58\n#> 95   adcocjo01 1955     1  ML1 NL  84 288  40  76  14   0 15  45   0  2  31  44\n#> 96   adcocjo01 1956     1  ML1 NL 137 454  76 132  23   1 38 103   1  0  32  86\n#> 97   adcocjo01 1957     1  ML1 NL  65 209  31  60  13   2 12  38   0  0  20  51\n#> 98   adcocjo01 1958     1  ML1 NL 105 320  40  88  15   1 19  54   0  0  21  63\n#> 99   adcocjo01 1959     1  ML1 NL 115 404  53 118  19   2 25  76   0  0  32  77\n#> 100  adcocjo01 1960     1  ML1 NL 138 514  55 153  21   4 25  91   2  2  46  86\n#> 101  adcocjo01 1961     1  ML1 NL 152 562  77 160  20   0 35 108   2  1  59  94\n#> 102  adcocjo01 1962     1  ML1 NL 121 391  48  97  12   1 29  78   2  0  50  91\n#> 103  adcocjo01 1963     1  CLE AL  97 283  28  71   7   1 13  49   1  2  30  53\n#> 104  adcocjo01 1964     1  LAA AL 118 366  39  98  13   0 21  64   0  2  48  61\n#> 105  adcocjo01 1965     1  CAL AL 122 349  30  84  14   0 14  47   2  2  37  74\n#> 106  adcocjo01 1966     1  CAL AL  83 231  33  63  10   3 18  48   2  2  31  48\n#> 107  agostju01 1981     1  CHA AL   2   0   0   0   0   0  0   0   0  0   0   0\n#> 108  agostju01 1982     1  CHA AL   1   0   0   0   0   0  0   0   0  0   0   0\n#> 109  agostju01 1983     1  CHA AL  39   0   0   0   0   0  0   0   0  0   0   0\n#> 110  agostju01 1984     1  CHA AL  49   0   0   0   0   0  0   0   0  0   0   0\n#> 111  agostju01 1985     1  CHA AL  54   0   0   0   0   0  0   0   0  0   0   0\n#> 112  agostju01 1986     1  CHA AL   9   0   0   0   0   0  0   0   0  0   0   0\n#> 113  agostju01 1986     2  MIN AL  17   0   0   0   0   0  0   0   0  0   0   0\n#> 114  agostju01 1987     1  HOU NL  27   1   0   0   0   0  0   0   0  0   0   1\n#> 115  agostju01 1988     1  HOU NL  75   5   0   0   0   0  0   0   0  0   0   0\n#> 116  agostju01 1989     1  HOU NL  71   5   0   1   0   0  0   0   0  0   0   2\n#> 117  agostju01 1990     1  HOU NL  82   2   0   0   0   0  0   0   0  0   0   0\n#> 118  agostju01 1991     1  SLN NL  72   3   0   1   0   0  0   0   0  0   1   2\n#> 119  agostju01 1992     2  SEA AL  17   0   0   0   0   0  0   0   0  0   0   0\n#> 120  agostju01 1992     1  SLN NL  22   4   0   0   0   0  0   0   0  0   0   2\n#> 121  agostju01 1993     1  HOU NL   6   0   0   0   0   0  0   0   0  0   0   0\n#> 122  aguilri01 1985     1  NYN NL  22  36   1  10   2   0  0   2   0  0   1   5\n#> 123  aguilri01 1986     1  NYN NL  32  51   4   8   0   0  2   6   0  0   3  12\n#> 124  aguilri01 1987     1  NYN NL  18  40   5   9   1   0  1   3   0  0   1  17\n#> 125  aguilri01 1988     1  NYN NL  11   4   1   1   0   0  0   0   0  0   0   1\n#> 126  aguilri01 1989     2  MIN AL  11   0   0   0   0   0  0   0   0  0   0   0\n#> 127  aguilri01 1989     1  NYN NL  36   7   1   0   0   0  0   0   0  0   1   2\n#> 128  aguilri01 1990     1  MIN AL  56   0   0   0   0   0  0   0   0  0   0   0\n#> 129  aguilri01 1991     1  MIN AL  63   0   0   0   0   0  0   0   0  0   0   0\n#> 130  aguilri01 1992     1  MIN AL  64   0   0   0   0   0  0   0   0  0   0   0\n#> 131  aguilri01 1993     1  MIN AL  65   0   0   0   0   0  0   0   0  0   0   0\n#> 132  aguilri01 1994     1  MIN AL  44   0   0   0   0   0  0   0   0  0   0   0\n#> 133  aguilri01 1995     1  MIN AL  22   0   0   0   0   0  0   0   0  0   0   0\n#> 134  aguilri01 1995     2  BOS AL  30   0   0   0   0   0  0   0   0  0   0   0\n#> 135  aguilri01 1996     1  MIN AL  19   0   0   0   0   0  0   0   0  0   0   0\n#> 136  aguilri01 1997     1  MIN AL  61   0   0   0   0   0  0   0   0  0   0   0\n#> 137  aguilri01 1998     1  MIN AL  68   0   0   0   0   0  0   0   0  0   0   0\n#> 138  aguilri01 1999     1  MIN AL  17   0   0   0   0   0  0   0   0  0   0   0\n#> 139  aguilri01 1999     2  CHN NL  41   1   0   0   0   0  0   0   0  0   0   0\n#> 140  aguilri01 2000     1  CHN NL  50   0   0   0   0   0  0   0   0  0   0   0\n#> 141  aguirha01 1955     1  CLE AL   4   4   0   0   0   0  0   0   0  0   0   1\n#> 142  aguirha01 1956     1  CLE AL  16  18   1   2   0   0  0   2   0  0   0  11\n#> 143  aguirha01 1957     1  CLE AL  10   4   0   0   0   0  0   0   0  0   0   1\n#> 144  aguirha01 1958     1  DET AL  44  14   1   3   1   0  0   1   0  0   1   5\n#> 145  aguirha01 1959     1  DET AL   3   0   0   0   0   0  0   0   0  0   0   0\n#> 146  aguirha01 1960     1  DET AL  37  28   0   1   0   0  0   0   0  0   0  19\n#> 147  aguirha01 1961     1  DET AL  45   9   0   0   0   0  0   1   0  0   0   8\n#> 148  aguirha01 1962     1  DET AL  42  75   0   2   0   0  0   1   0  0   1  46\n#> 149  aguirha01 1963     1  DET AL  38  76   5  10   3   0  0   6   1  0   3  48\n#> 150  aguirha01 1964     1  DET AL  32  53   1   3   1   0  0   3   0  0   1  32\n#> 151  aguirha01 1965     1  DET AL  32  70   4   6   1   0  0   4   0  0   4  43\n#> 152  aguirha01 1966     1  DET AL  30  25   0   3   1   0  0   0   0  0   4  16\n#> 153  aguirha01 1967     1  DET AL  31   2   0   1   0   1  0   3   0  0   0   1\n#> 154  aguirha01 1968     1  LAN NL  25   3   0   0   0   0  0   0   0  0   0   2\n#> 155  aguirha01 1969     1  CHN NL  41   5   2   2   0   0  0   0   0  0   0   1\n#> 156  aguirha01 1970     1  CHN NL  17   2   0   0   0   0  0   0   0  0   0   2\n#> 157  ainsmed01 1910     1  WS1 AL  33 104   4  20   1   2  0   9   0 NA   6  NA\n#> 158  ainsmed01 1911     1  WS1 AL  61 149  12  33   2   3  0  14   5 NA  10  NA\n#> 159  ainsmed01 1912     1  WS1 AL  61 186  22  42   7   2  0  22   4 NA  14  NA\n#> 160  ainsmed01 1913     1  WS1 AL  84 229  26  49   4   4  2  20  17 NA  12  41\n#> 161  ainsmed01 1914     1  WS1 AL  62 151  11  34   7   0  0  13   8  5   9  28\n#> 162  ainsmed01 1915     1  WS1 AL  47 120  13  24   4   2  0   6   7  4  10  18\n#> 163  ainsmed01 1916     1  WS1 AL  51 100  11  17   4   0  0   8   3 NA   8  14\n#> 164  ainsmed01 1917     1  WS1 AL 125 350  38  67  17   4  0  42  16 NA  40  48\n#> 165  ainsmed01 1918     1  WS1 AL  96 292  22  62  10   9  0  20   6 NA  29  44\n#> 166  ainsmed01 1919     1  DET AL 114 364  42  99  17  12  3  32   9 NA  45  30\n#> 167  ainsmed01 1920     1  DET AL  69 186  19  43   5   3  1  19   4  3  14  19\n#> 168  ainsmed01 1921     1  DET AL  35  98   6  27   5   2  0  12   1  0  13   7\n#> 169  ainsmed01 1921     2  SLN NL  27  62   5  18   0   1  0   5   0  0   3   4\n#> 170  ainsmed01 1922     1  SLN NL 119 379  46 111  14   4 13  59   2  3  28  43\n#> 171  ainsmed01 1923     1  SLN NL  82 263  22  56  11   6  3  34   4  0  22  19\n#> 172  ainsmed01 1923     2  BRO NL   2  10   0   2   0   0  0   2   0  1   0   0\n#> 173  ainsmed01 1924     1  NY1 NL  10   5   0   3   0   0  0   0   0  0   0   0\n#> 174  alexado01 1971     1  LAN NL  17  33   3   9   0   0  0   2   0  0   3  13\n#> 175  alexado01 1972     1  BAL AL  35  25   1   2   0   0  0   0   0  0   1   7\n#> 176  alexado01 1973     1  BAL AL  29   0   0   0   0   0  0   0   0  0   0   0\n#> 177  alexado01 1974     1  BAL AL  30   0   0   0   0   0  0   0   0  0   0   0\n#> 178  alexado01 1975     1  BAL AL  32   0   0   0   0   0  0   0   0  0   0   0\n#> 179  alexado01 1976     1  BAL AL  11   0   0   0   0   0  0   0   0  0   0   0\n#> 180  alexado01 1976     2  NYA AL  19   0   0   0   0   0  0   0   0  0   0   0\n#> 181  alexado01 1977     1  TEX AL  34   0   0   0   0   0  0   0   0  0   0   0\n#> 182  alexado01 1978     1  TEX AL  31   0   0   0   0   0  0   0   0  0   0   0\n#> 183  alexado01 1979     1  TEX AL  23   0   0   0   0   0  0   0   0  0   0   0\n#> 184  alexado01 1980     1  ATL NL  35  83   7  15   3   0  0   3   0  0   3  24\n#> 185  alexado01 1981     1  SFN NL  24  51   5   9   4   0  0   6   0  0   2  12\n#> 186  alexado01 1982     1  NYA AL  16   0   0   0   0   0  0   0   0  0   0   0\n#> 187  alexado01 1983     1  NYA AL   8   0   0   0   0   0  0   0   0  0   0   0\n#> 188  alexado01 1983     2  TOR AL  17   0   0   0   0   0  0   0   0  0   0   0\n#> 189  alexado01 1984     1  TOR AL  36   0   0   0   0   0  0   0   0  0   0   0\n#> 190  alexado01 1985     1  TOR AL  36   0   0   0   0   0  0   0   0  0   0   0\n#> 191  alexado01 1986     1  TOR AL  17   0   0   0   0   0  0   0   0  0   0   0\n#> 192  alexado01 1986     2  ATL NL  18  38   2   8   1   0  0   5   0  0   0   8\n#> 193  alexado01 1987     2  DET AL  11   0   0   0   0   0  0   0   0  0   0   0\n#> 194  alexado01 1987     1  ATL NL  16  35   1   1   0   0  0   1   0  0   0  13\n#> 195  alexado01 1988     1  DET AL  34   0   0   0   0   0  0   0   0  0   0   0\n#> 196  alexado01 1989     1  DET AL  33   0   0   0   0   0  0   0   0  0   0   0\n#> 197  alexape01 1911     1  PHI NL  50 138  12  24   5   1  0   9   1 NA   2  27\n#> 198  alexape01 1912     1  PHI NL  46 102   7  19   4   0  2  13   0 NA   6  14\n#> 199  alexape01 1913     1  PHI NL  47 103   9  13   4   1  0   4   0 NA   3  21\n#> 200  alexape01 1914     1  PHI NL  48 137  18  32   3   0  0   7   0 NA   3  12\n#> 201  alexape01 1915     1  PHI NL  49 130   9  22   3   0  1   8   0  1   6  23\n#> 202  alexape01 1916     1  PHI NL  49 138  10  33   7   4  0   9   1 NA   5  15\n#> 203  alexape01 1917     1  PHI NL  47 139  17  30   8   2  1  13   1 NA   3  23\n#> 204  alexape01 1918     1  CHN NL   3  10   1   1   0   0  0   0   0 NA   0   2\n#> 205  alexape01 1919     1  CHN NL  30  70   6  12   1   0  0   4   0 NA  10  18\n#> 206  alexape01 1920     1  CHN NL  46 118   9  27   4   1  1  14   0  0  11  26\n#> 207  alexape01 1921     1  CHN NL  31  95   8  29   3   1  1  14   0  1   2  13\n#> 208  alexape01 1922     1  CHN NL  33  85   4  15   1   0  0  11   0  0   6  16\n#> 209  alexape01 1923     1  CHN NL  39 111  10  24   3   1  1  10   0  0   1  11\n#> 210  alexape01 1924     1  CHN NL  21  65   3  15   2   0  1  10   0  1   2   8\n#> 211  alexape01 1925     1  CHN NL  32  79   7  19   4   1  2  12   0  2   1   5\n#> 212  alexape01 1926     1  CHN NL   7  15   1   7   2   0  0   3   0 NA   0   1\n#> 213  alexape01 1926     2  SLN NL  23  50   1   6   1   0  0   3   0 NA   2  14\n#> 214  alexape01 1927     1  SLN NL  37  94   7  23   3   1  0   6   0 NA   5  14\n#> 215  alexape01 1928     1  SLN NL  34  86  13  25   2   0  1  11   0 NA   4   8\n#> 216  alexape01 1929     1  SLN NL  22  41   2   2   0   0  0   2   0 NA   3   5\n#> 217  alexape01 1930     1  PHI NL   9   4   0   0   0   0  0   0   0 NA   2   0\n#> 218  allendi01 1963     1  PHI NL  10  24   6   7   2   1  0   2   0  0   0   5\n#> 219  allendi01 1964     1  PHI NL 162 632 125 201  38  13 29  91   3  4  67 138\n#> 220  allendi01 1965     1  PHI NL 161 619  93 187  31  14 20  85  15  2  74 150\n#> 221  allendi01 1966     1  PHI NL 141 524 112 166  25  10 40 110  10  6  68 136\n#> 222  allendi01 1967     1  PHI NL 122 463  89 142  31  10 23  77  20  5  75 117\n#> 223  allendi01 1968     1  PHI NL 152 521  87 137  17   9 33  90   7  7  74 161\n#> 224  allendi01 1969     1  PHI NL 118 438  79 126  23   3 32  89   9  3  64 144\n#> 225  allendi01 1970     1  SLN NL 122 459  88 128  17   5 34 101   5  4  71 118\n#> 226  allendi01 1971     1  LAN NL 155 549  82 162  24   1 23  90   8  1  93 113\n#> 227  allendi01 1972     1  CHA AL 148 506  90 156  28   5 37 113  19  8  99 126\n#> 228  allendi01 1973     1  CHA AL  72 250  39  79  20   3 16  41   7  2  33  51\n#> 229  allendi01 1974     1  CHA AL 128 462  84 139  23   1 32  88   7  1  57  89\n#> 230  allendi01 1975     1  PHI NL 119 416  54  97  21   3 12  62  11  2  58 109\n#> 231  allendi01 1976     1  PHI NL  85 298  52  80  16   1 15  49  11  4  37  63\n#> 232  allendi01 1977     1  OAK AL  54 171  19  41   4   0  5  31   1  3  24  36\n#> 233  allenet01 1926     1  CIN NL  18  13   3   4   1   0  0   0   0 NA   0   3\n#> 234  allenet01 1927     1  CIN NL 111 359  54 106  26   4  2  20  12 NA  14  23\n#> 235  allenet01 1928     1  CIN NL 129 485  55 148  30   7  1  62   6 NA  27  29\n#> 236  allenet01 1929     1  CIN NL 143 538  69 157  27  11  6  64  21 NA  20  21\n#> 237  allenet01 1930     1  CIN NL  21  46  10  10   1   0  3   7   1 NA   5   2\n#> 238  allenet01 1930     2  NY1 NL  76 238  48  73   9   2  7  31   5 NA  12  23\n#> 239  allenet01 1931     1  NY1 NL  94 298  58  98  18   2  5  43   6 NA  15  15\n#> 240  allenet01 1932     1  NY1 NL  54 103  13  18   6   2  1   7   0 NA   1  12\n#> 241  allenet01 1933     1  SLN NL  91 261  25  63   7   3  0  36   3 NA  13  22\n#> 242  allenet01 1934     1  PHI NL 145 581  87 192  42   4 10  85   6 NA  33  47\n#> 243  allenet01 1935     1  PHI NL 156 645  90 198  46   1  8  63   5 NA  43  54\n#> 244  allenet01 1936     1  PHI NL  30 125  21  37   3   1  1   9   4 NA   4   8\n#> 245  allenet01 1936     2  CHN NL  91 373  47 110  18   6  3  39  12 NA  13  30\n#> 246  allenet01 1937     1  SLA AL 103 320  39 101  18   1  0  31   3  4  21  17\n#> 247  allenet01 1938     1  SLA AL  19  33   4  10   3   1  0   4   0  0   2   4\n#> 248  allenjo02 1932     1  NYA AL  33  73   5   9   2   1  1   5   0  0   4  22\n#> 249  allenjo02 1933     1  NYA AL  25  72   7  13   1   1  0   3   0  0   4  16\n#> 250  allenjo02 1934     1  NYA AL  13  26   2   5   0   0  0   1   0  0   4   6\n#> 251  allenjo02 1935     1  NYA AL  23  67  12  15   1   0  1  12   0  0   3  13\n#> 252  allenjo02 1936     1  CLE AL  37  87  12  14   0   0  0  10   0  0   6  18\n#> 253  allenjo02 1937     1  CLE AL  24  67   5   6   0   0  0   6   0  0   1  15\n#> 254  allenjo02 1938     1  CLE AL  30  79  12  20   2   1  1  14   1  0   3  14\n#> 255  allenjo02 1939     1  CLE AL  34  71  10  16   2   0  0   3   0  0   3  11\n#> 256  allenjo02 1940     1  CLE AL  32  48   3  10   3   0  0   3   0  0   1   9\n#> 257  allenjo02 1941     1  SLA AL  20  22   6   3   0   0  1   4   0  0   1   3\n#> 258  allenjo02 1941     2  BRO NL  11  20   0   1   0   0  0   0   0 NA   0   5\n#> 259  allenjo02 1942     1  BRO NL  27  39   3   7   0   0  0   2   0 NA   1  11\n#> 260  allenjo02 1943     1  BRO NL  17   7   2   3   1   0  0   1   0 NA   2   0\n#> 261  allenjo02 1943     2  NY1 NL  15  14   1   0   0   0  0   0   0 NA   0   3\n#> 262  allenjo02 1944     1  NY1 NL  24  24   2   2   0   0  0   0   0 NA   0   9\n#> 263  almonbi01 1974     1  SDN NL  16  38   4  12   1   0  0   3   1  0   2   9\n#> 264  almonbi01 1975     1  SDN NL   6  10   0   4   0   0  0   0   0  0   0   1\n#> 265  almonbi01 1976     1  SDN NL  14  57   6  14   3   0  1   6   3  1   2   9\n#> 266  almonbi01 1977     1  SDN NL 155 613  75 160  18  11  2  43  20  9  37 114\n#> 267  almonbi01 1978     1  SDN NL 138 405  39 102  19   2  0  21  17  5  33  74\n#> 268  almonbi01 1979     1  SDN NL 100 198  20  45   3   0  1   8   6  5  21  48\n#> 269  almonbi01 1980     1  MON NL  18  38   2  10   1   1  0   3   0  0   1   5\n#> 270  almonbi01 1980     2  NYN NL  48 112  13  19   3   2  0   4   2  0   8  27\n#> 271  almonbi01 1981     1  CHA AL 103 349  46 105  10   2  4  41  16  6  21  60\n#> 272  almonbi01 1982     1  CHA AL 111 308  40  79  10   4  4  26  10  8  25  49\n#> 273  almonbi01 1983     1  OAK AL 143 451  45 120  29   1  4  63  26  8  26  67\n#> 274  almonbi01 1984     1  OAK AL 106 211  24  47  11   0  7  16   5  7  10  42\n#> 275  almonbi01 1985     1  PIT NL  88 244  33  66  17   0  6  29  10  7  22  61\n#> 276  almonbi01 1986     1  PIT NL 102 196  29  43   7   2  7  27  11  4  30  38\n#> 277  almonbi01 1987     1  PIT NL  19  20   5   4   1   0  0   1   0  0   1   5\n#> 278  almonbi01 1987     2  NYN NL  49  54   8  13   3   0  0   4   1  0   8  16\n#> 279  almonbi01 1988     1  PHI NL  20  26   1   3   2   0  0   1   0  0   3  11\n#> 280  alomaro01 1988     1  SDN NL 143 545  84 145  24   6  9  41  24  6  47  83\n#> 281  alomaro01 1989     1  SDN NL 158 623  82 184  27   1  7  56  42 17  53  76\n#> 282  alomaro01 1990     1  SDN NL 147 586  80 168  27   5  6  60  24  7  48  72\n#> 283  alomaro01 1991     1  TOR AL 161 637  88 188  41  11  9  69  53 11  57  86\n#> 284  alomaro01 1992     1  TOR AL 152 571 105 177  27   8  8  76  49  9  87  52\n#> 285  alomaro01 1993     1  TOR AL 153 589 109 192  35   6 17  93  55 15  80  67\n#> 286  alomaro01 1994     1  TOR AL 107 392  78 120  25   4  8  38  19  8  51  41\n#> 287  alomaro01 1995     1  TOR AL 130 517  71 155  24   7 13  66  30  3  47  45\n#> 288  alomaro01 1996     1  BAL AL 153 588 132 193  43   4 22  94  17  6  90  65\n#> 289  alomaro01 1997     1  BAL AL 112 412  64 137  23   2 14  60   9  3  40  43\n#> 290  alomaro01 1998     1  BAL AL 147 588  86 166  36   1 14  56  18  5  59  70\n#> 291  alomaro01 1999     1  CLE AL 159 563 138 182  40   3 24 120  37  6  99  96\n#> 292  alomaro01 2000     1  CLE AL 155 610 111 189  40   2 19  89  39  4  64  82\n#> 293  alomaro01 2001     1  CLE AL 157 575 113 193  34  12 20 100  30  6  80  71\n#> 294  alomaro01 2002     1  NYN NL 149 590  73 157  24   4 11  53  16  4  57  83\n#> 295  alomaro01 2003     1  NYN NL  73 263  34  69  17   1  2  22   6  0  29  40\n#> 296  alomaro01 2003     2  CHA AL  67 253  42  64  11   1  3  17   6  2  30  37\n#> 297  alomaro01 2004     2  CHA AL  18  61   4  11   1   0  1   8   0  0   2  13\n#> 298  alomaro01 2004     1  ARI NL  38 110  14  34   5   2  3  16   0  2  12  18\n#> 299  alomasa01 1964     1  ML1 NL  19  53   3  13   1   0  0   6   1  0   0  11\n#> 300  alomasa01 1965     1  ML1 NL  67 108  16  26   1   1  0   8  12  5   4  12\n#> 301  alomasa01 1966     1  ATL NL  31  44   4   4   1   0  0   2   0  0   1  10\n#> 302  alomasa01 1967     2  CHA AL  12  15   4   3   0   0  0   0   2  0   2   0\n#> 303  alomasa01 1967     1  NYN NL  15  22   1   0   0   0  0   0   0  0   0   6\n#> 304  alomasa01 1968     1  CHA AL 133 363  41  92   8   2  0  12  21  8  20  42\n#> 305  alomasa01 1969     1  CHA AL  22  58   8  13   2   0  0   4   2  0   4   6\n#> 306  alomasa01 1969     2  CAL AL 134 559  60 140  10   2  1  30  18  3  36  48\n#> 307  alomasa01 1970     1  CAL AL 162 672  82 169  18   2  2  36  35 12  49  65\n#> 308  alomasa01 1971     1  CAL AL 162 689  77 179  24   3  4  42  39 10  41  60\n#> 309  alomasa01 1972     1  CAL AL 155 610  65 146  20   3  1  25  20 12  47  55\n#> 310  alomasa01 1973     1  CAL AL 136 470  45 112   7   1  0  28  25 10  34  44\n#> 311  alomasa01 1974     1  CAL AL  46  54  12  12   0   1  0   1   2  0   2   8\n#> 312  alomasa01 1974     2  NYA AL  76 279  35  75   8   0  1  27   6  4  14  25\n#> 313  alomasa01 1975     1  NYA AL 151 489  61 117  18   4  2  39  28  6  26  58\n#> 314  alomasa01 1976     1  NYA AL  67 163  20  39   4   0  1  10  12  7  13  12\n#> 315  alomasa01 1977     1  TEX AL  69  83  21  22   3   0  1  11   4  3   8  13\n#> 316  alomasa01 1978     1  TEX AL  24  29   3   6   1   0  0   1   0  0   1   7\n#> 317  alomasa02 1988     1  SDN NL   1   1   0   0   0   0  0   0   0  0   0   1\n#> 318  alomasa02 1989     1  SDN NL   7  19   1   4   1   0  1   6   0  0   3   3\n#> 319  alomasa02 1990     1  CLE AL 132 445  60 129  26   2  9  66   4  1  25  46\n#> 320  alomasa02 1991     1  CLE AL  51 184  10  40   9   0  0   7   0  4   8  24\n#> 321  alomasa02 1992     1  CLE AL  89 299  22  75  16   0  2  26   3  3  13  32\n#> 322  alomasa02 1993     1  CLE AL  64 215  24  58   7   1  6  32   3  1  11  28\n#> 323  alomasa02 1994     1  CLE AL  80 292  44  84  15   1 14  43   8  4  25  31\n#> 324  alomasa02 1995     1  CLE AL  66 203  32  61   6   0 10  35   3  1   7  26\n#> 325  alomasa02 1996     1  CLE AL 127 418  53 110  23   0 11  50   1  0  19  42\n#> 326  alomasa02 1997     1  CLE AL 125 451  63 146  37   0 21  83   0  2  19  48\n#> 327  alomasa02 1998     1  CLE AL 117 409  45  96  26   2  6  44   0  3  18  45\n#> 328  alomasa02 1999     1  CLE AL  37 137  19  42  13   0  6  25   0  1   4  23\n#> 329  alomasa02 2000     1  CLE AL  97 356  44 103  16   2  7  42   2  2  16  41\n#> 330  alomasa02 2001     1  CHA AL  70 220  17  54   8   1  4  21   1  2  12  17\n#> 331  alomasa02 2002     2  COL NL  38 116   8  31   4   0  0  12   0  0   4  19\n#> 332  alomasa02 2002     1  CHA AL  51 167  21  48  10   1  7  25   0  0   5  14\n#> 333  alomasa02 2003     1  CHA AL  75 194  22  52  12   0  5  26   0  0   4  17\n#> 334  alomasa02 2004     1  CHA AL  50 146  15  35   4   0  2  14   0  0  11  13\n#> 335  alomasa02 2005     1  TEX AL  46 128  11  35   7   0  0  14   0  0   5  12\n#> 336  alomasa02 2006     1  LAN NL  27  62   3  20   5   0  0   9   0  0   0   7\n#> 337  alomasa02 2006     2  CHA AL  19  46   5  10   3   0  1   8   0  0   3   7\n#> 338  alomasa02 2007     1  NYN NL   8  22   1   3   1   0  0   0   0  0   0   3\n#> 339   aloufe01 1958     1  SFN NL  75 182  21  46   9   2  4  16   4  2  19  34\n#> 340   aloufe01 1959     1  SFN NL  95 247  38  68  13   2 10  33   5  3  17  38\n#> 341   aloufe01 1960     1  SFN NL 106 322  48  85  17   3  8  44  10  2  16  42\n#> 342   aloufe01 1961     1  SFN NL 132 415  59 120  19   0 18  52  11  4  26  41\n#> 343   aloufe01 1962     1  SFN NL 154 561  96 177  30   3 25  98  10  7  33  66\n#> 344   aloufe01 1963     1  SFN NL 157 565  75 159  31   9 20  82  11  2  27  87\n#> 345   aloufe01 1964     1  ML1 NL 121 415  60 105  26   3  9  51   5  2  30  41\n#> 346   aloufe01 1965     1  ML1 NL 143 555  80 165  29   2 23  78   8  4  31  63\n#> 347   aloufe01 1966     1  ATL NL 154 666 122 218  32   6 31  74   5  7  24  51\n#> 348   aloufe01 1967     1  ATL NL 140 574  76 157  26   3 15  43   6  5  32  50\n#> 349   aloufe01 1968     1  ATL NL 160 662  72 210  37   5 11  57  12 11  48  56\n#> 350   aloufe01 1969     1  ATL NL 123 476  54 134  13   1  5  32   4  6  23  23\n#> 351   aloufe01 1970     1  OAK AL 154 575  70 156  25   3  8  55  10  5  32  31\n#> 352   aloufe01 1971     1  OAK AL   2   8   0   2   1   0  0   0   0  0   0   1\n#> 353   aloufe01 1971     2  NYA AL 131 461  52 133  20   6  8  69   5  5  32  24\n#> 354   aloufe01 1972     1  NYA AL 120 324  33  90  18   1  6  37   1  0  22  27\n#> 355   aloufe01 1973     1  NYA AL  93 280  25  66  12   0  4  27   0  1   9  25\n#> 356   aloufe01 1973     2  MON NL  19  48   4  10   1   0  1   4   0  1   2   4\n#> 357   aloufe01 1974     1  ML4 AL   3   3   0   0   0   0  0   0   0  0   0   2\n#> 358   alouje01 1963     1  SFN NL  16  24   3   6   1   0  0   5   0  1   0   3\n#> 359   alouje01 1964     1  SFN NL 115 376  42 103  11   0  3  28   6  6  13  35\n#> 360   alouje01 1965     1  SFN NL 143 543  76 162  19   4  9  52   8  5  13  40\n#> 361   alouje01 1966     1  SFN NL 110 370  41  96  13   1  1  20   5  5   9  22\n#> 362   alouje01 1967     1  SFN NL 129 510  55 149  15   4  5  30   1  7  14  39\n#> 363   alouje01 1968     1  SFN NL 120 419  26 110  15   4  0  39   1  4   9  23\n#> 364   alouje01 1969     1  HOU NL 115 452  49 112  19   4  5  34   4  6  15  30\n#> 365   alouje01 1970     1  HOU NL 117 458  59 140  27   3  1  44   3  2  21  15\n#> 366   alouje01 1971     1  HOU NL 122 433  41 121  21   4  2  40   3  7  13  17\n#> 367   alouje01 1972     1  HOU NL  52  93   8  29   4   1  0  11   0  2   7   5\n#> 368   alouje01 1973     2  OAK AL  36 108  10  33   3   0  1  11   0  0   2   6\n#> 369   alouje01 1973     1  HOU NL  28  55   7  13   2   0  1   8   0  0   1   6\n#> 370   alouje01 1974     1  OAK AL  96 220  13  59   8   0  2  15   0  0   5   9\n#> 371   alouje01 1975     1  NYN NL  62 102   8  27   3   0  0  11   0  1   4   5\n#> 372   alouje01 1978     1  HOU NL  77 139   7  45   5   1  2  19   0  0   6   5\n#> 373   alouje01 1979     1  HOU NL  42  43   3  11   4   0  0  10   0  0   6   7\n#> 374   alouma01 1960     1  SFN NL   4   3   1   1   0   0  0   0   0  0   0   0\n#> 375   alouma01 1961     1  SFN NL  81 200  38  62   7   2  6  24   3  2  15  18\n#> 376   alouma01 1962     1  SFN NL  78 195  28  57   8   1  3  14   3  1  14  17\n#> 377   alouma01 1963     1  SFN NL  63  76   4  11   1   0  0   2   0  1   2  13\n#> 378   alouma01 1964     1  SFN NL 110 250  28  66   4   2  1  14   5  3  11  25\n#> 379   alouma01 1965     1  SFN NL 117 324  37  75  12   2  2  18  10  2  17  28\n#> 380   alouma01 1966     1  PIT NL 141 535  86 183  18   9  2  27  23 15  24  44\n#> 381   alouma01 1967     1  PIT NL 139 550  87 186  21   7  2  28  16 10  24  42\n#> 382   alouma01 1968     1  PIT NL 146 558  59 185  28   4  0  52  18 10  27  26\n#> 383   alouma01 1969     1  PIT NL 162 698 105 231  41   6  1  48  22  8  42  35\n#> 384   alouma01 1970     1  PIT NL 155 677  97 201  21   8  1  47  19 11  30  18\n#> 385   alouma01 1971     1  SLN NL 149 609  85 192  28   6  7  74  19 10  34  27\n#> 386   alouma01 1972     2  OAK AL  32 121  11  34   5   0  1  16   2  1  11  12\n#> 387   alouma01 1972     1  SLN NL 108 404  46 127  17   2  3  31  11  4  24  23\n#> 388   alouma01 1973     1  NYA AL 123 497  59 147  22   1  2  28   5  2  30  43\n#> 389   alouma01 1973     2  SLN NL  11  11   1   3   0   0  0   1   0  0   1   0\n#> 390   alouma01 1974     1  SDN NL  48  81   8  16   3   0  0   3   0  0   5   6\n#> 391   aloumo01 1990     1  PIT NL   2   5   0   1   0   0  0   0   0  0   0   0\n#> 392   aloumo01 1990     2  MON NL  14  15   4   3   0   1  0   0   0  0   0   3\n#> 393   aloumo01 1992     1  MON NL 115 341  53  96  28   2  9  56  16  2  25  46\n#> 394   aloumo01 1993     1  MON NL 136 482  70 138  29   6 18  85  17  6  38  53\n#> 395   aloumo01 1994     1  MON NL 107 422  81 143  31   5 22  78   7  6  42  63\n#> 396   aloumo01 1995     1  MON NL  93 344  48  94  22   0 14  58   4  3  29  56\n#> 397   aloumo01 1996     1  MON NL 143 540  87 152  28   2 21  96   9  4  49  83\n#> 398   aloumo01 1997     1  FLO NL 150 538  88 157  29   5 23 115   9  5  70  85\n#> 399   aloumo01 1998     1  HOU NL 159 584 104 182  34   5 38 124  11  3  84  87\n#> 400   aloumo01 2000     1  HOU NL 126 454  82 161  28   2 30 114   3  3  52  45\n#> 401   aloumo01 2001     1  HOU NL 136 513  79 170  31   1 27 108   5  1  57  57\n#> 402   aloumo01 2002     1  CHN NL 132 484  50 133  23   1 15  61   8  0  47  61\n#> 403   aloumo01 2003     1  CHN NL 151 565  83 158  35   1 22  91   3  1  63  67\n#> 404   aloumo01 2004     1  CHN NL 155 601 106 176  36   3 39 106   3  0  68  80\n#> 405   aloumo01 2005     1  SFN NL 123 427  67 137  21   3 19  63   5  1  56  43\n#> 406   aloumo01 2006     1  SFN NL  98 345  52 104  25   1 22  74   2  1  28  31\n#> 407   aloumo01 2007     1  NYN NL  87 328  51 112  19   1 13  49   3  0  27  30\n#> 408  altroni01 1898     1  LS3 NL  11  29   4   7   0   0  0   2   1 NA   2  NA\n#> 409  altroni01 1902     1  BOS AL   3   8   0   0   0   0  0   0   0 NA   0  NA\n#> 410  altroni01 1903     1  BOS AL   1   3   0   2   0   0  0   0   0 NA   1  NA\n#> 411  altroni01 1903     2  CHA AL  13  30   6   9   0   0  0   3   1 NA   3  NA\n#> 412  altroni01 1904     1  CHA AL  41 111  13  22   1   0  1   8   0 NA   4  NA\n#> 413  altroni01 1905     1  CHA AL  40 112   8  14   1   0  0   5   0 NA   6  NA\n#> 414  altroni01 1906     1  CHA AL  38 100   4  16   2   0  0   3   2 NA   8  NA\n#> 415  altroni01 1907     1  CHA AL  30  72   7  13   3   0  0   2   0 NA   3  NA\n#> 416  altroni01 1908     1  CHA AL  23  49   6  10   2   0  0   3   1 NA   0  NA\n#> 417  altroni01 1909     1  CHA AL   1   3   0   0   0   0  0   0   0 NA   0  NA\n#> 418  altroni01 1909     2  WS1 AL  12  19   2   1   0   0  0   0   0 NA   1  NA\n#> 419  altroni01 1912     1  WS1 AL   1   1   0   0   0   0  0   0   0 NA   0  NA\n#> 420  altroni01 1913     1  WS1 AL   4   1   0   0   0   0  0   0   0 NA   0   0\n#> 421  altroni01 1914     1  WS1 AL   1   0   0   0   0   0  0   0   0  0   0   0\n#> 422  altroni01 1915     1  WS1 AL   1   1   0   0   0   0  0   0   0 NA   0   0\n#> 423  altroni01 1918     1  WS1 AL   5   8   1   1   0   0  1   1   0 NA   0   0\n#> 424  altroni01 1919     1  WS1 AL   1   0   0   0   0   0  0   0   0  0   0   0\n#> 425  altroni01 1924     1  WS1 AL   1   1   1   1   0   1  0   0   0  0   0   0\n#> 426  altroni01 1929     1  WS1 AL   1   1   0   1   0   0  0   0   0  0   0   0\n#> 427  altroni01 1931     1  WS1 AL   1   0   0   0   0   0  0   0   0  1   1   0\n#> 428  altroni01 1933     1  WS1 AL   1   1   0   0   0   0  0   0   0  0   0   0\n#> 429  alvarwi01 1989     1  TEX AL   1   0   0   0   0   0  0   0   0  0   0   0\n#> 430  alvarwi01 1991     1  CHA AL  10   0   0   0   0   0  0   0   0  0   0   0\n#> 431  alvarwi01 1992     1  CHA AL  34   0   0   0   0   0  0   0   0  0   0   0\n#> 432  alvarwi01 1993     1  CHA AL  31   0   0   0   0   0  0   0   0  0   0   0\n#> 433  alvarwi01 1994     1  CHA AL  24   0   0   0   0   0  0   0   0  0   0   0\n#> 434  alvarwi01 1995     1  CHA AL  29   0   0   0   0   0  0   0   0  0   0   0\n#> 435  alvarwi01 1996     1  CHA AL  35   0   0   0   0   0  0   0   0  0   0   0\n#> 436  alvarwi01 1997     1  CHA AL  22   3   0   0   0   0  0   0   0  0   0   2\n#> 437  alvarwi01 1997     2  SFN NL  11  23   1   3   0   0  0   1   0  0   2   5\n#> 438  alvarwi01 1998     1  TBA AL  25   0   0   0   0   0  0   0   0  0   0   0\n#> 439  alvarwi01 1999     1  TBA AL   2   3   0   0   0   0  0   0   0  0   0   1\n#> 440  alvarwi01 2002     1  TBA AL   2   4   0   0   0   0  0   0   0  0   0   1\n#> 441  alvarwi01 2003     1  LAN NL  20  29   1   5   0   0  0   0   0  0   1   9\n#> 442  alvarwi01 2004     1  LAN NL  39  31   4   5   0   0  0   0   0  0   1  14\n#> 443  alvarwi01 2005     1  LAN NL  21   2   0   0   0   0  0   0   0  0   0   1\n#> 444   amesre01 1903     1  NY1 NL   2   6   0   0   0   0  0   1   0 NA   0  NA\n#> 445   amesre01 1904     1  NY1 NL  16  40   3   5   1   0  0   3   0 NA   3  NA\n#> 446   amesre01 1905     1  NY1 NL  34  97   6  14   0   3  0   7   0 NA   4  NA\n#> 447   amesre01 1906     1  NY1 NL  31  61   2   4   0   0  0   0   0 NA   8  NA\n#> 448   amesre01 1907     1  NY1 NL  39  69   5  12   0   0  1   5   0 NA   7  NA\n#> 449   amesre01 1908     1  NY1 NL  18  36   5   7   0   0  0   2   0 NA   1  NA\n#> 450   amesre01 1909     1  NY1 NL  34  81   5   6   1   0  0   6   0 NA   5  NA\n#> 451   amesre01 1910     1  NY1 NL  33  62   1  11   1   0  1   6   0 NA   1  21\n#> 452   amesre01 1911     1  NY1 NL  34  64   2   6   0   1  0   5   0 NA   5  12\n#> 453   amesre01 1912     1  NY1 NL  33  58   6  13   3   0  0   3   1 NA   4  23\n#> 454   amesre01 1913     1  NY1 NL   8  13   1   2   0   0  0   1   1 NA   0   5\n#> 455   amesre01 1913     2  CIN NL  31  59   2   6   0   0  0   2   0 NA   1  22\n#> 456   amesre01 1914     1  CIN NL  47  94   6  12   1   0  1   6   1 NA   2  33\n#> 457   amesre01 1915     1  CIN NL  17  20   1   1   0   0  0   0   1 NA   2   7\n#> 458   amesre01 1915     2  SLN NL  15  35   0   4   0   0  0   2   0  1   2  17\n#> 459   amesre01 1916     1  SLN NL  45  68   3  12   0   1  0   1   0 NA   3  19\n#> 460   amesre01 1917     1  SLN NL  43  64   3  12   1   2  0   7   0 NA   6  23\n#> 461   amesre01 1918     1  SLN NL  27  64   1  10   1   0  0   4   1 NA   7  14\n#> 462   amesre01 1919     1  SLN NL  23  18   0   4   0   0  0   1   0 NA   0   7\n#> 463   amesre01 1919     2  PHI NL   3   5   0   2   1   0  0   1   0 NA   0   1\n#> 464  anderbr01 1988     1  BOS AL  41 148  14  34   5   3  0  12   4  2  15  35\n#> 465  anderbr01 1988     2  BAL AL  53 177  17  35   8   1  1   9   6  4   8  40\n#> 466  anderbr01 1989     1  BAL AL  94 266  44  55  12   2  4  16  16  4  43  45\n#> 467  anderbr01 1990     1  BAL AL  89 234  24  54   5   2  3  24  15  2  31  46\n#> 468  anderbr01 1991     1  BAL AL 113 256  40  59  12   3  2  27  12  5  38  44\n#> 469  anderbr01 1992     1  BAL AL 159 623 100 169  28  10 21  80  53 16  98  98\n#> 470  anderbr01 1993     1  BAL AL 142 560  87 147  36   8 13  66  24 12  82  99\n#> 471  anderbr01 1994     1  BAL AL 111 453  78 119  25   5 12  48  31  1  57  75\n#> 472  anderbr01 1995     1  BAL AL 143 554 108 145  33  10 16  64  26  7  87 111\n#> 473  anderbr01 1996     1  BAL AL 149 579 117 172  37   5 50 110  21  8  76 106\n#> 474  anderbr01 1997     1  BAL AL 151 590  97 170  39   7 18  73  18 12  84 105\n#> 475  anderbr01 1998     1  BAL AL 133 479  84 113  28   3 18  51  21  7  75  78\n#> 476  anderbr01 1999     1  BAL AL 150 564 109 159  28   5 24  81  36  7  96 105\n#> 477  anderbr01 2000     1  BAL AL 141 506  89 130  26   0 19  50  16  9  92 103\n#> 478  anderbr01 2001     1  BAL AL 131 430  50  87  12   3  8  45  12  4  60  77\n#> 479  anderbr01 2002     1  CLE AL  34  80   4  13   4   0  1   5   4  0  18  23\n#> 480  anderjo01 1894     1  BRO NL  17  63  14  19   1   3  1  19   7 NA   3   3\n#> 481  anderjo01 1895     1  BRO NL 102 419  76 120  11  14  9  87  24 NA  12  29\n#> 482  anderjo01 1896     1  BRO NL 108 430  70 135  23  17  1  55  37 NA  18  23\n#> 483  anderjo01 1897     1  BRO NL 117 492  93 160  28  12  4  85  29 NA  17  NA\n#> 484  anderjo01 1898     1  BRO NL  19  69  11  19   3   4  0   8   2 NA   5  NA\n#> 485  anderjo01 1898     2  WSN NL 110 430  70 131  28  18  9  71  18 NA  23  NA\n#> 486  anderjo01 1898     3  BRO NL   6  21   1   3   2   0  0   2   0  0   1  NA\n#> 487  anderjo01 1899     1  BRO NL 117 439  65 118  18   7  4  92  25 NA  27  NA\n#> 488  anderjo01 1901     1  MLA AL 138 576  90 190  46   7  8  99  35 NA  24  NA\n#> 489  anderjo01 1902     1  SLA AL 126 524  60 149  29   6  4  85  15 NA  21  NA\n#> 490  anderjo01 1903     1  SLA AL 138 550  65 156  34   8  2  78  16 NA  23  NA\n#> 491  anderjo01 1904     1  NYA AL 143 558  62 155  27  12  3  82  20 NA  23  NA\n#> 492  anderjo01 1905     1  NYA AL  32  99  12  23   3   1  0  14   9 NA   8  NA\n#> 493  anderjo01 1905     2  WS1 AL 101 400  50 116  21   6  1  38  22 NA  22  NA\n#> 494  anderjo01 1906     1  WS1 AL 151 583  62 158  25   4  3  70  39 NA  19  NA\n#> 495  anderjo01 1907     1  WS1 AL  87 333  33  96  12   4  0  44  19 NA  34  NA\n#> 496  anderjo01 1908     1  CHA AL 123 355  36  93  17   1  0  47  21 NA  30  NA\n#> 497  anderla02 1975     1  CLE AL   3   0   0   0   0   0  0   0   0  0   0   0\n#> 498  anderla02 1977     1  CLE AL  11   0   0   0   0   0  0   0   0  0   0   0\n#> 499  anderla02 1979     1  CLE AL   8   0   0   0   0   0  0   0   0  0   0   0\n#> 500  anderla02 1981     1  SEA AL  41   0   0   0   0   0  0   0   0  0   0   0\n#> 501  anderla02 1982     1  SEA AL  40   0   0   0   0   0  0   0   0  0   0   0\n#> 502  anderla02 1983     1  PHI NL  17   2   0   0   0   0  0   0   0  0   0   0\n#> 503  anderla02 1984     1  PHI NL  64   4   0   0   0   0  0   0   0  0   0   3\n#> 504  anderla02 1985     1  PHI NL  57   4   1   0   0   0  0   0   0  0   0   0\n#> 505  anderla02 1986     1  PHI NL  10   0   0   0   0   0  0   0   0  0   0   0\n#> 506  anderla02 1986     2  HOU NL  38   6   0   0   0   0  0   0   0  0   0   3\n#> 507  anderla02 1987     1  HOU NL  67   6   1   1   0   0  0   0   0  0   1   4\n#> 508  anderla02 1988     1  HOU NL  53   6   1   2   0   0  0   0   0  0   0   1\n#> 509  anderla02 1989     1  HOU NL  60   3   0   1   0   0  0   0   0  0   0   2\n#> 510  anderla02 1990     2  BOS AL  15   0   0   0   0   0  0   0   0  0   0   0\n#> 511  anderla02 1990     1  HOU NL  50   3   0   0   0   0  0   0   0  0   0   0\n#> 512  anderla02 1991     1  SDN NL  38   2   0   0   0   0  0   0   0  0   0   1\n#> 513  anderla02 1992     1  SDN NL  34   1   1   0   0   0  0   0   0  0   1   1\n#> 514  anderla02 1993     1  PHI NL  64   1   0   1   0   0  0   0   0  0   0   0\n#> 515  anderla02 1994     1  PHI NL  29   0   0   0   0   0  0   0   0  0   1   0\n#> 516  ansonca01 1871     1  RC1     25 120  29  39  11   3  0  16   6  2   2   1\n#> 517  ansonca01 1872     1  PH1     46 217  60  90  10   7  0  50   6  6  16   3\n#> 518  ansonca01 1873     1  PH1     52 254  53 101   9   2  0  36   0  2   5   1\n#> 519  ansonca01 1874     1  PH1     55 259  51  87   8   3  0  37   6  0   4   1\n#> 520  ansonca01 1875     1  PH1     69 326  84 106  15   3  0  58  11  6   4   2\n#> 521  ansonca01 1876     1  CHN NL  66 309  63 110   9   7  2  59  NA NA  12   8\n#> 522  ansonca01 1877     1  CHN NL  59 255  52  86  19   1  0  32  NA NA   9   3\n#> 523  ansonca01 1878     1  CHN NL  60 261  55  89  12   2  0  40  NA NA  13   1\n#> 524  ansonca01 1879     1  CHN NL  51 227  40  72  20   1  0  34  NA NA   2   2\n#> 525  ansonca01 1880     1  CHN NL  86 356  54 120  24   1  1  74  NA NA  14  12\n#> 526  ansonca01 1881     1  CHN NL  84 343  67 137  21   7  1  82  NA NA  26   4\n#> 527  ansonca01 1882     1  CHN NL  82 348  69 126  29   8  1  83  NA NA  20   7\n#> 528  ansonca01 1883     1  CHN NL  98 413  70 127  36   5  0  68  NA NA  18   9\n#> 529  ansonca01 1884     1  CHN NL 112 475 108 159  30   3 21 102  NA NA  29  13\n#> 530  ansonca01 1885     1  CHN NL 112 464 100 144  35   7  7 108  NA NA  34  13\n#> 531  ansonca01 1886     1  CHN NL 125 504 117 187  35  11 10 147  29 NA  55  19\n#> 532  ansonca01 1887     1  CHN NL 122 472 107 164  33  13  7 102  27 NA  60  18\n#> 533  ansonca01 1888     1  CHN NL 134 515 101 177  20  12 12  84  28 NA  47  24\n#> 534  ansonca01 1889     1  CHN NL 134 518 100 161  32   7  7 117  27 NA  86  19\n#> 535  ansonca01 1890     1  CHN NL 139 504  95 157  14   5  7 107  29 NA 113  23\n#> 536  ansonca01 1891     1  CHN NL 136 540  81 157  24   8  8 120  17 NA  75  29\n#> 537  ansonca01 1892     1  CHN NL 146 559  62 152  25   9  1  74  13 NA  67  30\n#> 538  ansonca01 1893     1  CHN NL 103 398  70 125  24   2  0  91  13 NA  68  12\n#> 539  ansonca01 1894     1  CHN NL  83 340  82 132  28   4  5  99  17 NA  40  15\n#> 540  ansonca01 1895     1  CHN NL 122 474  87 159  23   6  2  91  12 NA  55  23\n#> 541  ansonca01 1896     1  CHN NL 108 402  72 133  18   2  2  90  24 NA  49  10\n#> 542  ansonca01 1897     1  CHN NL 114 424  67 121  17   3  3  75  11 NA  60  NA\n#> 543  aparilu01 1956     1  CHA AL 152 533  69 142  19   6  3  56  21  4  34  63\n#> 544  aparilu01 1957     1  CHA AL 143 575  82 148  22   6  3  41  28  8  52  55\n#> 545  aparilu01 1958     1  CHA AL 145 557  76 148  20   9  2  40  29  6  35  38\n#> 546  aparilu01 1959     1  CHA AL 152 612  98 157  18   5  6  51  56 13  53  40\n#> 547  aparilu01 1960     1  CHA AL 153 600  86 166  20   7  2  61  51  8  43  39\n#> 548  aparilu01 1961     1  CHA AL 156 625  90 170  24   4  6  45  53 13  38  33\n#> 549  aparilu01 1962     1  CHA AL 153 581  72 140  23   5  7  40  31 12  32  36\n#> 550  aparilu01 1963     1  BAL AL 146 601  73 150  18   8  5  45  40  6  36  35\n#> 551  aparilu01 1964     1  BAL AL 146 578  93 154  20   3 10  37  57 17  49  51\n#> 552  aparilu01 1965     1  BAL AL 144 564  67 127  20  10  8  40  26  7  46  56\n#> 553  aparilu01 1966     1  BAL AL 151 659  97 182  25   8  6  41  25 11  33  42\n#> 554  aparilu01 1967     1  BAL AL 134 546  55 127  22   5  4  31  18  5  29  44\n#> 555  aparilu01 1968     1  CHA AL 157 622  55 164  24   4  4  36  17 11  33  43\n#> 556  aparilu01 1969     1  CHA AL 156 599  77 168  24   5  5  51  24  4  66  29\n#> 557  aparilu01 1970     1  CHA AL 146 552  86 173  29   3  5  43   8  3  53  34\n#> 558  aparilu01 1971     1  BOS AL 125 491  56 114  23   0  4  45   6  4  35  43\n#> 559  aparilu01 1972     1  BOS AL 110 436  47 112  26   3  3  39   3  3  26  28\n#> 560  aparilu01 1973     1  BOS AL 132 499  56 135  17   1  0  49  13  1  43  33\n#> 561  appieke01 1989     1  KCA AL   6   0   0   0   0   0  0   0   0  0   0   0\n#> 562  appieke01 1990     1  KCA AL  32   0   0   0   0   0  0   0   0  0   0   0\n#> 563  appieke01 1991     1  KCA AL  34   0   0   0   0   0  0   0   0  0   0   0\n#> 564  appieke01 1992     1  KCA AL  30   0   0   0   0   0  0   0   0  0   0   0\n#> 565  appieke01 1993     1  KCA AL  34   0   0   0   0   0  0   0   0  0   0   0\n#> 566  appieke01 1994     1  KCA AL  23   0   0   0   0   0  0   0   0  0   0   0\n#> 567  appieke01 1995     1  KCA AL  31   0   0   0   0   0  0   0   0  0   0   0\n#> 568  appieke01 1996     1  KCA AL  32   0   0   0   0   0  0   0   0  0   0   0\n#> 569  appieke01 1997     1  KCA AL   3   6   0   0   0   0  0   0   0  0   0   5\n#> 570  appieke01 1998     1  KCA AL   3   0   0   0   0   0  0   0   0  0   0   0\n#> 571  appieke01 1999     1  KCA AL   1   2   0   0   0   0  0   0   0  0   0   1\n#> 572  appieke01 1999     2  OAK AL  12   0   0   0   0   0  0   0   0  0   0   0\n#> 573  appieke01 2000     1  OAK AL   2   6   0   1   0   0  0   0   0  0   0   3\n#> 574  appieke01 2001     1  NYN NL  31  62   4   7   0   0  0   4   0  0   1  24\n#> 575  appieke01 2002     1  ANA AL   2   2   0   0   0   0  0   0   0  0   0   2\n#> 576  appieke01 2003     2  KCA AL   4   0   0   0   0   0  0   0   0  0   0   0\n#> 577  appieke01 2003     1  ANA AL   2   5   0   0   0   0  0   0   0  0   0   4\n#> 578  appieke01 2004     1  KCA AL   2   0   0   0   0   0  0   0   0  0   0   0\n#> 579  applepe01 1927     1  CIN NL   6  11   1   6   0   0  0   1   0 NA   0   0\n#> 580  applepe01 1928     1  CIN NL  32  31   3  10   2   1  0   3   0 NA   0   4\n#> 581  applepe01 1930     1  CLE AL  39  40   4   8   1   0  0   2   0  0   3   9\n#> 582  applepe01 1931     1  CLE AL  30  24   1   5   0   1  0   1   0  0   1   3\n#> 583  applepe01 1932     1  CLE AL   4   0   0   0   0   0  0   0   0  0   0   0\n#> 584  applepe01 1932     2  BOS AL  11  17   3   3   1   0  0   1   0  0   0   5\n#> 585  applepe01 1933     1  NYA AL   1   0   0   0   0   0  0   0   0  0   0   0\n#> 586  applepe01 1936     1  WS1 AL  38  76   7  19   1   1  0   8   0  0   0  15\n#> 587  applepe01 1937     1  WS1 AL  35  59   3  11   0   1  0   7   0  0   0  12\n#> 588  applepe01 1938     1  WS1 AL  43  59   4  15   2   2  0   9   0  1   1   8\n#> 589  applepe01 1939     1  WS1 AL  40  25   1   4   1   0  0   0   0  0   1   3\n#> 590  applepe01 1940     1  CHA AL  25  17   2   3   0   0  0   0   0  0   1   5\n#> 591  applepe01 1941     1  CHA AL  13   4   0   1   0   0  0   0   0  0   0   0\n#> 592  applepe01 1942     1  CHA AL   4   0   0   0   0   0  0   0   0  0   0   0\n#> 593  applepe01 1942     2  SLA AL  14   6   1   1   0   1  0   1   0  0   1   1\n#> 594  applepe01 1945     1  SLA AL   2   0   0   0   0   0  0   0   0  0   0   0\n#> 595  applepe01 1945     2  WS1 AL   6   5   0   1   0   0  0   1   0  0   0   1\n#> 596  applilu01 1930     1  CHA AL   6  26   2   8   2   0  0   2   2  0   0   0\n#> 597  applilu01 1931     1  CHA AL  96 297  36  69  13   4  1  28   9  2  29  27\n#> 598  applilu01 1932     1  CHA AL 139 489  66 134  20  10  3  63   9  8  40  36\n#> 599  applilu01 1933     1  CHA AL 151 612  90 197  36  10  6  85   6 11  56  29\n#> 600  applilu01 1934     1  CHA AL 118 452  75 137  28   6  2  61   3  1  59  27\n#> 601  applilu01 1935     1  CHA AL 153 525  94 161  28   6  1  71  12  6 122  40\n#> 602  applilu01 1936     1  CHA AL 138 526 111 204  31   7  6 128  10  6  85  25\n#> 603  applilu01 1937     1  CHA AL 154 574  98 182  42   8  4  77  18 10  86  28\n#> 604  applilu01 1938     1  CHA AL  81 294  41  89  14   0  0  44   1  3  42  17\n#> 605  applilu01 1939     1  CHA AL 148 516  82 162  16   6  0  56  16  9 105  37\n#> 606  applilu01 1940     1  CHA AL 150 566  96 197  27  13  0  79   3  5  69  35\n#> 607  applilu01 1941     1  CHA AL 154 592  93 186  26   8  1  57  12  8  82  32\n#> 608  applilu01 1942     1  CHA AL 142 543  78 142  26   4  3  53  17  5  63  23\n#> 609  applilu01 1943     1  CHA AL 155 585  63 192  33   2  3  80  27  8  90  29\n#> 610  applilu01 1945     1  CHA AL  18  57  12  21   2   2  1  10   1  0  12   7\n#> 611  applilu01 1946     1  CHA AL 149 582  59 180  27   5  1  55   6  4  71  41\n#> 612  applilu01 1947     1  CHA AL 139 503  67 154  29   0  8  49   8  6  64  28\n#> 613  applilu01 1948     1  CHA AL 139 497  63 156  16   2  0  47  10  4  94  35\n#> 614  applilu01 1949     1  CHA AL 142 492  82 148  21   5  5  58   7 12 121  24\n#> 615  applilu01 1950     1  CHA AL  50 128  11  30   3   4  0  13   2  0  12   8\n#> 616  ashburi01 1948     1  PHI NL 117 463  78 154  17   4  2  40  32 NA  60  22\n#> 617  ashburi01 1949     1  PHI NL 154 662  84 188  18  11  1  37   9 NA  58  38\n#> 618  ashburi01 1950     1  PHI NL 151 594  84 180  25  14  2  41  14 NA  63  32\n#> 619  ashburi01 1951     1  PHI NL 154 643  92 221  31   5  4  63  29  6  50  37\n#> 620  ashburi01 1952     1  PHI NL 154 613  93 173  31   6  1  42  16 11  75  30\n#> 621  ashburi01 1953     1  PHI NL 156 622 110 205  25   9  2  57  14  6  61  35\n#> 622  ashburi01 1954     1  PHI NL 153 559 111 175  16   8  1  41  11  8 125  46\n#> 623  ashburi01 1955     1  PHI NL 140 533  91 180  32   9  3  42  12 10 105  36\n#> 624  ashburi01 1956     1  PHI NL 154 628  94 190  26   8  3  50  10  1  79  45\n#> 625  ashburi01 1957     1  PHI NL 156 626  93 186  26   8  0  33  13 10  94  44\n#> 626  ashburi01 1958     1  PHI NL 152 615  98 215  24  13  2  33  30 12  97  48\n#> 627  ashburi01 1959     1  PHI NL 153 564  86 150  16   2  1  20   9 11  79  42\n#> 628  ashburi01 1960     1  CHN NL 151 547  99 159  16   5  0  40  16  4 116  50\n#> 629  ashburi01 1961     1  CHN NL 109 307  49  79   7   4  0  19   7  6  55  27\n#> 630  ashburi01 1962     1  NYN NL 135 389  60 119   7   3  7  28  12  7  81  39\n#> 631  ashbyal01 1973     1  CLE AL  11  29   4   5   1   0  1   3   0  0   2  11\n#> 632  ashbyal01 1974     1  CLE AL  10   7   1   1   0   0  0   0   0  0   1   2\n#> 633  ashbyal01 1975     1  CLE AL  90 254  32  57  10   1  5  32   3  2  30  42\n#> 634  ashbyal01 1976     1  CLE AL  89 247  26  59   5   1  4  32   0  2  27  49\n#> 635  ashbyal01 1977     1  TOR AL 124 396  25  83  16   3  2  29   0  2  50  51\n#> 636  ashbyal01 1978     1  TOR AL  81 264  27  69  15   0  9  29   1  1  28  32\n#> 637  ashbyal01 1979     1  HOU NL 108 336  25  68  15   2  2  35   0  0  26  70\n#> 638  ashbyal01 1980     1  HOU NL 116 352  30  90  19   2  3  48   0  0  35  40\n#> 639  ashbyal01 1981     1  HOU NL  83 255  20  69  13   0  4  33   0  2  35  33\n#> 640  ashbyal01 1982     1  HOU NL 100 339  40  87  14   2 12  49   2  0  27  53\n#> 641  ashbyal01 1983     1  HOU NL  87 275  31  63  18   1  8  34   0  0  31  38\n#> 642  ashbyal01 1984     1  HOU NL  66 191  16  50   7   0  4  27   0  0  20  22\n#> 643  ashbyal01 1985     1  HOU NL  65 189  20  53   8   0  8  25   0  0  24  27\n#> 644  ashbyal01 1986     1  HOU NL 120 315  24  81  15   0  7  38   1  0  39  56\n#> 645  ashbyal01 1987     1  HOU NL 125 386  53 111  16   0 14  63   0  1  50  52\n#> 646  ashbyal01 1988     1  HOU NL  73 227  19  54  10   0  7  33   0  0  29  36\n#> 647  ashbyal01 1989     1  HOU NL  22  61   4  10   1   1  0   3   0  0   7   8\n#> 648  ashbyan01 1991     1  PHI NL   8  12   0   1   0   0  0   0   0  0   0   9\n#> 649  ashbyan01 1992     1  PHI NL  10  11   0   1   1   0  0   1   0  0   0   7\n#> 650  ashbyan01 1993     1  COL NL  20  15   1   4   0   0  0   1   0  0   0   3\n#> 651  ashbyan01 1993     2  SDN NL  12  21   2   1   1   0  0   0   0  0   2   6\n#> 652  ashbyan01 1994     1  SDN NL  24  49   2   8   0   0  0   0   0  0   1  19\n#> 653  ashbyan01 1995     1  SDN NL  31  49   2   8   1   0  0   3   1  0   1  24\n#> 654  ashbyan01 1996     1  SDN NL  25  45   6  11   5   0  0   5   0  0   0  13\n#> 655  ashbyan01 1997     1  SDN NL  29  60   1   4   1   0  0   1   0  0   2  24\n#> 656  ashbyan01 1998     1  SDN NL  32  72   1   8   2   0  0   2   0  0   2  35\n#> 657  ashbyan01 1999     1  SDN NL  29  62   3   8   2   0  0   2   0  0   3  25\n#> 658  ashbyan01 2000     1  PHI NL  15  28   0   5   0   0  0   5   0  0   2  10\n#> 659  ashbyan01 2000     2  ATL NL  16  33   2   4   0   0  0   1   0  0   0  12\n#> 660  ashbyan01 2001     1  LAN NL   3   2   1   1   0   0  0   1   0  0   1   0\n#> 661  ashbyan01 2002     1  LAN NL  27  48   5   6   0   0  1   4   0  0   2  23\n#> 662  ashbyan01 2003     1  LAN NL  20  14   0   0   0   0  0   0   0  0   0   8\n#> 663  ashbyan01 2004     1  SDN NL   2   0   0   0   0   0  0   0   0  0   0   0\n#> 664  assenpa01 1986     1  ATL NL  61   6   0   0   0   0  0   0   0  0   2   3\n#> 665  assenpa01 1987     1  ATL NL  52   4   1   0   0   0  0   0   0  0   1   2\n#> 666  assenpa01 1988     1  ATL NL  64   3   0   1   1   0  0   0   0  0   0   0\n#> 667  assenpa01 1989     1  ATL NL  49   2   0   0   0   0  0   0   0  0   0   1\n#> 668  assenpa01 1989     2  CHN NL  14   3   0   0   0   0  0   0   0  0   0   1\n#> 669  assenpa01 1990     1  CHN NL  74   8   0   0   0   0  0   0   0  0   0   3\n#> 670  assenpa01 1991     1  CHN NL  75   4   1   1   0   0  0   0   0  0   1   1\n#> 671  assenpa01 1992     1  CHN NL  70   4   1   0   0   0  0   0   0  0   1   1\n#> 672  assenpa01 1993     2  NYA AL  26   0   0   0   0   0  0   0   0  0   0   0\n#> 673  assenpa01 1993     1  CHN NL  46   2   0   1   0   0  0   0   0  0   0   0\n#> 674  assenpa01 1994     1  CHA AL  44   0   0   0   0   0  0   0   0  0   0   0\n#> 675  assenpa01 1995     1  CLE AL  47   0   0   0   0   0  0   0   0  0   0   0\n#> 676  assenpa01 1996     1  CLE AL  63   0   0   0   0   0  0   0   0  0   0   0\n#> 677  assenpa01 1997     1  CLE AL  75   0   0   0   0   0  0   0   0  0   0   0\n#> 678  assenpa01 1998     1  CLE AL  69   0   0   0   0   0  0   0   0  0   0   0\n#> 679  assenpa01 1999     1  CLE AL  55   0   0   0   0   0  0   0   0  0   0   0\n#> 680  astacpe01 1992     1  LAN NL  11  24   2   3   0   0  0   1   0  0   0  14\n#> 681  astacpe01 1993     1  LAN NL  31  62   4  10   0   0  0   2   0  1   0  26\n#> 682  astacpe01 1994     1  LAN NL  23  47   2   3   0   0  0   0   0  0   0  22\n#> 683  astacpe01 1995     1  LAN NL  48  24   0   3   1   0  0   0   0  0   1   9\n#> 684  astacpe01 1996     1  LAN NL  35  68   1   6   0   0  0   3   0  0   1  28\n#> 685  astacpe01 1997     1  LAN NL  26  41   2   6   0   0  0   1   0  0   0  16\n#> 686  astacpe01 1997     2  COL NL   7  13   0   1   0   0  0   0   0  0   0   8\n#> 687  astacpe01 1998     1  COL NL  34  62   4   8   2   0  0   3   0  0   0  21\n#> 688  astacpe01 1999     1  COL NL  36  85   5  20   2   1  0   7   0  0   1  24\n#> 689  astacpe01 2000     1  COL NL  32  82   2   8   0   0  0   6   0  0   1  25\n#> 690  astacpe01 2001     1  COL NL  20  42   2   4   0   0  0   3   0  0   0  12\n#> 691  astacpe01 2001     2  HOU NL   4  11   0   1   0   0  0   0   0  0   0   5\n#> 692  astacpe01 2002     1  NYN NL  30  62   3  10   2   0  0   1   0  0   0  31\n#> 693  astacpe01 2003     1  NYN NL   7  11   1   1   0   0  0   0   0  0   0   2\n#> 694  astacpe01 2004     1  BOS AL   5   0   0   0   0   0  0   0   0  0   0   0\n#> 695  astacpe01 2006     1  WAS NL  17  25   2   5   0   0  0   0   0  0   0   8\n#> 696  astacpe01 2005     2  SDN NL  12  16   1   1   0   0  0   1   0  0   1   5\n#> 697  astacpe01 2005     1  TEX AL  12   1   0   0   0   0  0   0   0  0   0   0\n#> 698  ausmubr01 1993     1  SDN NL  49 160  18  41   8   1  5  12   2  0   6  28\n#> 699  ausmubr01 1994     1  SDN NL 101 327  45  82  12   1  7  24   5  1  30  63\n#> 700  ausmubr01 1995     1  SDN NL 103 328  44  96  16   4  5  34  16  5  31  56\n#> 701  ausmubr01 1996     2  DET AL  75 226  30  56  12   0  4  22   3  4  26  45\n#> 702  ausmubr01 1996     1  SDN NL  50 149  16  27   4   0  1  13   1  4  13  27\n#> 703  ausmubr01 1997     1  HOU NL 130 425  45 113  25   1  4  44  14  6  38  78\n#> 704  ausmubr01 1998     1  HOU NL 128 412  62 111  10   4  6  45  10  3  53  60\n#> 705  ausmubr01 1999     1  DET AL 127 458  62 126  25   6  9  54  12  9  51  71\n#> 706  ausmubr01 2000     1  DET AL 150 523  75 139  25   3  7  51  11  5  69  79\n#> 707  ausmubr01 2001     1  HOU NL 128 422  45  98  23   4  5  34   4  1  30  64\n#> 708  ausmubr01 2002     1  HOU NL 130 447  57 115  19   3  6  50   2  3  38  71\n#> 709  ausmubr01 2003     1  HOU NL 143 450  43 103  12   2  4  47   5  3  46  66\n#> 710  ausmubr01 2004     1  HOU NL 129 403  38 100  14   1  5  31   2  2  33  56\n#> 711  ausmubr01 2005     1  HOU NL 134 387  35 100  19   0  3  47   5  3  51  48\n#> 712  ausmubr01 2006     1  HOU NL 139 439  37 101  16   1  2  39   3  1  45  71\n#> 713  ausmubr01 2007     1  HOU NL 117 349  38  82  16   3  3  25   6  1  37  74\n#> 714  austiji01 1909     1  NYA AL 136 437  37 101  11   5  1  39  30 NA  32  NA\n#> 715  austiji01 1910     1  NYA AL 133 432  46  94  11   4  2  36  22 NA  47  NA\n#> 716  austiji01 1911     1  SLA AL 148 541  84 141  25  11  2  45  26 NA  69  NA\n#> 717  austiji01 1912     1  SLA AL 149 536  57 135  14   8  2  44  28 NA  38  NA\n#> 718  austiji01 1913     1  SLA AL 142 489  56 130  18   6  2  42  37 NA  45  51\n#> 719  austiji01 1914     1  SLA AL 130 466  55 111  16   4  0  30  20 23  40  59\n#> 720  austiji01 1915     1  SLA AL 141 477  61 127   6   6  1  30  18 15  64  60\n#> 721  austiji01 1916     1  SLA AL 129 411  55  85  15   6  1  28  19 NA  74  59\n#> 722  austiji01 1917     1  SLA AL 127 455  61 109  18   8  0  19  13 NA  50  46\n#> 723  austiji01 1918     1  SLA AL 110 367  42  97  14   4  0  20  18 NA  53  32\n#> 724  austiji01 1919     1  SLA AL 106 396  54  94   9   9  1  21   8 NA  42  31\n#> 725  austiji01 1920     1  SLA AL  83 280  38  76  11   3  1  32   2  4  31  15\n#> 726  austiji01 1921     1  SLA AL  27  66   8  18   2   1  0   2   2  1   4   7\n#> 727  austiji01 1922     1  SLA AL  15  31   6   9   3   1  0   1   0  0   3   2\n#> 728  austiji01 1923     1  SLA AL   1   0   0   0   0   0  0   0   0  0   0   0\n#> 729  austiji01 1925     1  SLA AL   1   1   0   0   0   0  0   0   0  0   0   0\n#> 730  austiji01 1926     1  SLA AL   1   2   1   1   1   0  0   1   1  0   0   0\n#> 731  austiji01 1929     1  SLA AL   1   1   0   0   0   0  0   0   0  0   0   1\n#> 732  azcuejo01 1960     1  CIN NL  14  31   1   3   0   0  0   3   0  1   2   6\n#> 733  azcuejo01 1962     1  KC1 AL  72 223  18  51   9   1  2  25   1  0  17  27\n#> 734  azcuejo01 1963     1  KC1 AL   2   4   0   0   0   0  0   0   0  0   0   1\n#> 735  azcuejo01 1963     2  CLE AL  94 320  26  91  16   0 14  46   1  1  15  46\n#> 736  azcuejo01 1964     1  CLE AL  83 271  20  74   9   1  4  34   0  2  16  38\n#> 737  azcuejo01 1965     1  CLE AL 111 335  16  77   7   0  2  35   2  1  27  54\n#> 738  azcuejo01 1966     1  CLE AL  98 302  22  83  10   1  9  37   0  2  20  22\n#> 739  azcuejo01 1967     1  CLE AL  86 295  33  74  12   5 11  34   0  3  22  35\n#> 740  azcuejo01 1968     1  CLE AL 115 357  23 100  10   0  4  42   1  1  28  33\n#> 741  azcuejo01 1969     1  CLE AL   7  24   1   7   0   0  1   1   0  0   4   3\n#> 742  azcuejo01 1969     2  BOS AL  19  51   7  11   2   0  0   3   0  0   4   5\n#> 743  azcuejo01 1969     3  CAL AL  80 248  15  54   6   0  1  19   0  1  27  28\n#> 744  azcuejo01 1970     1  CAL AL 114 351  19  85  13   1  2  25   0  0  24  40\n#> 745  azcuejo01 1972     1  CAL AL   3   2   0   0   0   0  0   0   0  0   0   1\n#> 746  azcuejo01 1972     2  ML4 AL  11  14   0   2   0   0  0   0   0  0   1   5\n#> 747  baergca01 1990     1  CLE AL 108 312  46  81  17   2  7  47   0  2  16  57\n#> 748  baergca01 1991     1  CLE AL 158 593  80 171  28   2 11  69   3  2  48  74\n#> 749  baergca01 1992     1  CLE AL 161 657  92 205  32   1 20 105  10  2  35  76\n#> 750  baergca01 1993     1  CLE AL 154 624 105 200  28   6 21 114  15  4  34  68\n#> 751  baergca01 1994     1  CLE AL 103 442  81 139  32   2 19  80   8  2  10  45\n#> 752  baergca01 1995     1  CLE AL 135 557  87 175  28   2 15  90  11  2  35  31\n#> 753  baergca01 1996     1  CLE AL 100 424  54 113  25   0 10  55   1  1  16  25\n#> 754  baergca01 1996     2  NYN NL  26  83   5  16   3   0  2  11   0  0   5   2\n#> 755  baergca01 1997     1  NYN NL 133 467  53 131  25   1  9  52   2  6  20  54\n#> 756  baergca01 1998     1  NYN NL 147 511  46 136  27   1  7  53   0  1  24  55\n#> 757  baergca01 1999     2  CLE AL  22  57   4  13   0   0  1   5   1  1   4  10\n#> 758  baergca01 1999     1  SDN NL  33  80   6  20   1   0  2   5   1  0   6  14\n#> 759  baergca01 2002     1  BOS AL  73 182  17  52  11   0  2  19   6  0   7  20\n#> 760  baergca01 2003     1  ARI NL 105 207  31  71  13   0  4  39   1  1  18  20\n#> 761  baergca01 2004     1  ARI NL  79  85   6  20   2   0  2  11   0  0   6  12\n#> 762  baergca01 2005     1  WAS NL  93 158  18  40   7   0  2  19   0  0   7  17\n#> 763  bagweje01 1991     1  HOU NL 156 554  79 163  26   4 15  82   7  4  75 116\n#> 764  bagweje01 1992     1  HOU NL 162 586  87 160  34   6 18  96  10  6  84  97\n#> 765  bagweje01 1993     1  HOU NL 142 535  76 171  37   4 20  88  13  4  62  73\n#> 766  bagweje01 1994     1  HOU NL 110 400 104 147  32   2 39 116  15  4  65  65\n#> 767  bagweje01 1995     1  HOU NL 114 448  88 130  29   0 21  87  12  5  79 102\n#> 768  bagweje01 1996     1  HOU NL 162 568 111 179  48   2 31 120  21  7 135 114\n#> 769  bagweje01 1997     1  HOU NL 162 566 109 162  40   2 43 135  31 10 127 122\n#> 770  bagweje01 1998     1  HOU NL 147 540 124 164  33   1 34 111  19  7 109  90\n#> 771  bagweje01 1999     1  HOU NL 162 562 143 171  35   0 42 126  30 11 149 127\n#> 772  bagweje01 2000     1  HOU NL 159 590 152 183  37   1 47 132   9  6 107 116\n#> 773  bagweje01 2001     1  HOU NL 161 600 126 173  43   4 39 130  11  3 106 135\n#> 774  bagweje01 2002     1  HOU NL 158 571  94 166  33   2 31  98   7  3 101 130\n#> 775  bagweje01 2003     1  HOU NL 160 605 109 168  28   2 39 100  11  4  88 119\n#> 776  bagweje01 2004     1  HOU NL 156 572 104 152  29   2 27  89   6  4  96 131\n#> 777  bagweje01 2005     1  HOU NL  39 100  11  25   4   0  3  19   0  0  18  21\n#> 778  bahnsst01 1966     1  NYA AL   4   7   0   1   0   0  0   0   0  0   0   5\n#> 779  bahnsst01 1968     1  NYA AL  37  81   4   4   0   0  0   3   0  0   6  49\n#> 780  bahnsst01 1969     1  NYA AL  40  60   1   5   1   0  0   1   0  0   2  33\n#> 781  bahnsst01 1970     1  NYA AL  36  74   3  11   0   1  0   1   0  0   2  34\n#> 782  bahnsst01 1971     1  NYA AL  36  79   6  12   2   1  0   3   0  0   1  32\n#> 783  bahnsst01 1972     1  CHA AL  44  92   5  14   2   0  0   2   0  0   1  38\n#> 784  bahnsst01 1973     1  CHA AL  42   0   0   0   0   0  0   0   0  0   0   0\n#> 785  bahnsst01 1974     1  CHA AL  38   0   0   0   0   0  0   0   0  0   0   0\n#> 786  bahnsst01 1975     1  CHA AL  12   0   0   0   0   0  0   0   0  0   0   0\n#> 787  bahnsst01 1975     2  OAK AL  21   1   0   0   0   0  0   0   0  0   0   1\n#> 788  bahnsst01 1976     1  OAK AL  35   0   0   0   0   0  0   0   0  0   0   0\n#> 789  bahnsst01 1977     1  OAK AL  11   0   0   0   0   0  0   0   0  0   0   0\n#> 790  bahnsst01 1977     2  MON NL  23  42   0   5   2   0  0   7   0  0   3  18\n#> 791  bahnsst01 1978     1  MON NL  44  11   0   1   0   0  0   0   0  0   0   3\n#> 792  bahnsst01 1979     1  MON NL  55  14   2   1   0   0  1   2   0  0   0   5\n#> 793  bahnsst01 1980     1  MON NL  57   9   1   1   1   0  0   0   0  0   4   3\n#> 794  bahnsst01 1981     1  MON NL  25   9   0   1   0   0  0   0   0  0   0   4\n#> 795  bahnsst01 1982     1  CAL AL   7   0   0   0   0   0  0   0   0  0   0   0\n#> 796  bahnsst01 1982     2  PHI NL   8   0   0   0   0   0  0   0   0  0   0   0\n#> 797  bailebo01 1962     1  PIT NL  14  42   6   7   2   1  0   6   1  1   6  10\n#> 798  bailebo01 1963     1  PIT NL 154 570  60 130  15   3 12  45  10  9  58  98\n#> 799  bailebo01 1964     1  PIT NL 143 530  73 149  26   3 11  51  10  8  44  78\n#> 800  bailebo01 1965     1  PIT NL 159 626  87 160  28   3 11  49  10 14  70  93\n#> 801  bailebo01 1966     1  PIT NL 126 380  51 106  19   3 13  46   5  3  47  65\n#> 802  bailebo01 1967     1  LAN NL 116 322  21  73   8   2  4  28   5  5  40  50\n#> 803  bailebo01 1968     1  LAN NL 105 322  24  73   9   3  8  39   1  2  38  69\n#> 804  bailebo01 1969     1  MON NL 111 358  46  95  16   6  9  53   3  3  40  76\n#> 805  bailebo01 1970     1  MON NL 131 352  77 101  19   3 28  84   5  3  72  70\n#> 806  bailebo01 1971     1  MON NL 157 545  65 137  21   4 14  83  13  7  97 105\n#> 807  bailebo01 1972     1  MON NL 143 489  55 114  10   4 16  57   6  7  59 112\n#> 808  bailebo01 1973     1  MON NL 151 513  77 140  25   4 26  86   5  8  88  99\n#> 809  bailebo01 1974     1  MON NL 152 507  69 142  20   2 20  73   4  7 100 107\n#> 810  bailebo01 1975     1  MON NL 106 227  23  62   5   0  5  30   4  4  46  38\n#> 811  bailebo01 1976     1  CIN NL  69 124  17  37   6   1  6  23   0  0  16  26\n#> 812  bailebo01 1977     2  BOS AL   2   2   0   0   0   0  0   0   0  0   0   1\n#> 813  bailebo01 1977     1  CIN NL  49  79   9  20   2   1  2  11   1  1  12  10\n#> 814  bailebo01 1978     1  BOS AL  43  94  12  18   3   0  4   9   2  1  19  19\n#> 815  baileed01 1953     1  CIN NL   2   8   1   3   1   0  0   1   0  0   1   3\n#> 816  baileed01 1954     1  CIN NL  73 183  21  36   2   3  9  20   1  0  35  34\n#> 817  baileed01 1955     1  CIN NL  21  39   3   8   1   1  1   4   0  0   4  10\n#> 818  baileed01 1956     1  CIN NL 118 383  59 115   8   2 28  75   2  0  52  50\n#> 819  baileed01 1957     1  CIN NL 122 391  54 102  15   2 20  48   5  3  73  69\n#> 820  baileed01 1958     1  CIN NL 112 360  39  90  23   1 11  59   2  2  47  61\n#> 821  baileed01 1959     1  CIN NL 121 379  43 100  13   0 12  40   2  0  62  53\n#> 822  baileed01 1960     1  CIN NL 133 441  52 115  19   3 13  67   1  0  59  70\n#> 823  baileed01 1961     1  CIN NL  12  43   4  13   4   0  0   2   0  0   3   5\n#> 824  baileed01 1961     2  SFN NL 107 340  39  81   9   1 13  51   1  5  42  41\n#> 825  baileed01 1962     1  SFN NL  96 254  32  59   9   1 17  45   1  1  42  42\n#> 826  baileed01 1963     1  SFN NL 105 308  41  81   8   0 21  68   0  6  50  64\n#> 827  baileed01 1964     1  ML1 NL  95 271  30  71  10   1  5  34   2  0  34  39\n#> 828  baileed01 1965     1  SFN NL  24  28   1   3   0   0  0   3   0  0   6   7\n#> 829  baileed01 1965     2  CHN NL  66 150  13  38   6   0  5  23   0  1  34  28\n#> 830  baileed01 1966     1  CAL AL   5   3   0   0   0   0  0   0   0  0   1   1\n#> 831  baineha01 1980     1  CHA AL 141 491  55 125  23   6 13  49   2  4  19  65\n#> 832  baineha01 1981     1  CHA AL  82 280  42  80  11   7 10  41   6  2  12  41\n#> 833  baineha01 1982     1  CHA AL 161 608  89 165  29   8 25 105  10  3  49  95\n#> 834  baineha01 1983     1  CHA AL 156 596  76 167  33   2 20  99   7  5  49  85\n#> 835  baineha01 1984     1  CHA AL 147 569  72 173  28  10 29  94   1  2  54  75\n#> 836  baineha01 1985     1  CHA AL 160 640  86 198  29   3 22 113   1  1  42  89\n#> 837  baineha01 1986     1  CHA AL 145 570  72 169  29   2 21  88   2  1  38  89\n#> 838  baineha01 1987     1  CHA AL 132 505  59 148  26   4 20  93   0  0  46  82\n#> 839  baineha01 1988     1  CHA AL 158 599  55 166  39   1 13  81   0  0  67 109\n#> 840  baineha01 1989     1  CHA AL  96 333  55 107  20   1 13  56   0  1  60  52\n#> 841  baineha01 1989     2  TEX AL  50 172  18  49   9   0  3  16   0  2  13  27\n#> 842  baineha01 1990     1  TEX AL 103 321  41  93  10   1 13  44   0  1  47  63\n#> 843  baineha01 1990     2  OAK AL  32  94  11  25   5   0  3  21   0  2  20  17\n#> 844  baineha01 1991     1  OAK AL 141 488  76 144  25   1 20  90   0  1  72  67\n#> 845  baineha01 1992     1  OAK AL 140 478  58 121  18   0 16  76   1  3  59  61\n#> 846  baineha01 1993     1  BAL AL 118 416  64 130  22   0 20  78   0  0  57  52\n#> 847  baineha01 1994     1  BAL AL  94 326  44  96  12   1 16  54   0  0  30  49\n#> 848  baineha01 1995     1  BAL AL 127 385  60 115  19   1 24  63   0  2  70  45\n#> 849  baineha01 1996     1  CHA AL 143 495  80 154  29   0 22  95   3  1  73  62\n#> 850  baineha01 1997     1  CHA AL  93 318  40  97  18   0 12  52   0  1  41  47\n#> 851  baineha01 1997     2  BAL AL  44 134  15  39   5   0  4  15   0  0  14  15\n#> 852  baineha01 1998     1  BAL AL 104 293  40  88  17   0  9  57   0  0  32  40\n#> 853  baineha01 1999     1  BAL AL 107 345  57 111  16   1 24  81   1  2  43  38\n#> 854  baineha01 1999     2  CLE AL  28  85   5  23   2   0  1  22   0  0  11  10\n#> 855  baineha01 2000     1  BAL AL  72 222  24  59   8   0 10  30   0  0  29  39\n#> 856  baineha01 2000     2  CHA AL  24  61   2  13   5   0  1   9   0  0   7  11\n#> 857  baineha01 2001     1  CHA AL  32  84   3  11   1   0  0   6   0  0   8  16\n#> 858   bairdo01 1976     1  PIT NL   4   0   0   0   0   0  0   0   0  0   0   0\n#> 859   bairdo01 1977     1  OAK AL  45   0   0   0   0   0  0   0   0  0   0   0\n#> 860   bairdo01 1978     1  CIN NL  70  14   1   2   0   0  0   1   0  0   0   4\n#> 861   bairdo01 1979     1  CIN NL  65   8   0   0   0   0  0   0   0  0   0   5\n#> 862   bairdo01 1980     1  CIN NL  61   2   0   0   0   0  0   0   0  0   0   1\n#> 863   bairdo01 1981     1  CIN NL  24   3   1   1   0   0  1   3   0  0   0   1\n#> 864   bairdo01 1981     2  SLN NL  11   3   0   0   0   0  0   0   0  0   0   3\n#> 865   bairdo01 1982     1  SLN NL  63  13   0   1   0   0  0   0   0  0   0   3\n#> 866   bairdo01 1983     2  DET AL  27   0   0   0   0   0  0   0   0  0   0   0\n#> 867   bairdo01 1983     1  SLN NL  26   2   0   0   0   0  0   0   0  0   0   2\n#> 868   bairdo01 1984     1  DET AL  47   0   0   0   0   0  0   0   0  0   0   0\n#> 869   bairdo01 1985     1  DET AL  21   0   0   0   0   0  0   0   0  0   0   0\n#> 870   bairdo01 1985     2  SLN NL   2   0   0   0   0   0  0   0   0  0   0   0\n#> 871   bairdo01 1986     1  OAK AL  31   0   0   0   0   0  0   0   0  0   0   0\n#> 872   bairdo01 1987     1  PHI NL  11   1   0   0   0   0  0   0   0  0   0   0\n#> 873   bairdo01 1988     1  TOR AL  10   0   0   0   0   0  0   0   0  0   0   0\n#> 874   bairdo01 1989     1  PIT NL  44   5   0   1   1   0  0   0   0  0   0   3\n#> 875   bairdo01 1990     1  PIT NL  22   1   0   0   0   0  0   0   0  0   0   1\n#> 876  bakerdu01 1968     1  ATL NL   6   5   0   2   0   0  0   0   0  0   0   1\n#> 877  bakerdu01 1969     1  ATL NL   3   7   0   0   0   0  0   0   0  0   0   3\n#> 878  bakerdu01 1970     1  ATL NL  13  24   3   7   0   0  0   4   0  0   2   4\n#> 879  bakerdu01 1971     1  ATL NL  29  62   2  14   2   0  0   4   0  1   1  14\n#> 880  bakerdu01 1972     1  ATL NL 127 446  62 143  27   2 17  76   4  7  45  68\n#> 881  bakerdu01 1973     1  ATL NL 159 604 101 174  29   4 21  99  24  3  67  72\n#> 882  bakerdu01 1974     1  ATL NL 149 574  80 147  35   0 20  69  18  7  71  87\n#> 883  bakerdu01 1975     1  ATL NL 142 494  63 129  18   2 19  72  12  7  67  57\n#> 884  bakerdu01 1976     1  LAN NL 112 384  36  93  13   0  4  39   2  4  31  54\n#> 885  bakerdu01 1977     1  LAN NL 153 533  86 155  26   1 30  86   2  6  58  89\n#> 886  bakerdu01 1978     1  LAN NL 149 522  62 137  24   1 11  66  12  3  47  66\n#> 887  bakerdu01 1979     1  LAN NL 151 554  86 152  29   1 23  88  11  4  56  70\n#> 888  bakerdu01 1980     1  LAN NL 153 579  80 170  26   4 29  97  12 10  43  66\n#> 889  bakerdu01 1981     1  LAN NL 103 400  48 128  17   3  9  49  10  7  29  43\n#> 890  bakerdu01 1982     1  LAN NL 147 570  80 171  19   1 23  88  17 10  56  62\n#> 891  bakerdu01 1983     1  LAN NL 149 531  71 138  25   1 15  73   7  1  72  59\n#> 892  bakerdu01 1984     1  SFN NL 100 243  31  71   7   2  3  32   4  1  40  27\n#> 893  bakerdu01 1985     1  OAK AL 111 343  48  92  15   1 14  52   2  1  50  47\n#> 894  bakerdu01 1986     1  OAK AL  83 242  25  58   8   0  4  19   0  1  27  37\n#> 895  bakerfl01 1943     1  SLA AL  22  46   5   8   2   0  0   4   0  1   6   4\n#> 896  bakerfl01 1944     1  SLA AL  44  97  10  17   3   0  0   5   2  0  11   5\n#> 897  bakerfl01 1945     1  CHA AL  82 208  22  52   8   0  0  19   3  2  23  12\n#> 898  bakerfl01 1946     1  CHA AL   9  24   2   6   1   0  0   3   0  0   2   3\n#> 899  bakerfl01 1947     1  CHA AL 105 371  61  98  12   3  0  22   9  7  66  28\n#> 900  bakerfl01 1948     1  CHA AL 104 335  47  72   8   3  0  18   4 10  73  26\n#> 901  bakerfl01 1949     1  CHA AL 125 388  38 101  15   4  1  40   3  1  84  32\n#> 902  bakerfl01 1950     1  CHA AL  83 186  26  59   7   0  0  11   1  1  32  10\n#> 903  bakerfl01 1951     1  CHA AL  82 133  24  35   6   1  0  14   0  1  25  12\n#> 904  bakerfl01 1952     1  WS1 AL  79 263  27  69   8   0  0  33   1  0  30  17\n#> 905  bakerfl01 1953     1  WS1 AL   9   7   0   0   0   0  0   0   0  0   1   0\n#> 906  bakerfl01 1953     2  BOS AL  81 172  22  47   4   2  0  24   0  2  24  10\n#> 907  bakerfl01 1954     1  BOS AL  21  20   1   4   2   0  0   3   0  0   0   1\n#> 908  bakerfl01 1954     2  PHI NL  23  22   0   5   0   0  0   0   0  0   5   4\n#> 909  bakerfl01 1955     1  PHI NL   5   8   0   0   0   0  0   0   0  0   0   1\n#> 910  bancrda01 1915     1  PHI NL 153 563  85 143  18   2  7  30  15 27  77  62\n#> 911  bancrda01 1916     1  PHI NL 142 477  53 101  10   0  3  33  15 NA  74  57\n#> 912  bancrda01 1917     1  PHI NL 127 478  56 116  22   5  4  43  14 NA  44  42\n#> 913  bancrda01 1918     1  PHI NL 125 499  69 132  19   4  0  26  11 NA  54  36\n#> 914  bancrda01 1919     1  PHI NL  92 335  45  91  13   7  0  25   8 NA  31  30\n#> 915  bancrda01 1920     1  PHI NL  42 171  23  51   7   2  0   5   1  7   9  12\n#> 916  bancrda01 1920     2  NY1 NL 108 442  79 132  29   7  0  31   7  5  33  32\n#> 917  bancrda01 1921     1  NY1 NL 153 606 121 193  26  15  6  67  17 10  66  23\n#> 918  bancrda01 1922     1  NY1 NL 156 651 117 209  41   5  4  60  16 11  79  27\n#> 919  bancrda01 1923     1  NY1 NL 107 444  80 135  33   3  1  31   8  7  62  23\n#> 920  bancrda01 1924     1  BSN NL  79 319  49  89  11   1  2  21   4  4  37  24\n#> 921  bancrda01 1925     1  BSN NL 128 479  75 153  29   8  2  49   7  4  64  22\n#> 922  bancrda01 1926     1  BSN NL 127 453  70 141  18   6  1  44   3 NA  64  29\n#> 923  bancrda01 1927     1  BSN NL 111 375  44  91  13   4  1  31   5 NA  43  36\n#> 924  bancrda01 1928     1  BRO NL 149 515  47 127  19   5  0  51   7 NA  59  20\n#> 925  bancrda01 1929     1  BRO NL 104 358  35  99  11   3  1  44   7 NA  29  11\n#> 926  bancrda01 1930     1  NY1 NL  10  17   0   1   1   0  0   0   0 NA   2   1\n#> 927  bandosa01 1966     1  KC1 AL  11  24   1   7   1   1  0   1   0  0   1   3\n#> 928  bandosa01 1967     1  KC1 AL  47 130  11  25   3   2  0   6   1  0  16  24\n#> 929  bandosa01 1968     1  OAK AL 162 605  67 152  25   5  9  67  13  4  51  78\n#> 930  bandosa01 1969     1  OAK AL 162 609 106 171  25   3 31 113   1  4 111  82\n#> 931  bandosa01 1970     1  OAK AL 155 502  93 132  20   2 20  75   6 10 118  88\n#> 932  bandosa01 1971     1  OAK AL 153 538  75 146  23   1 24  94   3  7  86  55\n#> 933  bandosa01 1972     1  OAK AL 152 535  64 126  20   3 15  77   3  1  78  55\n#> 934  bandosa01 1973     1  OAK AL 162 592  97 170  32   3 29  98   4  2  82  84\n#> 935  bandosa01 1974     1  OAK AL 146 498  84 121  21   2 22 103   2  3  86  79\n#> 936  bandosa01 1975     1  OAK AL 160 562  64 129  24   1 15  78   7  1  87  80\n#> 937  bandosa01 1976     1  OAK AL 158 550  75 132  18   2 27  84  20  6  76  74\n#> 938  bandosa01 1977     1  ML4 AL 159 580  65 145  27   3 17  82   4  2  75  89\n#> 939  bandosa01 1978     1  ML4 AL 152 540  85 154  20   6 17  78   3  2  72  52\n#> 940  bandosa01 1979     1  ML4 AL 130 476  57 117  14   3  9  43   2  0  57  42\n#> 941  bandosa01 1980     1  ML4 AL  78 254  28  50  12   1  5  31   5  3  29  35\n#> 942  bandosa01 1981     1  ML4 AL  32  65  10  13   4   0  2   9   1  1   6   3\n#> 943  bankser01 1953     1  CHN NL  10  35   3  11   1   1  2   6   0  0   4   5\n#> 944  bankser01 1954     1  CHN NL 154 593  70 163  19   7 19  79   6 10  40  50\n#> 945  bankser01 1955     1  CHN NL 154 596  98 176  29   9 44 117   9  3  45  72\n#> 946  bankser01 1956     1  CHN NL 139 538  82 160  25   8 28  85   6  9  52  62\n#> 947  bankser01 1957     1  CHN NL 156 594 113 169  34   6 43 102   8  4  70  85\n#> 948  bankser01 1958     1  CHN NL 154 617 119 193  23  11 47 129   4  4  52  87\n#> 949  bankser01 1959     1  CHN NL 155 589  97 179  25   6 45 143   2  4  64  72\n#> 950  bankser01 1960     1  CHN NL 156 597  94 162  32   7 41 117   1  3  71  69\n#> 951  bankser01 1961     1  CHN NL 138 511  75 142  22   4 29  80   1  2  54  75\n#> 952  bankser01 1962     1  CHN NL 154 610  87 164  20   6 37 104   5  1  30  71\n#> 953  bankser01 1963     1  CHN NL 130 432  41  98  20   1 18  64   0  3  39  73\n#> 954  bankser01 1964     1  CHN NL 157 591  67 156  29   6 23  95   1  2  36  84\n#> 955  bankser01 1965     1  CHN NL 163 612  79 162  25   3 28 106   3  5  55  64\n#> 956  bankser01 1966     1  CHN NL 141 511  52 139  23   7 15  75   0  1  29  59\n#> 957  bankser01 1967     1  CHN NL 151 573  68 158  26   4 23  95   2  2  27  93\n#> 958  bankser01 1968     1  CHN NL 150 552  71 136  27   0 32  83   2  0  27  67\n#> 959  bankser01 1969     1  CHN NL 155 565  60 143  19   2 23 106   0  0  42 101\n#> 960  bankser01 1970     1  CHN NL  72 222  25  56   6   2 12  44   0  0  20  33\n#> 961  bankser01 1971     1  CHN NL  39  83   4  16   2   0  3   6   0  0   6  14\n#> 962  bannifl01 1977     1  HOU NL  24  48   4   9   0   0  0   1   0  0   1  14\n#> 963  bannifl01 1978     1  HOU NL  28  31   2   5   1   0  0   0   0  0   1  12\n#> 964  bannifl01 1979     1  SEA AL  30   0   0   0   0   0  0   0   0  0   0   0\n#> 965  bannifl01 1980     1  SEA AL  32   0   0   0   0   0  0   0   0  0   0   0\n#> 966  bannifl01 1981     1  SEA AL  21   0   0   0   0   0  0   0   0  0   0   0\n#> 967  bannifl01 1982     1  SEA AL  35   0   0   0   0   0  0   0   0  0   0   0\n#> 968  bannifl01 1983     1  CHA AL  34   0   0   0   0   0  0   0   0  0   0   0\n#> 969  bannifl01 1984     1  CHA AL  34   1   0   0   0   0  0   0   0  0   0   0\n#> 970  bannifl01 1985     1  CHA AL  34   0   0   0   0   0  0   0   0  0   0   0\n#> 971  bannifl01 1986     1  CHA AL  28   0   0   0   0   0  0   0   0  0   0   0\n#> 972  bannifl01 1987     1  CHA AL  34   0   0   0   0   0  0   0   0  0   0   0\n#> 973  bannifl01 1988     1  KCA AL  31   0   0   0   0   0  0   0   0  0   0   0\n#> 974  bannifl01 1989     1  KCA AL  14   0   0   0   0   0  0   0   0  0   0   0\n#> 975  bannifl01 1991     1  CAL AL  16   0   0   0   0   0  0   0   0  0   0   0\n#> 976  bannifl01 1992     1  TEX AL  36   0   0   0   0   0  0   0   0  0   0   0\n#> 977  barbest01 1960     1  BAL AL  36  54   1   3   0   0  0   1   0  0   5  32\n#> 978  barbest01 1961     1  BAL AL  37  80   6  13   1   0  2   6   0  0   5  42\n#> 979  barbest01 1962     1  BAL AL  28  42   2   3   0   0  0   1   0  0   2  24\n#> 980  barbest01 1963     1  BAL AL  39  87   3  12   2   0  1   4   0  0   4  38\n#> 981  barbest01 1964     1  BAL AL  36  47   2   7   0   0  1   4   0  1   4  24\n#> 982  barbest01 1965     1  BAL AL  37  65   2   5   1   0  1   2   0  0   4  43\n#> 983  barbest01 1966     1  BAL AL  25  44   1   3   0   0  0   1   0  0   0  30\n#> 984  barbest01 1967     1  BAL AL  15  22   0   2   0   0  0   3   0  0   2  14\n#> 985  barbest01 1967     2  NYA AL  17  29   2   5   1   1  0   4   0  0   1  17\n#> 986  barbest01 1968     1  NYA AL  20  39   1   2   0   0  0   0   0  0   6  23\n#> 987  barbest01 1969     1  SE1 AL  25  25   4   5   0   1  0   1   0  0   1  15\n#> 988  barbest01 1970     1  CHN NL   5   0   0   0   0   0  0   0   0  0   0   0\n#> 989  barbest01 1970     2  ATL NL   5   4   0   1   0   0  0   0   0  0   0   3\n#> 990  barbest01 1971     1  ATL NL  39  13   0   2   0   0  0   0   0  0   1  10\n#> 991  barbest01 1972     2  CAL AL  34   7   0   1   0   0  0   0   0  0   3   4\n#> 992  barbest01 1972     1  ATL NL   5   5   0   1   0   0  0   0   0  0   0   1\n#> 993  barbest01 1973     1  CAL AL  50   0   0   0   0   0  0   0   0  0   0   0\n#> 994  barbest01 1974     1  SFN NL  13   0   0   0   0   0  0   0   0  0   0   0\n#> 995  barrysh01 1899     1  WSN NL  78 247  31  71   7   5  1  33  11 NA  12  NA\n#> 996  barrysh01 1900     1  BSN NL  81 254  40  66  10   7  1  37   9 NA  13  NA\n#> 997  barrysh01 1901     1  BSN NL  11  40   3   7   2   0  0   6   1 NA   2  NA\n#> 998  barrysh01 1901     2  PHI NL  67 252  35  62  10   0  1  22  13 NA  15  NA\n#> 999  barrysh01 1902     1  PHI NL 138 543  65 156  20   6  3  58  14 NA  44  NA\n#> 1000 barrysh01 1903     1  PHI NL 138 550  75 152  24   5  1  60  26 NA  30  NA\n#> 1001 barrysh01 1904     1  PHI NL  35 122  15  25   2   0  0   3   2 NA  11  NA\n#> 1002 barrysh01 1904     2  CHN NL  73 263  29  69   7   2  1  26  12 NA  17  NA\n#> 1003 barrysh01 1905     1  CHN NL  27 104  10  22   2   0  0  10   5 NA   5  NA\n#> 1004 barrysh01 1905     2  CIN NL 125 494  90 160  11  12  1  56  16 NA  33  NA\n#> 1005 barrysh01 1906     1  CIN NL  73 279  38  80  10   5  1  33  11 NA  26  NA\n#> 1006 barrysh01 1906     2  SLN NL  62 237  26  59   9   1  0  12   6 NA  15  NA\n#> 1007 barrysh01 1907     1  SLN NL  81 294  30  73   5   2  0  19   4 NA  28  NA\n#> 1008 barrysh01 1908     1  SLN NL  74 268  24  61   8   1  0  11   9 NA  19  NA\n#> 1009 barrysh01 1908     2  NY1 NL  37  67   5  10   1   1  0   5   1 NA   9  NA\n#> 1010 bartedi01 1927     1  PIT NL   1   2   0   0   0   0  0   0   0 NA   2   0\n#> 1011 bartedi01 1928     1  PIT NL  72 233  27  71   8   4  1  36   4 NA  21  18\n#> 1012 bartedi01 1929     1  PIT NL 143 610 101 184  40  13  2  57  11 NA  40  29\n#> 1013 bartedi01 1930     1  PIT NL 129 475  69 152  32  13  4  75   8 NA  39  34\n#> 1014 bartedi01 1931     1  PHI NL 135 554  88 160  43   7  0  34   6 NA  27  38\n#> 1015 bartedi01 1932     1  PHI NL 154 614 118 189  48   7  1  53   8 NA  64  47\n#> 1016 bartedi01 1933     1  PHI NL 152 587  78 159  25   5  1  37   6 NA  56  46\n#> 1017 bartedi01 1934     1  PHI NL 146 604 102 187  30   4  0  37  13 NA  64  59\n#> 1018 bartedi01 1935     1  NY1 NL 137 539  60 141  28   4 14  53   5 NA  37  52\n#> 1019 bartedi01 1936     1  NY1 NL 145 510  71 152  31   3  8  42   6 NA  40  36\n#> 1020 bartedi01 1937     1  NY1 NL 128 516  91 158  38   2 14  62   5 NA  40  38\n#> 1021 bartedi01 1938     1  NY1 NL 127 481  67 126  26   1  9  49   4 NA  55  60\n#> 1022 bartedi01 1939     1  CHN NL 105 336  37  80  24   2  3  34   6 NA  42  25\n#> 1023 bartedi01 1940     1  DET AL 139 528  76 123  24   3  7  53  12  2  76  53\n#> 1024 bartedi01 1941     1  DET AL   5  12   0   2   1   0  0   1   0  1   2   2\n#> 1025 bartedi01 1941     2  NY1 NL 104 373  44 113  20   0  5  35   6 NA  52  29\n#> 1026 bartedi01 1942     1  NY1 NL  90 316  53  77  10   3  5  24   4 NA  44  34\n#> 1027 bartedi01 1943     1  NY1 NL  99 337  48  91  14   0  5  28   5 NA  47  27\n#> 1028 bartedi01 1946     1  NY1 NL   5   2   0   0   0   0  0   0   0 NA   0   0\n#> 1029  basske01 1982     1  ML4 AL  18   9   4   0   0   0  0   0   0  0   1   1\n#> 1030  basske01 1982     2  HOU NL  12  24   2   1   0   0  0   1   0  0   0   8\n#> 1031  basske01 1983     1  HOU NL  88 195  25  46   7   3  2  18   2  2   6  27\n#> 1032  basske01 1984     1  HOU NL 121 331  33  86  17   5  2  29   5  5   6  57\n#> 1033  basske01 1985     1  HOU NL 150 539  72 145  27   5 16  68  19  8  31  63\n#> 1034  basske01 1986     1  HOU NL 157 591  83 184  33   5 20  79  22 13  38  72\n#> 1035  basske01 1987     1  HOU NL 157 592  83 168  31   5 19  85  21  8  53  77\n#> 1036  basske01 1988     1  HOU NL 157 541  57 138  27   2 14  72  31  6  42  65\n#> 1037  basske01 1989     1  HOU NL  87 313  42  94  19   4  5  44  11  4  29  44\n#> 1038  basske01 1990     1  SFN NL  61 214  25  54   9   1  7  32   2  2  14  26\n#> 1039  basske01 1991     1  SFN NL 124 361  43  84  10   4 10  40   7  4  36  56\n#> 1040  basske01 1992     1  SFN NL  89 265  25  71  11   3  7  30   7  7  16  53\n#> 1041  basske01 1992     2  NYN NL  46 137  15  37  12   2  2   9   7  2   7  17\n#> 1042  basske01 1993     1  HOU NL 111 229  31  65  18   0  3  37   7  1  26  31\n#> 1043  basske01 1994     1  HOU NL  82 203  37  63  15   1  6  35   2  3  28  24\n#> 1044  basske01 1995     1  BAL AL 111 295  32  72  12   0  5  32   8  8  24  47\n#> 1045 baylodo01 1970     1  BAL AL   8  17   4   4   0   0  0   4   1  1   2   3\n#> 1046 baylodo01 1971     1  BAL AL   1   2   0   0   0   0  0   1   0  0   2   1\n#> 1047 baylodo01 1972     1  BAL AL 102 320  33  81  13   3 11  38  24  2  29  50\n#> 1048 baylodo01 1973     1  BAL AL 118 405  64 116  20   4 11  51  32  9  35  48\n#> 1049 baylodo01 1974     1  BAL AL 137 489  66 133  22   1 10  59  29 12  43  56\n#> 1050 baylodo01 1975     1  BAL AL 145 524  79 148  21   6 25  76  32 17  53  64\n#> 1051 baylodo01 1976     1  OAK AL 157 595  85 147  25   1 15  68  52 12  58  72\n#> 1052 baylodo01 1977     1  CAL AL 154 561  87 141  27   0 25  75  26 12  62  76\n#> 1053 baylodo01 1978     1  CAL AL 158 591 103 151  26   0 34  99  22  9  56  71\n#> 1054 baylodo01 1979     1  CAL AL 162 628 120 186  33   3 36 139  22 12  71  51\n#> 1055 baylodo01 1980     1  CAL AL  90 340  39  85  12   2  5  51   6  6  24  32\n#> 1056 baylodo01 1981     1  CAL AL 103 377  52  90  18   1 17  66   3  3  42  51\n#> 1057 baylodo01 1982     1  CAL AL 157 608  80 160  24   1 24  93  10  4  57  69\n#> 1058 baylodo01 1983     1  NYA AL 144 534  82 162  33   3 21  85  17  7  40  53\n#> 1059 baylodo01 1984     1  NYA AL 134 493  84 129  29   1 27  89   1  1  38  68\n#> 1060 baylodo01 1985     1  NYA AL 142 477  70 110  24   1 23  91   0  4  52  90\n#> 1061 baylodo01 1986     1  BOS AL 160 585  93 139  23   1 31  94   3  5  62 111\n#> 1062 baylodo01 1987     1  BOS AL 108 339  64  81   8   0 16  57   5  2  40  47\n#> 1063 baylodo01 1987     2  MIN AL  20  49   3  14   1   0  0   6   0  1   5  12\n#> 1064 baylodo01 1988     1  OAK AL  92 264  28  58   7   0  7  34   0  1  34  44\n#> 1065 becklja01 1888     1  PIT NL  71 283  35  97  15   3  0  27  20 NA   7  22\n#> 1066 becklja01 1889     1  PIT NL 123 522  91 157  24  10  9  97  11 NA  29  29\n#> 1067 becklja01 1890     1  PTP PL 121 516 109 167  38  22  9 120  18 NA  42  32\n#> 1068 becklja01 1891     1  PIT NL 133 554  94 162  20  19  4  73  13 NA  44  46\n#> 1069 becklja01 1892     1  PIT NL 151 614 102 145  21  19 10  96  30 NA  31  44\n#> 1070 becklja01 1893     1  PIT NL 131 542 108 164  32  19  5 106  15 NA  54  26\n#> 1071 becklja01 1894     1  PIT NL 131 533 121 183  36  18  7 120  21 NA  43  16\n#> 1072 becklja01 1895     1  PIT NL 129 530 104 174  31  19  5 110  20 NA  24  20\n#> 1073 becklja01 1896     1  PIT NL  59 217  44  55   7   5  3  32   8 NA  22  28\n#> 1074 becklja01 1896     2  NY1 NL  46 182  37  55   8   4  5  38  11 NA   9   7\n#> 1075 becklja01 1897     1  NY1 NL  17  68   8  17   2   3  1  11   2 NA   2  NA\n#> 1076 becklja01 1897     2  CIN NL  97 365  76 126  17   9  7  76  23 NA  18  NA\n#> 1077 becklja01 1898     1  CIN NL 118 459  86 135  20  12  4  72   6 NA  28  NA\n#> 1078 becklja01 1899     1  CIN NL 134 513  87 171  27  16  3  99  20 NA  40  NA\n#> 1079 becklja01 1900     1  CIN NL 141 558  98 190  26  10  2  94  23 NA  40  NA\n#> 1080 becklja01 1901     1  CIN NL 140 580  78 178  36  13  3  79   4 NA  28  NA\n#> 1081 becklja01 1902     1  CIN NL 129 531  82 175  23   7  5  69  15 NA  34  NA\n#> 1082 becklja01 1903     1  CIN NL 120 459  85 150  29  10  2  81  23 NA  42  NA\n#> 1083 becklja01 1904     1  SLN NL 142 551  72 179  22   9  1  67  17 NA  35  NA\n#> 1084 becklja01 1905     1  SLN NL 134 514  48 147  20  10  1  57  12 NA  30  NA\n#> 1085 becklja01 1906     1  SLN NL  87 320  29  79  16   6  0  44   3 NA  13  NA\n#> 1086 becklja01 1907     1  SLN NL  32 115   6  24   3   0  0   7   0 NA   1  NA\n#> 1087 bedrost01 1981     1  ATL NL  15   2   0   0   0   0  0   0   0  0   0   1\n#> 1088 bedrost01 1982     1  ATL NL  64  26   0   1   0   0  0   0   0  0   1   6\n#> 1089 bedrost01 1983     1  ATL NL  70  19   0   2   0   0  0   0   0  0   0   7\n#> 1090 bedrost01 1984     1  ATL NL  40  17   0   2   0   0  0   0   0  0   0   9\n#> 1091 bedrost01 1985     1  ATL NL  37  64   3   5   0   0  0   1   0  0   1  22\n#> 1092 bedrost01 1986     1  PHI NL  68   5   0   1   0   0  0   0   0  0   1   1\n#> 1093 bedrost01 1987     1  PHI NL  65   4   0   0   0   0  0   0   0  0   0   3\n#> 1094 bedrost01 1988     1  PHI NL  57   2   0   0   0   0  0   0   0  0   0   2\n#> 1095 bedrost01 1989     1  PHI NL  28   0   0   0   0   0  0   0   0  0   0   0\n#> 1096 bedrost01 1989     2  SFN NL  40   6   0   1   0   0  0   0   0  0   0   3\n#> 1097 bedrost01 1990     1  SFN NL  68   4   0   2   0   0  0   1   0  0   0   1\n#> 1098 bedrost01 1991     1  MIN AL  56   0   0   0   0   0  0   0   0  0   0   0\n#> 1099 bedrost01 1993     1  ATL NL  49   2   0   0   0   0  0   0   0  0   0   2\n#> 1100 bedrost01 1994     1  ATL NL  46   2   0   1   0   0  0   0   0  0   0   1\n#> 1101 bedrost01 1995     1  ATL NL  29   0   0   0   0   0  0   0   0  0   0   0\n#> 1102 belanma01 1965     1  BAL AL  11   3   1   1   0   0  0   0   0  1   0   0\n#> 1103 belanma01 1966     1  BAL AL   8  19   2   3   1   0  0   0   0  0   0   3\n#> 1104 belanma01 1967     1  BAL AL  69 184  19  32   5   0  1  10   6  1  12  46\n#> 1105 belanma01 1968     1  BAL AL 145 472  40  98  13   0  2  21  10  1  40 114\n#> 1106 belanma01 1969     1  BAL AL 150 530  76 152  17   4  2  50  14  6  53  54\n#> 1107 belanma01 1970     1  BAL AL 145 459  53 100   6   5  1  36  13  2  52  65\n#> 1108 belanma01 1971     1  BAL AL 150 500  67 133  19   4  0  35  10  8  73  48\n#> 1109 belanma01 1972     1  BAL AL 113 285  36  53   9   1  2  16   6  3  18  53\n#> 1110 belanma01 1973     1  BAL AL 154 470  60 106  15   1  0  27  13  6  49  54\n#> 1111 belanma01 1974     1  BAL AL 155 493  54 111  14   4  5  36  17  7  51  69\n#> 1112 belanma01 1975     1  BAL AL 152 442  44 100  11   1  3  27  16  4  36  53\n#> 1113 belanma01 1976     1  BAL AL 153 522  66 141  22   2  1  40  27 17  51  64\n#> 1114 belanma01 1977     1  BAL AL 144 402  39  83  13   4  2  30  15  8  43  68\n#> 1115 belanma01 1978     1  BAL AL 135 348  39  74  13   0  0  16   6  6  40  55\n#> 1116 belanma01 1979     1  BAL AL 101 198  28  33   6   2  0   9   5  1  29  33\n#> 1117 belanma01 1980     1  BAL AL 113 268  37  61   7   3  0  22   6  3  12  25\n#> 1118 belanma01 1981     1  BAL AL  64 139   9  23   3   2  1  10   2  1  12  25\n#> 1119 belanma01 1982     1  LAN NL  54  50   6  12   1   0  0   4   1  0   5  10\n#> 1120 belchti01 1987     1  LAN NL   6  10   0   2   0   0  0   1   0  0   0   4\n#> 1121 belchti01 1988     1  LAN NL  36  56   2   4   2   0  1   3   0  0   0  28\n#> 1122 belchti01 1989     1  LAN NL  39  70   3   7   1   0  0   6   0  0   2  26\n#> 1123 belchti01 1990     1  LAN NL  24  43   5   7   1   0  0   1   0  0   0  15\n#> 1124 belchti01 1991     1  LAN NL  33  67   3   8   2   0  0   3   0  0   0  26\n#> 1125 belchti01 1992     1  CIN NL  35  76   3   8   1   0  1   4   0  0   0  28\n#> 1126 belchti01 1993     2  CHA AL  12   0   0   0   0   0  0   0   0  0   0   0\n#> 1127 belchti01 1993     1  CIN NL  22  50   2  10   1   0  0   7   0  1   0  15\n#> 1128 belchti01 1994     1  DET AL  25   0   0   0   0   0  0   0   0  0   0   0\n#> 1129 belchti01 1995     1  SEA AL  28   0   0   0   0   0  0   0   0  0   0   0\n#> 1130 belchti01 1996     1  KCA AL  35   0   0   0   0   0  0   0   0  0   0   0\n#> 1131 belchti01 1997     1  KCA AL   2   6   0   0   0   0  0   0   0  0   0   1\n#> 1132 belchti01 1998     1  KCA AL   2   5   1   1   0   0  0   0   0  0   0   2\n#> 1133 belchti01 1999     1  ANA AL   2   5   0   1   1   0  0   0   0  0   0   2\n#> 1134 belchti01 2000     1  ANA AL   9   0   0   0   0   0  0   0   0  0   0   0\n#> 1135  bellbu01 1972     1  CLE AL 132 466  49 119  21   1  9  36   5  6  34  29\n#> 1136  bellbu01 1973     1  CLE AL 156 631  86 169  23   7 14  59   7 15  49  47\n#> 1137  bellbu01 1974     1  CLE AL 116 423  51 111  15   1  7  46   1  3  35  29\n#> 1138  bellbu01 1975     1  CLE AL 153 553  66 150  20   4 10  59   6  5  51  72\n#> 1139  bellbu01 1976     1  CLE AL 159 604  75 170  26   2  7  60   3  8  44  49\n#> 1140  bellbu01 1977     1  CLE AL 129 479  64 140  23   4 11  64   1  8  45  63\n#> 1141  bellbu01 1978     1  CLE AL 142 556  71 157  27   8  6  62   1  3  39  43\n#> 1142  bellbu01 1979     1  TEX AL 162 670  89 200  42   3 18 101   5  4  30  45\n#> 1143  bellbu01 1980     1  TEX AL 129 490  76 161  24   4 17  83   3  1  40  39\n#> 1144  bellbu01 1981     1  TEX AL  97 360  44 106  16   1 10  64   3  3  42  30\n#> 1145  bellbu01 1982     1  TEX AL 148 537  62 159  27   2 13  67   5  4  70  50\n#> 1146  bellbu01 1983     1  TEX AL 156 618  75 171  35   3 14  66   3  5  50  48\n#> 1147  bellbu01 1984     1  TEX AL 148 553  88 174  36   5 11  83   2  1  63  54\n#> 1148  bellbu01 1985     1  TEX AL  84 313  33  74  13   3  4  32   3  2  33  21\n#> 1149  bellbu01 1985     2  CIN NL  67 247  28  54  15   2  6  36   0  1  34  27\n#> 1150  bellbu01 1986     1  CIN NL 155 568  89 158  29   3 20  75   2  8  73  49\n#> 1151  bellbu01 1987     1  CIN NL 143 522  74 148  19   2 17  70   4  1  71  39\n#> 1152  bellbu01 1988     1  CIN NL  21  54   3  10   0   0  0   3   0  0   7   3\n#> 1153  bellbu01 1988     2  HOU NL  74 269  24  68  10   1  7  37   1  1  19  29\n#> 1154  bellbu01 1989     1  TEX AL  34  82   4  15   4   0  0   3   0  0   7  10\n#> 1155  bellda01 1995     1  CLE AL   2   2   0   0   0   0  0   0   0  0   0   0\n#> 1156  bellda01 1995     2  SLN NL  39 144  13  36   7   2  2  19   1  2   4  25\n#> 1157  bellda01 1996     1  SLN NL  62 145  12  31   6   0  1   9   1  1  10  22\n#> 1158  bellda01 1997     1  SLN NL  66 142   9  30   7   2  1  12   1  0  10  28\n#> 1159  bellda01 1998     2  CLE AL 107 340  37  89  21   2 10  41   0  4  22  54\n#> 1160  bellda01 1998     3  SEA AL  21  80  11  26   8   0  0   8   0  0   5   8\n#> 1161  bellda01 1998     1  SLN NL   4   9   0   2   1   0  0   0   0  0   0   3\n#> 1162  bellda01 1999     1  SEA AL 157 597  92 160  31   2 21  78   7  4  58  90\n#> 1163  bellda01 2000     1  SEA AL 133 454  57 112  24   2 11  47   2  3  42  66\n#> 1164  bellda01 2001     1  SEA AL 135 470  62 122  28   0 15  64   2  1  28  59\n#> 1165  bellda01 2002     1  SFN NL 154 552  82 144  29   2 20  73   1  2  54  80\n#> 1166  bellda01 2003     1  PHI NL  85 297  32  58  14   0  4  37   0  0  41  40\n#> 1167  bellda01 2004     1  PHI NL 143 533  67 155  33   1 18  77   1  1  57  75\n#> 1168  bellda01 2006     1  PHI NL  92 324  39  90  17   2  6  34   1  0  32  38\n#> 1169  bellda01 2006     2  MIL NL  53 180  21  46  10   2  4  29   2  1  18  30\n#> 1170  bellda01 2005     1  PHI NL 150 557  53 138  31   1 10  61   0  1  47  69\n#> 1171  bellgu01 1950     1  PIT NL 111 422  62 119  22  11  8  53   4 NA  28  46\n#> 1172  bellgu01 1951     1  PIT NL 149 600  80 167  27  12 16  89   1  4  42  41\n#> 1173  bellgu01 1952     1  PIT NL 131 468  53 117  21   5 16  59   1  4  36  72\n#> 1174  bellgu01 1953     1  CIN NL 151 610 102 183  37   5 30 105   0  2  48  72\n#> 1175  bellgu01 1954     1  CIN NL 153 619 104 185  38   7 17 101   5  3  48  58\n#> 1176  bellgu01 1955     1  CIN NL 154 610  88 188  30   6 27 104   4  4  54  57\n#> 1177  bellgu01 1956     1  CIN NL 150 603  82 176  31   4 29  84   6  2  50  66\n#> 1178  bellgu01 1957     1  CIN NL 121 510  65 149  20   3 13  61   0  1  30  54\n#> 1179  bellgu01 1958     1  CIN NL 112 385  42  97  16   2 10  46   2  3  36  40\n#> 1180  bellgu01 1959     1  CIN NL 148 580  59 170  27   2 19 115   2  3  29  44\n#> 1181  bellgu01 1960     1  CIN NL 143 515  65 135  19   5 12  62   4  3  29  40\n#> 1182  bellgu01 1961     1  CIN NL 103 235  27  60  10   1  3  33   1  1  18  21\n#> 1183  bellgu01 1962     1  NYN NL  30 101   8  15   2   0  1   6   0  1  10   7\n#> 1184  bellgu01 1962     2  ML1 NL  79 214  28  61  11   3  5  24   0  0  12  17\n#> 1185  bellgu01 1963     1  ML1 NL   3   3   0   1   0   0  0   0   0  0   0   0\n#> 1186  bellgu01 1964     1  ML1 NL   3   3   0   0   0   0  0   0   0  0   0   1\n#> 1187 bellira01 1982     1  PIT NL   9   2   3   1   0   0  0   0   1  0   0   0\n#> 1188 bellira01 1983     1  PIT NL   4   1   1   0   0   0  0   0   0  0   0   1\n#> 1189 bellira01 1984     1  PIT NL  20  22   3   5   0   0  0   0   4  1   0   1\n#> 1190 bellira01 1985     1  PIT NL  17  20   1   4   0   0  0   1   0  0   0   5\n#> 1191 bellira01 1986     1  PIT NL 117 309  33  72   5   2  0  31  12  2  26  54\n#> 1192 bellira01 1987     1  PIT NL  81 203  26  42   4   3  1  15   5  1  20  25\n#> 1193 bellira01 1988     1  PIT NL 122 286  28  61   0   4  0  11   7  1  26  47\n#> 1194 bellira01 1989     1  PIT NL  67 154  10  33   4   0  0   8   5  2   8  22\n#> 1195 bellira01 1990     1  PIT NL  47  54  10  11   3   0  0   6   1  2   5  13\n#> 1196 bellira01 1991     1  ATL NL 149 353  36  88   9   2  0  27   3  1  22  63\n#> 1197 bellira01 1992     1  ATL NL 144 285  20  60   6   1  0  14   0  1  14  43\n#> 1198 bellira01 1993     1  ATL NL  91  79   6  18   5   0  0   6   0  0   4  13\n#> 1199 bellira01 1994     1  ATL NL  46 120   9  29   7   1  0   9   0  2   2  29\n#> 1200 bellira01 1995     1  ATL NL  75 180  12  40   2   1  0   7   2  2   6  28\n#> 1201 bellira01 1996     1  ATL NL  87 142   9  24   7   0  0   3   3  1   2  22\n#> 1202 bellira01 1997     1  ATL NL  72  71   9  15   3   0  1   3   0  1   1  17\n#> 1203 bellira01 1998     1  ATL NL   7  20   1   5   0   0  0   1   0  0   0   1\n#> 1204  bellja01 1986     1  CLE AL   5  14   3   5   2   0  1   4   0  0   2   3\n#> 1205  bellja01 1987     1  CLE AL  38 125  14  27   9   1  2  13   2  0   8  31\n#> 1206  bellja01 1988     1  CLE AL  73 211  23  46   5   1  2  21   4  2  21  53\n#> 1207  bellja01 1989     1  PIT NL  78 271  33  70  13   3  2  27   5  3  19  47\n#> 1208  bellja01 1990     1  PIT NL 159 583  93 148  28   7  7  52  10  6  65 109\n#> 1209  bellja01 1991     1  PIT NL 157 608  96 164  32   8 16  67  10  6  52  99\n#> 1210  bellja01 1992     1  PIT NL 159 632  87 167  36   6  9  55   7  5  55 103\n#> 1211  bellja01 1993     1  PIT NL 154 604 102 187  32   9  9  51  16 10  77 122\n#> 1212  bellja01 1994     1  PIT NL 110 424  68 117  35   4  9  45   2  0  49  82\n#> 1213  bellja01 1995     1  PIT NL 138 530  79 139  28   4 13  55   2  5  55 110\n#> 1214  bellja01 1996     1  PIT NL 151 527  65 132  29   3 13  71   6  4  54 108\n#> 1215  bellja01 1997     1  KCA AL 153 573  89 167  28   3 21  92  10  6  71 101\n#> 1216  bellja01 1998     1  ARI NL 155 549  79 138  29   5 20  67   3  5  81 129\n#> 1217  bellja01 1999     1  ARI NL 151 589 132 170  32   6 38 112   7  4  82 132\n#> 1218  bellja01 2000     1  ARI NL 149 565  87 151  30   6 18  68   7  3  70  88\n#> 1219  bellja01 2001     1  ARI NL 129 428  59 106  24   1 13  46   0  1  65  79\n#> 1220  bellja01 2002     1  ARI NL  32  49   3   8   1   0  2  11   0  0   5   9\n#> 1221  bellja01 2003     1  NYN NL  72 116  11  21   1   0  0   3   0  0  22  38\n#> 1222 benchjo01 1967     1  CIN NL  26  86   7  14   3   1  1   6   0  1   5  19\n#> 1223 benchjo01 1968     1  CIN NL 154 564  67 155  40   2 15  82   1  5  31  96\n#> 1224 benchjo01 1969     1  CIN NL 148 532  83 156  23   1 26  90   6  6  49  86\n#> 1225 benchjo01 1970     1  CIN NL 158 605  97 177  35   4 45 148   5  2  54 102\n#> 1226 benchjo01 1971     1  CIN NL 149 562  80 134  19   2 27  61   2  1  49  83\n#> 1227 benchjo01 1972     1  CIN NL 147 538  87 145  22   2 40 125   6  6 100  84\n#> 1228 benchjo01 1973     1  CIN NL 152 557  83 141  17   3 25 104   4  1  83  83\n#> 1229 benchjo01 1974     1  CIN NL 160 621 108 174  38   2 33 129   5  4  80  90\n#> 1230 benchjo01 1975     1  CIN NL 142 530  83 150  39   1 28 110  11  0  65 108\n#> 1231 benchjo01 1976     1  CIN NL 135 465  62 109  24   1 16  74  13  2  81  95\n#> 1232 benchjo01 1977     1  CIN NL 142 494  67 136  34   2 31 109   2  4  58  95\n#> 1233 benchjo01 1978     1  CIN NL 120 393  52 102  17   1 23  73   4  2  50  83\n#> 1234 benchjo01 1979     1  CIN NL 130 464  73 128  19   0 22  80   4  2  67  73\n#> 1235 benchjo01 1980     1  CIN NL 114 360  52  90  12   0 24  68   4  2  41  64\n#> 1236 benchjo01 1981     1  CIN NL  52 178  14  55   8   0  8  25   0  2  17  21\n#> 1237 benchjo01 1982     1  CIN NL 119 399  44 103  16   0 13  38   1  2  37  58\n#> 1238 benchjo01 1983     1  CIN NL 110 310  32  79  15   2 12  54   0  1  24  38\n#> 1239 bendech01 1903     1  PHA AL  43 120  10  22   4   1  0   8   3 NA   3  NA\n#> 1240 bendech01 1904     1  PHA AL  31  79   8  18   3   2  0   5   3 NA   5  NA\n#> 1241 bendech01 1905     1  PHA AL  38  92  11  20   3   2  0  14   3 NA   3  NA\n#> 1242 bendech01 1906     1  PHA AL  44  99   9  25   4   0  3  13   2 NA   9  NA\n#> 1243 bendech01 1907     1  PHA AL  45 100  10  23   6   1  0   8   2 NA   5  NA\n#> 1244 bendech01 1908     1  PHA AL  20  50   5  11   1   0  0   2   1 NA  10  NA\n#> 1245 bendech01 1909     1  PHA AL  40  93   6  20   5   0  0   9   1 NA   5  NA\n#> 1246 bendech01 1910     1  PHA AL  36  93   6  25   3   2  0  16   0 NA   6  NA\n#> 1247 bendech01 1911     1  PHA AL  32  79   9  13   0   0  0   8   2 NA   2  NA\n#> 1248 bendech01 1912     1  PHA AL  27  60   5   9   1   1  0   4   2 NA   6  NA\n#> 1249 bendech01 1913     1  PHA AL  48  78   7  12   3   1  0  10   1 NA   6  17\n#> 1250 bendech01 1914     1  PHA AL  28  62   4   9   1   0  1   8   0 NA   4  13\n#> 1251 bendech01 1915     1  BLF FL  26  60   7  16   2   0  1   2   0 NA   6   6\n#> 1252 bendech01 1916     1  PHI NL  28  43   2  12   4   0  0   5   0 NA   3   9\n#> 1253 bendech01 1917     1  PHI NL  20  39   3   8   0   0  1   4   0 NA   2   3\n#> 1254 bendech01 1925     1  CHA AL   1   0   0   0   0   0  0   0   0  0   0   0\n#> 1255 benesan01 1989     1  SDN NL  10  24   2   6   0   0  1   2   0  0   0  12\n#> 1256 benesan01 1990     1  SDN NL  32  60   2   6   1   0  0   2   0  0   2  25\n#> 1257 benesan01 1991     1  SDN NL  33  62   4   2   0   0  1   1   0  0   6  29\n#> 1258 benesan01 1992     1  SDN NL  34  67   3  10   2   0  1   5   0  0   5  29\n#> 1259 benesan01 1993     1  SDN NL  34  72   5   9   3   0  1   4   0  0   1  33\n#> 1260 benesan01 1994     1  SDN NL  25  49   2   8   1   0  0   7   0  0   1  22\n#> 1261 benesan01 1995     2  SEA AL  12   0   0   0   0   0  0   0   0  0   0   0\n#> 1262 benesan01 1995     1  SDN NL  19  40   2   6   1   0  0   3   0  0   1  18\n#> 1263 benesan01 1996     1  SLN NL  36  73   5  11   4   0  0   6   0  0   1  37\n#> 1264 benesan01 1997     1  SLN NL  25  55   4  12   2   0  0   5   0  0   1  14\n#> 1265 benesan01 1998     1  ARI NL  33  65   8  11   3   0  1   3   0  0   6  28\n#> 1266 benesan01 1999     1  ARI NL  31  58   6   9   0   0  1   5   0  0   4  17\n#> 1267 benesan01 2000     1  SLN NL  28  50   1   4   0   0  1   1   0  0   4  19\n#> 1268 benesan01 2001     1  SLN NL  26  32   1   5   3   0  0   4   0  0   1  15\n#> 1269 benesan01 2002     1  SLN NL  19  34   3   7   1   0  1   2   0  0   1   9\n#> 1270 beniqju01 1971     1  BOS AL  16  57   8  17   2   0  0   4   3  1   3   4\n#> 1271 beniqju01 1972     1  BOS AL  33  99  10  24   4   1  1   8   2  0   7  11\n#> 1272 beniqju01 1974     1  BOS AL 106 389  60 104  14   3  5  33  19 11  25  61\n#> 1273 beniqju01 1975     1  BOS AL  78 254  43  74  14   4  2  17   7 10  25  26\n#> 1274 beniqju01 1976     1  TEX AL 145 478  49 122  14   4  0  33  17  6  39  56\n#> 1275 beniqju01 1977     1  TEX AL 123 424  56 114  19   6 10  50  26 18  43  43\n#> 1276 beniqju01 1978     1  TEX AL 127 473  61 123  17   3 11  50  10 12  20  59\n#> 1277 beniqju01 1979     1  NYA AL  62 142  19  36   6   1  4  17   3  3   9  17\n#> 1278 beniqju01 1980     1  SEA AL  70 237  26  54  10   0  6  21   2  3  17  25\n#> 1279 beniqju01 1981     1  CAL AL  58 166  18  30   5   0  3  13   2  1  15  16\n#> 1280 beniqju01 1982     1  CAL AL 112 196  25  52  11   2  3  24   3  0  15  21\n#> 1281 beniqju01 1983     1  CAL AL  92 315  44  96  15   0  3  34   4  2  15  29\n#> 1282 beniqju01 1984     1  CAL AL 110 354  60 119  17   0  8  39   0  3  18  43\n#> 1283 beniqju01 1985     1  CAL AL 132 411  54 125  13   5  8  42   4  3  34  46\n#> 1284 beniqju01 1986     1  BAL AL 113 343  48 103  15   0  6  36   2  3  40  49\n#> 1285 beniqju01 1987     1  KCA AL  57 174  14  41   7   0  3  26   0  0  11  26\n#> 1286 beniqju01 1987     2  TOR AL  39  81   6  23   5   1  5  21   0  0   5  13\n#> 1287 beniqju01 1988     1  TOR AL  27  58   9  17   2   0  1   8   0  0   8   6\n#> 1288 benitar01 1994     1  BAL AL   3   0   0   0   0   0  0   0   0  0   0   0\n#> 1289 benitar01 1995     1  BAL AL  44   0   0   0   0   0  0   0   0  0   0   0\n#> 1290 benitar01 1996     1  BAL AL  18   0   0   0   0   0  0   0   0  0   0   0\n#> 1291 benitar01 1997     1  BAL AL  71   0   0   0   0   0  0   0   0  0   0   0\n#> 1292 benitar01 1998     1  BAL AL  71   0   0   0   0   0  0   0   0  0   0   0\n#> 1293 benitar01 1999     1  NYN NL  72   5   0   0   0   0  0   1   0  0   0   2\n#> 1294 benitar01 2000     1  NYN NL  71   0   0   0   0   0  0   0   0  0   0   0\n#> 1295 benitar01 2001     1  NYN NL  71   1   0   0   0   0  0   1   0  0   0   0\n#> 1296 benitar01 2002     1  NYN NL  59   0   0   0   0   0  0   0   0  0   0   0\n#> 1297 benitar01 2003     3  SEA AL  15   0   0   0   0   0  0   0   0  0   0   0\n#> 1298 benitar01 2003     2  NYA AL   9   0   0   0   0   0  0   0   0  0   0   0\n#> 1299 benitar01 2003     1  NYN NL  43   1   0   0   0   0  0   0   0  0   0   1\n#> 1300 benitar01 2004     1  FLO NL  62   1   0   0   0   0  0   0   0  0   0   1\n#> 1301 benitar01 2006     1  SFN NL  41   0   0   0   0   0  0   0   0  0   0   0\n#> 1302 benitar01 2005     1  SFN NL  30   0   0   0   0   0  0   0   0  0   0   0\n#> 1303 benitar01 2007     2  FLO NL  34   0   0   0   0   0  0   0   0  0   0   0\n#> 1304 benitar01 2007     1  SFN NL  19   0   0   0   0   0  0   0   0  0   0   0\n#> 1305 bennech01 1878     1  ML2 NL  49 184  16  45   9   0  1  12  NA NA  10  26\n#> 1306 bennech01 1880     1  WOR NL  51 193  20  44   9   3  0  18  NA NA  10  30\n#> 1307 bennech01 1881     1  DTN NL  76 299  44  90  18   7  7  64  NA NA  18  37\n#> 1308 bennech01 1882     1  DTN NL  84 342  43 103  16  10  5  51  NA NA  20  33\n#> 1309 bennech01 1883     1  DTN NL  92 371  56 113  34   7  5  55  NA NA  26  59\n#> 1310 bennech01 1884     1  DTN NL  90 341  37  90  18   6  3  40  NA NA  36  40\n#> 1311 bennech01 1885     1  DTN NL  91 349  49  94  24  13  5  60  NA NA  47  37\n#> 1312 bennech01 1886     1  DTN NL  72 235  37  57  13   5  4  34   4 NA  48  29\n#> 1313 bennech01 1887     1  DTN NL  46 160  26  39   6   5  3  20   7 NA  30  22\n#> 1314 bennech01 1888     1  DTN NL  74 258  32  68  12   4  5  29   4 NA  31  40\n#> 1315 bennech01 1889     1  BSN NL  82 247  42  57   8   2  4  28   7 NA  21  43\n#> 1316 bennech01 1890     1  BSN NL  85 281  59  60  17   2  3  40   6 NA  72  56\n#> 1317 bennech01 1891     1  BSN NL  75 256  35  55   9   3  5  39   3 NA  42  61\n#> 1318 bennech01 1892     1  BSN NL  35 114  19  23   4   0  1  16   6 NA  27  23\n#> 1319 bennech01 1893     1  BSN NL  60 191  34  40   6   0  4  27   5 NA  40  36\n#> 1320 bentola01 1923     1  BSN NL  35  31   4   5   0   0  0   0   0  0   4  13\n#> 1321 bentola01 1924     1  BSN NL  30  33   4   3   1   0  0   0   0  0   2  10\n#> 1322 bentola01 1925     1  BSN NL  32  58   6  14   2   0  0   1   1  0   3  20\n#> 1323 bentola01 1926     1  BSN NL  45  78   3  12   1   0  0   4   0 NA   2  25\n#> 1324 bentola01 1927     1  BSN NL  11  18   1   4   1   0  0   4   0 NA   0   5\n#> 1325 bentola01 1927     2  NY1 NL  31  50   4   8   0   0  0   3   0 NA   1  14\n#> 1326 bentola01 1928     1  NY1 NL  42 112  12  16   2   1  0   8   0 NA   5  17\n#> 1327 bentola01 1929     1  NY1 NL  41  86   2   9   1   0  1   8   0 NA   1  15\n#> 1328 bentola01 1930     1  NY1 NL   8  10   2   3   0   0  1   3   0 NA   1   4\n#> 1329 bentola01 1930     2  CIN NL  35  62   1  11   0   1  0   5   0 NA   3  13\n#> 1330 bentola01 1931     1  CIN NL  38  66   2  11   2   0  0   1   0 NA   3  13\n#> 1331 bentola01 1932     1  CIN NL  35  54   8  11   1   0  0   1   0 NA   3  11\n#> 1332 bentola01 1933     1  CIN NL  34  53   4   9   0   0  0   2   0 NA   1  14\n#> 1333 bentola01 1934     1  CIN NL  16   7   0   2   0   0  0   1   0 NA   0   3\n#> 1334 bentola01 1935     1  BSN NL  29  20   1   4   1   0  0   1   0 NA   1   4\n#> 1335 bentoru01 1910     1  CIN NL  12  11   0   1   0   0  0   0   0 NA   0   6\n#> 1336 bentoru01 1911     1  CIN NL   6  14   0   2   1   0  0   2   0 NA   0   6\n#> 1337 bentoru01 1912     1  CIN NL  50 104   6  14   3   0  0   9   1 NA   0  31\n#> 1338 bentoru01 1913     1  CIN NL  23  48   8  10   0   1  0   8   0 NA   4   7\n#> 1339 bentoru01 1914     1  CIN NL  41  91   4  13   2   1  0   7   1 NA   1  31\n#> 1340 bentoru01 1915     1  CIN NL  35  53   1  11   1   0  0   3   0  1   0  11\n#> 1341 bentoru01 1915     2  NY1 NL  10  23   2   5   2   0  0   4   1 NA   0   5\n#> 1342 bentoru01 1916     1  NY1 NL  38  78   3   7   0   1  0   3   1 NA   2  21\n#> 1343 bentoru01 1917     1  NY1 NL  35  72   1  12   1   1  0   2   0 NA   2  18\n#> 1344 bentoru01 1918     1  NY1 NL   3   7   1   1   1   0  0   0   0 NA   2   1\n#> 1345 bentoru01 1919     1  NY1 NL  35  67   5  13   0   0  1   7   0 NA   0   8\n#> 1346 bentoru01 1920     1  NY1 NL  33  65   3   6   0   0  0   3   0  0   0  14\n#> 1347 bentoru01 1921     1  NY1 NL  18  21   1   3   1   0  0   1   0  0   1   4\n#> 1348 bentoru01 1923     1  CIN NL  33  80   5  23   3   0  0   4   0  0   1  12\n#> 1349 bentoru01 1924     1  CIN NL  32  46   5  12   2   0  0   3   0  0   5  10\n#> 1350 bentoru01 1925     1  CIN NL  33  45   0   9   2   0  0   4   0  0   4   3\n#> 1351 berenju01 1978     1  NYN NL   5   3   0   0   0   0  0   0   0  0   0   2\n#> 1352 berenju01 1979     1  NYN NL   5   7   0   1   0   0  0   0   0  0   2   2\n#> 1353 berenju01 1980     1  NYN NL   6   0   0   0   0   0  0   0   0  0   0   0\n#> 1354 berenju01 1981     1  KCA AL   8   0   0   0   0   0  0   0   0  0   0   0\n#> 1355 berenju01 1981     2  TOR AL  12   0   0   0   0   0  0   0   0  0   0   0\n#> 1356 berenju01 1982     1  DET AL   2   0   0   0   0   0  0   0   0  0   0   0\n#> 1357 berenju01 1983     1  DET AL  37   0   0   0   0   0  0   0   0  0   0   0\n#> 1358 berenju01 1984     1  DET AL  31   0   0   0   0   0  0   0   0  0   0   0\n#> 1359 berenju01 1985     1  DET AL  31   0   0   0   0   0  0   0   0  0   0   0\n#> 1360 berenju01 1986     1  SFN NL  46   7   0   1   0   0  0   0   0  0   0   1\n#> 1361 berenju01 1987     1  MIN AL  47   0   0   0   0   0  0   0   0  0   0   0\n#> 1362 berenju01 1988     1  MIN AL  57   0   0   0   0   0  0   0   0  0   0   0\n#> 1363 berenju01 1989     1  MIN AL  56   0   0   0   0   0  0   0   0  0   0   0\n#> 1364 berenju01 1990     1  MIN AL  51   0   0   0   0   0  0   0   0  0   0   0\n#> 1365 berenju01 1991     1  ATL NL  49   5   0   0   0   0  0   0   0  0   0   3\n#> 1366 berenju01 1992     2  KCA AL  19   0   0   0   0   0  0   0   0  0   0   0\n#> 1367 berenju01 1992     1  ATL NL  28   2   0   0   0   0  0   0   0  0   0   1\n#> 1368 bergmda01 1975     1  NYA AL   7  17   0   0   0   0  0   0   0  0   2   4\n#> 1369 bergmda01 1977     1  NYA AL   5   4   1   1   0   0  0   1   0  0   0   0\n#> 1370 bergmda01 1978     1  HOU NL 104 186  15  43   5   1  0  12   2  0  39  32\n#> 1371 bergmda01 1979     1  HOU NL  13  15   4   6   0   0  1   2   0  0   0   3\n#> 1372 bergmda01 1980     1  HOU NL  90  78  12  20   6   1  0   3   1  0  10  10\n#> 1373 bergmda01 1981     1  HOU NL   6   6   1   1   0   0  1   1   0  0   0   0\n#> 1374 bergmda01 1981     2  SFN NL  63 145  16  37   9   0  3  13   2  0  19  18\n#> 1375 bergmda01 1982     1  SFN NL 100 121  22  33   3   1  4  14   3  0  18  11\n#> 1376 bergmda01 1983     1  SFN NL  90 140  16  40   4   1  6  24   2  1  24  21\n#> 1377 bergmda01 1984     1  DET AL 120 271  42  74   8   5  7  44   3  4  33  40\n#> 1378 bergmda01 1985     1  DET AL  69 140   8  25   2   0  3   7   0  0  14  15\n#> 1379 bergmda01 1986     1  DET AL  65 130  14  30   6   1  1   9   0  0  21  16\n#> 1380 bergmda01 1987     1  DET AL  91 172  25  47   7   3  6  22   0  1  30  23\n#> 1381 bergmda01 1988     1  DET AL 116 289  37  85  14   0  5  35   0  2  38  34\n#> 1382 bergmda01 1989     1  DET AL 137 385  38 103  13   1  7  37   1  3  44  44\n#> 1383 bergmda01 1990     1  DET AL 100 205  21  57  10   1  2  26   3  2  33  17\n#> 1384 bergmda01 1991     1  DET AL  86 194  23  46  10   1  7  29   1  1  35  40\n#> 1385 bergmda01 1992     1  DET AL  87 181  17  42   3   0  1  10   1  0  20  19\n#> 1386  bergmo01 1923     1  BRO NL  49 129   9  24   3   2  0   6   1  0   2   5\n#> 1387  bergmo01 1926     1  CHA AL  41 113   4  25   6   0  0   7   0  2   6   9\n#> 1388  bergmo01 1927     1  CHA AL  35  69   4  17   4   0  0   4   0  0   4  10\n#> 1389  bergmo01 1928     1  CHA AL  76 224  25  55  16   0  0  29   2  1  14  25\n#> 1390  bergmo01 1929     1  CHA AL 107 352  32 101   7   0  0  47   5  1  17  16\n#> 1391  bergmo01 1930     1  CHA AL  20  61   4   7   3   0  0   7   0  0   1   5\n#> 1392  bergmo01 1931     1  CLE AL  10  13   1   1   1   0  0   0   0  0   1   1\n#> 1393  bergmo01 1932     1  WS1 AL  75 195  16  46   8   1  1  26   1  1   8  13\n#> 1394  bergmo01 1933     1  WS1 AL  40  65   8  12   3   0  2   9   0  0   4   5\n#> 1395  bergmo01 1934     1  WS1 AL  33  86   5  21   4   0  0   6   2  0   6   4\n#> 1396  bergmo01 1934     2  CLE AL  29  97   4  25   3   1  0   9   0  0   1   7\n#> 1397  bergmo01 1935     1  BOS AL  38  98  13  28   5   0  2  12   0  0   5   3\n#> 1398  bergmo01 1936     1  BOS AL  39 125   9  30   4   1  0  19   0  0   2   6\n#> 1399  bergmo01 1937     1  BOS AL  47 141  13  36   3   1  0  20   0  0   5   4\n#> 1400  bergmo01 1938     1  BOS AL  10  12   0   4   0   0  0   0   0  0   0   1\n#> 1401  bergmo01 1939     1  BOS AL  14  33   3   9   1   0  1   5   0  0   2   3\n#> 1402 berrayo01 1946     1  NYA AL   7  22   3   8   1   0  2   4   0  0   1   1\n#> 1403 berrayo01 1947     1  NYA AL  83 293  41  82  15   3 11  54   0  1  13  12\n#> 1404 berrayo01 1948     1  NYA AL 125 469  70 143  24  10 14  98   3  3  25  24\n#> 1405 berrayo01 1949     1  NYA AL 116 415  59 115  20   2 20  91   2  1  22  25\n#> 1406 berrayo01 1950     1  NYA AL 151 597 116 192  30   6 28 124   4  2  55  12\n#> 1407 berrayo01 1951     1  NYA AL 141 547  92 161  19   4 27  88   5  4  44  20\n#> 1408 berrayo01 1952     1  NYA AL 142 534  97 146  17   1 30  98   2  3  66  24\n#> 1409 berrayo01 1953     1  NYA AL 137 503  80 149  23   5 27 108   0  3  50  32\n#> 1410 berrayo01 1954     1  NYA AL 151 584  88 179  28   6 22 125   0  1  56  29\n#> 1411 berrayo01 1955     1  NYA AL 147 541  84 147  20   3 27 108   1  0  60  20\n#> 1412 berrayo01 1956     1  NYA AL 140 521  93 155  29   2 30 105   3  2  65  29\n#> 1413 berrayo01 1957     1  NYA AL 134 482  74 121  14   2 24  82   1  2  57  24\n#> 1414 berrayo01 1958     1  NYA AL 122 433  60 115  17   3 22  90   3  0  35  35\n#> 1415 berrayo01 1959     1  NYA AL 131 472  64 134  25   1 19  69   1  2  43  38\n#> 1416 berrayo01 1960     1  NYA AL 120 359  46  99  14   1 15  62   2  1  38  23\n#> 1417 berrayo01 1961     1  NYA AL 119 395  62 107  11   0 22  61   2  0  35  28\n#> 1418 berrayo01 1962     1  NYA AL  86 232  25  52   8   0 10  35   0  1  24  18\n#> 1419 berrayo01 1963     1  NYA AL  64 147  20  43   6   0  8  28   1  0  15  17\n#> 1420 berrayo01 1965     1  NYN NL   4   9   1   2   0   0  0   0   0  0   0   3\n#> 1421 bevacku01 1971     1  CLE AL  55 137   9  28   3   1  3  13   0  0   4  28\n#> 1422 bevacku01 1972     1  CLE AL  19  35   2   4   0   0  1   1   0  0   3  10\n#> 1423 bevacku01 1973     1  KCA AL  99 276  39  71   8   3  2  40   2  3  25  42\n#> 1424 bevacku01 1974     2  KCA AL  39  90  10  19   0   0  0   3   1  1   9  20\n#> 1425 bevacku01 1974     1  PIT NL  18  35   1   4   1   0  0   0   0  0   2  10\n#> 1426 bevacku01 1975     1  ML4 AL 104 258  30  59  14   0  2  24   3  4  26  45\n#> 1427 bevacku01 1976     1  ML4 AL  12   7   3   1   0   0  0   0   0  0   0   0\n#> 1428 bevacku01 1977     1  TEX AL  39  96  13  32   7   2  5  28   0  1   6  13\n#> 1429 bevacku01 1978     1  TEX AL  90 248  21  55  12   0  6  30   1  2  18  31\n#> 1430 bevacku01 1979     1  SDN NL 114 297  23  75  12   4  1  34   2  5  38  25\n#> 1431 bevacku01 1980     1  SDN NL  62  71   4  19   6   1  0  12   1  1   6   1\n#> 1432 bevacku01 1980     2  PIT NL  22  43   1   7   1   0  0   4   0  0   6   7\n#> 1433 bevacku01 1981     1  PIT NL  29  27   2   7   1   0  1   4   0  0   4   6\n#> 1434 bevacku01 1982     1  SDN NL  64 123  15  31   9   0  0  24   2  0  17  22\n#> 1435 bevacku01 1983     1  SDN NL  74 156  17  38   7   0  2  24   0  3  18  33\n#> 1436 bevacku01 1984     1  SDN NL  59  80   7  16   3   0  1   9   0  0  14  19\n#> 1437 bevacku01 1985     1  SDN NL  71 138  17  33   6   0  3  25   0  0  25  17\n#> 1438 bicheda01 1988     1  CAL AL  21  46   1  12   2   0  0   8   0  0   0   7\n#> 1439 bicheda01 1989     1  CAL AL  48 138  13  29   7   0  3  15   3  0   6  24\n#> 1440 bicheda01 1990     1  CAL AL 109 349  40  89  15   1 15  53   5  2  16  79\n#> 1441 bicheda01 1991     1  ML4 AL 134 445  53 106  18   3 15  59  14  8  22 107\n#> 1442 bicheda01 1992     1  ML4 AL 112 387  37 111  27   2  5  41  18  7  16  74\n#> 1443 bicheda01 1993     1  COL NL 141 538  93 167  43   5 21  89  14  8  28  99\n#> 1444 bicheda01 1994     1  COL NL 116 484  74 147  33   2 27  95  21  8  19  70\n#> 1445 bicheda01 1995     1  COL NL 139 579 102 197  38   2 40 128  13  9  22  96\n#> 1446 bicheda01 1996     1  COL NL 159 633 114 198  39   3 31 141  31 12  45 105\n#> 1447 bicheda01 1997     1  COL NL 151 561  81 173  31   2 26 118   6  5  30  90\n#> 1448 bicheda01 1998     1  COL NL 161 662  97 219  48   2 22 122  14  4  28  76\n#> 1449 bicheda01 1999     1  COL NL 151 593 104 177  38   2 34 133   6  6  54  84\n#> 1450 bicheda01 2000     2  BOS AL  30 114  13  33   5   0  7  14   0  0   8  22\n#> 1451 bicheda01 2000     1  CIN NL 125 461  67 136  27   2 16  76   5  2  41  69\n#> 1452 bicheda01 2001     1  BOS AL 107 391  45 112  30   1 12  49   2  2  20  76\n#> 1453 bielemi01 1984     1  PIT NL   4   0   0   0   0   0  0   0   0  0   0   0\n#> 1454 bielemi01 1985     1  PIT NL  13  10   1   0   0   0  0   0   0  0   1   5\n#> 1455 bielemi01 1986     1  PIT NL  31  48   3   3   0   0  0   1   0  0   2  26\n#> 1456 bielemi01 1987     1  PIT NL   8  16   0   1   0   0  0   0   0  0   0   8\n#> 1457 bielemi01 1988     1  CHN NL  19  10   0   1   0   0  0   0   0  0   0   7\n#> 1458 bielemi01 1989     1  CHN NL  33  70   1   3   0   0  0   3   1  0   3  35\n#> 1459 bielemi01 1990     1  CHN NL  36  43   3   7   0   0  0   1   0  0   2  20\n#> 1460 bielemi01 1991     1  CHN NL  39  46   1   3   0   0  0   7   0  0   3  21\n#> 1461 bielemi01 1991     2  ATL NL   2   0   0   0   0   0  0   0   0  0   0   0\n#> 1462 bielemi01 1992     1  ATL NL  19  24   1   3   0   0  0   0   0  0   0  13\n#> 1463 bielemi01 1993     1  CLE AL  13   0   0   0   0   0  0   0   0  0   0   0\n#> 1464 bielemi01 1994     1  ATL NL  19   3   0   0   0   0  0   0   0  0   0   3\n#> 1465 bielemi01 1995     1  CAL AL  22   0   0   0   0   0  0   0   0  0   0   0\n#> 1466 bielemi01 1996     1  ATL NL  40  10   1   1   0   0  0   1   0  0   2   5\n#> 1467 bielemi01 1997     1  ATL NL  48   2   0   0   0   0  0   0   0  0   1   1\n#> 1468 biggicr01 1988     1  HOU NL  50 123  14  26   6   1  3   5   6  1   7  29\n#> 1469 biggicr01 1989     1  HOU NL 134 443  64 114  21   2 13  60  21  3  49  64\n#> 1470 biggicr01 1990     1  HOU NL 150 555  53 153  24   2  4  42  25 11  53  79\n#> 1471 biggicr01 1991     1  HOU NL 149 546  79 161  23   4  4  46  19  6  53  71\n#> 1472 biggicr01 1992     1  HOU NL 162 613  96 170  32   3  6  39  38 15  94  95\n#> 1473 biggicr01 1993     1  HOU NL 155 610  98 175  41   5 21  64  15 17  77  93\n#> 1474 biggicr01 1994     1  HOU NL 114 437  88 139  44   5  6  56  39  4  62  58\n#> 1475 biggicr01 1995     1  HOU NL 141 553 123 167  30   2 22  77  33  8  80  85\n#> 1476 biggicr01 1996     1  HOU NL 162 605 113 174  24   4 15  75  25  7  75  72\n#> 1477 biggicr01 1997     1  HOU NL 162 619 146 191  37   8 22  81  47 10  84 107\n#> 1478 biggicr01 1998     1  HOU NL 160 646 123 210  51   2 20  88  50  8  64 113\n#> 1479 biggicr01 1999     1  HOU NL 160 639 123 188  56   0 16  73  28 14  88 107\n#> 1480 biggicr01 2000     1  HOU NL 101 377  67 101  13   5  8  35  12  2  61  73\n#> 1481 biggicr01 2001     1  HOU NL 155 617 118 180  35   3 20  70   7  4  66 100\n#> 1482 biggicr01 2002     1  HOU NL 145 577  96 146  36   3 15  58  16  2  50 111\n#> 1483 biggicr01 2003     1  HOU NL 153 628 102 166  44   2 15  62   8  4  57 116\n#> 1484 biggicr01 2004     1  HOU NL 156 633 100 178  47   0 24  63   7  2  40  94\n#> 1485 biggicr01 2005     1  HOU NL 155 590  94 156  40   1 26  69  11  1  37  90\n#> 1486 biggicr01 2006     1  HOU NL 145 548  79 135  33   0 21  62   3  2  40  84\n#> 1487 biggicr01 2007     1  HOU NL 141 517  68 130  31   3 10  50   4  3  23 112\n#> 1488 biittla01 1970     1  WS2 AL   2   2   0   0   0   0  0   0   0  0   0   0\n#> 1489 biittla01 1971     1  WS2 AL  66 171  12  44   4   1  0  16   1  0  16  20\n#> 1490 biittla01 1972     1  TEX AL 137 382  34  99  18   1  3  31   1  3  29  37\n#> 1491 biittla01 1973     1  TEX AL  83 258  19  65   8   2  1  12   1  0  20  21\n#> 1492 biittla01 1974     1  MON NL  18  26   2   7   1   0  0   3   0  0   0   2\n#> 1493 biittla01 1975     1  MON NL 121 346  34 109  13   5  3  28   2  1  34  33\n#> 1494 biittla01 1976     1  MON NL  11  32   2   6   1   0  0   1   0  0   0   3\n#> 1495 biittla01 1976     2  CHN NL  78 192  21  47  13   1  0  17   0  2  10   6\n#> 1496 biittla01 1977     1  CHN NL 138 493  74 147  28   1 12  62   2  1  35  36\n#> 1497 biittla01 1978     1  CHN NL 120 343  32  88  15   1  4  50   0  1  23  37\n#> 1498 biittla01 1979     1  CHN NL 111 272  35  79  13   3  3  50   1  1  21  23\n#> 1499 biittla01 1980     1  CHN NL 127 273  21  68  12   2  1  34   1  3  18  33\n#> 1500 biittla01 1981     1  CIN NL  42  61   1  13   4   0  0   8   0  0   4   4\n#> 1501 biittla01 1982     1  CIN NL  97 184  18  57   9   2  2  24   1  0  17  16\n#> 1502 biittla01 1983     1  TEX AL  66 116   5  32   5   1  0  18   0  0   9  16\n#> 1503 blackbu02 1981     1  SEA AL   2   0   0   0   0   0  0   0   0  0   0   0\n#> 1504 blackbu02 1982     1  KCA AL  23   0   0   0   0   0  0   0   0  0   0   0\n#> 1505 blackbu02 1983     1  KCA AL  24   0   0   0   0   0  0   0   0  0   0   0\n#> 1506 blackbu02 1984     1  KCA AL  35   0   0   0   0   0  0   0   0  0   0   0\n#> 1507 blackbu02 1985     1  KCA AL  33   0   0   0   0   0  0   0   0  0   0   0\n#> 1508 blackbu02 1986     1  KCA AL  56   0   0   0   0   0  0   0   0  0   0   0\n#> 1509 blackbu02 1987     1  KCA AL  29   0   0   0   0   0  0   0   0  0   0   0\n#> 1510 blackbu02 1988     1  KCA AL  17   0   0   0   0   0  0   0   0  0   0   0\n#> 1511 blackbu02 1988     2  CLE AL  16   0   0   0   0   0  0   0   0  0   0   0\n#> 1512 blackbu02 1989     1  CLE AL  33   0   0   0   0   0  0   0   0  0   0   0\n#> 1513 blackbu02 1990     1  CLE AL  29   0   0   0   0   0  0   0   0  0   0   0\n#> 1514 blackbu02 1990     2  TOR AL   3   0   0   0   0   0  0   0   0  0   0   0\n#> 1515 blackbu02 1991     1  SFN NL  35  71   3  13   3   0  0   6   0  0   0  20\n#> 1516 blackbu02 1992     1  SFN NL  28  54   1   3   1   0  0   2   0  0   2  16\n#> 1517 blackbu02 1993     1  SFN NL  16  37   2   9   0   0  0   3   0  0   2   8\n#> 1518 blackbu02 1994     1  SFN NL  10  17   0   1   0   0  0   1   0  0   0   5\n#> 1519 blackbu02 1995     1  CLE AL  11   0   0   0   0   0  0   0   0  0   0   0\n#> 1520 blairpa01 1964     1  BAL AL   8   1   0   0   0   0  0   0   0  1   0   1\n#> 1521 blairpa01 1965     1  BAL AL 119 364  49  85  19   2  5  25   8  5  32  52\n#> 1522 blairpa01 1966     1  BAL AL 133 303  35  84  20   2  6  33   5  6  15  36\n#> 1523 blairpa01 1967     1  BAL AL 151 552  72 162  27  12 11  64   8  6  50  68\n#> 1524 blairpa01 1968     1  BAL AL 141 421  48  89  22   1  7  38   4  2  37  60\n#> 1525 blairpa01 1969     1  BAL AL 150 625 102 178  32   5 26  76  20  6  40  72\n#> 1526 blairpa01 1970     1  BAL AL 133 480  79 128  24   2 18  65  24 11  56  93\n#> 1527 blairpa01 1971     1  BAL AL 141 516  75 135  24   8 10  44  14 11  32  94\n#> 1528 blairpa01 1972     1  BAL AL 142 477  47 111  20   8  8  49   7  8  25  78\n#> 1529 blairpa01 1973     1  BAL AL 146 500  73 140  25   3 10  64  18  8  43  72\n#> 1530 blairpa01 1974     1  BAL AL 151 552  77 144  27   4 17  62  27  9  43  59\n#> 1531 blairpa01 1975     1  BAL AL 140 440  51  96  13   4  5  31  17 11  25  82\n#> 1532 blairpa01 1976     1  BAL AL 145 375  29  74  16   0  3  16  15  6  22  49\n#> 1533 blairpa01 1977     1  NYA AL  83 164  20  43   4   3  4  25   3  2   9  16\n#> 1534 blairpa01 1978     1  NYA AL  75 125  10  22   5   0  2  13   1  1   9  17\n#> 1535 blairpa01 1979     1  NYA AL   2   5   0   1   0   0  0   0   0  0   0   1\n#> 1536 blairpa01 1979     2  CIN NL  75 140   7  21   4   1  2  15   0  0  11  27\n#> 1537 blairpa01 1980     1  NYA AL  12   2   2   0   0   0  0   0   0  0   0   0\n#> 1538 blasido01 1955     1  SLN NL   5  16   4   6   1   0  0   0   1  1   6   0\n#> 1539 blasido01 1956     1  SLN NL 150 587  94 153  22   7  0  27   8  8  72  52\n#> 1540 blasido01 1957     1  SLN NL 154 650 108 176  25   7  8  58  21  9  71  49\n#> 1541 blasido01 1958     1  SLN NL 143 547  71 150  19  10  2  36  20  5  57  47\n#> 1542 blasido01 1959     1  SLN NL 150 615  90 178  26   7  1  24  15 15  67  42\n#> 1543 blasido01 1960     1  SFN NL 136 523  72 123  12   8  2  31  14  2  49  53\n#> 1544 blasido01 1961     1  SFN NL   3   1   1   0   0   0  0   0   0  0   2   1\n#> 1545 blasido01 1961     2  CIN NL 123 450  59 100  18   4  1  21   4  3  39  38\n#> 1546 blasido01 1962     1  CIN NL 141 494  77 139   9   7  2  35   4  3  63  44\n#> 1547 blasido01 1963     2  WS2 AL  69 254  29  65  10   2  2  12   3  2  24  18\n#> 1548 blasido01 1963     1  CIN NL  18  31   4   5   2   0  0   0   0  1   7   5\n#> 1549 blasido01 1964     1  WS2 AL 143 506  56 135  17   2  1  34   8  5  40  44\n#> 1550 blasido01 1965     1  WS2 AL 129 403  47  90   8   8  1  18   5  4  35  45\n#> 1551 blasido01 1966     1  WS2 AL  68 200  18  43   9   0  1  11   2  1  18  21\n#> 1552 blasido01 1966     2  KC1 AL  12  19   1   3   0   0  0   1   0  1   2   3\n#> 1553 bluegos01 1922     1  WS1 AL  19  61   5  12   1   0  0   2   1  0   7   7\n#> 1554 bluegos01 1923     1  WS1 AL 109 379  48  93  15   7  2  42   5  3  48  53\n#> 1555 bluegos01 1924     1  WS1 AL 117 402  59 113  15   4  2  49   7  5  39  36\n#> 1556 bluegos01 1925     1  WS1 AL 145 522  77 150  27   4  4  79  16 15  59  56\n#> 1557 bluegos01 1926     1  WS1 AL 139 487  69 132  19   8  3  65  12  9  70  46\n#> 1558 bluegos01 1927     1  WS1 AL 146 503  71 138  21  10  1  66  15  5  57  47\n#> 1559 bluegos01 1928     1  WS1 AL 146 518  78 154  33   7  2  75  18  6  46  27\n#> 1560 bluegos01 1929     1  WS1 AL  64 220  35  65   6   0  5  31   6  4  19  15\n#> 1561 bluegos01 1930     1  WS1 AL 134 476  64 138  27   7  3  69  15  8  51  40\n#> 1562 bluegos01 1931     1  WS1 AL 152 570  82 155  25   7  8  98  16 10  50  39\n#> 1563 bluegos01 1932     1  WS1 AL 149 507  64 131  22   4  5  64   9  7  83  41\n#> 1564 bluegos01 1933     1  WS1 AL 140 501  63 131  14   0  6  71   6  7  55  34\n#> 1565 bluegos01 1934     1  WS1 AL  99 285  39  70   9   2  0  11   2  1  23  15\n#> 1566 bluegos01 1935     1  WS1 AL 100 320  44  84  14   3  0  34   2  2  37  21\n#> 1567 bluegos01 1936     1  WS1 AL  90 319  43  92  12   1  1  55   5  3  38  16\n#> 1568 bluegos01 1937     1  WS1 AL  42 127  12  36   4   2  1  13   1  1  13   9\n#> 1569 bluegos01 1938     1  WS1 AL  58 184  25  48  12   1  0  21   3  1  21  11\n#> 1570 bluegos01 1939     1  WS1 AL  18  59   5   9   0   0  0   3   1  0   7   2\n#> 1571  bluevi01 1969     1  OAK AL  12  10   1   0   0   0  0   0   0  0   2   4\n#> 1572  bluevi01 1970     1  OAK AL   6  15   1   3   1   0  1   3   0  0   1   7\n#> 1573  bluevi01 1971     1  OAK AL  39 102   6  12   1   0  0   2   0  1   4  63\n#> 1574  bluevi01 1972     1  OAK AL  27  45   4   2   0   0  0   0   0  1   5  34\n#> 1575  bluevi01 1973     1  OAK AL  38   1   0   0   0   0  0   0   0  0   0   0\n#> 1576  bluevi01 1974     1  OAK AL  40   0   0   0   0   0  0   0   0  0   0   0\n#> 1577  bluevi01 1975     1  OAK AL  39   0   0   0   0   0  0   0   0  0   0   0\n#> 1578  bluevi01 1976     1  OAK AL  37   0   0   0   0   0  0   0   0  0   0   0\n#> 1579  bluevi01 1977     1  OAK AL  38   1   0   0   0   0  0   0   0  0   0   1\n#> 1580  bluevi01 1978     1  SFN NL  35  79   8   6   1   0  1   2   0  0  16  51\n#> 1581  bluevi01 1979     1  SFN NL  37  83   7  10   1   0  1   3   0  0   6  35\n#> 1582  bluevi01 1980     1  SFN NL  31  68   3   5   1   0  0   1   0  0   3  34\n#> 1583  bluevi01 1981     1  SFN NL  18  35   4   7   2   0  0   1   0  0   3  10\n#> 1584  bluevi01 1982     1  KCA AL  31   0   0   0   0   0  0   0   0  0   0   0\n#> 1585  bluevi01 1983     1  KCA AL  19   0   0   0   0   0  0   0   0  0   0   0\n#> 1586  bluevi01 1985     1  SFN NL  33  30   0   4   1   0  0   0   0  0   3  12\n#> 1587  bluevi01 1986     1  SFN NL  28  43   3   4   1   0  1   3   0  0   6  20\n#> 1588 blylebe01 1970     1  MIN AL  27  50   2   7   0   0  0   1   0  0   1  25\n#> 1589 blylebe01 1971     1  MIN AL  38  91   3  12   1   0  0   2   0  0   1  37\n#> 1590 blylebe01 1972     1  MIN AL  39  94   9  15   2   0  0   6   0  0   2  36\n#> 1591 blylebe01 1973     1  MIN AL  40   0   0   0   0   0  0   0   0  0   0   0\n#> 1592 blylebe01 1974     1  MIN AL  37   0   0   0   0   0  0   0   0  0   0   0\n#> 1593 blylebe01 1975     1  MIN AL  35   0   0   0   0   0  0   0   0  0   0   0\n#> 1594 blylebe01 1976     1  MIN AL  12   0   0   0   0   0  0   0   0  0   0   0\n#> 1595 blylebe01 1976     2  TEX AL  24   0   0   0   0   0  0   0   0  0   0   0\n#> 1596 blylebe01 1977     1  TEX AL  30   0   0   0   0   0  0   0   0  0   0   0\n#> 1597 blylebe01 1978     1  PIT NL  37  85   4  11   2   0  0  11   0  0   1  35\n#> 1598 blylebe01 1979     1  PIT NL  38  70   1   9   1   0  0   3   0  0   0  33\n#> 1599 blylebe01 1980     1  PIT NL  37  61   0   5   1   0  0   2   0  0   0  27\n#> 1600 blylebe01 1981     1  CLE AL  20   0   0   0   0   0  0   0   0  0   0   0\n#> 1601 blylebe01 1982     1  CLE AL   4   0   0   0   0   0  0   0   0  0   0   0\n#> 1602 blylebe01 1983     1  CLE AL  24   0   0   0   0   0  0   0   0  0   0   0\n#> 1603 blylebe01 1984     1  CLE AL  33   0   0   0   0   0  0   0   0  0   0   0\n#> 1604 blylebe01 1985     1  CLE AL  23   0   0   0   0   0  0   0   0  0   0   0\n#> 1605 blylebe01 1985     2  MIN AL  14   0   0   0   0   0  0   0   0  0   0   0\n#> 1606 blylebe01 1986     1  MIN AL  36   0   0   0   0   0  0   0   0  0   0   0\n#> 1607 blylebe01 1987     1  MIN AL  37   0   0   0   0   0  0   0   0  0   0   0\n#> 1608 blylebe01 1988     1  MIN AL  33   0   0   0   0   0  0   0   0  0   0   0\n#> 1609 blylebe01 1989     1  CAL AL  33   0   0   0   0   0  0   0   0  0   0   0\n#> 1610 blylebe01 1990     1  CAL AL  23   0   0   0   0   0  0   0   0  0   0   0\n#> 1611 blylebe01 1992     1  CAL AL  25   0   0   0   0   0  0   0   0  0   0   0\n#> 1612 boddimi01 1980     1  BAL AL   1   0   0   0   0   0  0   0   0  0   0   0\n#> 1613 boddimi01 1981     1  BAL AL   2   0   0   0   0   0  0   0   0  0   0   0\n#> 1614 boddimi01 1982     1  BAL AL   7   0   0   0   0   0  0   0   0  0   0   0\n#> 1615 boddimi01 1983     1  BAL AL  27   0   0   0   0   0  0   0   0  0   0   0\n#> 1616 boddimi01 1984     1  BAL AL  35   0   1   0   0   0  0   0   0  0   0   0\n#> 1617 boddimi01 1985     1  BAL AL  34   0   1   0   0   0  0   0   0  0   0   0\n#> 1618 boddimi01 1986     1  BAL AL  33   0   0   0   0   0  0   0   0  0   0   0\n#> 1619 boddimi01 1987     1  BAL AL  34   0   0   0   0   0  0   0   0  0   0   0\n#> 1620 boddimi01 1988     1  BAL AL  21   0   0   0   0   0  0   0   0  0   0   0\n#> 1621 boddimi01 1988     2  BOS AL  15   0   0   0   0   0  0   0   0  0   0   0\n#> 1622 boddimi01 1989     1  BOS AL  34   0   0   0   0   0  0   0   0  0   0   0\n#> 1623 boddimi01 1990     1  BOS AL  34   0   0   0   0   0  0   0   0  0   0   0\n#> 1624 boddimi01 1991     1  KCA AL  30   0   0   0   0   0  0   0   0  0   0   0\n#> 1625 boddimi01 1992     1  KCA AL  29   0   0   0   0   0  0   0   0  0   0   0\n#> 1626 boddimi01 1993     1  ML4 AL  10   0   0   0   0   0  0   0   0  0   0   0\n#> 1627 boggswa01 1982     1  BOS AL 104 338  51 118  14   1  5  44   1  0  35  21\n#> 1628 boggswa01 1983     1  BOS AL 153 582 100 210  44   7  5  74   3  3  92  36\n#> 1629 boggswa01 1984     1  BOS AL 158 625 109 203  31   4  6  55   3  2  89  44\n#> 1630 boggswa01 1985     1  BOS AL 161 653 107 240  42   3  8  78   2  1  96  61\n#> 1631 boggswa01 1986     1  BOS AL 149 580 107 207  47   2  8  71   0  4 105  44\n#> 1632 boggswa01 1987     1  BOS AL 147 551 108 200  40   6 24  89   1  3 105  48\n#> 1633 boggswa01 1988     1  BOS AL 155 584 128 214  45   6  5  58   2  3 125  34\n#> 1634 boggswa01 1989     1  BOS AL 156 621 113 205  51   7  3  54   2  6 107  51\n#> 1635 boggswa01 1990     1  BOS AL 155 619  89 187  44   5  6  63   0  0  87  68\n#> 1636 boggswa01 1991     1  BOS AL 144 546  93 181  42   2  8  51   1  2  89  32\n#> 1637 boggswa01 1992     1  BOS AL 143 514  62 133  22   4  7  50   1  3  74  31\n#> 1638 boggswa01 1993     1  NYA AL 143 560  83 169  26   1  2  59   0  1  74  49\n#> 1639 boggswa01 1994     1  NYA AL  97 366  61 125  19   1 11  55   2  1  61  29\n#> 1640 boggswa01 1995     1  NYA AL 126 460  76 149  22   4  5  63   1  1  74  50\n#> 1641 boggswa01 1996     1  NYA AL 132 501  80 156  29   2  2  41   1  2  67  32\n#> 1642 boggswa01 1997     1  NYA AL 103 353  55 103  23   1  4  28   0  1  48  38\n#> 1643 boggswa01 1998     1  TBA AL 123 435  51 122  23   4  7  52   3  2  46  54\n#> 1644 boggswa01 1999     1  TBA AL  90 292  40  88  14   1  2  29   1  0  38  23\n#> 1645 bondsba01 1986     1  PIT NL 113 413  72  92  26   3 16  48  36  7  65 102\n#> 1646 bondsba01 1987     1  PIT NL 150 551  99 144  34   9 25  59  32 10  54  88\n#> 1647 bondsba01 1988     1  PIT NL 144 538  97 152  30   5 24  58  17 11  72  82\n#> 1648 bondsba01 1989     1  PIT NL 159 580  96 144  34   6 19  58  32 10  93  93\n#> 1649 bondsba01 1990     1  PIT NL 151 519 104 156  32   3 33 114  52 13  93  83\n#> 1650 bondsba01 1991     1  PIT NL 153 510  95 149  28   5 25 116  43 13 107  73\n#> 1651 bondsba01 1992     1  PIT NL 140 473 109 147  36   5 34 103  39  8 127  69\n#> 1652 bondsba01 1993     1  SFN NL 159 539 129 181  38   4 46 123  29 12 126  79\n#> 1653 bondsba01 1994     1  SFN NL 112 391  89 122  18   1 37  81  29  9  74  43\n#> 1654 bondsba01 1995     1  SFN NL 144 506 109 149  30   7 33 104  31 10 120  83\n#> 1655 bondsba01 1996     1  SFN NL 158 517 122 159  27   3 42 129  40  7 151  76\n#> 1656 bondsba01 1997     1  SFN NL 159 532 123 155  26   5 40 101  37  8 145  87\n#> 1657 bondsba01 1998     1  SFN NL 156 552 120 167  44   7 37 122  28 12 130  92\n#> 1658 bondsba01 1999     1  SFN NL 102 355  91  93  20   2 34  83  15  2  73  62\n#> 1659 bondsba01 2000     1  SFN NL 143 480 129 147  28   4 49 106  11  3 117  77\n#> 1660 bondsba01 2001     1  SFN NL 153 476 129 156  32   2 73 137  13  3 177  93\n#> 1661 bondsba01 2002     1  SFN NL 143 403 117 149  31   2 46 110   9  2 198  47\n#> 1662 bondsba01 2003     1  SFN NL 130 390 111 133  22   1 45  90   7  0 148  58\n#> 1663 bondsba01 2004     1  SFN NL 147 373 129 135  27   3 45 101   6  1 232  41\n#> 1664 bondsba01 2006     1  SFN NL 130 367  74  99  23   0 26  77   3  0 115  51\n#> 1665 bondsba01 2005     1  SFN NL  14  42   8  12   1   0  5  10   0  0   9   6\n#> 1666 bondsba01 2007     1  SFN NL 126 340  75  94  14   0 28  66   5  0 132  54\n#> 1667 bondsbo01 1968     1  SFN NL  81 307  55  78  10   5  9  35  16  7  38  84\n#> 1668 bondsbo01 1969     1  SFN NL 158 622 120 161  25   6 32  90  45  4  81 187\n#> 1669 bondsbo01 1970     1  SFN NL 157 663 134 200  36  10 26  78  48 10  77 189\n#> 1670 bondsbo01 1971     1  SFN NL 155 619 110 178  32   4 33 102  26  8  62 137\n#> 1671 bondsbo01 1972     1  SFN NL 153 626 118 162  29   5 26  80  44  6  60 137\n#> 1672 bondsbo01 1973     1  SFN NL 160 643 131 182  34   4 39  96  43 17  87 148\n#> 1673 bondsbo01 1974     1  SFN NL 150 567  97 145  22   8 21  71  41 11  95 134\n#> 1674 bondsbo01 1975     1  NYA AL 145 529  93 143  26   3 32  85  30 17  89 137\n#> 1675 bondsbo01 1976     1  CAL AL  99 378  48 100  10   3 10  54  30 15  41  90\n#> 1676 bondsbo01 1977     1  CAL AL 158 592 103 156  23   9 37 115  41 18  74 141\n#> 1677 bondsbo01 1978     1  CHA AL  26  90   8  25   4   0  2   8   6  2  10  10\n#> 1678 bondsbo01 1978     2  TEX AL 130 475  85 126  15   4 29  82  37 20  69 110\n#> 1679 bondsbo01 1979     1  CLE AL 146 538  93 148  24   1 25  85  34 23  74 135\n#> 1680 bondsbo01 1980     1  SLN NL  86 231  37  47   5   3  5  24  15  5  33  74\n#> 1681 bondsbo01 1981     1  CHN NL  45 163  26  35   7   1  6  19   5  6  24  44\n#> 1682 bonilbo01 1986     1  CHA AL  75 234  27  63  10   2  2  26   4  1  33  49\n#> 1683 bonilbo01 1986     2  PIT NL  63 192  28  46   6   2  1  17   4  4  29  39\n#> 1684 bonilbo01 1987     1  PIT NL 141 466  58 140  33   3 15  77   3  5  39  64\n#> 1685 bonilbo01 1988     1  PIT NL 159 584  87 160  32   7 24 100   3  5  85  82\n#> 1686 bonilbo01 1989     1  PIT NL 163 616  96 173  37  10 24  86   8  8  76  93\n#> 1687 bonilbo01 1990     1  PIT NL 160 625 112 175  39   7 32 120   4  3  45 103\n#> 1688 bonilbo01 1991     1  PIT NL 157 577 102 174  44   6 18 100   2  4  90  67\n#> 1689 bonilbo01 1992     1  NYN NL 128 438  62 109  23   0 19  70   4  3  66  73\n#> 1690 bonilbo01 1993     1  NYN NL 139 502  81 133  21   3 34  87   3  3  72  96\n#> 1691 bonilbo01 1994     1  NYN NL 108 403  60 117  24   1 20  67   1  3  55 101\n#> 1692 bonilbo01 1995     2  BAL AL  61 237  47  79  12   4 10  46   0  2  23  31\n#> 1693 bonilbo01 1995     1  NYN NL  80 317  49 103  25   4 18  53   0  3  31  48\n#> 1694 bonilbo01 1996     1  BAL AL 159 595 107 171  27   5 28 116   1  3  75  85\n#> 1695 bonilbo01 1997     1  FLO NL 153 562  77 167  39   3 17  96   6  6  73  94\n#> 1696 bonilbo01 1998     1  FLO NL  28  97  11  27   5   0  4  15   0  1  12  22\n#> 1697 bonilbo01 1998     2  LAN NL  72 236  28  56   6   1  7  30   1  1  29  37\n#> 1698 bonilbo01 1999     1  NYN NL  60 119  12  19   5   0  4  18   0  1  19  16\n#> 1699 bonilbo01 2000     1  ATL NL 114 239  23  61  13   3  5  28   0  0  37  51\n#> 1700 bonilbo01 2001     1  SLN NL  93 174  17  37   7   0  5  21   1  1  23  53\n#> 1701 boonebo01 1972     1  PHI NL  16  51   4  14   1   0  1   4   1  0   5   7\n#> 1702 boonebo01 1973     1  PHI NL 145 521  42 136  20   2 10  61   3  4  41  36\n#> 1703 boonebo01 1974     1  PHI NL 146 488  41 118  24   3  3  52   3  1  35  29\n#> 1704 boonebo01 1975     1  PHI NL  97 289  28  71  14   2  2  20   1  3  32  14\n#> 1705 boonebo01 1976     1  PHI NL 121 361  40  98  18   2  4  54   2  5  45  44\n#> 1706 boonebo01 1977     1  PHI NL 132 440  55 125  26   4 11  66   5  5  42  54\n#> 1707 boonebo01 1978     1  PHI NL 132 435  48 123  18   4 12  62   2  5  46  37\n#> 1708 boonebo01 1979     1  PHI NL 119 398  38 114  21   3  9  58   1  4  49  33\n#> 1709 boonebo01 1980     1  PHI NL 141 480  34 110  23   1  9  55   3  4  48  41\n#> 1710 boonebo01 1981     1  PHI NL  76 227  19  48   7   0  4  24   2  2  22  16\n#> 1711 boonebo01 1982     1  CAL AL 143 472  42 121  17   0  7  58   0  2  39  34\n#> 1712 boonebo01 1983     1  CAL AL 142 468  46 120  18   0  9  52   4  3  24  42\n#> 1713 boonebo01 1984     1  CAL AL 139 450  33  91  16   1  3  32   3  3  25  45\n#> 1714 boonebo01 1985     1  CAL AL 150 460  37 114  17   0  5  55   1  2  37  35\n#> 1715 boonebo01 1986     1  CAL AL 144 442  48  98  12   2  7  49   1  0  43  30\n#> 1716 boonebo01 1987     1  CAL AL 128 389  42  94  18   0  3  33   0  2  35  36\n#> 1717 boonebo01 1988     1  CAL AL 122 352  38 104  17   0  5  39   2  2  29  26\n#> 1718 boonebo01 1989     1  KCA AL 131 405  33 111  13   2  1  43   3  2  49  37\n#> 1719 boonebo01 1990     1  KCA AL  40 117  11  28   3   0  0   9   1  1  17  12\n#> 1720 boonebr01 1992     1  SEA AL  33 129  15  25   4   0  4  15   1  1   4  34\n#> 1721 boonebr01 1993     1  SEA AL  76 271  31  68  12   2 12  38   2  3  17  52\n#> 1722 boonebr01 1994     1  CIN NL 108 381  59 122  25   2 12  68   3  4  24  74\n#> 1723 boonebr01 1995     1  CIN NL 138 513  63 137  34   2 15  68   5  1  41  84\n#> 1724 boonebr01 1996     1  CIN NL 142 520  56 121  21   3 12  69   3  2  31 100\n#> 1725 boonebr01 1997     1  CIN NL 139 443  40  99  25   1  7  46   5  5  45 101\n#> 1726 boonebr01 1998     1  CIN NL 157 583  76 155  38   1 24  95   6  4  48 104\n#> 1727 boonebr01 1999     1  ATL NL 152 608 102 153  38   1 20  63  14  9  47 112\n#> 1728 boonebr01 2000     1  SDN NL 127 463  61 116  18   2 19  74   8  4  50  97\n#> 1729 boonebr01 2001     1  SEA AL 158 623 118 206  37   3 37 141   5  5  40 110\n#> 1730 boonebr01 2002     1  SEA AL 155 608  88 169  34   3 24 107  12  5  53 102\n#> 1731 boonebr01 2003     1  SEA AL 159 622 111 183  35   5 35 117  16  3  68 125\n#> 1732 boonebr01 2004     1  SEA AL 148 593  74 149  30   0 24  83  10  5  56 135\n#> 1733 boonebr01 2005     1  SEA AL  74 273  30  63  15   3  7  34   4  2  24  52\n#> 1734 boonebr01 2005     2  MIN AL  14  53   3   9   0   0  0   3   0  0   4  13\n#> 1735 boonera01 1948     1  CLE AL   6   5   0   2   1   0  0   1   0  0   0   1\n#> 1736 boonera01 1949     1  CLE AL  86 258  39  65   4   4  4  26   0  2  38  17\n#> 1737 boonera01 1950     1  CLE AL 109 365  53 110  14   6  7  58   4  3  56  27\n#> 1738 boonera01 1951     1  CLE AL 151 544  65 127  14   1 12  51   5  3  48  36\n#> 1739 boonera01 1952     1  CLE AL 103 316  57  83   8   2  7  45   0  1  53  33\n#> 1740 boonera01 1953     1  CLE AL  34 112  21  27   1   2  4  21   1  2  24  21\n#> 1741 boonera01 1953     2  DET AL 101 385  73 120  16   6 22  93   2  1  48  47\n#> 1742 boonera01 1954     1  DET AL 148 543  76 160  19   7 20  85   4  2  71  53\n#> 1743 boonera01 1955     1  DET AL 135 500  61 142  22   7 20 116   1  1  50  49\n#> 1744 boonera01 1956     1  DET AL 131 481  77 148  14   6 25  81   0  0  77  46\n#> 1745 boonera01 1957     1  DET AL 129 462  48 126  25   3 12  65   1  1  57  47\n#> 1746 boonera01 1958     1  DET AL  39 114  16  27   4   1  6  20   0  2  14  13\n#> 1747 boonera01 1958     2  CHA AL  77 246  25  60  12   1  7  41   1  1  18  33\n#> 1748 boonera01 1959     1  CHA AL   9  21   3   5   0   0  1   5   1  0   7   5\n#> 1749 boonera01 1959     2  KC1 AL  61 132  19  36   6   0  2  12   1  0  27  17\n#> 1750 boonera01 1959     3  ML1 NL  13  15   3   3   0   0  1   2   0  0   4   2\n#> 1751 boonera01 1960     2  BOS AL  34  78   6  16   1   0  1  11   0  0  11  15\n#> 1752 boonera01 1960     1  ML1 NL   7  12   3   3   1   0  0   4   0  0   5   1\n#> 1753 bordepa01 1988     1  TOR AL  56 154  15  42   6   3  5  21   0  0   3  24\n#> 1754 bordepa01 1989     1  TOR AL  94 241  22  62  11   1  3  29   2  1  11  45\n#> 1755 bordepa01 1990     1  TOR AL 125 346  36  99  24   2 15  49   0  1  18  57\n#> 1756 bordepa01 1991     1  TOR AL 105 291  22  71  17   0  5  36   0  0  11  45\n#> 1757 bordepa01 1992     1  TOR AL 138 480  47 116  26   2 13  53   1  1  33  75\n#> 1758 bordepa01 1993     1  TOR AL 138 488  38 124  30   0  9  55   2  2  20  66\n#> 1759 bordepa01 1994     1  TOR AL  85 295  24  73  13   1  3  26   1  1  15  50\n#> 1760 bordepa01 1995     1  KCA AL  52 143  14  33   8   1  4  13   0  0   7  22\n#> 1761 bordepa01 1995     2  HOU NL  11  35   1   4   0   0  0   0   0  0   2   7\n#> 1762 bordepa01 1996     2  CAL AL  19  57   6  13   3   0  2   8   0  1   3  11\n#> 1763 bordepa01 1996     3  CHA AL  31  94   6  26   1   0  3   6   0  0   5  18\n#> 1764 bordepa01 1996     1  SLN NL  26  69   3  22   3   0  0   4   0  1   1  14\n#> 1765 bordepa01 1997     1  CLE AL  55 159  17  47   7   1  4  15   0  2   9  27\n#> 1766 bordepa01 1998     1  CLE AL  54 160  12  38   6   0  0   6   0  2  10  40\n#> 1767 bordepa01 1999     1  CLE AL   6  20   2   6   0   1  0   3   0  1   0   3\n#> 1768 bordepa01 1999     2  TOR AL   6  14   1   3   0   0  1   3   0  0   1   2\n#> 1769 bordepa01 2001     1  SEA AL   5   6   1   3   0   0  0   0   0  0   0   1\n#> 1770 bordepa01 2002     1  SEA AL   4   4   0   2   1   0  0   1   0  0   0   1\n#> 1771 bordepa01 2003     1  SEA AL  12  14   1   2   1   0  0   1   0  0   1   5\n#> 1772 bordepa01 2004     1  SEA AL  19  53   6  10   2   0  1   5   1  1   1  12\n#> 1773 bordepa01 2004     2  MIN AL  19  42   3  12   4   0  0   5   2  0   0  10\n#> 1774 bordepa01 2005     1  SEA AL  39 117  12  23   5   0  1   7   0  0   4  22\n#> 1775 bordimi01 1990     1  OAK AL  25  14   0   1   0   0  0   0   0  0   1   4\n#> 1776 bordimi01 1991     1  OAK AL  90 235  21  56   5   1  0  21   3  4  14  37\n#> 1777 bordimi01 1992     1  OAK AL 154 504  62 151  19   4  3  48  12  6  40  59\n#> 1778 bordimi01 1993     1  OAK AL 159 546  60 136  21   2  3  48  10 10  60  58\n#> 1779 bordimi01 1994     1  OAK AL 114 391  38  99  18   4  2  37   7  2  38  44\n#> 1780 bordimi01 1995     1  OAK AL 126 428  46 113  13   0  8  44  11  3  35  48\n#> 1781 bordimi01 1996     1  OAK AL 155 525  46 126  18   4  5  54   5  6  52  59\n#> 1782 bordimi01 1997     1  BAL AL 153 509  55 120  19   1  7  46   0  2  33  66\n#> 1783 bordimi01 1998     1  BAL AL 151 465  59 121  29   1 13  51   6  7  39  65\n#> 1784 bordimi01 1999     1  BAL AL 160 631  93 175  35   7 10  77  14  4  54 102\n#> 1785 bordimi01 2000     1  BAL AL 100 391  70 116  22   1 16  59   6  5  34  71\n#> 1786 bordimi01 2000     2  NYN NL  56 192  18  50   8   0  4  21   3  1  15  28\n#> 1787 bordimi01 2001     1  BAL AL  58 229  32  57  13   0  7  30   9  3  17  36\n#> 1788 bordimi01 2002     1  BAL AL 117 367  37  85  19   3  8  36   7  4  35  63\n#> 1789 bordimi01 2003     1  TOR AL 102 343  39  94  18   2  5  54   3  1  33  60\n#> 1790 bosleth01 1977     1  CAL AL  58 212  19  63  10   2  0  19   5  4  16  32\n#> 1791 bosleth01 1978     1  CHA AL  66 219  25  59   5   1  2  13  12 11  13  32\n#> 1792 bosleth01 1979     1  CHA AL  36  77  13  24   1   1  1   8   4  1   9  14\n#> 1793 bosleth01 1980     1  CHA AL  70 147  12  33   2   0  2  14   3  2  10  27\n#> 1794 bosleth01 1981     1  ML4 AL  42 105  11  24   2   0  0   3   2  1   6  13\n#> 1795 bosleth01 1982     1  SEA AL  22  46   3   8   1   0  0   2   3  1   4   8\n#> 1796 bosleth01 1983     1  CHN NL  43  72  12  21   4   1  2  12   1  1  10  12\n#> 1797 bosleth01 1984     1  CHN NL  55  98  17  29   2   2  2  14   5  1  13  22\n#> 1798 bosleth01 1985     1  CHN NL 108 180  25  59   6   3  7  27   5  1  20  29\n#> 1799 bosleth01 1986     1  CHN NL  87 120  15  33   4   1  1   9   3  0  18  24\n#> 1800 bosleth01 1987     1  KCA AL  80 140  13  39   6   1  1  16   0  0   9  26\n#> 1801 bosleth01 1988     1  KCA AL  15  21   1   4   0   0  0   2   0  0   2   6\n#> 1802 bosleth01 1988     2  CAL AL  35  75   9  21   5   0  0   7   1  1   6  12\n#> 1803 bosleth01 1989     1  TEX AL  37  40   5   9   2   0  1   9   2  0   3  11\n#> 1804 bosleth01 1990     1  TEX AL  30  29   3   4   0   0  1   3   1  0   4   7\n#> 1805 bottoji01 1922     1  SLN NL  37 151  29  49   8   5  5  35   3  1   6  13\n#> 1806 bottoji01 1923     1  SLN NL 134 523  79 194  34  14  8  94   4  6  45  44\n#> 1807 bottoji01 1924     1  SLN NL 137 528  87 167  31  12 14 111   5  4  35  35\n#> 1808 bottoji01 1925     1  SLN NL 153 619  92 227  44  12 21 128   3  4  47  36\n#> 1809 bottoji01 1926     1  SLN NL 154 603  98 180  40  14 19 120   4 NA  58  52\n#> 1810 bottoji01 1927     1  SLN NL 152 574  95 174  31  15 19 124   8 NA  74  49\n#> 1811 bottoji01 1928     1  SLN NL 149 576 123 187  42  20 31 136  10 NA  71  54\n#> 1812 bottoji01 1929     1  SLN NL 146 560 108 176  31  12 29 137   3 NA  70  54\n#> 1813 bottoji01 1930     1  SLN NL 131 487  92 148  33   7 15  97   5 NA  44  36\n#> 1814 bottoji01 1931     1  SLN NL 108 382  73 133  34   5  9  75   3 NA  34  24\n#> 1815 bottoji01 1932     1  SLN NL  91 311  45  92  16   3 11  48   2 NA  25  32\n#> 1816 bottoji01 1933     1  CIN NL 145 549  57 137  23   9 13  83   3 NA  42  28\n#> 1817 bottoji01 1934     1  CIN NL 142 556  72 158  31  11 11  78   1 NA  33  40\n#> 1818 bottoji01 1935     1  CIN NL 107 399  44 103  21   1  1  49   3 NA  18  24\n#> 1819 bottoji01 1936     1  SLA AL 140 544  72 162  39  11 12  95   0  0  44  55\n#> 1820 bottoji01 1937     1  SLA AL  65 109  11  26   7   0  1  12   1  0  18  15\n#> 1821 boudrlo01 1938     1  CLE AL   1   1   0   0   0   0  0   0   0  0   1   0\n#> 1822 boudrlo01 1939     1  CLE AL  53 225  42  58  15   4  0  19   2  1  28  24\n#> 1823 boudrlo01 1940     1  CLE AL 155 627  97 185  46  10  9 101   6  3  73  39\n#> 1824 boudrlo01 1941     1  CLE AL 148 579  95 149  45   8 10  56   9  4  85  57\n#> 1825 boudrlo01 1942     1  CLE AL 147 506  57 143  18  10  2  58   7 16  75  39\n#> 1826 boudrlo01 1943     1  CLE AL 152 539  69 154  32   7  3  67   4  7  90  31\n#> 1827 boudrlo01 1944     1  CLE AL 150 584  91 191  45   5  3  67  11  3  73  39\n#> 1828 boudrlo01 1945     1  CLE AL  97 345  50 106  24   1  3  48   0  4  35  20\n#> 1829 boudrlo01 1946     1  CLE AL 140 515  51 151  30   6  6  62   6  7  40  14\n#> 1830 boudrlo01 1947     1  CLE AL 150 538  79 165  45   3  4  67   1  0  67  10\n#> 1831 boudrlo01 1948     1  CLE AL 152 560 116 199  34   6 18 106   3  2  98   9\n#> 1832 boudrlo01 1949     1  CLE AL 134 475  53 135  20   3  4  60   0  1  70  10\n#> 1833 boudrlo01 1950     1  CLE AL  81 260  23  70  13   2  1  29   1  2  31   5\n#> 1834 boudrlo01 1951     1  BOS AL  82 273  37  73  18   1  5  47   1  0  30  12\n#> 1835 boudrlo01 1952     1  BOS AL   4   2   1   0   0   0  0   2   0  0   0   0\n#> 1836  bowala01 1970     1  PHI NL 145 547  50 137  17   6  0  34  24 13  21  48\n#> 1837  bowala01 1971     1  PHI NL 159 650  74 162  18   5  0  25  28 11  36  61\n#> 1838  bowala01 1972     1  PHI NL 152 579  67 145  11  13  1  31  17  9  32  51\n#> 1839  bowala01 1973     1  PHI NL 122 446  42  94  11   3  0  23  10  6  24  31\n#> 1840  bowala01 1974     1  PHI NL 162 669  97 184  19  10  1  36  39 11  23  52\n#> 1841  bowala01 1975     1  PHI NL 136 583  79 178  18   9  2  38  24  6  24  32\n#> 1842  bowala01 1976     1  PHI NL 156 624  71 155  15   9  0  49  30  8  32  31\n#> 1843  bowala01 1977     1  PHI NL 154 624  93 175  19   3  4  41  32  3  32  32\n#> 1844  bowala01 1978     1  PHI NL 156 654  78 192  31   5  3  43  27  5  24  40\n#> 1845  bowala01 1979     1  PHI NL 147 539  74 130  17  11  0  31  20  9  61  32\n#> 1846  bowala01 1980     1  PHI NL 147 540  57 144  16   4  2  39  21  6  24  28\n#> 1847  bowala01 1981     1  PHI NL 103 360  34 102  14   3  0  31  16  7  26  17\n#> 1848  bowala01 1982     1  CHN NL 142 499  50 123  15   7  0  29   8  3  39  38\n#> 1849  bowala01 1983     1  CHN NL 147 499  73 133  20   5  2  43   7  3  35  30\n#> 1850  bowala01 1984     1  CHN NL 133 391  33  87  14   2  0  17  10  4  28  24\n#> 1851  bowala01 1985     1  CHN NL  72 195  13  48   6   4  0  13   5  1  11  20\n#> 1852  bowala01 1985     2  NYN NL  14  19   2   2   1   0  0   2   0  0   2   2\n#> 1853 bowerfr01 1895     1  BLN NL   1   1   0   0   0   0  0   0   0 NA   0   0\n#> 1854 bowerfr01 1896     1  BLN NL   4  16   0   2   0   0  0   4   0 NA   1   0\n#> 1855 bowerfr01 1897     1  BLN NL  38 130  16  41   5   0  1  21   3 NA   1  NA\n#> 1856 bowerfr01 1898     1  BLN NL   5  16   5   7   1   0  0   1   1 NA   2  NA\n#> 1857 bowerfr01 1898     2  PIT NL  69 241  17  66   6   3  0  29   4 NA   7  NA\n#> 1858 bowerfr01 1899     1  PIT NL 109 424  49 110  16  10  3  53  10 NA  11  NA\n#> 1859 bowerfr01 1900     1  NY1 NL  80 270  25  65   5   3  1  42  10 NA   6  NA\n#> 1860 bowerfr01 1901     1  NY1 NL  59 191  20  38   5   3  0  14   3 NA   7  NA\n#> 1861 bowerfr01 1902     1  NY1 NL 107 367  38  93  14   6  0  26  12 NA  13  NA\n#> 1862 bowerfr01 1903     1  NY1 NL  64 210  22  58   6   2  1  31   5 NA   6  NA\n#> 1863 bowerfr01 1904     1  NY1 NL  93 289  38  67  11   4  2  27   7 NA  16  NA\n#> 1864 bowerfr01 1905     1  NY1 NL  98 297  37  80   8   1  3  41   6 NA  12  NA\n#> 1865 bowerfr01 1906     1  NY1 NL 103 285  23  65   7   3  1  42   5 NA  15  NA\n#> 1866 bowerfr01 1907     1  NY1 NL  96 311  31  81   8   2  0  32  11 NA  17  NA\n#> 1867 bowerfr01 1908     1  BSN NL  86 254  16  58   8   1  1  25   4 NA  13  NA\n#> 1868 bowerfr01 1909     1  BSN NL  33  99   6  21   2   0  0   4   0 NA   2  NA\n#> 1869 boyercl02 1955     1  KC1 AL  47  79   3  19   1   0  0   6   0  0   3  17\n#> 1870 boyercl02 1956     1  KC1 AL  67 129  15  28   3   1  1   4   1  1  11  24\n#> 1871 boyercl02 1957     1  KC1 AL  10   0   0   0   0   0  0   0   0  0   0   0\n#> 1872 boyercl02 1959     1  NYA AL  47 114   4  20   2   0  0   3   1  0   6  23\n#> 1873 boyercl02 1960     1  NYA AL 124 393  54  95  20   1 14  46   2  3  23  85\n#> 1874 boyercl02 1961     1  NYA AL 148 504  61 113  19   5 11  55   1  3  63  83\n#> 1875 boyercl02 1962     1  NYA AL 158 566  85 154  24   1 18  68   3  2  51 106\n#> 1876 boyercl02 1963     1  NYA AL 152 557  59 140  20   3 12  54   4  2  33  91\n#> 1877 boyercl02 1964     1  NYA AL 147 510  43 111  10   5  8  52   6  1  36  93\n#> 1878 boyercl02 1965     1  NYA AL 148 514  69 129  23   6 18  58   4  1  39  79\n#> 1879 boyercl02 1966     1  NYA AL 144 500  59 120  22   4 14  57   6  0  46  48\n#> 1880 boyercl02 1967     1  ATL NL 154 572  63 140  18   3 26  96   6  3  39  81\n#> 1881 boyercl02 1968     1  ATL NL  71 273  19  62   7   2  4  17   2  0  16  32\n#> 1882 boyercl02 1969     1  ATL NL 144 496  57 124  16   1 14  57   3  7  55  87\n#> 1883 boyercl02 1970     1  ATL NL 134 475  44 117  14   1 16  62   2  5  41  71\n#> 1884 boyercl02 1971     1  ATL NL  30  98  10  24   1   0  6  19   0  0   8  11\n#> 1885 boyerke01 1955     1  SLN NL 147 530  78 140  27   2 18  62  22 17  37  67\n#> 1886 boyerke01 1956     1  SLN NL 150 595  91 182  30   2 26  98   8  3  38  65\n#> 1887 boyerke01 1957     1  SLN NL 142 544  79 144  18   3 19  62  12  8  44  77\n#> 1888 boyerke01 1958     1  SLN NL 150 570 101 175  21   9 23  90  11  6  49  53\n#> 1889 boyerke01 1959     1  SLN NL 149 563  86 174  18   5 28  94  12  6  67  77\n#> 1890 boyerke01 1960     1  SLN NL 151 552  95 168  26  10 32  97   8  7  56  77\n#> 1891 boyerke01 1961     1  SLN NL 153 589 109 194  26  11 24  95   6  3  68  91\n#> 1892 boyerke01 1962     1  SLN NL 160 611  92 178  27   5 24  98  12  7  75 104\n#> 1893 boyerke01 1963     1  SLN NL 159 617  86 176  28   2 24 111   1  0  70  90\n#> 1894 boyerke01 1964     1  SLN NL 162 628 100 185  30  10 24 119   3  5  70  85\n#> 1895 boyerke01 1965     1  SLN NL 144 535  71 139  18   2 13  75   2  7  57  73\n#> 1896 boyerke01 1966     1  NYN NL 136 496  62 132  28   2 14  61   4  3  30  64\n#> 1897 boyerke01 1967     2  CHA AL  57 180  17  47   5   1  4  21   0  2   7  25\n#> 1898 boyerke01 1967     1  NYN NL  56 166  17  39   7   2  3  13   2  1  26  22\n#> 1899 boyerke01 1968     1  CHA AL  10  24   0   3   0   0  0   0   0  0   1   6\n#> 1900 boyerke01 1968     2  LAN NL  83 221  20  60   7   2  6  41   2  2  16  34\n#> 1901 boyerke01 1969     1  LAN NL  25  34   0   7   2   0  0   4   0  0   2   7\n#> 1902 braunst01 1971     1  MIN AL 128 343  51  87  12   2  5  35   8  3  48  50\n#> 1903 braunst01 1972     1  MIN AL 121 402  40 116  21   0  2  50   4  5  45  38\n#> 1904 braunst01 1973     1  MIN AL 115 361  46 102  28   5  6  42   4  3  74  48\n#> 1905 braunst01 1974     1  MIN AL 129 453  53 127  12   1  8  40   4  4  56  51\n#> 1906 braunst01 1975     1  MIN AL 136 453  70 137  18   3 11  45   0  2  66  55\n#> 1907 braunst01 1976     1  MIN AL 122 417  73 120  12   3  3  61  12  4  67  43\n#> 1908 braunst01 1977     1  SEA AL 139 451  51 106  19   1  5  31   8  3  80  59\n#> 1909 braunst01 1978     1  SEA AL  32  74  11  17   4   0  3  15   1  0   9   5\n#> 1910 braunst01 1978     2  KCA AL  64 137  16  36  10   1  0  14   3  2  28  16\n#> 1911 braunst01 1979     1  KCA AL  58 116  15  31   2   0  4  10   0  0  22  11\n#> 1912 braunst01 1980     1  KCA AL  14  23   0   1   0   0  0   1   0  0   2   2\n#> 1913 braunst01 1980     2  TOR AL  37  55   4  15   2   0  1   9   0  0   8   5\n#> 1914 braunst01 1981     1  SLN NL  44  46   9   9   2   1  0   2   1  0  15   7\n#> 1915 braunst01 1982     1  SLN NL  58  62   6  17   4   0  0   4   0  0  11  10\n#> 1916 braunst01 1983     1  SLN NL  78  92   8  25   2   1  3   7   0  1  21   7\n#> 1917 braunst01 1984     1  SLN NL  86  98   6  27   3   1  0  16   0  0  17  17\n#> 1918 braunst01 1985     1  SLN NL  64  67   7  16   4   0  1   6   0  0  10   9\n#> 1919 bresnro01 1897     1  WSN NL   6  16   1   6   0   0  0   3   0 NA   1  NA\n#> 1920 bresnro01 1900     1  CHN NL   2   2   0   0   0   0  0   0   0 NA   0  NA\n#> 1921 bresnro01 1901     1  BLA AL  86 295  40  79   9   9  1  32  10 NA  23  NA\n#> 1922 bresnro01 1902     1  BLA AL  65 235  30  64   8   6  4  34  12 NA  21  NA\n#> 1923 bresnro01 1902     2  NY1 NL  51 178  16  51   9   3  1  22   6 NA  16  NA\n#> 1924 bresnro01 1903     1  NY1 NL 113 406  87 142  30   8  4  55  34 NA  61  NA\n#> 1925 bresnro01 1904     1  NY1 NL 109 402  81 114  22   7  5  33  13 NA  58  NA\n#> 1926 bresnro01 1905     1  NY1 NL 104 331  58 100  18   3  0  46  11 NA  50  NA\n#> 1927 bresnro01 1906     1  NY1 NL 124 405  69 114  22   4  0  43  25 NA  81  NA\n#> 1928 bresnro01 1907     1  NY1 NL 110 328  57  83   9   7  4  38  15 NA  61  NA\n#> 1929 bresnro01 1908     1  NY1 NL 140 449  70 127  25   3  1  54  14 NA  83  NA\n#> 1930 bresnro01 1909     1  SLN NL  72 234  27  57   4   1  0  23  11 NA  46  NA\n#> 1931 bresnro01 1910     1  SLN NL  88 234  35  65  15   3  0  27  13 NA  55  17\n#> 1932 bresnro01 1911     1  SLN NL  81 227  22  63  17   8  3  41   4 NA  45  19\n#> 1933 bresnro01 1912     1  SLN NL  48 108   8  36   7   2  1  15   4 NA  14   9\n#> 1934 bresnro01 1913     1  CHN NL  69 162  20  37   5   2  1  21   7 NA  21  11\n#> 1935 bresnro01 1914     1  CHN NL 101 248  42  69  10   4  0  24  14 NA  49  20\n#> 1936 bresnro01 1915     1  CHN NL  77 221  19  45   8   1  1  19  19  3  29  23\n#> 1937 bressru01 1914     1  PHA AL  29  51   6  11   1   1  0   4   0 NA   6   7\n#> 1938 bressru01 1915     1  PHA AL  33  55   9   8   0   1  1   4   0 NA   9  13\n#> 1939 bressru01 1916     1  PHA AL   4   5   1   1   0   1  0   1   0 NA   0   0\n#> 1940 bressru01 1917     1  CIN NL   3   5   0   1   0   0  0   0   0 NA   0   2\n#> 1941 bressru01 1918     1  CIN NL  23  62  10  17   5   0  0   6   0 NA   5   4\n#> 1942 bressru01 1919     1  CIN NL  61 165  22  34   3   4  2  17   2 NA  23  15\n#> 1943 bressru01 1920     1  CIN NL  21  30   4   8   1   0  0   3   1  0   1   4\n#> 1944 bressru01 1921     1  CIN NL 109 323  41  99  18   6  1  54   5  5  39  20\n#> 1945 bressru01 1922     1  CIN NL  52  53   7  14   0   2  0   8   1  0   4   4\n#> 1946 bressru01 1923     1  CIN NL  54 119  25  33   3   1  0  18   3  1  20   4\n#> 1947 bressru01 1924     1  CIN NL 115 383  41 133  14  13  4  49   9 10  22  20\n#> 1948 bressru01 1925     1  CIN NL  97 319  43 111  17   6  4  61   9  5  40  16\n#> 1949 bressru01 1926     1  CIN NL  86 297  58 106  15   9  1  51   3 NA  37  20\n#> 1950 bressru01 1927     1  CIN NL 124 467  43 136  14   8  3  77   4 NA  32  22\n#> 1951 bressru01 1928     1  BRO NL 145 501  78 148  29  13  4  70   2 NA  80  33\n#> 1952 bressru01 1929     1  BRO NL 136 456  72 145  22   8  9  77   4 NA  67  27\n#> 1953 bressru01 1930     1  BRO NL 109 335  53 100  12   8  3  52   4 NA  51  19\n#> 1954 bressru01 1931     1  BRO NL  67 153  22  43   4   5  0  26   0 NA  11  10\n#> 1955 bressru01 1932     1  PHI NL  27  83   9  19   6   1  0   6   0 NA   2   5\n#> 1956 bressru01 1932     2  SLN NL  10  19   0   3   0   0  0   2   0 NA   0   1\n#> 1957 brettge01 1973     1  KCA AL  13  40   2   5   2   0  0   0   0  0   0   5\n#> 1958 brettge01 1974     1  KCA AL 133 457  49 129  21   5  2  47   8  5  21  38\n#> 1959 brettge01 1975     1  KCA AL 159 634  84 195  35  13 11  89  13 10  46  49\n#> 1960 brettge01 1976     1  KCA AL 159 645  94 215  34  14  7  67  21 11  49  36\n#> 1961 brettge01 1977     1  KCA AL 139 564 105 176  32  13 22  88  14 12  55  24\n#> 1962 brettge01 1978     1  KCA AL 128 510  79 150  45   8  9  62  23  7  39  35\n#> 1963 brettge01 1979     1  KCA AL 154 645 119 212  42  20 23 107  17 10  51  36\n#> 1964 brettge01 1980     1  KCA AL 117 449  87 175  33   9 24 118  15  6  58  22\n#> 1965 brettge01 1981     1  KCA AL  89 347  42 109  27   7  6  43  14  6  27  23\n#> 1966 brettge01 1982     1  KCA AL 144 552 101 166  32   9 21  82   6  1  71  51\n#> 1967 brettge01 1983     1  KCA AL 123 464  90 144  38   2 25  93   0  1  57  39\n#> 1968 brettge01 1984     1  KCA AL 104 377  42 107  21   3 13  69   0  2  38  37\n#> 1969 brettge01 1985     1  KCA AL 155 550 108 184  38   5 30 112   9  1 103  49\n#> 1970 brettge01 1986     1  KCA AL 124 441  70 128  28   4 16  73   1  2  80  45\n#> 1971 brettge01 1987     1  KCA AL 115 427  71 124  18   2 22  78   6  3  72  47\n#> 1972 brettge01 1988     1  KCA AL 157 589  90 180  42   3 24 103  14  3  82  51\n#> 1973 brettge01 1989     1  KCA AL 124 457  67 129  26   3 12  80  14  4  59  47\n#> 1974 brettge01 1990     1  KCA AL 142 544  82 179  45   7 14  87   9  2  56  63\n#> 1975 brettge01 1991     1  KCA AL 131 505  77 129  40   2 10  61   2  0  58  75\n#> 1976 brettge01 1992     1  KCA AL 152 592  55 169  35   5  7  61   8  6  35  69\n#> 1977 brettge01 1993     1  KCA AL 145 560  69 149  31   3 19  75   7  5  39  67\n#> 1978 brettke01 1967     1  BOS AL   1   0   0   0   0   0  0   0   0  0   0   0\n#> 1979 brettke01 1969     1  BOS AL   8  10   1   3   1   0  1   3   0  0   1   1\n#> 1980 brettke01 1970     1  BOS AL  41  41   8  13   3   0  2   3   0  0   2   7\n#> 1981 brettke01 1971     1  BOS AL  29  10   0   2   0   0  0   0   0  0   0   2\n#> 1982 brettke01 1972     1  ML4 AL  31  44   6  10   1   0  0   1   0  0   2  10\n#> 1983 brettke01 1973     1  PHI NL  37  80   6  20   5   0  4  16   0  0   4  17\n#> 1984 brettke01 1974     1  PIT NL  43  87  13  27   4   1  2  15   0  0   4  20\n#> 1985 brettke01 1975     1  PIT NL  26  52   5  12   4   0  1   4   0  0   1   7\n#> 1986 brettke01 1976     1  NYA AL   2   0   0   0   0   0  0   0   0  0   0   0\n#> 1987 brettke01 1976     2  CHA AL  33  12   0   1   0   0  0   0   0  0   0   1\n#> 1988 brettke01 1977     1  CHA AL  13   0   0   0   0   0  0   0   0  0   0   0\n#> 1989 brettke01 1977     2  CAL AL  22   0   0   0   0   0  0   0   0  0   0   0\n#> 1990 brettke01 1978     1  CAL AL  31   0   0   0   0   0  0   0   0  0   0   0\n#> 1991 brettke01 1979     1  MIN AL   9   0   0   0   0   0  0   0   0  0   0   0\n#> 1992 brettke01 1979     2  LAN NL  30  11   0   3   0   0  0   2   0  0   0   2\n#> 1993 brettke01 1980     1  KCA AL   8   0   0   0   0   0  0   0   0  0   0   0\n#> 1994 brettke01 1981     1  KCA AL  22   0   0   0   0   0  0   0   0  0   0   0\n#> 1995 breweji01 1960     1  CHN NL   6   6   0   1   0   0  0   0   0  0   1   2\n#> 1996 breweji01 1961     1  CHN NL  36  22   1   4   0   0  0   0   0  0   2  10\n#> 1997 breweji01 1962     1  CHN NL   6   0   0   0   0   0  0   0   0  0   0   0\n#> 1998 breweji01 1963     1  CHN NL  29   6   0   0   0   0  0   1   0  0   3   4\n#> 1999 breweji01 1964     1  LAN NL  34  22   0   6   0   0  0   3   0  0   1  10\n#> 2000 breweji01 1965     1  LAN NL  20  10   0   0   0   0  0   0   0  0   0   2\n#> 2001 breweji01 1966     1  LAN NL  13   0   0   0   0   0  0   0   0  0   0   0\n#> 2002 breweji01 1967     1  LAN NL  30  22   0   1   1   0  0   1   0  0   0   8\n#> 2003 breweji01 1968     1  LAN NL  54   9   0   2   0   0  0   2   0  0   0   1\n#> 2004 breweji01 1969     1  LAN NL  59  11   0   1   1   0  0   0   0  0   1   4\n#> 2005 breweji01 1970     1  LAN NL  58  12   0   1   0   0  0   1   1  0   1   6\n#> 2006 breweji01 1971     1  LAN NL  55   9   0   3   0   0  0   1   0  0   0   2\n#> 2007 breweji01 1972     1  LAN NL  51   1   1   0   0   0  0   0   0  0   1   0\n#> 2008 breweji01 1973     1  LAN NL  56   5   0   2   0   0  0   0   0  0   0   2\n#> 2009 breweji01 1974     1  LAN NL  24   2   0   0   0   0  0   0   0  0   0   1\n#> 2010 breweji01 1975     2  CAL AL  21   0   0   0   0   0  0   0   0  0   0   0\n#> 2011 breweji01 1975     1  LAN NL  21   3   0   0   0   0  0   0   0  0   0   0\n#> 2012 breweji01 1976     1  CAL AL  13   0   0   0   0   0  0   0   0  0   0   0\n#> 2013 bridgto01 1930     1  DET AL   8  10   1   3   1   0  0   0   0  0   1   3\n#> 2014 bridgto01 1931     1  DET AL  35  54   4   8   0   0  0   1   0  0   5  23\n#> 2015 bridgto01 1932     1  DET AL  34  67   5  11   1   1  0   4   0  0   7  24\n#> 2016 bridgto01 1933     1  DET AL  33  78   5  16   2   2  0   5   0  0   7  17\n#> 2017 bridgto01 1934     1  DET AL  36  98   7  12   2   0  0  10   0  0   7  25\n#> 2018 bridgto01 1935     1  DET AL  36 109   9  26   5   1  0  10   0  0   6  24\n#> 2019 bridgto01 1936     1  DET AL  39 118  10  25   4   1  0  15   0  0   3  26\n#> 2020 bridgto01 1937     1  DET AL  34  96   9  23   2   1  0   8   0  0   5  26\n#> 2021 bridgto01 1938     1  DET AL  25  54   5   7   1   1  0   3   0  0   6  17\n#> 2022 bridgto01 1939     1  DET AL  29  71  11  14   2   0  0   6   0  0   8  24\n#> 2023 bridgto01 1940     1  DET AL  29  68   5  12   2   0  0   4   0  0   3  23\n#> 2024 bridgto01 1941     1  DET AL  25  47   2   4   1   0  0   1   0  0   4  11\n#> 2025 bridgto01 1942     1  DET AL  23  63   5   6   1   1  0   2   0  0   5  12\n#> 2026 bridgto01 1943     1  DET AL  25  64   4  14   3   0  0   3   0  0   5  14\n#> 2027 bridgto01 1945     1  DET AL   4   3   0   0   0   0  0   0   0  0   0   0\n#> 2028 bridgto01 1946     1  DET AL   9   3   1   0   0   0  0   0   0  0   2   2\n#> 2029 brilene01 1965     1  SLN NL  37  15   0   2   0   0  0   2   0  0   1   8\n#> 2030 brilene01 1966     1  SLN NL  49  38   2   3   0   0  0   0   0  0   2  16\n#> 2031 brilene01 1967     1  SLN NL  49  40   5   6   0   0  0   0   0  0   3  20\n#> 2032 brilene01 1968     1  SLN NL  33  80   5  11   2   0  0   5   0  0   4  21\n#> 2033 brilene01 1969     1  SLN NL  36  76   1   8   0   0  1   5   0  0   4  26\n#> 2034 brilene01 1970     1  SLN NL  30  39   4   7   1   2  0   3   0  0   1  14\n#> 2035 brilene01 1971     1  PIT NL  37  39   3  10   3   0  1   4   0  0   2  13\n#> 2036 brilene01 1972     1  PIT NL  28  70   6  11   1   0  0   4   0  0   2  32\n#> 2037 brilene01 1973     1  PIT NL  33  72   3  14   2   0  1   6   0  0   2  21\n#> 2038 brilene01 1974     1  KCA AL  18   0   0   0   0   0  0   0   0  0   0   0\n#> 2039 brilene01 1975     1  KCA AL  24   0   0   0   0   0  0   0   0  0   0   0\n#> 2040 brilene01 1976     1  TEX AL  32   0   0   0   0   0  0   0   0  0   0   0\n#> 2041 brilene01 1977     1  TEX AL  28   0   0   0   0   0  0   0   0  0   0   0\n#> 2042 brilene01 1977     2  BAL AL   2   0   0   0   0   0  0   0   0  0   0   0\n#> 2043 brilene01 1978     1  BAL AL  16   0   0   0   0   0  0   0   0  0   0   0\n#> 2044 brinked01 1961     1  WS2 AL   4  11   0   1   0   0  0   0   0  0   1   1\n#> 2045 brinked01 1962     1  WS2 AL  54 133   8  22   7   1  0   4   1  0  11  28\n#> 2046 brinked01 1963     1  WS2 AL 145 514  44 117  20   3  7  45   5  3  31  86\n#> 2047 brinked01 1964     1  WS2 AL 132 447  54 100  20   3  8  34   2  2  26  99\n#> 2048 brinked01 1965     1  WS2 AL 154 444  35  82  13   2  5  35   1  2  38  82\n#> 2049 brinked01 1966     1  WS2 AL 158 582  42 133  18   9  7  48   7  9  29 105\n#> 2050 brinked01 1967     1  WS2 AL 109 320  21  60   9   2  1  18   1  3  24  58\n#> 2051 brinked01 1968     1  WS2 AL  77 193  12  36   3   0  0   6   0  0  19  31\n#> 2052 brinked01 1969     1  WS2 AL 151 576  71 153  18   5  2  43   2  2  50  42\n#> 2053 brinked01 1970     1  WS2 AL 158 625  63 164  17   2  1  40   8  9  60  41\n#> 2054 brinked01 1971     1  DET AL 159 527  40 120  18   2  1  37   1  4  44  54\n#> 2055 brinked01 1972     1  DET AL 156 516  42 105  19   1  6  49   0  0  38  51\n#> 2056 brinked01 1973     1  DET AL 162 515  55 122  16   4  7  40   0  1  34  79\n#> 2057 brinked01 1974     1  DET AL 153 502  55 111  15   3 14  54   2  0  29  71\n#> 2058 brinked01 1975     2  TEX AL   1   2   0   0   0   0  0   0   0  0   0   1\n#> 2059 brinked01 1975     3  NYA AL  44  63   2  11   4   1  0   2   0  0   3   6\n#> 2060 brinked01 1975     1  SLN NL  28  75   6  18   4   0  1   6   0  0   7  10\n#> 2061 brocklo01 1961     1  CHN NL   4  11   1   1   0   0  0   0   0  0   1   3\n#> 2062 brocklo01 1962     1  CHN NL 123 434  73 114  24   7  9  35  16  7  35  96\n#> 2063 brocklo01 1963     1  CHN NL 148 547  79 141  19  11  9  37  24 12  31 122\n#> 2064 brocklo01 1964     1  CHN NL  52 215  30  54   9   2  2  14  10  3  13  40\n#> 2065 brocklo01 1964     2  SLN NL 103 419  81 146  21   9 12  44  33 15  27  87\n#> 2066 brocklo01 1965     1  SLN NL 155 631 107 182  35   8 16  69  63 27  45 116\n#> 2067 brocklo01 1966     1  SLN NL 156 643  94 183  24  12 15  46  74 18  31 134\n#> 2068 brocklo01 1967     1  SLN NL 159 689 113 206  32  12 21  76  52 18  24 109\n#> 2069 brocklo01 1968     1  SLN NL 159 660  92 184  46  14  6  51  62 12  46 124\n#> 2070 brocklo01 1969     1  SLN NL 157 655  97 195  33  10 12  47  53 14  50 115\n#> 2071 brocklo01 1970     1  SLN NL 155 664 114 202  29   5 13  57  51 15  60  99\n#> 2072 brocklo01 1971     1  SLN NL 157 640 126 200  37   7  7  61  64 19  76 107\n#> 2073 brocklo01 1972     1  SLN NL 153 621  81 193  26   8  3  42  63 18  47  93\n#> 2074 brocklo01 1973     1  SLN NL 160 650 110 193  29   8  7  63  70 20  71 112\n#> 2075 brocklo01 1974     1  SLN NL 153 635 105 194  25   7  3  48 118 33  61  88\n#> 2076 brocklo01 1975     1  SLN NL 136 528  78 163  27   6  3  47  56 16  38  64\n#> 2077 brocklo01 1976     1  SLN NL 133 498  73 150  24   5  4  67  56 19  35  75\n#> 2078 brocklo01 1977     1  SLN NL 141 489  69 133  22   6  2  46  35 24  30  74\n#> 2079 brocklo01 1978     1  SLN NL  92 298  31  66   9   0  0  12  17  5  17  29\n#> 2080 brocklo01 1979     1  SLN NL 120 405  56 123  15   4  5  38  21 12  23  43\n#> 2081 brookhu01 1980     1  NYN NL  24  81   8  25   2   1  1  10   1  1   5   9\n#> 2082 brookhu01 1981     1  NYN NL  98 358  34 110  21   2  4  38   9  5  23  65\n#> 2083 brookhu01 1982     1  NYN NL 126 457  40 114  21   2  2  40   6  3  28  76\n#> 2084 brookhu01 1983     1  NYN NL 150 586  53 147  18   4  5  58   6  4  24  96\n#> 2085 brookhu01 1984     1  NYN NL 153 561  61 159  23   2 16  73   6  5  48  79\n#> 2086 brookhu01 1985     1  MON NL 156 605  67 163  34   7 13 100   6  9  34  79\n#> 2087 brookhu01 1986     1  MON NL  80 306  50 104  18   5 14  58   4  2  25  60\n#> 2088 brookhu01 1987     1  MON NL 112 430  57 113  22   3 14  72   4  3  24  72\n#> 2089 brookhu01 1988     1  MON NL 151 588  61 164  35   2 20  90   7  3  35 108\n#> 2090 brookhu01 1989     1  MON NL 148 542  56 145  30   1 14  70   6 11  39 108\n#> 2091 brookhu01 1990     1  LAN NL 153 568  74 151  28   1 20  91   2  5  33 108\n#> 2092 brookhu01 1991     1  NYN NL 103 357  48  85  11   1 16  50   3  1  44  62\n#> 2093 brookhu01 1992     1  CAL AL  82 306  28  66  13   0  8  36   3  3  12  46\n#> 2094 brookhu01 1993     1  KCA AL  75 168  14  48  12   0  1  24   0  1  11  27\n#> 2095 brookhu01 1994     1  KCA AL  34  61   5  14   2   0  1  14   1  0   2  10\n#> 2096 broutda01 1879     1  TRN NL  39 168  17  46  12   1  4  17  NA NA   1  18\n#> 2097 broutda01 1880     1  TRN NL   3  12   0   2   0   0  0   1  NA NA   1   0\n#> 2098 broutda01 1881     1  BFN NL  65 270  60  86  18   9  8  45  NA NA  18  22\n#> 2099 broutda01 1882     1  BFN NL  84 351  71 129  23  11  6  63  NA NA  21   7\n#> 2100 broutda01 1883     1  BFN NL  98 425  85 159  41  17  3  97  NA NA  16  17\n#> 2101 broutda01 1884     1  BFN NL  94 398  82 130  22  15 14  79  NA NA  33  20\n#> 2102 broutda01 1885     1  BFN NL  98 407  87 146  32  11  7  59  NA NA  34  10\n#> 2103 broutda01 1886     1  DTN NL 121 489 139 181  40  15 11  72  21 NA  66  16\n#> 2104 broutda01 1887     1  DTN NL 123 500 153 169  36  20 12 101  34 NA  71   9\n#> 2105 broutda01 1888     1  DTN NL 129 522 118 160  33  11  9  66  34 NA  68  13\n#> 2106 broutda01 1889     1  BSN NL 126 485 105 181  26   9  7 118  22 NA  66   6\n#> 2107 broutda01 1890     1  BSP PL 123 460 117 152  36   9  1  97  28 NA  99  17\n#> 2108 broutda01 1891     1  BS2 AA 130 486 117 170  26  19  5 109  31 NA  87  20\n#> 2109 broutda01 1892     1  BRO NL 152 588 121 197  30  20  5 124  31 NA  84  30\n#> 2110 broutda01 1893     1  BRO NL  77 282  57  95  21  11  2  59   9 NA  52  10\n#> 2111 broutda01 1894     1  BLN NL 123 525 137 182  39  23  9 128  38 NA  67   9\n#> 2112 broutda01 1895     1  BLN NL   5  23   2   6   2   0  0   5   0 NA   1   1\n#> 2113 broutda01 1895     2  LS3 NL  24  97  13  30  10   1  2  15   1 NA  11   2\n#> 2114 broutda01 1896     1  PHI NL  57 218  42  75  13   3  1  41   7 NA  44  11\n#> 2115 broutda01 1904     1  NY1 NL   2   5   0   0   0   0  0   0   0 NA   0  NA\n#> 2116 browncl01 1928     1  CLE AL   2   5   1   1   0   0  0   0   0  0   0   1\n#> 2117 browncl01 1929     1  CLE AL   3   7   1   0   0   0  0   0   0  0   0   0\n#> 2118 browncl01 1930     1  CLE AL  35  73   5  18   5   0  0   3   0  0   8   9\n#> 2119 browncl01 1931     1  CLE AL  39  87   8  15   3   0  0   9   0  0   7   6\n#> 2120 browncl01 1932     1  CLE AL  39 100  13  25   4   2  2  18   0  0   8  13\n#> 2121 browncl01 1933     1  CLE AL  34  62   4   9   1   0  0   3   1  0   2   6\n#> 2122 browncl01 1934     1  CLE AL  17  17   1   5   1   0  0   1   0  0   2   3\n#> 2123 browncl01 1935     1  CLE AL  23  10   1   2   0   0  0   0   0  0   2   0\n#> 2124 browncl01 1936     1  CHA AL  38  25   5   4   2   0  0   3   0  0   2   1\n#> 2125 browncl01 1937     1  CHA AL  53  18   1   4   0   0  0   3   0  0   5   5\n#> 2126 browncl01 1938     1  CHA AL   8   2   1   1   1   0  0   0   0  0   1   0\n#> 2127 browncl01 1939     1  CHA AL  61  19   0   4   0   0  0   3   0  0   4   3\n#> 2128 browncl01 1940     1  CHA AL  37  14   0   1   0   0  0   1   0  0   2   2\n#> 2129 browncl01 1941     1  CLE AL  41  17   1   2   0   1  0   2   0  0   2   5\n#> 2130 browncl01 1942     1  CLE AL   7   1   0   0   0   0  0   0   0  0   0   1\n#> 2131 brownge01 1901     1  PHI NL   8  26   2   5   1   0  0   4   2 NA   1  NA\n#> 2132 brownge01 1902     1  PHI NL  70 281  41  73   7   1  0  26  11 NA  16  NA\n#> 2133 brownge01 1902     2  NY1 NL  53 216  30  69   9   5  0  14  13 NA   9  NA\n#> 2134 brownge01 1903     1  NY1 NL 141 591 105 185  20   3  3  45  27 NA  43  NA\n#> 2135 brownge01 1904     1  NY1 NL 150 596  99 169  16   5  4  39  24 NA  39  NA\n#> 2136 brownge01 1905     1  NY1 NL 127 536  95 157  16  14  4  43  26 NA  20  NA\n#> 2137 brownge01 1906     1  NY1 NL 122 477  61 126  10   4  0  38  32 NA  27  NA\n#> 2138 brownge01 1907     1  NY1 NL 127 458  54 119  11  10  5  37  15 NA  31  NA\n#> 2139 brownge01 1908     1  BSN NL 138 536  61 122  10   6  1  34  17 NA  36  NA\n#> 2140 brownge01 1909     2  WS1 AL 103 393  40 107  15   5  1  16  13 NA  17  NA\n#> 2141 brownge01 1909     1  CHN NL  12  39   7   8   0   1  0   1   3 NA   5  NA\n#> 2142 brownge01 1910     1  WS1 AL   7  22   1   4   0   0  0   0   0 NA   1  NA\n#> 2143 brownge01 1910     2  CHA AL  30 112  17  27   4   1  0   4   5 NA  12  NA\n#> 2144 brownge01 1911     1  BRO NL   8  12   1   4   0   0  0   2   2 NA   1   1\n#> 2145 brownge01 1912     1  PHI NL   6   5   0   1   0   0  0   0   0 NA   1   0\n#> 2146 brownha01 1951     1  CHA AL   4   2   0   2   0   0  0   1   0  0   1   0\n#> 2147 brownha01 1952     1  CHA AL  51  19   6   3   1   0  1   3   0  0   1   8\n#> 2148 brownha01 1953     1  BOS AL  30  58   5  17   5   0  1  10   0  1   2   5\n#> 2149 brownha01 1954     1  BOS AL  40  24   1   3   1   0  0   3   0  0   3   6\n#> 2150 brownha01 1955     1  BOS AL   2   1   0   1   0   0  0   1   0  0   0   0\n#> 2151 brownha01 1955     2  BAL AL  25  16   5   0   0   0  0   0   0  0   2   5\n#> 2152 brownha01 1956     1  BAL AL  42  42   5   8   2   0  0   0   0  0   5   8\n#> 2153 brownha01 1957     1  BAL AL  30  48   2  10   2   1  0   3   0  0   2   9\n#> 2154 brownha01 1958     1  BAL AL  21  27   4   4   1   0  0   1   0  0   1   6\n#> 2155 brownha01 1959     1  BAL AL  31  42   2   2   0   1  0   1   0  0   4  13\n#> 2156 brownha01 1960     1  BAL AL  30  44   5   8   2   0  0   3   0  0   8   8\n#> 2157 brownha01 1961     1  BAL AL  27  50   3   7   2   0  0   1   0  0   3  11\n#> 2158 brownha01 1962     1  BAL AL  22  28   1   8   0   0  0   1   0  0   0   9\n#> 2159 brownha01 1962     2  NYA AL   2   1   0   0   0   0  0   0   0  0   0   0\n#> 2160 brownha01 1963     1  HOU NL  26  43   2   4   0   0  0   2   0  0   1  11\n#> 2161 brownha01 1964     1  HOU NL  27  39   2   5   0   0  0   0   0  0   1   9\n#> 2162 brownke01 1986     1  TEX AL   1   0   0   0   0   0  0   0   0  0   0   0\n#> 2163 brownke01 1988     1  TEX AL   4   0   0   0   0   0  0   0   0  0   0   0\n#> 2164 brownke01 1989     1  TEX AL  28   0   0   0   0   0  0   0   0  0   0   0\n#> 2165 brownke01 1990     1  TEX AL  27   1   0   0   0   0  0   0   0  0   0   0\n#> 2166 brownke01 1991     1  TEX AL  33   0   0   0   0   0  0   0   0  0   0   0\n#> 2167 brownke01 1992     1  TEX AL  35   0   0   0   0   0  0   0   0  0   0   0\n#> 2168 brownke01 1993     1  TEX AL  34   0   0   0   0   0  0   0   0  0   0   0\n#> 2169 brownke01 1994     1  TEX AL  26   0   0   0   0   0  0   0   0  0   0   0\n#> 2170 brownke01 1995     1  BAL AL  26   0   0   0   0   0  0   0   0  0   0   0\n#> 2171 brownke01 1996     1  FLO NL  34  75   1   9   1   0  0   3   0  0   6  28\n#> 2172 brownke01 1997     1  FLO NL  31  72   4   9   1   0  0   4   0  0   5  25\n#> 2173 brownke01 1998     1  SDN NL  34  82   4  17   3   0  0  10   0  0   4  29\n#> 2174 brownke01 1999     1  LAN NL  34  78   1   5   0   0  0   3   0  0   2  24\n#> 2175 brownke01 2000     1  LAN NL  32  66   2   5   0   0  0   3   0  0   2  29\n#> 2176 brownke01 2001     1  LAN NL  20  36   2   3   0   0  1   2   0  0   0  12\n#> 2177 brownke01 2002     1  LAN NL  17  20   2   5   1   0  1   2   0  0   0  11\n#> 2178 brownke01 2003     1  LAN NL  30  63   4  10   3   0  0   2   0  0   0  28\n#> 2179 brownke01 2004     1  NYA AL  22   0   0   0   0   0  0   0   0  0   0   0\n#> 2180 brownke01 2005     1  NYA AL  13   2   0   1   1   0  0   0   0  0   0   1\n#> 2181 brownmo01 1903     1  SLN NL  26  77   4  15   2   1  0   6   2 NA   1  NA\n#> 2182 brownmo01 1904     1  CHN NL  31  89   8  19   3   1  0   8   0 NA   2  NA\n#> 2183 brownmo01 1905     1  CHN NL  31  93   6  13   1   1  1   3   1 NA   4  NA\n#> 2184 brownmo01 1906     1  CHN NL  36  98  11  20   1   0  0   4   0 NA   6  NA\n#> 2185 brownmo01 1907     1  CHN NL  36  85   6  13   0   2  1   7   0 NA   1  NA\n#> 2186 brownmo01 1908     1  CHN NL  46 121   5  25   0   0  0   4   2 NA   2  NA\n#> 2187 brownmo01 1909     1  CHN NL  50 125  13  22   3   1  0   9   0 NA   5  NA\n#> 2188 brownmo01 1910     1  CHN NL  46 103   9  18   1   2  0   6   1 NA   6  17\n#> 2189 brownmo01 1911     1  CHN NL  53  91   8  23   4   1  0   6   0 NA   6  12\n#> 2190 brownmo01 1912     1  CHN NL  16  31   3   9   1   0  0   5   1 NA   2   6\n#> 2191 brownmo01 1913     1  CIN NL  39  54   2  11   0   1  0   3   0 NA   1  10\n#> 2192 brownmo01 1914     2  BRF FL   9  19   2   4   0   0  0   1   0 NA   0   3\n#> 2193 brownmo01 1914     1  SLF FL  26  59   4  15   2   0  0   6   1 NA   4   9\n#> 2194 brownmo01 1915     1  CHF FL  36  82  10  24   2   1  0   6   0 NA   3  14\n#> 2195 brownmo01 1916     1  CHN NL  12  16   2   4   0   0  0   0   0 NA   1   4\n#> 2196 brownol02 1965     1  SFN NL   6  10   0   2   1   0  0   0   0  0   0   2\n#> 2197 brownol02 1966     1  SFN NL 115 348  32  81   7   1  7  33   2  5  33  66\n#> 2198 brownol02 1967     1  SFN NL 120 412  44 110  12   1 13  53   0  2  25  65\n#> 2199 brownol02 1968     1  SFN NL  40  95   7  22   4   0  0  11   1  0   3  23\n#> 2200 brownol02 1969     1  SDN NL 151 568  76 150  18   3 20  61  10  6  44  97\n#> 2201 brownol02 1970     1  SDN NL 139 534  79 156  34   1 23  89   5  3  34  78\n#> 2202 brownol02 1971     1  SDN NL 145 484  36 132  16   0  9  55   3  3  52  74\n#> 2203 brownol02 1972     2  OAK AL  20  54   5  13   1   0  1   4   1  1   6  14\n#> 2204 brownol02 1972     3  ML4 AL  66 179  21  50   8   0  3  25   0  2  17  24\n#> 2205 brownol02 1972     1  SDN NL  23  70   3  12   2   0  0   3   0  0   5   9\n#> 2206 brownol02 1973     1  ML4 AL  97 296  28  83  10   1  7  32   4  1  33  53\n#> 2207 brownol02 1974     1  HOU NL  27  69   8  15   1   0  3   6   0  0   4  15\n#> 2208 brownol02 1974     2  PHI NL  43  99  11  24   5   2  4  13   0  1   6  20\n#> 2209 brownol02 1975     1  PHI NL  84 145  19  44  12   0  6  26   1  1  15  29\n#> 2210 brownol02 1976     1  PHI NL  92 209  30  53  10   1  5  30   2  1  33  33\n#> 2211 brownol02 1977     1  PHI NL  53  70   5  17   3   1  1  13   1  1   4  14\n#> 2212 brownpe01 1882     1  LS2 AA  69 288  67 109  17   3  5  NA   0 NA  26  NA\n#> 2213 brownpe01 1883     1  LS2 AA  84 358  95 121  15   9  4   0   0 NA  23  NA\n#> 2214 brownpe01 1884     1  LS2 AA 103 447 101 150  33   8  4  47   0 NA  13  NA\n#> 2215 brownpe01 1885     1  LS2 AA 112 481  98 174  34  10  9  73   0 NA  25  NA\n#> 2216 brownpe01 1886     1  LS2 AA 112 467  86 159  29   6  2  68  26 NA  30  NA\n#> 2217 brownpe01 1887     1  LS2 AA 134 547 137 220  35  16  4 118 103 NA  55  NA\n#> 2218 brownpe01 1888     1  LS2 AA  99 383  58 120  22   8  3  72  36 NA  37  NA\n#> 2219 brownpe01 1889     1  LS2 AA  83 324  39  83  19   5  2  32  21 NA  34  30\n#> 2220 brownpe01 1890     1  CLP PL 118 493 112 184  40   8  5  93  35 NA  75  36\n#> 2221 brownpe01 1891     1  PIT NL  50 203  35  59  14   1  4  28   4 NA  27  31\n#> 2222 brownpe01 1891     2  CIN NL  55 216  29  74  10   3  0  33  12 NA  24  23\n#> 2223 brownpe01 1892     1  CIN NL  83 307  47  93  12   5  3  52   8 NA  40  25\n#> 2224 brownpe01 1892     2  LS3 NL  21  77  10  19   4   0  0   4   5 NA  12   7\n#> 2225 brownpe01 1893     1  LS3 NL  57 220  38  78  11   3  1  37   8 NA  44  15\n#> 2226 brownpe01 1894     1  SLN NL   2   7   1   1   0   0  0   0   0 NA   0   0\n#> 2227 brownpe01 1894     2  BRO NL   1   2   1   2   0   0  0   2   0 NA   1   0\n#> 2228 brownto01 1882     1  BL2 AA  45 181  30  55   5   2  1  23   0 NA   6  NA\n#> 2229 brownto01 1883     1  CL5 AA  97 420  69 115  12   7  5  32   0 NA  20  NA\n#> 2230 brownto01 1884     1  CL5 AA 107 451  93 123   9  11  5  32   0 NA  24  NA\n#> 2231 brownto01 1885     1  PT1 AA 108 437  81 134  16  12  4  68   0 NA  34  NA\n#> 2232 brownto01 1886     1  PT1 AA 115 460 106 131  11  11  1  51  30 NA  56  NA\n#> 2233 brownto01 1887     1  PIT NL  47 192  30  47   3   4  0   6  12 NA  11  40\n#> 2234 brownto01 1887     2  IN3 NL  36 140  20  25   3   0  2   9  13 NA   8  25\n#> 2235 brownto01 1888     1  BSN NL 107 420  62 104  10   7  9  49  46 NA  30  68\n#> 2236 brownto01 1889     1  BSN NL  90 362  93  84  10   5  2  24  63 NA  59  56\n#> 2237 brownto01 1890     1  BSP PL 128 543 146 149  23  14  4  61  79 NA  86  84\n#> 2238 brownto01 1891     1  BS2 AA 137 589 177 189  30  21  5  72 106 NA  70  96\n#> 2239 brownto01 1892     1  LS3 NL 153 660 105 150  16   8  2  45  78 NA  47  94\n#> 2240 brownto01 1893     1  LS3 NL 122 529 104 127  15   7  5  54  66 NA  56  63\n#> 2241 brownto01 1894     1  LS3 NL 129 536 122 136  22  14  9  57  66 NA  60  73\n#> 2242 brownto01 1895     1  SLN NL  83 350  72  76  11   4  1  31  34 NA  48  44\n#> 2243 brownto01 1895     2  WSN NL  34 134  25  32   8   3  2  16   8 NA  18  16\n#> 2244 brownto01 1896     1  WSN NL 116 435  87 128  17   6  2  59  28 NA  58  49\n#> 2245 brownto01 1897     1  WSN NL 116 469  91 137  17   2  5  45  25 NA  52  NA\n#> 2246 brownto01 1898     1  WSN NL  16  55   8   9   1   0  0   2   3 NA   5  NA\n#> 2247 brunato01 1981     1  CAL AL  11  33   7   5   0   0  3   6   1  0   8  10\n#> 2248 brunato01 1982     1  MIN AL 127 463  77 126  30   1 20  46   1  2  71 101\n#> 2249 brunato01 1983     1  MIN AL 151 542  70 123  24   5 28  82   2  5  61  95\n#> 2250 brunato01 1984     1  MIN AL 155 567  75 144  21   0 32  85   4  5  57  94\n#> 2251 brunato01 1985     1  MIN AL 157 567  71 137  28   4 27  90   5  3  71  86\n#> 2252 brunato01 1986     1  MIN AL 157 593  69 152  28   1 23  75  12  4  53  98\n#> 2253 brunato01 1987     1  MIN AL 155 532  83 138  22   2 32  85  11 11  74 104\n#> 2254 brunato01 1988     1  MIN AL  14  49   5   9   1   0  1   6   1  2   7  11\n#> 2255 brunato01 1988     2  SLN NL 143 523  69 128  22   4 22  79  16  6  79  82\n#> 2256 brunato01 1989     1  SLN NL 158 556  67 133  29   3 20  85   5  9  59 107\n#> 2257 brunato01 1990     2  BOS AL 129 461  61 123  24   5 15  71   5 10  54 105\n#> 2258 brunato01 1990     1  SLN NL  19  57   5   9   3   0  1   2   0  0  12  10\n#> 2259 brunato01 1991     1  BOS AL 142 459  54 105  24   1 16  70   1  2  49  72\n#> 2260 brunato01 1992     1  BOS AL 138 458  47 122  31   3 15  74   2  5  66  96\n#> 2261 brunato01 1993     1  ML4 AL  80 224  20  41   7   3  6  29   3  4  25  59\n#> 2262 brunato01 1994     1  ML4 AL  16  28   2   6   2   0  0   0   0  0   1   9\n#> 2263 brunato01 1994     2  BOS AL  48 177  22  42  10   1 10  34   0  2  23  48\n#> 2264 brunege01 1956     1  KC1 AL   6   2   0   0   0   0  0   0   0  0   0   2\n#> 2265 brunege01 1957     1  KC1 AL   4   2   0   0   0   0  0   0   0  0   0   1\n#> 2266 brunege01 1959     1  KC1 AL   2   0   0   0   0   0  0   0   0  0   0   0\n#> 2267 brunege01 1960     1  KC1 AL   3   3   0   0   0   0  0   0   0  0   0   3\n#> 2268 brunege01 1960     2  ML1 NL  17  11   0   1   0   0  0   0   0  0   0   4\n#> 2269 brunege01 1961     1  ML1 NL   5   0   0   0   0   0  0   0   0  0   0   0\n#> 2270 brunege01 1962     1  HOU NL  17  17   2   1   0   0  0   0   0  0   1   9\n#> 2271 brunege01 1963     2  BAL AL  16   1   0   0   0   0  0   0   0  0   0   1\n#> 2272 brunege01 1963     1  HOU NL   5   3   0   0   0   0  0   0   0  0   0   1\n#> 2273 brunege01 1964     1  LAA AL  10  11   0   2   0   0  0   1   0  0   0   5\n#> 2274 brunege01 1965     1  CAL AL  41  56   3   3   2   0  0   1   0  1   4  34\n#> 2275 brunege01 1966     1  CAL AL  41  68   5   7   1   0  1   3   0  0   2  34\n#> 2276 brunege01 1967     1  CAL AL  40  78   2   6   0   0  0   0   0  0   1  40\n#> 2277 brunege01 1968     1  CAL AL  39  74   3   6   0   0  0   2   0  1   2  38\n#> 2278 brunege01 1969     1  CAL AL  23  27   1   1   1   0  0   0   0  0   3  13\n#> 2279 brunege01 1969     2  SE1 AL  12  20   2   3   0   0  1   1   0  0   1  11\n#> 2280 brunege01 1970     1  WS2 AL  24  38   4   6   1   0  1   4   0  0   1  21\n#> 2281 brunege01 1970     2  PIT NL  12   4   0   0   0   0  0   0   0  0   0   2\n#> 2282 brunege01 1971     1  SLN NL   7   3   1   1   0   0  0   0   0  0   0   1\n#> 2283 bucknbi01 1969     1  LAN NL   1   1   0   0   0   0  0   0   0  0   0   0\n#> 2284 bucknbi01 1970     1  LAN NL  28  68   6  13   3   1  0   4   0  1   3   7\n#> 2285 bucknbi01 1971     1  LAN NL 108 358  37  99  15   1  5  41   4  1  11  18\n#> 2286 bucknbi01 1972     1  LAN NL 105 383  47 122  14   3  5  37  10  3  17  13\n#> 2287 bucknbi01 1973     1  LAN NL 140 575  68 158  20   0  8  46  12  2  17  34\n#> 2288 bucknbi01 1974     1  LAN NL 145 580  83 182  30   3  7  58  31 13  30  24\n#> 2289 bucknbi01 1975     1  LAN NL  92 288  30  70  11   2  6  31   8  3  17  15\n#> 2290 bucknbi01 1976     1  LAN NL 154 642  76 193  28   4  7  60  28  9  26  26\n#> 2291 bucknbi01 1977     1  CHN NL 122 426  40 121  27   0 11  60   7  5  21  23\n#> 2292 bucknbi01 1978     1  CHN NL 117 446  47 144  26   1  5  74   7  5  18  17\n#> 2293 bucknbi01 1979     1  CHN NL 149 591  72 168  34   7 14  66   9  4  30  28\n#> 2294 bucknbi01 1980     1  CHN NL 145 578  69 187  41   3 10  68   1  2  30  18\n#> 2295 bucknbi01 1981     1  CHN NL 106 421  45 131  35   3 10  75   5  2  26  16\n#> 2296 bucknbi01 1982     1  CHN NL 161 657  93 201  34   5 15 105  15  5  36  26\n#> 2297 bucknbi01 1983     1  CHN NL 153 626  79 175  38   6 16  66  12  4  25  30\n#> 2298 bucknbi01 1984     2  BOS AL 114 439  51 122  21   2 11  67   2  2  24  38\n#> 2299 bucknbi01 1984     1  CHN NL  21  43   3   9   0   0  0   2   0  0   1   1\n#> 2300 bucknbi01 1985     1  BOS AL 162 673  89 201  46   3 16 110  18  4  30  36\n#> 2301 bucknbi01 1986     1  BOS AL 153 629  73 168  39   2 18 102   6  4  40  25\n#> 2302 bucknbi01 1987     1  BOS AL  75 286  23  78   6   1  2  42   1  3  13  19\n#> 2303 bucknbi01 1987     2  CAL AL  57 183  16  56  12   1  3  32   1  0   9   7\n#> 2304 bucknbi01 1988     1  CAL AL  19  43   1   9   0   0  0   9   2  0   4   0\n#> 2305 bucknbi01 1988     2  KCA AL  89 242  18  62  14   0  3  34   3  1  13  19\n#> 2306 bucknbi01 1989     1  KCA AL  79 176   7  38   4   1  1  16   1  0   6  11\n#> 2307 bucknbi01 1990     1  BOS AL  22  43   4   8   0   0  1   3   0  0   3   2\n#> 2308  buhlbo01 1953     1  ML1 NL  30  53   3   6   0   0  0   2   0  0   2  18\n#> 2309  buhlbo01 1954     1  ML1 NL  31  31   0   1   0   0  0   0   0  0   2  12\n#> 2310  buhlbo01 1955     1  ML1 NL  38  57   2   6   0   0  0   0   0  0   3  24\n#> 2311  buhlbo01 1956     1  ML1 NL  38  73   1   7   2   0  0   3   0  0   1  34\n#> 2312  buhlbo01 1957     1  ML1 NL  34  73   4   6   0   0  0   4   0  0   6  34\n#> 2313  buhlbo01 1958     1  ML1 NL  11  25   3   5   0   0  0   0   0  0   0   6\n#> 2314  buhlbo01 1959     1  ML1 NL  31  70   2   4   0   0  0   1   0  0   2  38\n#> 2315  buhlbo01 1960     1  ML1 NL  36  89   4  14   0   0  0   4   0  0   0  40\n#> 2316  buhlbo01 1961     1  ML1 NL  32  60   2   4   0   0  0   2   0  0   5  30\n#> 2317  buhlbo01 1962     1  ML1 NL   1   1   0   0   0   0  0   0   0  0   0   1\n#> 2318  buhlbo01 1962     2  CHN NL  34  69   2   0   0   0  0   1   1  1   6  35\n#> 2319  buhlbo01 1963     1  CHN NL  37  74   2   8   0   0  0   5   1  0   0  28\n#> 2320  buhlbo01 1964     1  CHN NL  36  73   3   7   0   0  0   1   0  0   6  31\n#> 2321  buhlbo01 1965     1  CHN NL  32  67   3   4   0   0  0   2   0  1   3  36\n#> 2322  buhlbo01 1966     1  CHN NL   1   1   0   0   0   0  0   0   0  0   0   0\n#> 2323  buhlbo01 1966     2  PHI NL  32  41   0   4   0   0  0   1   0  0   2  22\n#> 2324  buhlbo01 1967     1  PHI NL   3   0   0   0   0   0  0   0   0  0   0   0\n#> 2325 buhneja01 1987     1  NYA AL   7  22   0   5   2   0  0   1   0  0   1   6\n#> 2326 buhneja01 1988     1  NYA AL  25  69   8  13   0   0  3  13   0  0   3  25\n#> 2327 buhneja01 1988     2  SEA AL  60 192  28  43  13   1 10  25   1  1  25  68\n#> 2328 buhneja01 1989     1  SEA AL  58 204  27  56  15   1  9  33   1  4  19  55\n#> 2329 buhneja01 1990     1  SEA AL  51 163  16  45  12   0  7  33   2  2  17  50\n#> 2330 buhneja01 1991     1  SEA AL 137 406  64  99  14   4 27  77   0  1  53 117\n#> 2331 buhneja01 1992     1  SEA AL 152 543  69 132  16   3 25  79   0  6  71 146\n#> 2332 buhneja01 1993     1  SEA AL 158 563  91 153  28   3 27  98   2  5 100 144\n#> 2333 buhneja01 1994     1  SEA AL 101 358  74 100  23   4 21  68   0  1  66  63\n#> 2334 buhneja01 1995     1  SEA AL 126 470  86 123  23   0 40 121   0  1  60 120\n#> 2335 buhneja01 1996     1  SEA AL 150 564 107 153  29   0 44 138   0  1  84 159\n#> 2336 buhneja01 1997     1  SEA AL 157 540 104 131  18   2 40 109   0  0 119 175\n#> 2337 buhneja01 1998     1  SEA AL  72 244  33  59   7   1 15  45   0  0  38  71\n#> 2338 buhneja01 1999     1  SEA AL  87 266  37  59  11   0 14  38   0  0  69 100\n#> 2339 buhneja01 2000     1  SEA AL 112 364  50  92  20   0 26  82   0  2  59  98\n#> 2340 buhneja01 2001     1  SEA AL  19  45   4  10   2   0  2   5   0  0   8   9\n#> 2341 bunniji01 1955     1  DET AL  15  15   0   3   0   0  0   0   0  0   0   5\n#> 2342 bunniji01 1956     1  DET AL  15  18   4   6   2   0  0   1   0  0   0   5\n#> 2343 bunniji01 1957     1  DET AL  45  94  10  20   2   1  1   4   0  0   5  29\n#> 2344 bunniji01 1958     1  DET AL  36  75   7  14   2   0  0   3   0  0   3  24\n#> 2345 bunniji01 1959     1  DET AL  40  89   7  17   0   1  1   7   0  0   5  25\n#> 2346 bunniji01 1960     1  DET AL  38  81   2  13   1   0  0   4   0  2   3  22\n#> 2347 bunniji01 1961     1  DET AL  38 100   6  13   1   0  0   4   0  0   2  30\n#> 2348 bunniji01 1962     1  DET AL  43  95   9  23   2   1  1   5   0  0   1  19\n#> 2349 bunniji01 1963     1  DET AL  41  84   4  13   1   1  0   5   0  0   4  15\n#> 2350 bunniji01 1964     1  PHI NL  41  99   4  12   2   0  0   8   0  0   0  29\n#> 2351 bunniji01 1965     1  PHI NL  39 103   6  22   1   0  1   4   0  0   1  25\n#> 2352 bunniji01 1966     1  PHI NL  43 106  10  19   3   0  0   5   0  0   3  39\n#> 2353 bunniji01 1967     1  PHI NL  40 104   8  17   3   0  2  12   0  0   1  33\n#> 2354 bunniji01 1968     1  PIT NL  27  51   0   5   1   0  0   3   0  0   0  17\n#> 2355 bunniji01 1969     1  PIT NL  25  47   3   2   0   0  0   1   0  0   3  12\n#> 2356 bunniji01 1969     2  LAN NL   9  18   0   2   0   0  0   1   0  0   0   6\n#> 2357 bunniji01 1970     1  PHI NL  35  71   1   9   0   0  0   6   0  0   2  18\n#> 2358 bunniji01 1971     1  PHI NL  31  25   1   3   0   0  1   2   0  0   1   9\n#> 2359 burbada01 1990     1  SEA AL   6   0   0   0   0   0  0   0   0  0   0   0\n#> 2360 burbada01 1991     1  SEA AL  22   0   0   0   0   0  0   0   0  0   0   0\n#> 2361 burbada01 1992     1  SFN NL  23  15   0   1   0   0  0   1   0  0   1   8\n#> 2362 burbada01 1993     1  SFN NL  54  17   1   5   1   0  0   2   0  0   1   7\n#> 2363 burbada01 1994     1  SFN NL  57   3   0   0   0   0  0   0   0  0   0   2\n#> 2364 burbada01 1995     1  SFN NL  37   0   0   0   0   0  0   0   0  0   0   0\n#> 2365 burbada01 1995     2  CIN NL  15  15   2   1   0   0  0   0   0  0   3   9\n#> 2366 burbada01 1996     1  CIN NL  34  67   3   7   0   0  2   5   0  0   3  26\n#> 2367 burbada01 1997     1  CIN NL  30  46   2   9   0   0  0   2   0  0   1  18\n#> 2368 burbada01 1998     1  CLE AL   2   6   1   1   0   0  1   2   0  0   0   1\n#> 2369 burbada01 1999     1  CLE AL   2   3   0   1   0   0  0   0   0  0   1   0\n#> 2370 burbada01 2000     1  CLE AL   1   1   0   0   0   0  0   0   0  0   0   1\n#> 2371 burbada01 2001     1  CLE AL   3   2   1   0   0   0  0   0   0  0   0   1\n#> 2372 burbada01 2002     2  CLE AL  12   0   0   0   0   0  0   0   0  0   0   0\n#> 2373 burbada01 2002     1  TEX AL   2   5   0   1   0   0  0   0   0  0   0   3\n#> 2374 burbada01 2003     1  MIL NL  16  10   0   0   0   0  0   0   0  0   0   7\n#> 2375 burbada01 2004     2  SFN NL   6   1   0   0   0   0  0   0   0  0   0   0\n#> 2376 burbada01 2004     1  MIL NL  43   3   0   0   0   0  0   0   0  0   0   1\n#> 2377 burdele01 1950     1  NYA AL   2   0   0   0   0   0  0   0   0  0   0   0\n#> 2378 burdele01 1951     1  BSN NL   3   1   0   0   0   0  0   0   0  0   0   0\n#> 2379 burdele01 1952     1  BSN NL  45  35   1   4   0   0  0   0   0  0   3   8\n#> 2380 burdele01 1953     1  ML1 NL  46  53   4   9   0   0  0   1   0  0   0  13\n#> 2381 burdele01 1954     1  ML1 NL  39  79   3   7   1   0  0   4   0  0   1  14\n#> 2382 burdele01 1955     1  ML1 NL  45  86  10  20   5   0  0   7   0  0   3  20\n#> 2383 burdele01 1956     1  ML1 NL  45  86   9  16   1   0  0   8   0  0   2  16\n#> 2384 burdele01 1957     1  ML1 NL  41  88  11  13   2   0  2   9   0  0   3  22\n#> 2385 burdele01 1958     1  ML1 NL  47  99  11  24   1   1  3  15   0  0   3  24\n#> 2386 burdele01 1959     1  ML1 NL  52 104  14  21   7   1  0   8   0  0   3  36\n#> 2387 burdele01 1960     1  ML1 NL  46  91  11  16   3   0  2   4   0  0   7  22\n#> 2388 burdele01 1961     1  ML1 NL  42 103  10  21   5   0  3  11   0  0   2  39\n#> 2389 burdele01 1962     1  ML1 NL  39  51   6   9   0   0  0   1   0  0   1  17\n#> 2390 burdele01 1963     1  ML1 NL  17  26   2   1   0   1  0   1   0  0   1  11\n#> 2391 burdele01 1963     2  SLN NL  21  31   0   3   1   0  0   1   1  0   0   6\n#> 2392 burdele01 1964     1  SLN NL   8   1   0   0   0   0  0   0   0  0   0   0\n#> 2393 burdele01 1964     2  CHN NL  28  43   6  12   0   1  2   4   0  0   3  12\n#> 2394 burdele01 1965     1  CHN NL   8   6   0   2   1   0  0   0   1  0   0   1\n#> 2395 burdele01 1965     2  PHI NL  19  20   3   6   0   0  0   0   0  0   0   7\n#> 2396 burdele01 1966     1  CAL AL  54   8   0   1   0   0  0   1   0  0   0   3\n#> 2397 burdele01 1967     1  CAL AL  19   0   0   0   0   0  0   0   0  0   0   0\n#> 2398 burdoja01 1872     1  BR2     37 174  26  46   3   0  0  15   0  1   1   1\n#> 2399 burdoja01 1873     1  BR2     55 245  56  62   7   1  2  36   3  1   7   4\n#> 2400 burdoja01 1874     1  NY2     61 273  45  75  11   4  1  27   4  0   1   5\n#> 2401 burdoja01 1875     1  HR1     74 350  72 103  12   5  0  35  20 11   3  13\n#> 2402 burdoja01 1876     1  HAR NL  69 309  66  80   9   1  0  23  NA NA  13  16\n#> 2403 burdoja01 1877     1  HAR NL  58 277  35  72   6   0  0   9  NA NA   2  16\n#> 2404 burdoja01 1878     1  BSN NL  60 246  37  64  12   6  0  25  NA NA   3  17\n#> 2405 burdoja01 1879     1  BSN NL  84 359  64  86  10   3  0  36  NA NA   9  28\n#> 2406 burdoja01 1880     1  BSN NL  86 356  58  90  17   4  2  35  NA NA   8  26\n#> 2407 burdoja01 1881     1  BSN NL  73 282  36  67  12   4  1  24  NA NA   7  18\n#> 2408 burdoja01 1882     1  BSN NL  83 319  36  76   6   7  0  27  NA NA   9  24\n#> 2409 burdoja01 1883     1  BSN NL  96 400  80 132  27   8  5  88  NA NA  14  35\n#> 2410 burdoja01 1884     1  BSN NL  87 361  65  97  14   4  6  49  NA NA  15  52\n#> 2411 burdoja01 1885     1  BSN NL  45 169  18  24   5   0  0   7  NA NA   8  18\n#> 2412 burdoja01 1886     1  BSN NL  59 221  26  48   6   1  0  25   3 NA  11  27\n#> 2413 burdoja01 1887     1  BSN NL  65 237  36  61   6   0  0  29  19 NA  18  22\n#> 2414 burdoja01 1888     2  BR3 AA  70 246  15  30   1   2  1   8   9 NA   8  NA\n#> 2415 burdoja01 1888     1  BSN NL  22  79   5  16   0   0  0   4   1 NA   2   5\n#> 2416 burdoja01 1891     1  BRO NL   3  12   1   1   0   0  0   1   0 NA   1   1\n#> 2417 burgesm01 1949     1  CHN NL  46  56   4  15   0   0  1  12   0 NA   4   4\n#> 2418 burgesm01 1951     1  CHN NL  94 219  21  55   4   2  2  20   2  0  21  12\n#> 2419 burgesm01 1952     1  PHI NL 110 371  49 110  27   2  6  56   3  1  49  21\n#> 2420 burgesm01 1953     1  PHI NL 102 312  31  91  17   5  4  36   3  2  37  17\n#> 2421 burgesm01 1954     1  PHI NL 108 345  41 127  27   5  4  46   1  5  42  11\n#> 2422 burgesm01 1955     1  PHI NL   7  21   4   4   2   0  1   1   0  0   3   1\n#> 2423 burgesm01 1955     2  CIN NL 116 421  67 129  15   3 20  77   1  1  47  35\n#> 2424 burgesm01 1956     1  CIN NL  90 229  28  63  10   0 12  39   0  1  26  18\n#> 2425 burgesm01 1957     1  CIN NL  90 205  29  58  14   1 14  39   0  0  24  16\n#> 2426 burgesm01 1958     1  CIN NL  99 251  28  71  12   1  6  31   0  0  22  20\n#> 2427 burgesm01 1959     1  PIT NL 114 377  41 112  28   5 11  59   0  0  31  16\n#> 2428 burgesm01 1960     1  PIT NL 110 337  33  99  15   2  7  39   0  1  35  13\n#> 2429 burgesm01 1961     1  PIT NL 100 323  37  98  17   3 12  52   1  0  30  16\n#> 2430 burgesm01 1962     1  PIT NL 103 360  38 118  19   2 13  61   0  1  31  19\n#> 2431 burgesm01 1963     1  PIT NL  91 264  20  74  10   1  6  37   0  1  24  14\n#> 2432 burgesm01 1964     2  CHA AL   7   5   1   1   0   0  1   1   0  0   2   0\n#> 2433 burgesm01 1964     1  PIT NL  68 171   9  42   3   1  2  17   2  1  13  14\n#> 2434 burgesm01 1965     1  CHA AL  80  77   2  22   4   0  2  24   0  0  11   7\n#> 2435 burgesm01 1966     1  CHA AL  79  67   0  21   5   0  0  15   0  0  11   8\n#> 2436 burgesm01 1967     1  CHA AL  77  60   2   8   1   0  2  11   0  0  14   8\n#> 2437 burgmto01 1968     1  CAL AL  71   2   7   0   0   0  0   0   1  0   1   0\n#> 2438 burgmto01 1969     1  KCA AL  47  18   7   3   0   0  0   0   0  0   0   4\n#> 2439 burgmto01 1970     1  KCA AL  42  14   1   2   0   0  0   0   0  0   1   5\n#> 2440 burgmto01 1971     1  KCA AL  68  20   2   5   2   0  0   0   0  0   1   7\n#> 2441 burgmto01 1972     1  KCA AL  51  12   2   4   0   0  0   0   0  0   0   4\n#> 2442 burgmto01 1973     1  KCA AL   6   0   0   0   0   0  0   0   0  0   0   0\n#> 2443 burgmto01 1974     1  MIN AL  51   0   0   0   0   0  0   0   0  0   0   0\n#> 2444 burgmto01 1975     1  MIN AL  47   0   0   0   0   0  0   0   0  0   0   0\n#> 2445 burgmto01 1976     1  MIN AL  57   0   0   0   0   0  0   0   0  0   0   0\n#> 2446 burgmto01 1977     1  MIN AL  61   0   0   0   0   0  0   0   0  0   0   0\n#> 2447 burgmto01 1978     1  BOS AL  35   0   0   0   0   0  0   0   0  0   0   0\n#> 2448 burgmto01 1979     1  BOS AL  44   0   0   0   0   0  0   0   0  0   0   0\n#> 2449 burgmto01 1980     1  BOS AL  62   0   0   0   0   0  0   0   0  0   0   0\n#> 2450 burgmto01 1981     1  BOS AL  32   0   0   0   0   0  0   0   0  0   0   0\n#> 2451 burgmto01 1982     1  BOS AL  40   0   0   0   0   0  0   0   0  0   0   0\n#> 2452 burgmto01 1983     1  OAK AL  51   0   1   0   0   0  0   0   0  0   0   0\n#> 2453 burgmto01 1984     1  OAK AL  17   0   0   0   0   0  0   0   0  0   0   0\n#> 2454 burkeje01 1890     1  NY1 NL 101 401  67 124  23  13  4  60  14 NA  33  52\n#> 2455 burkeje01 1891     1  CL4 NL  40 167  29  45   7   4  0  13   1 NA  23  19\n#> 2456 burkeje01 1892     1  CL4 NL 145 608 119 167  15  14  6  66  36 NA  67  59\n#> 2457 burkeje01 1893     1  CL4 NL 125 511 145 178  25  15  6  82  39 NA  98  23\n#> 2458 burkeje01 1894     1  CL4 NL 125 523 138 187  27  14  8  94  28 NA  84  27\n#> 2459 burkeje01 1895     1  CL4 NL 131 550 153 225  22  13  5  83  41 NA  74  31\n#> 2460 burkeje01 1896     1  CL4 NL 133 586 160 240  27  16  6  72  34 NA  49  19\n#> 2461 burkeje01 1897     1  CL4 NL 127 517 129 198  28   7  2  60  28 NA  76  NA\n#> 2462 burkeje01 1898     1  CL4 NL 150 624 114 213  18   9  0  42  19 NA  69  NA\n#> 2463 burkeje01 1899     1  SLN NL 141 558 116 221  21   8  7  71  25 NA  67  NA\n#> 2464 burkeje01 1900     1  SLN NL 141 559  88 203  11  15  7  68  32 NA  62  NA\n#> 2465 burkeje01 1901     1  SLN NL 142 601 142 226  20  15 10  75  27 NA  59  NA\n#> 2466 burkeje01 1902     1  SLA AL 138 553  97 169  29   9  5  52  23 NA  71  NA\n#> 2467 burkeje01 1903     1  SLA AL 132 515  73 151  20   7  3  40  17 NA  52  NA\n#> 2468 burkeje01 1904     1  SLA AL 147 575  72 156  15  10  2  27  12 NA  78  NA\n#> 2469 burkeje01 1905     1  BOS AL 148 573  78 147  12  13  4  47  13 NA  67  NA\n#> 2470 burkejo03 1987     1  SFN NL   3   1   0   0   0   0  0   0   0  0   0   1\n#> 2471 burkejo03 1990     1  SFN NL  33  63   1   3   0   0  0   3   0  0   5  35\n#> 2472 burkejo03 1991     1  SFN NL  36  55   0   5   1   0  0   1   0  0   3  26\n#> 2473 burkejo03 1992     1  SFN NL  32  55   2   1   1   0  0   2   0  0   4  24\n#> 2474 burkejo03 1993     1  SFN NL  34  76   7   9   0   0  0   4   0  0   5  31\n#> 2475 burkejo03 1994     1  SFN NL  25  51   1   3   0   0  0   0   0  0   1  21\n#> 2476 burkejo03 1995     1  FLO NL  31  66   3   7   1   0  0   3   0  0   2  23\n#> 2477 burkejo03 1996     2  TEX AL  10   0   0   0   0   0  0   0   0  0   0   0\n#> 2478 burkejo03 1996     1  FLO NL  24  52   2   9   2   0  0   1   0  0   0  17\n#> 2479 burkejo03 1997     1  TEX AL   2   5   1   1   0   0  0   0   0  0   0   1\n#> 2480 burkejo03 1998     1  TEX AL   1   3   1   0   0   0  0   0   0  0   0   0\n#> 2481 burkejo03 1999     1  TEX AL   3   2   0   0   0   0  0   0   0  0   0   2\n#> 2482 burkejo03 2000     1  ATL NL  30  42   2   6   1   0  0   3   0  0   3  15\n#> 2483 burkejo03 2001     1  ATL NL  32  65   2   6   0   0  0   1   0  0   3  29\n#> 2484 burkejo03 2002     1  BOS AL   2   3   0   0   0   0  0   0   0  0   0   1\n#> 2485 burkejo03 2003     1  BOS AL   1   1   0   0   0   0  0   0   0  0   0   0\n#> 2486 burksel01 1987     1  BOS AL 133 558  94 152  30   2 20  59  27  6  41  98\n#> 2487 burksel01 1988     1  BOS AL 144 540  93 159  37   5 18  92  25  9  62  89\n#> 2488 burksel01 1989     1  BOS AL  97 399  73 121  19   6 12  61  21  5  36  52\n#> 2489 burksel01 1990     1  BOS AL 152 588  89 174  33   8 21  89   9 11  48  82\n#> 2490 burksel01 1991     1  BOS AL 130 474  56 119  33   3 14  56   6 11  39  81\n#> 2491 burksel01 1992     1  BOS AL  66 235  35  60   8   3  8  30   5  2  25  48\n#> 2492 burksel01 1993     1  CHA AL 146 499  75 137  24   4 17  74   6  9  60  97\n#> 2493 burksel01 1994     1  COL NL  42 149  33  48   8   3 13  24   3  1  16  39\n#> 2494 burksel01 1995     1  COL NL 103 278  41  74  10   6 14  49   7  3  39  72\n#> 2495 burksel01 1996     1  COL NL 156 613 142 211  45   8 40 128  32  6  61 114\n#> 2496 burksel01 1997     1  COL NL 119 424  91 123  19   2 32  82   7  2  47  75\n#> 2497 burksel01 1998     1  COL NL 100 357  54 102  22   5 16  54   3  7  39  80\n#> 2498 burksel01 1998     2  SFN NL  42 147  22  45   6   1  5  22   8  1  19  31\n#> 2499 burksel01 1999     1  SFN NL 120 390  73 110  19   0 31  96   7  5  69  86\n#> 2500 burksel01 2000     1  SFN NL 122 393  74 135  21   5 24  96   5  1  56  49\n#> 2501 burksel01 2001     1  CLE AL 124 439  83 123  29   1 28  74   5  1  62  85\n#> 2502 burksel01 2002     1  CLE AL 138 518  92 156  28   0 32  91   2  3  44 108\n#> 2503 burksel01 2003     1  CLE AL  55 198  27  52  11   1  6  28   1  1  27  46\n#> 2504 burksel01 2004     1  BOS AL  11  33   6   6   0   0  1   1   2  0   3   8\n#> 2505 burnije01 1993     1  NYN NL  86 263  49  64  10   6 13  38   3  6  38  66\n#> 2506 burnije01 1994     1  NYN NL  45 143  26  34   4   0  3  15   1  1  23  45\n#> 2507 burnije01 1995     1  CLE AL   9   7   4   4   1   0  0   0   0  0   0   0\n#> 2508 burnije01 1996     1  CLE AL  71 128  30  36  10   0  7  26   2  1  25  31\n#> 2509 burnije01 1996     2  ML4 AL  23  72   8  17   4   0  2  14   2  0   8  16\n#> 2510 burnije01 1997     1  ML4 AL 153 494  85 139  37   8 27  85  20 13  75 111\n#> 2511 burnije01 1998     1  MIL NL 161 609  92 160  28   1 38 125   7  4  70 158\n#> 2512 burnije01 1999     1  MIL NL 130 467  87 126  33   2 33 103   7  3  91 124\n#> 2513 burnije01 2000     1  MIL NL 161 564  91 131  29   2 31  98   6  4  99 121\n#> 2514 burnije01 2001     1  MIL NL 154 562 104 141  32   4 34 100   0  4  80 150\n#> 2515 burnije01 2002     1  NYN NL 154 479  65 103  15   0 19  54  10  7  58 135\n#> 2516 burnije01 2003     1  NYN NL  65 234  38  64  18   0 18  45   1  4  21  55\n#> 2517 burnije01 2003     2  LAN NL  61 230  25  47   4   0 13  32   4  0  14  57\n#> 2518 burnije01 2004     1  COL NL 150 540  94 153  30   4 37 110   5  6  58 124\n#> 2519 burnije01 2006     1  PIT NL 111 313  35  72  12   0 16  49   1  1  22  74\n#> 2520 burnije01 2005     1  CHN NL 160 605  84 156  31   2 24  87   5  4  57 109\n#> 2521 burnsge01 1911     1  NY1 NL   6  17   2   1   0   0  0   0   0 NA   1   0\n#> 2522 burnsge01 1912     1  NY1 NL  29  51  11  15   4   0  0   3   7 NA   8   8\n#> 2523 burnsge01 1913     1  NY1 NL 150 605  81 173  37   4  2  54  40 NA  58  74\n#> 2524 burnsge01 1914     1  NY1 NL 154 561 100 170  35  10  3  60  62 NA  89  53\n#> 2525 burnsge01 1915     1  NY1 NL 155 622  83 169  27  14  3  51  27 20  56  57\n#> 2526 burnsge01 1916     1  NY1 NL 155 623 105 174  24   8  5  41  37 26  63  47\n#> 2527 burnsge01 1917     1  NY1 NL 152 597 103 180  25  13  5  45  40 NA  75  55\n#> 2528 burnsge01 1918     1  NY1 NL 119 465  80 135  22   6  4  51  40 NA  43  37\n#> 2529 burnsge01 1919     1  NY1 NL 139 534  86 162  30   9  2  46  40 NA  82  37\n#> 2530 burnsge01 1920     1  NY1 NL 154 631 115 181  35   9  6  46  22 22  76  48\n#> 2531 burnsge01 1921     1  NY1 NL 149 605 111 181  28   9  4  61  19 20  80  24\n#> 2532 burnsge01 1922     1  CIN NL 156 631 104 180  20  10  1  53  30 23  78  38\n#> 2533 burnsge01 1923     1  CIN NL 154 614  99 168  27  13  3  45  12 14 101  46\n#> 2534 burnsge01 1924     1  CIN NL  93 336  43  86  19   2  2  33   3  6  29  21\n#> 2535 burnsge01 1925     1  PHI NL  88 349  65 102  29   1  1  22   4  8  33  20\n#> 2536 burnsge02 1914     1  DET AL 137 478  55 139  22   5  5  57  23 13  32  56\n#> 2537 burnsge02 1915     1  DET AL 105 392  49  99  18   3  5  50   9  3  22  51\n#> 2538 burnsge02 1916     1  DET AL 135 479  60 137  22   6  4  73  12 NA  22  30\n#> 2539 burnsge02 1917     1  DET AL 119 407  42  92  14  10  1  40   3 NA  15  33\n#> 2540 burnsge02 1918     1  PHA AL 130 505  61 178  22   9  6  70   8 NA  23  25\n#> 2541 burnsge02 1919     1  PHA AL 126 470  63 139  29   9  8  57  15 NA  19  18\n#> 2542 burnsge02 1920     1  PHA AL  22  60   1  14   3   0  1   7   4  0   6   7\n#> 2543 burnsge02 1920     2  CLE AL  44  56   7  15   4   1  0  13   1  0   4   3\n#> 2544 burnsge02 1921     1  CLE AL  84 244  52  88  21   4  0  49   3  1  13  19\n#> 2545 burnsge02 1922     1  BOS AL 147 558  71 171  32   5 12  73   8  2  20  28\n#> 2546 burnsge02 1923     1  BOS AL 146 551  91 181  47   5  7  82   9  7  45  33\n#> 2547 burnsge02 1924     1  CLE AL 129 462  64 143  37   5  4  68  14  5  29  27\n#> 2548 burnsge02 1925     1  CLE AL 127 488  69 164  41   4  6  79  16 11  24  24\n#> 2549 burnsge02 1926     1  CLE AL 151 603  97 216  64   3  4 114  13  7  28  33\n#> 2550 burnsge02 1927     1  CLE AL 140 549  84 175  51   2  3  78  13 11  42  27\n#> 2551 burnsge02 1928     1  CLE AL  82 209  29  52  12   1  5  30   2  3  17  11\n#> 2552 burnsge02 1928     2  NYA AL   4   4   1   2   0   0  0   0   0  0   0   1\n#> 2553 burnsge02 1929     1  NYA AL   9   9   0   0   0   0  0   0   0  0   0   4\n#> 2554 burnsge02 1929     2  PHA AL  29  49   5  13   5   0  1  11   1  0   2   3\n#> 2555 burrira01 1973     1  CHN NL  31   7   0   1   0   0  0   0   0  0   1   3\n#> 2556 burrira01 1974     1  CHN NL  41  13   0   1   0   0  0   0   0  1   2   4\n#> 2557 burrira01 1975     1  CHN NL  38  82  10  15   2   0  0   4   0  1   7  24\n#> 2558 burrira01 1976     1  CHN NL  39  81   4   9   0   0  0   1   0  0   1  28\n#> 2559 burrira01 1977     1  CHN NL  40  69   4  12   2   1  1   8   0  0   4  22\n#> 2560 burrira01 1978     1  CHN NL  41  61   3   7   1   2  0   2   0  0   2  13\n#> 2561 burrira01 1979     2  NYA AL  15   0   0   0   0   0  0   0   0  0   0   0\n#> 2562 burrira01 1979     1  CHN NL  14   1   1   0   0   0  0   0   0  0   1   0\n#> 2563 burrira01 1979     3  NYN NL   4   6   0   1   0   0  0   0   0  0   0   2\n#> 2564 burrira01 1980     1  NYN NL  29  51   1   5   0   0  0   0   0  1   2  18\n#> 2565 burrira01 1981     1  MON NL  22  37   4   7   0   0  0   2   0  0   4  12\n#> 2566 burrira01 1982     1  MON NL  37  28   0   5   1   0  0   1   0  0   3  10\n#> 2567 burrira01 1983     1  MON NL  40  39   2   9   2   0  0   2   0  0   4  15\n#> 2568 burrira01 1984     1  OAK AL  37   0   1   0   0   0  0   0   0  0   0   0\n#> 2569 burrira01 1985     1  ML4 AL  29   0   0   0   0   0  0   0   0  0   0   0\n#> 2570 burrira01 1986     1  SLN NL  23  27   0   4   3   0  0   7   0  0   0   9\n#> 2571 burrira01 1987     1  ML4 AL  10   0   0   0   0   0  0   0   0  0   0   0\n#> 2572 burroje01 1970     1  WS2 AL   6  12   1   2   0   0  0   1   0  0   2   5\n#> 2573 burroje01 1971     1  WS2 AL  59 181  20  42   9   0  5  25   1  0  22  55\n#> 2574 burroje01 1972     1  TEX AL  22  65   4  12   1   0  1   3   0  2   5  22\n#> 2575 burroje01 1973     1  TEX AL 151 526  71 147  17   1 30  85   0  0  67  88\n#> 2576 burroje01 1974     1  TEX AL 152 554  84 167  33   2 25 118   2  3  91 104\n#> 2577 burroje01 1975     1  TEX AL 152 585  81 132  20   0 29  94   4  4  79 155\n#> 2578 burroje01 1976     1  TEX AL 158 604  71 143  22   2 18  86   0  0  69  93\n#> 2579 burroje01 1977     1  ATL NL 154 579  91 157  19   1 41 114   4  1  86 126\n#> 2580 burroje01 1978     1  ATL NL 153 488  72 147  30   6 23  77   1  2 117  92\n#> 2581 burroje01 1979     1  ATL NL 116 397  49  89  14   1 11  47   2  2  73  75\n#> 2582 burroje01 1980     1  ATL NL  99 278  35  73  14   0 13  51   1  1  35  57\n#> 2583 burroje01 1981     1  SEA AL  89 319  32  81  13   1 10  41   0  1  41  64\n#> 2584 burroje01 1982     1  OAK AL 113 285  42  79  13   2 16  48   1  3  45  61\n#> 2585 burroje01 1983     1  OAK AL 121 401  43 108  15   1 10  56   0  2  47  79\n#> 2586 burroje01 1984     1  OAK AL  58  71   5  15   1   0  2   8   0  0  18  23\n#> 2587 burroje01 1985     1  TOR AL  86 191  19  49   9   3  6  28   0  1  34  36\n#> 2588 busbyji01 1950     1  CHA AL  18  48   5  10   0   0  0   4   0  2   1   5\n#> 2589 busbyji01 1951     1  CHA AL 143 477  59 135  15   2  5  68  26 11  40  46\n#> 2590 busbyji01 1952     1  CHA AL  16  39   5   5   0   0  0   0   0  2   2   7\n#> 2591 busbyji01 1952     2  WS1 AL 129 512  58 125  24   4  2  47   5  6  22  48\n#> 2592 busbyji01 1953     1  WS1 AL 150 586  68 183  28   7  6  82  13  6  38  45\n#> 2593 busbyji01 1954     1  WS1 AL 155 628  83 187  22   7  7  80  17  2  43  56\n#> 2594 busbyji01 1955     1  WS1 AL  47 191  23  44   6   2  6  14   5  0  13  22\n#> 2595 busbyji01 1955     2  CHA AL  99 337  38  82  13   4  1  27   7  3  25  37\n#> 2596 busbyji01 1956     1  CLE AL 135 494  72 116  17   3 12  50   8  3  43  47\n#> 2597 busbyji01 1957     1  CLE AL  30  74   9  14   2   1  2   4   0  1   1   8\n#> 2598 busbyji01 1957     2  BAL AL  86 288  31  72  10   1  3  19   6  3  23  36\n#> 2599 busbyji01 1958     1  BAL AL 113 215  32  51   7   2  3  19   6  4  24  37\n#> 2600 busbyji01 1959     1  BOS AL  61 102  16  23   8   0  1   5   0  1   5  18\n#> 2601 busbyji01 1960     1  BOS AL   1   0   0   0   0   0  0   0   0  0   0   0\n#> 2602 busbyji01 1960     2  BAL AL  79 159  25  41   7   1  0  12   2  3  20  14\n#> 2603 busbyji01 1961     1  BAL AL  75  89  15  23   3   1  0   6   2  0   8  10\n#> 2604 busbyji01 1962     1  HOU NL  15  11   2   2   0   0  0   1   0  1   2   3\n#> 2605  bushdo01 1908     1  DET AL  20  68  13  20   1   1  0   4   2 NA   7  NA\n#> 2606  bushdo01 1909     1  DET AL 157 532 114 145  18   2  0  33  53 NA  88  NA\n#> 2607  bushdo01 1910     1  DET AL 142 496  90 130  13   4  3  34  49 NA  78  NA\n#> 2608  bushdo01 1911     1  DET AL 150 561 126 130  18   5  1  36  40 NA  98  NA\n#> 2609  bushdo01 1912     1  DET AL 144 511 107 118  14   8  2  38  35 NA 117  NA\n#> 2610  bushdo01 1913     1  DET AL 153 597  98 150  19  10  1  40  44 NA  80  32\n#> 2611  bushdo01 1914     1  DET AL 157 596  97 150  18   4  0  32  35 26 112  54\n#> 2612  bushdo01 1915     1  DET AL 155 561  99 128  12   8  1  44  35 27 118  44\n#> 2613  bushdo01 1916     1  DET AL 145 550  73 124   5   9  0  34  19 NA  75  42\n#> 2614  bushdo01 1917     1  DET AL 147 581 112 163  18   3  0  24  34 NA  80  40\n#> 2615  bushdo01 1918     1  DET AL 128 500  74 117  10   3  0  22   9 NA  79  31\n#> 2616  bushdo01 1919     1  DET AL 129 509  82 124  11   6  0  26  22 NA  75  36\n#> 2617  bushdo01 1920     1  DET AL 141 506  85 133  18   5  1  33  15  7  73  32\n#> 2618  bushdo01 1921     1  DET AL 104 402  72 113   6   5  0  27   8 11  45  23\n#> 2619  bushdo01 1921     2  WS1 AL  23  84  15  18   1   0  0   2   2  2  12   4\n#> 2620  bushdo01 1922     1  WS1 AL  41 134  17  32   4   1  0   7   1  1  21   7\n#> 2621  bushdo01 1923     1  WS1 AL  10  22   6   9   0   0  0   0   1  1   0   1\n#> 2622  bushgu01 1923     1  CHN NL   1   0   0   0   0   0  0   0   0  0   0   0\n#> 2623  bushgu01 1924     1  CHN NL  16  26   1   4   1   0  0   4   0  0   1   5\n#> 2624  bushgu01 1925     1  CHN NL  42  57   3  11   0   0  0   2   0  0   2   5\n#> 2625  bushgu01 1926     1  CHN NL  35  48   1   8   0   0  0   2   0 NA   1   7\n#> 2626  bushgu01 1927     1  CHN NL  36  65   2   8   1   0  0   1   0 NA   1  10\n#> 2627  bushgu01 1928     1  CHN NL  42  73   3   6   0   0  0   2   0 NA   2  18\n#> 2628  bushgu01 1929     1  CHN NL  50  91   5  15   0   0  0   3   1 NA   3  19\n#> 2629  bushgu01 1930     1  CHN NL  46  78   7  22   0   1  0   7   0 NA   6  19\n#> 2630  bushgu01 1931     1  CHN NL  39  57   6   7   1   0  0   9   0 NA   5  11\n#> 2631  bushgu01 1932     1  CHN NL  40  84   6  15   2   1  0   1   0 NA   4  12\n#> 2632  bushgu01 1933     1  CHN NL  41  88   4  11   4   0  0   3   0 NA   8  16\n#> 2633  bushgu01 1934     1  CHN NL  41  70   4  16   1   0  0  10   2 NA   2  13\n#> 2634  bushgu01 1935     1  PIT NL  41  63   6   8   1   0  0   2   0 NA   8   7\n#> 2635  bushgu01 1936     1  PIT NL  16   9   1   3   0   0  0   3   0 NA   0   0\n#> 2636  bushgu01 1936     2  BSN NL  15  25   4   3   0   0  0   0   0 NA   3   4\n#> 2637  bushgu01 1937     1  BSN NL  33  54   4   6   1   0  0   3   0 NA   4  16\n#> 2638  bushgu01 1938     1  SLN NL   6   0   0   0   0   0  0   0   0  0   0   0\n#> 2639  bushgu01 1945     1  CIN NL   4   0   0   0   0   0  0   0   0  0   0   0\n#> 2640  bushjo01 1912     1  PHA AL   1   4   1   2   0   1  0   3   0 NA   0  NA\n#> 2641  bushjo01 1913     1  PHA AL  39  70   8  11   3   1  0   1   0 NA   2  21\n#> 2642  bushjo01 1914     1  PHA AL  38  74   6  14   4   0  1   8   0 NA   2  25\n#> 2643  bushjo01 1915     1  PHA AL  25  49   2   7   0   0  0   0   0 NA   1  22\n#> 2644  bushjo01 1916     1  PHA AL  41 100   4  14   4   0  0   6   0 NA   0  23\n#> 2645  bushjo01 1917     1  PHA AL  37  80   9  16   2   1  0   4   0 NA   5  12\n#> 2646  bushjo01 1918     1  BOS AL  36  98   8  27   3   2  0  14   0 NA   6  11\n#> 2647  bushjo01 1919     1  BOS AL   5   5   1   2   0   0  0   2   0 NA   0   1\n#> 2648  bushjo01 1920     1  BOS AL  45 102  14  25   2   0  0   7   0  2   9  15\n#> 2649  bushjo01 1921     1  BOS AL  50 120  19  39   5   4  0  17   2  0   3  14\n#> 2650  bushjo01 1922     1  NYA AL  39  95  15  31   6   2  0  12   0  1   3  11\n#> 2651  bushjo01 1923     1  NYA AL  38 113  12  31   5   3  2  19   0  0   3   8\n#> 2652  bushjo01 1924     1  NYA AL  60 124  13  42   9   3  1  14   0  0   7   6\n#> 2653  bushjo01 1925     1  SLA AL  57 102  10  26  12   0  2  18   2  0   6   8\n#> 2654  bushjo01 1926     1  WS1 AL  17  30   1   7   0   0  0   3   0  1   3   2\n#> 2655  bushjo01 1926     2  PIT NL  28  49   5  13   4   0  1   7   0 NA   1  10\n#> 2656  bushjo01 1927     1  PIT NL   7   5   0   3   0   0  0   2   0 NA   1   1\n#> 2657  bushjo01 1927     2  NY1 NL   3   4   0   2   0   0  0   0   0 NA   0   0\n#> 2658  bushjo01 1928     1  PHA AL  15  15   0   1   0   0  0   0   0  0   1   2\n#> 2659 butlebr01 1981     1  ATL NL  40 126  17  32   2   3  0   4   9  1  19  17\n#> 2660 butlebr01 1982     1  ATL NL  89 240  35  52   2   0  0   7  21  8  25  35\n#> 2661 butlebr01 1983     1  ATL NL 151 549  84 154  21  13  5  37  39 23  54  56\n#> 2662 butlebr01 1984     1  CLE AL 159 602 108 162  25   9  3  49  52 22  86  62\n#> 2663 butlebr01 1985     1  CLE AL 152 591 106 184  28  14  5  50  47 20  63  42\n#> 2664 butlebr01 1986     1  CLE AL 161 587  92 163  17  14  4  51  32 15  70  65\n#> 2665 butlebr01 1987     1  CLE AL 137 522  91 154  25   8  9  41  33 16  91  55\n#> 2666 butlebr01 1988     1  SFN NL 157 568 109 163  27   9  6  43  43 20  97  64\n#> 2667 butlebr01 1989     1  SFN NL 154 594 100 168  22   4  4  36  31 16  59  69\n#> 2668 butlebr01 1990     1  SFN NL 160 622 108 192  20   9  3  44  51 19  90  62\n#> 2669 butlebr01 1991     1  LAN NL 161 615 112 182  13   5  2  38  38 28 108  79\n#> 2670 butlebr01 1992     1  LAN NL 157 553  86 171  14  11  3  39  41 21  95  67\n#> 2671 butlebr01 1993     1  LAN NL 156 607  80 181  21  10  1  42  39 19  86  69\n#> 2672 butlebr01 1994     1  LAN NL 111 417  79 131  13   9  8  33  27  8  68  52\n#> 2673 butlebr01 1995     1  NYN NL  90 367  54 114  13   7  1  25  21  7  43  42\n#> 2674 butlebr01 1995     2  LAN NL  39 146  24  40   5   2  0  13  11  1  24   9\n#> 2675 butlebr01 1996     1  LAN NL  34 131  22  35   1   1  0   8   8  3   9  22\n#> 2676 butlebr01 1997     1  LAN NL 105 343  52  97   8   3  0  18  15 10  42  40\n#> 2677 byrneto01 1943     1  NYA AL  13  11   0   1   0   0  0   0   0  0   2   3\n#> 2678 byrneto01 1946     1  NYA AL  14   9   2   2   0   0  0   0   0  0   1   0\n#> 2679 byrneto01 1947     1  NYA AL   4   0   0   0   0   0  0   0   0  0   1   0\n#> 2680 byrneto01 1948     1  NYA AL  31  46   8  15   3   1  1   7   0  0   1   7\n#> 2681 byrneto01 1949     1  NYA AL  35  83   8  16   4   2  0  13   0  0   2  20\n#> 2682 byrneto01 1950     1  NYA AL  34  81  14  22   3   1  2  16   1  0   4  15\n#> 2683 byrneto01 1951     1  NYA AL   9   9   2   2   0   0  1   3   0  0   0   2\n#> 2684 byrneto01 1951     2  SLA AL  34  57   7  16   3   0  1  12   0  0   4   8\n#> 2685 byrneto01 1952     1  SLA AL  40  84   9  21   5   1  1  12   0  0   5  18\n#> 2686 byrneto01 1953     1  CHA AL  18  18   2   3   0   0  1   5   0  0   2   6\n#> 2687 byrneto01 1953     2  WS1 AL  14  17   0   1   0   0  0   0   0  0   3   7\n#> 2688 byrneto01 1954     1  NYA AL   7  19   2   7   4   1  0   6   0  0   0   3\n#> 2689 byrneto01 1955     1  NYA AL  45  78   6  16   1   1  1   6   0  0   8  15\n#> 2690 byrneto01 1956     1  NYA AL  44  52   8  14   1   1  3  10   0  0   2  11\n#> 2691 byrneto01 1957     1  NYA AL  35  37   5   7   2   0  3   8   0  0   3  11\n#> 2692 cabelen01 1972     1  BAL AL   3   5   0   0   0   0  0   1   0  0   0   0\n#> 2693 cabelen01 1973     1  BAL AL  32  47  12  10   2   0  1   3   1  3   3   7\n#> 2694 cabelen01 1974     1  BAL AL  80 174  24  42   4   2  3  17   5  3   7  20\n#> 2695 cabelen01 1975     1  HOU NL 117 348  43  92  17   6  2  43  12  3  18  53\n#> 2696 cabelen01 1976     1  HOU NL 144 586  85 160  13   7  2  43  35  8  29  79\n#> 2697 cabelen01 1977     1  HOU NL 150 625 101 176  36   7 16  68  42 22  27  55\n#> 2698 cabelen01 1978     1  HOU NL 162 660  92 195  31   8  7  71  33 15  22  80\n#> 2699 cabelen01 1979     1  HOU NL 155 603  60 164  30   5  6  67  37 18  21  68\n#> 2700 cabelen01 1980     1  HOU NL 152 604  69 167  23   8  2  55  21 13  26  84\n#> 2701 cabelen01 1981     1  SFN NL  96 396  41 101  20   1  2  36   6  7  10  47\n#> 2702 cabelen01 1982     1  DET AL 125 464  45 121  17   3  2  37  15  6  15  48\n#> 2703 cabelen01 1983     1  DET AL 121 392  62 122  23   5  5  46   4  8  16  41\n#> 2704 cabelen01 1984     1  HOU NL 127 436  52 135  17   3  8  44   8 11  21  47\n#> 2705 cabelen01 1985     1  HOU NL  60 143  20  35   8   1  2  14   3  1  16  15\n#> 2706 cabelen01 1985     2  LAN NL  57 192  20  56  11   0  0  22   6  2  14  21\n#> 2707 cabelen01 1986     1  LAN NL 107 277  27  71  11   0  2  29  10  4  14  26\n#> 2708 caldwmi01 1971     1  SDN NL   6   1   0   1   1   0  0   0   0  0   0   0\n#> 2709 caldwmi01 1972     1  SDN NL  42  50   1   7   0   0  0   3   0  0   0  20\n#> 2710 caldwmi01 1973     1  SDN NL  56  35   2   5   0   0  0   0   0  0   1  12\n#> 2711 caldwmi01 1974     1  SFN NL  31  63   4   9   0   0  0   2   0  0   2  15\n#> 2712 caldwmi01 1975     1  SFN NL  38  44   2   7   3   0  0   3   0  0   0  11\n#> 2713 caldwmi01 1976     1  SFN NL  50  19   1   3   1   0  0   0   0  0   0   4\n#> 2714 caldwmi01 1977     2  ML4 AL  21   0   0   0   0   0  0   0   0  0   0   0\n#> 2715 caldwmi01 1977     1  CIN NL  14   4   1   2   2   0  0   0   0  0   1   0\n#> 2716 caldwmi01 1978     1  ML4 AL  37   0   0   0   0   0  0   0   0  0   0   0\n#> 2717 caldwmi01 1979     1  ML4 AL  30   0   0   0   0   0  0   0   0  0   0   0\n#> 2718 caldwmi01 1980     1  ML4 AL  34   0   0   0   0   0  0   0   0  0   0   0\n#> 2719 caldwmi01 1981     1  ML4 AL  24   0   0   0   0   0  0   0   0  0   0   0\n#> 2720 caldwmi01 1982     1  ML4 AL  35   0   0   0   0   0  0   0   0  0   0   0\n#> 2721 caldwmi01 1983     1  ML4 AL  32   0   0   0   0   0  0   0   0  0   0   0\n#> 2722 caldwmi01 1984     1  ML4 AL  26   0   0   0   0   0  0   0   0  0   0   0\n#> 2723 callijo01 1958     1  CHA AL  18  64  10  19   4   2  1  12   1  0   6  14\n#> 2724 callijo01 1959     1  CHA AL  49 104  12  18   3   0  3  12   0  1  13  20\n#> 2725 callijo01 1960     1  PHI NL  99 288  36  75  11   5  9  30   0  4  45  70\n#> 2726 callijo01 1961     1  PHI NL 138 455  74 121  20  11  9  47  10  4  69  76\n#> 2727 callijo01 1962     1  PHI NL 157 603 107 181  26  10 23  83  10  3  54  96\n#> 2728 callijo01 1963     1  PHI NL 157 626  96 178  36  11 26  78   8  3  50 111\n#> 2729 callijo01 1964     1  PHI NL 162 654 101 179  30  10 31 104   6  3  36  95\n#> 2730 callijo01 1965     1  PHI NL 160 619  93 162  25  16 32 101   6  5  57 117\n#> 2731 callijo01 1966     1  PHI NL 155 612  93 169  40   7 11  55   8  8  56  83\n#> 2732 callijo01 1967     1  PHI NL 149 556  62 145  30   5 14  64   6 12  55  63\n#> 2733 callijo01 1968     1  PHI NL 121 398  46  97  18   4 14  40   4  3  42  70\n#> 2734 callijo01 1969     1  PHI NL 134 495  66 131  29   5 16  64   2  1  49  73\n#> 2735 callijo01 1970     1  CHN NL 147 477  65 126  23   2 19  68   7  2  60  63\n#> 2736 callijo01 1971     1  CHN NL 103 290  27  61  12   1  8  38   2  1  36  55\n#> 2737 callijo01 1972     1  NYA AL  92 275  28  71  10   0  9  34   3  0  18  34\n#> 2738 callijo01 1973     1  NYA AL  45 136  10  24   4   0  1  10   1  1   4  24\n#> 2739 caminke01 1987     1  HOU NL  63 203  10  50   7   1  3  23   0  0  12  44\n#> 2740 caminke01 1988     1  HOU NL  30  83   5  15   2   0  1   7   0  0   5  18\n#> 2741 caminke01 1989     1  HOU NL 161 585  71 149  31   3 10  72   4  1  51  93\n#> 2742 caminke01 1990     1  HOU NL 153 541  52 131  20   2  4  51   9  4  48  97\n#> 2743 caminke01 1991     1  HOU NL 152 574  65 145  30   3 13  80   4  5  46  85\n#> 2744 caminke01 1992     1  HOU NL 135 506  68 149  31   2 13  62  10  4  44  68\n#> 2745 caminke01 1993     1  HOU NL 143 543  75 142  31   0 13  75   8  5  49  88\n#> 2746 caminke01 1994     1  HOU NL 111 406  63 115  28   2 18  75   4  3  43  71\n#> 2747 caminke01 1995     1  SDN NL 143 526  74 159  33   0 26  94  12  5  69  94\n#> 2748 caminke01 1996     1  SDN NL 146 546 109 178  37   2 40 130  11  5  78  99\n#> 2749 caminke01 1997     1  SDN NL 137 486  92 141  28   0 26  90  11  2  80 118\n#> 2750 caminke01 1998     1  SDN NL 131 452  87 114  29   0 29  82   6  2  71 108\n#> 2751 caminke01 1999     1  HOU NL  78 273  45  78  11   1 13  56   6  2  46  58\n#> 2752 caminke01 2000     1  HOU NL  59 208  42  63  13   0 15  45   3  0  42  37\n#> 2753 caminke01 2001     1  TEX AL  54 185  24  43   8   1  9  25   0  0  22  41\n#> 2754 caminke01 2001     2  ATL NL  64 171  12  38   9   0  6  16   0  1  21  44\n#> 2755 campabe01 1964     1  KC1 AL  67 269  27  69  14   3  4  22  10  2  15  41\n#> 2756 campabe01 1965     1  KC1 AL 144 578  67 156  23  12  6  42  51 19  41  71\n#> 2757 campabe01 1966     1  KC1 AL 142 573  82 153  29  10  5  42  52 10  25  72\n#> 2758 campabe01 1967     1  KC1 AL 147 601  85 149  29   6  3  32  55 16  36  82\n#> 2759 campabe01 1968     1  OAK AL 159 642  87 177  25   9  4  38  62 22  50  69\n#> 2760 campabe01 1969     1  OAK AL 135 547  71 142  15   2  2  25  62  8  30  62\n#> 2761 campabe01 1970     1  OAK AL 147 603  97 168  28   4 22  64  42 10  36  73\n#> 2762 campabe01 1971     1  OAK AL 134 569  80 143  18   4  5  47  34  7  29  64\n#> 2763 campabe01 1972     1  OAK AL 149 625  85 150  25   2  8  32  52 14  32  88\n#> 2764 campabe01 1973     1  OAK AL 151 601  89 150  17   6  4  46  34 10  50  79\n#> 2765 campabe01 1974     1  OAK AL 134 527  77 153  18   8  2  41  34 15  47  81\n#> 2766 campabe01 1975     1  OAK AL 137 509  69 135  15   3  4  46  24 12  50  71\n#> 2767 campabe01 1976     1  OAK AL 149 536  67 137  14   1  1  52  54 12  63  80\n#> 2768 campabe01 1977     1  TEX AL 150 552  77 140  19   7  5  46  27 20  47  86\n#> 2769 campabe01 1978     1  TEX AL  98 269  30  50   5   3  1  17  22  4  20  36\n#> 2770 campabe01 1979     1  TEX AL   8   9   2   1   0   0  0   0   1  0   1   3\n#> 2771 campabe01 1979     2  CAL AL  85 239  27  56   4   4  0  15  12  4  19  32\n#> 2772 campabe01 1980     1  CAL AL  77 210  32  53   8   1  2  18  10  5  14  33\n#> 2773 campabe01 1981     1  CAL AL  55  82  11  21   2   1  1  10   5  2   5  10\n#> 2774 campabe01 1983     1  NYA AL  60 143  19  46   5   0  0  11   6  7   8   9\n#> 2775 campbbi02 1973     1  MIN AL  28   0   0   0   0   0  0   0   0  0   0   0\n#> 2776 campbbi02 1974     1  MIN AL  63   0   0   0   0   0  0   0   0  0   0   0\n#> 2777 campbbi02 1975     1  MIN AL  47   1   0   0   0   0  0   0   0  0   0   1\n#> 2778 campbbi02 1976     1  MIN AL  78   0   0   0   0   0  0   0   0  0   0   0\n#> 2779 campbbi02 1977     1  BOS AL  69   0   0   0   0   0  0   0   0  0   0   0\n#> 2780 campbbi02 1978     1  BOS AL  29   0   0   0   0   0  0   0   0  0   0   0\n#> 2781 campbbi02 1979     1  BOS AL  41   0   0   0   0   0  0   0   0  0   0   0\n#> 2782 campbbi02 1980     1  BOS AL  23   0   0   0   0   0  0   0   0  0   0   0\n#> 2783 campbbi02 1981     1  BOS AL  30   0   0   0   0   0  0   0   0  0   0   0\n#> 2784 campbbi02 1982     1  CHN NL  62   7   0   1   0   0  0   0   0  0   0   3\n#> 2785 campbbi02 1983     1  CHN NL  82  10   0   1   0   0  0   1   0  0   0   3\n#> 2786 campbbi02 1984     1  PHI NL  57   1   0   0   0   0  0   0   0  0   0   0\n#> 2787 campbbi02 1985     1  SLN NL  50   6   2   2   0   0  0   1   0  1   3   2\n#> 2788 campbbi02 1986     1  DET AL  34   0   0   0   0   0  0   0   0  0   0   0\n#> 2789 campbbi02 1987     1  MON NL   7   1   0   0   0   0  0   0   0  0   1   1\n#> 2790 candejo01 1975     1  PIT NL  18  43   2   6   0   0  0   2   0  0   3  12\n#> 2791 candejo01 1976     1  PIT NL  32  76   5  14   2   1  0   5   0  0   7  17\n#> 2792 candejo01 1977     1  PIT NL  33  80   5  18   3   2  0  11   0  1   4  18\n#> 2793 candejo01 1978     1  PIT NL  31  52   6   9   3   0  0   1   0  0   9  19\n#> 2794 candejo01 1979     1  PIT NL  33  68   0   9   4   0  0   6   0  0   1  18\n#> 2795 candejo01 1980     1  PIT NL  35  77   5  15   3   0  0   7   0  0   4  14\n#> 2796 candejo01 1981     1  PIT NL   6  13   0   3   0   0  0   3   0  0   0   1\n#> 2797 candejo01 1982     1  PIT NL  33  54   6  12   2   0  0   9   0  0   6  20\n#> 2798 candejo01 1983     1  PIT NL  33  65   4   9   1   0  0   2   0  0   5  17\n#> 2799 candejo01 1984     1  PIT NL  33  62   6   8   2   0  1   2   0  1   4  25\n#> 2800 candejo01 1985     2  CAL AL  13   0   0   0   0   0  0   0   0  0   0   0\n#> 2801 candejo01 1985     1  PIT NL  37   1   0   0   0   0  0   0   0  0   0   1\n#> 2802 candejo01 1986     1  CAL AL  16   0   0   0   0   0  0   0   0  0   0   0\n#> 2803 candejo01 1987     1  CAL AL  20   0   0   0   0   0  0   0   0  0   0   0\n#> 2804 candejo01 1987     2  NYN NL   3   5   0   1   0   0  0   0   0  0   0   0\n#> 2805 candejo01 1988     1  NYA AL  25   0   0   0   0   0  0   0   0  0   0   0\n#> 2806 candejo01 1989     1  NYA AL  10   0   0   0   0   0  0   0   0  0   0   0\n#> 2807 candejo01 1989     2  MON NL  12   0   0   0   0   0  0   0   0  0   0   0\n#> 2808 candejo01 1990     1  MIN AL  34   0   0   0   0   0  0   0   0  0   0   0\n#> 2809 candejo01 1990     2  TOR AL  13   0   0   0   0   0  0   0   0  0   0   0\n#> 2810 candejo01 1991     1  LAN NL  59   0   0   0   0   0  0   0   0  0   0   0\n#> 2811 candejo01 1992     1  LAN NL  50   0   0   0   0   0  0   0   0  0   1   0\n#> 2812 candejo01 1993     1  PIT NL  24   0   0   0   0   0  0   0   0  0   0   0\n#> 2813 candito01 1983     1  ML4 AL  10   0   0   0   0   0  0   0   0  0   0   0\n#> 2814 candito01 1984     1  ML4 AL   8   0   0   0   0   0  0   0   0  0   0   0\n#> 2815 candito01 1986     1  CLE AL  36   0   0   0   0   0  0   0   0  0   0   0\n#> 2816 candito01 1987     1  CLE AL  32   0   0   0   0   0  0   0   0  0   0   0\n#> 2817 candito01 1988     1  CLE AL  31   0   0   0   0   0  0   0   0  0   0   0\n#> 2818 candito01 1989     1  CLE AL  31   0   0   0   0   0  0   0   0  0   0   0\n#> 2819 candito01 1990     1  CLE AL  31   0   0   0   0   0  0   0   0  0   0   0\n#> 2820 candito01 1991     1  CLE AL  15   0   0   0   0   0  0   0   0  0   0   0\n#> 2821 candito01 1991     2  TOR AL  19   0   0   0   0   0  0   0   0  0   0   0\n#> 2822 candito01 1992     1  LAN NL  32  56   3   6   1   0  0   1   0  0   1   9\n#> 2823 candito01 1993     1  LAN NL  33  60   1   8   2   0  0   2   0  0   1  13\n#> 2824 candito01 1994     1  LAN NL  23  50   2   7   1   0  0   3   0  0   1   9\n#> 2825 candito01 1995     1  LAN NL  30  55   2   6   0   0  0   2   0  0   3  16\n#> 2826 candito01 1996     1  LAN NL  28  45   3   4   0   0  0   2   0  0   0  14\n#> 2827 candito01 1997     1  LAN NL  41  32   0   3   0   0  0   2   0  0   1  10\n#> 2828 candito01 1998     1  OAK AL   1   1   0   1   1   0  0   0   0  0   0   0\n#> 2829 candito01 1999     1  OAK AL  11   0   0   0   0   0  0   0   0  0   0   0\n#> 2830 candito01 1999     2  CLE AL   7   0   0   0   0   0  0   0   0  0   0   0\n#> 2831 cansejo01 1985     1  OAK AL  29  96  16  29   3   0  5  13   1  1   4  31\n#> 2832 cansejo01 1986     1  OAK AL 157 600  85 144  29   1 33 117  15  7  65 175\n#> 2833 cansejo01 1987     1  OAK AL 159 630  81 162  35   3 31 113  15  3  50 157\n#> 2834 cansejo01 1988     1  OAK AL 158 610 120 187  34   0 42 124  40 16  78 128\n#> 2835 cansejo01 1989     1  OAK AL  65 227  40  61   9   1 17  57   6  3  23  69\n#> 2836 cansejo01 1990     1  OAK AL 131 481  83 132  14   2 37 101  19 10  72 158\n#> 2837 cansejo01 1991     1  OAK AL 154 572 115 152  32   1 44 122  26  6  78 152\n#> 2838 cansejo01 1992     1  OAK AL  97 366  66  90  11   0 22  72   5  7  48 104\n#> 2839 cansejo01 1992     2  TEX AL  22  73   8  17   4   0  4  15   1  0  15  24\n#> 2840 cansejo01 1993     1  TEX AL  60 231  30  59  14   1 10  46   6  6  16  62\n#> 2841 cansejo01 1994     1  TEX AL 111 429  88 121  19   2 31  90  15  8  69 114\n#> 2842 cansejo01 1995     1  BOS AL 102 396  64 121  25   1 24  81   4  0  42  93\n#> 2843 cansejo01 1996     1  BOS AL  96 360  68 104  22   1 28  82   3  1  63  82\n#> 2844 cansejo01 1997     1  OAK AL 108 388  56  91  19   0 23  74   8  2  51 122\n#> 2845 cansejo01 1998     1  TOR AL 151 583  98 138  26   0 46 107  29 17  65 159\n#> 2846 cansejo01 1999     1  TBA AL 113 430  75 120  18   1 34  95   3  0  58 135\n#> 2847 cansejo01 2000     1  TBA AL  61 218  31  56  15   0  9  30   2  0  41  65\n#> 2848 cansejo01 2000     2  NYA AL  37 111  16  27   3   0  6  19   0  0  23  37\n#> 2849 cansejo01 2001     1  CHA AL  76 256  46  66   8   0 16  49   2  1  45  75\n#> 2850 carbobe01 1969     1  CIN NL   4   3   0   0   0   0  0   0   0  0   0   2\n#> 2851 carbobe01 1970     1  CIN NL 125 365  54 113  19   3 21  63  10  4  94  77\n#> 2852 carbobe01 1971     1  CIN NL 106 310  33  68  20   1  5  20   2  1  54  56\n#> 2853 carbobe01 1972     1  CIN NL  19  21   2   3   0   0  0   0   0  0   6   3\n#> 2854 carbobe01 1972     2  SLN NL  99 302  42  78  13   1  7  34   0  1  57  56\n#> 2855 carbobe01 1973     1  SLN NL 111 308  42  88  18   0  8  40   2  0  58  52\n#> 2856 carbobe01 1974     1  BOS AL 117 338  40  84  20   0 12  61   4  3  58  90\n#> 2857 carbobe01 1975     1  BOS AL 107 319  64  82  21   3 15  50   2  4  83  69\n#> 2858 carbobe01 1976     1  BOS AL  17  55   5  13   4   0  2   6   1  0   8  17\n#> 2859 carbobe01 1976     2  ML4 AL  69 183  20  43   7   0  3  15   1  2  33  55\n#> 2860 carbobe01 1977     1  BOS AL  86 228  36  66   6   1 15  34   1  2  47  72\n#> 2861 carbobe01 1978     1  BOS AL  17  46   7  12   3   0  1   6   1  1   8   8\n#> 2862 carbobe01 1978     2  CLE AL  60 174  21  50   8   0  4  16   1  0  20  31\n#> 2863 carbobe01 1979     1  SLN NL  52  64   6  18   1   0  3  12   1  0  10  22\n#> 2864 carbobe01 1980     1  SLN NL  14  11   0   2   0   0  0   0   0  0   1   0\n#> 2865 carbobe01 1980     2  PIT NL   7   6   0   2   0   0  0   1   0  0   1   1\n#> 2866 cardejo02 1963     1  SFN NL   9   5   1   1   0   0  0   2   0  1   1   1\n#> 2867 cardejo02 1964     1  SFN NL  20  15   3   0   0   0  0   0   2  0   2   3\n#> 2868 cardejo02 1965     1  CAL AL 134 512  58 128  23   2 11  57  37 17  27  72\n#> 2869 cardejo02 1966     1  CAL AL 154 561  67 155  15   3 16  48  24 11  34  69\n#> 2870 cardejo02 1967     1  CAL AL 108 381  40  90  13   5  6  27  10  5  15  63\n#> 2871 cardejo02 1968     1  CLE AL 157 583  78 150  21   7  7  44  40 18  39  74\n#> 2872 cardejo02 1969     1  CLE AL 146 557  75 143  26   3 11  45  36  6  49  58\n#> 2873 cardejo02 1970     1  SLN NL 148 552  73 162  32   6 10  74  26  9  45  70\n#> 2874 cardejo02 1971     2  ML4 AL  53 198  20  51  10   0  3  32   9  5  13  20\n#> 2875 cardejo02 1971     1  SLN NL  89 301  37  73  12   4  7  48  12  3  29  35\n#> 2876 cardejo02 1972     1  CHN NL 143 533  96 155  24   6 17  70  25 14  55  58\n#> 2877 cardejo02 1973     1  CHN NL 145 522  80 158  33   2 11  68  19  7  58  62\n#> 2878 cardejo02 1974     1  CHN NL 143 542  75 159  35   3 13  72  23  9  56  67\n#> 2879 cardejo02 1975     1  CHN NL 154 574  85 182  30   2  9  68  34 12  77  50\n#> 2880 cardejo02 1976     1  CHN NL 136 521  64 156  25   2  8  47  23 14  32  39\n#> 2881 cardejo02 1977     1  CHN NL 100 226  33  54  12   1  3  18   5  4  28  30\n#> 2882 cardejo02 1978     1  PHI NL  87 201  27  50  12   0  4  33   2  3  23  16\n#> 2883 cardejo02 1979     1  PHI NL  29  48   4  10   3   0  0   9   1  0   8   8\n#> 2884 cardejo02 1979     2  NYN NL  11  37   8  11   4   0  2   4   1  0   6   3\n#> 2885 cardejo02 1980     2  KCA AL  25  53   8  18   2   0  0   5   0  0   5   5\n#> 2886 cardejo02 1980     1  NYN NL  26  42   4   7   1   0  0   4   0  1   6   4\n#> 2887 cardele01 1960     1  CIN NL  48 142  13  33   2   4  1  12   0  0   6  32\n#> 2888 cardele01 1961     1  CIN NL  74 198  23  61  18   1  5  24   1  0  15  39\n#> 2889 cardele01 1962     1  CIN NL 153 589  77 173  31   4 10  60   2  5  39  99\n#> 2890 cardele01 1963     1  CIN NL 158 565  42 133  22   4  7  48   3  5  23 101\n#> 2891 cardele01 1964     1  CIN NL 163 597  61 150  32   2  9  69   4  4  41 110\n#> 2892 cardele01 1965     1  CIN NL 156 557  65 160  25  11 11  57   1  4  60 100\n#> 2893 cardele01 1966     1  CIN NL 160 568  59 145  25   4 20  81   9  4  45  87\n#> 2894 cardele01 1967     1  CIN NL 108 379  30  97  14   3  2  21   4  5  34  77\n#> 2895 cardele01 1968     1  CIN NL 137 452  45 106  13   2  7  41   2  1  36  83\n#> 2896 cardele01 1969     1  MIN AL 160 578  67 162  24   4 10  70   5  6  66  96\n#> 2897 cardele01 1970     1  MIN AL 160 588  67 145  34   4 11  65   2  5  42 101\n#> 2898 cardele01 1971     1  MIN AL 153 554  59 146  25   4 18  75   3  3  51  69\n#> 2899 cardele01 1972     1  CAL AL 150 551  25 123  11   2  6  42   1  2  35  73\n#> 2900 cardele01 1973     1  CLE AL  72 195   9  42   4   0  0  12   1  4  13  42\n#> 2901 cardele01 1974     1  TEX AL  34  92   5  25   3   0  0   7   1  0   2  14\n#> 2902 cardele01 1975     1  TEX AL  55 102  15  24   2   0  1   5   0  0  14  12\n#> 2903 cardwdo01 1957     1  PHI NL  30  35   4   7   1   0  1   2   0  0   0  17\n#> 2904 cardwdo01 1958     1  PHI NL  16  38   0   8   2   0  0   3   0  0   0  11\n#> 2905 cardwdo01 1959     1  PHI NL  26  55   3   3   0   0  1   2   0  0   1  28\n#> 2906 cardwdo01 1960     1  PHI NL   5   8   2   2   0   0  2   3   0  0   0   5\n#> 2907 cardwdo01 1960     2  CHN NL  33  69   9  14   1   0  3   6   1  0   0  30\n#> 2908 cardwdo01 1961     1  CHN NL  40  95   6  10   3   0  3   6   0  0   6  55\n#> 2909 cardwdo01 1962     1  CHN NL  41  61   2   9   0   1  0   3   0  0   4  27\n#> 2910 cardwdo01 1963     1  PIT NL  33  71   3   6   0   0  0   2   0  0   5  35\n#> 2911 cardwdo01 1964     1  PIT NL   4   7   0   1   0   0  0   0   0  0   0   4\n#> 2912 cardwdo01 1965     1  PIT NL  37  74   6  12   1   0  2  10   1  1   4  35\n#> 2913 cardwdo01 1966     1  PIT NL  32  29   1   3   1   0  0   3   0  0   2  12\n#> 2914 cardwdo01 1967     1  NYN NL  27  38   1   6   1   0  1   3   0  0   3  15\n#> 2915 cardwdo01 1968     1  NYN NL  30  61   3   3   0   0  1   4   0  0   0  34\n#> 2916 cardwdo01 1969     1  NYN NL  30  47   3   8   0   0  1   5   0  0   0  26\n#> 2917 cardwdo01 1970     1  NYN NL  16   5   0   0   0   0  0   1   0  0   0   3\n#> 2918 cardwdo01 1970     2  ATL NL  16   5   1   2   0   0  0   0   0  0   0   3\n#> 2919 carewro01 1967     1  MIN AL 137 514  66 150  22   7  8  51   5  9  37  91\n#> 2920 carewro01 1968     1  MIN AL 127 461  46 126  27   2  1  42  12  4  26  71\n#> 2921 carewro01 1969     1  MIN AL 123 458  79 152  30   4  8  56  19  8  37  72\n#> 2922 carewro01 1970     1  MIN AL  51 191  27  70  12   3  4  28   4  6  11  28\n#> 2923 carewro01 1971     1  MIN AL 147 577  88 177  16  10  2  48   6  7  45  81\n#> 2924 carewro01 1972     1  MIN AL 142 535  61 170  21   6  0  51  12  6  43  60\n#> 2925 carewro01 1973     1  MIN AL 149 580  98 203  30  11  6  62  41 16  62  55\n#> 2926 carewro01 1974     1  MIN AL 153 599  86 218  30   5  3  55  38 16  74  49\n#> 2927 carewro01 1975     1  MIN AL 143 535  89 192  24   4 14  80  35  9  64  40\n#> 2928 carewro01 1976     1  MIN AL 156 605  97 200  29  12  9  90  49 22  67  52\n#> 2929 carewro01 1977     1  MIN AL 155 616 128 239  38  16 14 100  23 13  69  55\n#> 2930 carewro01 1978     1  MIN AL 152 564  85 188  26  10  5  70  27  7  78  62\n#> 2931 carewro01 1979     1  CAL AL 110 409  78 130  15   3  3  44  18  8  73  46\n#> 2932 carewro01 1980     1  CAL AL 144 540  74 179  34   7  3  59  23 15  59  38\n#> 2933 carewro01 1981     1  CAL AL  93 364  57 111  17   1  2  21  16  9  45  45\n#> 2934 carewro01 1982     1  CAL AL 138 523  88 167  25   5  3  44  10 17  67  49\n#> 2935 carewro01 1983     1  CAL AL 129 472  66 160  24   2  2  44   6  7  57  48\n#> 2936 carewro01 1984     1  CAL AL  93 329  42  97   8   1  3  31   4  3  40  39\n#> 2937 carewro01 1985     1  CAL AL 127 443  69 124  17   3  2  39   5  5  64  47\n#> 2938 careyma01 1910     1  PIT NL   2   6   2   3   0   1  0   2   0 NA   2   1\n#> 2939 careyma01 1911     1  PIT NL 129 427  77 110  15  10  5  43  27 NA  44  75\n#> 2940 careyma01 1912     1  PIT NL 150 587 114 177  23   8  5  66  45 NA  61  79\n#> 2941 careyma01 1913     1  PIT NL 154 620  99 172  23  10  5  49  61 NA  55  67\n#> 2942 careyma01 1914     1  PIT NL 156 593  76 144  25  17  1  31  38 NA  59  56\n#> 2943 careyma01 1915     1  PIT NL 140 564  76 143  26   5  3  27  36 17  57  58\n#> 2944 careyma01 1916     1  PIT NL 154 599  90 158  23  11  7  42  63 19  59  58\n#> 2945 careyma01 1917     1  PIT NL 155 588  82 174  21  12  1  51  46 NA  58  38\n#> 2946 careyma01 1918     1  PIT NL 126 468  70 128  14   6  3  48  58 NA  62  25\n#> 2947 careyma01 1919     1  PIT NL  66 244  41  75  10   2  0   9  18 NA  25  24\n#> 2948 careyma01 1920     1  PIT NL 130 485  74 140  18   4  1  35  52 10  59  31\n#> 2949 careyma01 1921     1  PIT NL 140 521  85 161  34   4  7  56  37 12  70  30\n#> 2950 careyma01 1922     1  PIT NL 155 629 140 207  28  12 10  70  51  2  80  26\n#> 2951 careyma01 1923     1  PIT NL 153 610 120 188  32  19  6  63  51  8  73  28\n#> 2952 careyma01 1924     1  PIT NL 149 599 113 178  30   9  8  55  49 13  58  17\n#> 2953 careyma01 1925     1  PIT NL 133 542 109 186  39  13  5  44  46 11  66  19\n#> 2954 careyma01 1926     1  PIT NL  86 324  46  72  14   5  0  28  10 NA  30  14\n#> 2955 careyma01 1926     2  BRO NL  27 100  18  26   3   1  0   7   0 NA   8   5\n#> 2956 careyma01 1927     1  BRO NL 144 538  70 143  30  10  1  54  32 NA  64  18\n#> 2957 careyma01 1928     1  BRO NL 108 296  41  73  11   0  2  19  18 NA  47  24\n#> 2958 careyma01 1929     1  BRO NL  19  23   2   7   0   0  0   1   0 NA   3   2\n#> 2959 carlsha01 1917     1  PIT NL  34  49   0   6   0   1  0   2   0 NA   1  13\n#> 2960 carlsha01 1918     1  PIT NL   3   5   0   1   0   0  0   0   0 NA   0   1\n#> 2961 carlsha01 1919     1  PIT NL  22  43   3   7   1   1  0   3   0 NA   1  14\n#> 2962 carlsha01 1920     1  PIT NL  39  85   3  23   4   1  0   2   0  0   1  16\n#> 2963 carlsha01 1921     1  PIT NL  31  34   3  10   2   0  0   2   0  0   0   6\n#> 2964 carlsha01 1922     1  PIT NL  39  56  10  15   2   0  1   9   0  0   2   7\n#> 2965 carlsha01 1923     1  PIT NL   4   5   0   0   0   0  0   0   0  0   1   1\n#> 2966 carlsha01 1924     1  PHI NL  39  76   6  21   1   0  2   8   0  0   2   8\n#> 2967 carlsha01 1925     1  PHI NL  38  93   9  17   1   0  2   8   0  1   5  14\n#> 2968 carlsha01 1926     1  PHI NL  38  96  13  23   5   1  0  13   0 NA   7  15\n#> 2969 carlsha01 1927     1  PHI NL  12  25   4   6   0   0  0   4   0 NA   1   2\n#> 2970 carlsha01 1927     2  CHN NL  27  67   1  11   0   0  0   9   0 NA   0   7\n#> 2971 carlsha01 1928     1  CHN NL  20  19   1   5   0   0  0   1   0 NA   0   2\n#> 2972 carlsha01 1929     1  CHN NL  31  39   4   9   2   0  0   8   0 NA   2   7\n#> 2973 carlsha01 1930     1  CHN NL   8  20   1   5   0   0  0   3   0 NA   1   5\n#> 2974 carltst01 1965     1  SLN NL  15   2   0   0   0   0  0   0   0  0   0   1\n#> 2975 carltst01 1966     1  SLN NL   9  15   0   4   0   0  0   0   0  0   0   3\n#> 2976 carltst01 1967     1  SLN NL  30  72   5  11   2   0  0   3   0  0   3  28\n#> 2977 carltst01 1968     1  SLN NL  35  73   6  12   0   1  2   3   0  0   0  25\n#> 2978 carltst01 1969     1  SLN NL  32  80   5  17   4   1  1   7   0  0   3  27\n#> 2979 carltst01 1970     1  SLN NL  34  80   4  16   2   0  0   4   1  1   1  28\n#> 2980 carltst01 1971     1  SLN NL  37  96   5  17   4   0  0   8   0  0   4  31\n#> 2981 carltst01 1972     1  PHI NL  41 117   6  23   3   1  1   8   0  0   5  31\n#> 2982 carltst01 1973     1  PHI NL  40 100   6  16   2   0  2   5   0  0   2  19\n#> 2983 carltst01 1974     1  PHI NL  39 102   7  25   3   0  0   9   0  1   0  16\n#> 2984 carltst01 1975     1  PHI NL  37  90   8  14   2   0  0   9   0  0   5  24\n#> 2985 carltst01 1976     1  PHI NL  35  92   5  20   1   0  0   6   0  0   1  24\n#> 2986 carltst01 1977     1  PHI NL  36  97   7  26   4   0  3  15   0  0   2  20\n#> 2987 carltst01 1978     1  PHI NL  34  86   7  25   3   1  0  13   0  0   3  14\n#> 2988 carltst01 1979     1  PHI NL  36  94   9  21   3   0  0  10   1  0   3  17\n#> 2989 carltst01 1980     1  PHI NL  38 101   7  19   1   0  0   6   0  0   1  21\n#> 2990 carltst01 1981     1  PHI NL  24  67   5   9   2   2  0   4   0  0   2  16\n#> 2991 carltst01 1982     1  PHI NL  38 101   8  22   4   0  2   8   0  0   0  13\n#> 2992 carltst01 1983     1  PHI NL  37  97   9  19   5   0  0   1   0  0   2  20\n#> 2993 carltst01 1984     1  PHI NL  34  84   8  16   2   0  1  10   0  0   2  20\n#> 2994 carltst01 1985     1  PHI NL  16  28   2   5   1   0  0   3   0  0   1   8\n#> 2995 carltst01 1986     3  CHA AL  10   0   0   0   0   0  0   0   0  0   0   0\n#> 2996 carltst01 1986     1  PHI NL  16  34   3   7   1   0  0   5   0  0   1   4\n#> 2997 carltst01 1986     2  SFN NL   6  11   1   2   0   0  1   3   0  0   0   3\n#> 2998 carltst01 1987     1  CLE AL  23   0   0   0   0   0  0   0   0  0   0   0\n#> 2999 carltst01 1987     2  MIN AL   9   0   0   0   0   0  0   0   0  0   0   0\n#> 3000 carltst01 1988     1  MIN AL   4   0   0   0   0   0  0   0   0  0   0   0\n#> 3001 carrocl02 1964     1  ML1 NL  11   2   0   0   0   0  0   0   0  0   0   0\n#> 3002 carrocl02 1965     1  ML1 NL  19   5   0   0   0   0  0   0   0  0   0   3\n#> 3003 carrocl02 1966     1  ATL NL  73  30   2   3   0   0  0   0   0  0   0  11\n#> 3004 carrocl02 1967     1  ATL NL  42  16   0   1   0   0  0   1   0  0   1   5\n#> 3005 carrocl02 1968     1  ATL NL  10   5   0   0   0   0  0   0   0  0   0   1\n#> 3006 carrocl02 1968     2  CIN NL  58  24   2   6   0   0  0   2   0  0   1   5\n#> 3007 carrocl02 1969     1  CIN NL  71  29   6   6   0   0  1   1   0  0   4   9\n#> 3008 carrocl02 1970     1  CIN NL  65  14   1   1   0   0  0   0   0  0   1   4\n#> 3009 carrocl02 1971     1  CIN NL  61  10   0   1   0   0  0   0   0  0   0   4\n#> 3010 carrocl02 1972     1  CIN NL  65  11   2   2   0   0  0   1   0  0   0   3\n#> 3011 carrocl02 1973     1  CIN NL  53  14   2   3   0   0  0   1   0  0   0   4\n#> 3012 carrocl02 1974     1  CIN NL  57  18   1   3   0   0  0   1   0  0   0   8\n#> 3013 carrocl02 1975     1  CIN NL  56  19   1   0   0   0  0   0   0  0   0   6\n#> 3014 carrocl02 1976     1  CHA AL  29   0   0   0   0   0  0   0   0  0   0   0\n#> 3015 carrocl02 1977     2  CHA AL   8   0   0   0   0   0  0   0   0  0   0   0\n#> 3016 carrocl02 1977     1  SLN NL  51  11   0   1   0   0  0   0   0  0   0   2\n#> 3017 carrocl02 1978     1  PIT NL   2   0   0   0   0   0  0   0   0  0   0   0\n#> 3018 cartega01 1974     1  MON NL   9  27   5  11   0   1  1   6   2  0   1   2\n#> 3019 cartega01 1975     1  MON NL 144 503  58 136  20   1 17  68   5  2  72  83\n#> 3020 cartega01 1976     1  MON NL  91 311  31  68   8   1  6  38   0  2  30  43\n#> 3021 cartega01 1977     1  MON NL 154 522  86 148  29   2 31  84   5  5  58 103\n#> 3022 cartega01 1978     1  MON NL 157 533  76 136  27   1 20  72  10  6  62  70\n#> 3023 cartega01 1979     1  MON NL 141 505  74 143  26   5 22  75   3  2  40  62\n#> 3024 cartega01 1980     1  MON NL 154 549  76 145  25   5 29 101   3  2  58  78\n#> 3025 cartega01 1981     1  MON NL 100 374  48  94  20   2 16  68   1  5  35  35\n#> 3026 cartega01 1982     1  MON NL 154 557  91 163  32   1 29  97   2  5  78  64\n#> 3027 cartega01 1983     1  MON NL 145 541  63 146  37   3 17  79   1  1  51  57\n#> 3028 cartega01 1984     1  MON NL 159 596  75 175  32   1 27 106   2  2  64  57\n#> 3029 cartega01 1985     1  NYN NL 149 555  83 156  17   1 32 100   1  1  69  46\n#> 3030 cartega01 1986     1  NYN NL 132 490  81 125  14   2 24 105   1  0  62  63\n#> 3031 cartega01 1987     1  NYN NL 139 523  55 123  18   2 20  83   0  0  42  73\n#> 3032 cartega01 1988     1  NYN NL 130 455  39 110  16   2 11  46   0  2  34  52\n#> 3033 cartega01 1989     1  NYN NL  50 153  14  28   8   0  2  15   0  0  12  15\n#> 3034 cartega01 1990     1  SFN NL  92 244  24  62  10   0  9  27   1  1  25  31\n#> 3035 cartega01 1991     1  LAN NL 101 248  22  61  14   0  6  26   2  2  22  26\n#> 3036 cartega01 1992     1  MON NL  95 285  24  62  18   1  5  29   0  4  33  37\n#> 3037 cartejo01 1983     1  CHN NL  23  51   6   9   1   1  0   1   1  0   0  21\n#> 3038 cartejo01 1984     1  CLE AL  66 244  32  67   6   1 13  41   2  4  11  48\n#> 3039 cartejo01 1985     1  CLE AL 143 489  64 128  27   0 15  59  24  6  25  74\n#> 3040 cartejo01 1986     1  CLE AL 162 663 108 200  36   9 29 121  29  7  32  95\n#> 3041 cartejo01 1987     1  CLE AL 149 588  83 155  27   2 32 106  31  6  27 105\n#> 3042 cartejo01 1988     1  CLE AL 157 621  85 168  36   6 27  98  27  5  35  82\n#> 3043 cartejo01 1989     1  CLE AL 162 651  84 158  32   4 35 105  13  5  39 112\n#> 3044 cartejo01 1990     1  SDN NL 162 634  79 147  27   1 24 115  22  6  48  93\n#> 3045 cartejo01 1991     1  TOR AL 162 638  89 174  42   3 33 108  20  9  49 112\n#> 3046 cartejo01 1992     1  TOR AL 158 622  97 164  30   7 34 119  12  5  36 109\n#> 3047 cartejo01 1993     1  TOR AL 155 603  92 153  33   5 33 121   8  3  47 113\n#> 3048 cartejo01 1994     1  TOR AL 111 435  70 118  25   2 27 103  11  0  33  64\n#> 3049 cartejo01 1995     1  TOR AL 139 558  70 141  23   0 25  76  12  1  37  87\n#> 3050 cartejo01 1996     1  TOR AL 157 625  84 158  35   7 30 107   7  6  44 106\n#> 3051 cartejo01 1997     1  TOR AL 157 612  76 143  30   4 21 102   8  2  40 105\n#> 3052 cartejo01 1998     1  BAL AL  85 283  36  70  15   1 11  34   3  1  18  48\n#> 3053 cartejo01 1998     2  SFN NL  41 105  15  31   7   0  7  29   1  0   6  13\n#> 3054 cartyri01 1963     1  ML1 NL   2   2   0   0   0   0  0   0   0  0   0   2\n#> 3055 cartyri01 1964     1  ML1 NL 133 455  72 150  28   4 22  88   1  2  43  78\n#> 3056 cartyri01 1965     1  ML1 NL  83 271  37  84  18   1 10  35   1  4  17  44\n#> 3057 cartyri01 1966     1  ATL NL 151 521  73 170  25   2 15  76   4  6  60  74\n#> 3058 cartyri01 1967     1  ATL NL 134 444  41 113  16   2 15  64   4  3  49  70\n#> 3059 cartyri01 1969     1  ATL NL 104 304  47 104  15   0 16  58   0  2  32  28\n#> 3060 cartyri01 1970     1  ATL NL 136 478  84 175  23   3 25 101   1  2  77  46\n#> 3061 cartyri01 1972     1  ATL NL  86 271  31  75  12   2  6  29   0  0  44  33\n#> 3062 cartyri01 1973     1  TEX AL  86 306  24  71  12   0  3  33   2  0  36  39\n#> 3063 cartyri01 1973     3  OAK AL   7   8   1   2   1   0  1   1   0  0   2   1\n#> 3064 cartyri01 1973     2  CHN NL  22  70   4  15   0   0  1   8   0  0   6  10\n#> 3065 cartyri01 1974     1  CLE AL  33  91   6  33   5   0  1  16   0  0   5   9\n#> 3066 cartyri01 1975     1  CLE AL 118 383  57 118  19   1 18  64   2  2  45  31\n#> 3067 cartyri01 1976     1  CLE AL 152 552  67 171  34   0 13  83   1  1  67  45\n#> 3068 cartyri01 1977     1  CLE AL 127 461  50 129  23   1 15  80   1  2  56  51\n#> 3069 cartyri01 1978     1  TOR AL 104 387  51 110  16   0 20  68   1  1  36  41\n#> 3070 cartyri01 1978     2  OAK AL  41 141  19  39   5   1 11  31   0  0  21  16\n#> 3071 cartyri01 1979     1  TOR AL 132 461  48 118  26   0 12  55   3  1  46  45\n#> 3072  cashno01 1958     1  CHA AL  13   8   2   2   0   0  0   0   0  0   0   1\n#> 3073  cashno01 1959     1  CHA AL  58 104  16  25   0   1  4  16   1  1  18   9\n#> 3074  cashno01 1960     1  DET AL 121 353  64 101  16   3 18  63   4  2  65  58\n#> 3075  cashno01 1961     1  DET AL 159 535 119 193  22   8 41 132  11  5 124  85\n#> 3076  cashno01 1962     1  DET AL 148 507  94 123  16   2 39  89   6  3 104  82\n#> 3077  cashno01 1963     1  DET AL 147 493  67 133  19   1 26  79   2  3  89  76\n#> 3078  cashno01 1964     1  DET AL 144 479  63 123  15   5 23  83   2  1  70  66\n#> 3079  cashno01 1965     1  DET AL 142 467  79 124  23   1 30  82   6  6  77  62\n#> 3080  cashno01 1966     1  DET AL 160 603  98 168  18   3 32  93   2  1  66  91\n#> 3081  cashno01 1967     1  DET AL 152 488  64 118  16   5 22  72   3  2  81 100\n#> 3082  cashno01 1968     1  DET AL 127 411  50 108  15   1 25  63   1  1  39  70\n#> 3083  cashno01 1969     1  DET AL 142 483  81 135  15   4 22  74   2  1  63  80\n#> 3084  cashno01 1970     1  DET AL 130 370  58  96  18   2 15  53   0  1  72  58\n#> 3085  cashno01 1971     1  DET AL 135 452  72 128  10   3 32  91   1  0  59  86\n#> 3086  cashno01 1972     1  DET AL 137 440  51 114  16   0 22  61   0  2  50  64\n#> 3087  cashno01 1973     1  DET AL 121 363  51  95  19   0 19  40   1  0  47  73\n#> 3088  cashno01 1974     1  DET AL  53 149  17  34   3   2  7  12   1  1  19  30\n#> 3089 castivi02 1991     1  ATL NL  12   5   1   1   0   0  0   0   0  0   0   2\n#> 3090 castivi02 1992     1  ATL NL   9  16   1   4   1   0  0   1   0  0   1   4\n#> 3091 castivi02 1993     1  COL NL 105 337  36  86   9   7  9  30   2  5  13  45\n#> 3092 castivi02 1994     1  COL NL  52 130  16  43  11   1  3  18   2  1   7  23\n#> 3093 castivi02 1995     1  COL NL 139 527  82 163  34   2 32  90   2  8  30  87\n#> 3094 castivi02 1996     1  COL NL 160 629  97 191  34   0 40 113   7  2  35  88\n#> 3095 castivi02 1997     1  COL NL 159 612  94 186  25   2 40 113   2  4  44 108\n#> 3096 castivi02 1998     1  COL NL 162 645 108 206  28   4 46 144   5  9  40  89\n#> 3097 castivi02 1999     1  COL NL 158 615  83 169  24   1 33 102   2  3  53  75\n#> 3098 castivi02 2000     1  TBA AL  85 331  22  73   9   1  6  42   1  2  14  41\n#> 3099 castivi02 2001     1  TBA AL  24  93   7  20   6   0  2   9   0  0   3  22\n#> 3100 castivi02 2001     2  HOU NL 122 445  62 120  28   1 23  82   1  4  32  86\n#> 3101 castivi02 2002     1  ATL NL 143 543  56 126  23   2 12  61   4  1  22  69\n#> 3102 castivi02 2003     1  ATL NL 147 542  65 150  28   3 22  76   1  2  26  86\n#> 3103 castivi02 2004     1  COL NL 148 583  93 158  43   3 35 131   0  0  51 113\n#> 3104 castivi02 2005     1  WAS NL 142 494  53 125  36   1 12  66   4  2  43  82\n#> 3105 castivi02 2006     2  COL NL  15  21   2   4   0   0  1   4   0  0   0   3\n#> 3106 castivi02 2006     1  SDN NL  72 254  24  59  10   0  4  23   0  0   9  46\n#> 3107 cavarph01 1934     1  CHN NL   7  21   5   8   0   1  1   6   1 NA   2   3\n#> 3108 cavarph01 1935     1  CHN NL 146 589  85 162  28  12  8  82   4 NA  39  61\n#> 3109 cavarph01 1936     1  CHN NL 124 458  55 125  18   1  9  56   8 NA  17  36\n#> 3110 cavarph01 1937     1  CHN NL 106 329  43  94  18   7  5  56   7 NA  32  35\n#> 3111 cavarph01 1938     1  CHN NL  92 268  29  64  11   4  1  28   4 NA  14  27\n#> 3112 cavarph01 1939     1  CHN NL  22  55   4  15   3   1  0   0   2 NA   4   3\n#> 3113 cavarph01 1940     1  CHN NL  65 193  34  54  11   4  2  22   3 NA  31  18\n#> 3114 cavarph01 1941     1  CHN NL 107 346  46  99  18   4  6  40   2 NA  53  28\n#> 3115 cavarph01 1942     1  CHN NL 136 482  59 130  28   4  3  54   7 NA  71  42\n#> 3116 cavarph01 1943     1  CHN NL 143 530  93 154  27   9  8  73   3 NA  75  42\n#> 3117 cavarph01 1944     1  CHN NL 152 614 106 197  35  15  5  82   4 NA  67  42\n#> 3118 cavarph01 1945     1  CHN NL 132 498  94 177  34  10  6  97   5 NA  81  34\n#> 3119 cavarph01 1946     1  CHN NL 139 510  89 150  28  10  8  78   2 NA  88  54\n#> 3120 cavarph01 1947     1  CHN NL 127 459  56 144  22   5  2  63   2 NA  58  35\n#> 3121 cavarph01 1948     1  CHN NL 111 334  41  93  16   5  3  40   4 NA  35  29\n#> 3122 cavarph01 1949     1  CHN NL 105 360  46 106  22   4  8  49   2 NA  45  31\n#> 3123 cavarph01 1950     1  CHN NL  82 256  49  70  11   1 10  31   1 NA  40  31\n#> 3124 cavarph01 1951     1  CHN NL  89 206  24  64   7   1  6  28   0  0  27  28\n#> 3125 cavarph01 1952     1  CHN NL  41  63   7  15   1   1  1   8   0  0   9   3\n#> 3126 cavarph01 1953     1  CHN NL  27  21   3   6   3   0  0   3   0  0   6   3\n#> 3127 cavarph01 1954     1  CHA AL  71 158  21  50   6   0  3  24   4  0  26  12\n#> 3128 cavarph01 1955     1  CHA AL   6   4   1   0   0   0  0   0   0  0   0   1\n#> 3129 cedence01 1970     1  HOU NL  90 355  46 110  21   4  7  42  17  4  15  57\n#> 3130 cedence01 1971     1  HOU NL 161 611  85 161  40   6 10  81  20  9  25 102\n#> 3131 cedence01 1972     1  HOU NL 139 559 103 179  39   8 22  82  55 21  56  62\n#> 3132 cedence01 1973     1  HOU NL 139 525  86 168  35   2 25  70  56 15  41  79\n#> 3133 cedence01 1974     1  HOU NL 160 610  95 164  29   5 26 102  57 17  64 103\n#> 3134 cedence01 1975     1  HOU NL 131 500  93 144  31   3 13  63  50 17  62  52\n#> 3135 cedence01 1976     1  HOU NL 150 575  89 171  26   5 18  83  58 15  55  51\n#> 3136 cedence01 1977     1  HOU NL 141 530  92 148  36   8 14  71  61 14  47  50\n#> 3137 cedence01 1978     1  HOU NL  50 192  31  54   8   2  7  23  23  2  15  24\n#> 3138 cedence01 1979     1  HOU NL 132 470  57 123  27   4  6  54  30 13  64  52\n#> 3139 cedence01 1980     1  HOU NL 137 499  71 154  32   8 10  73  48 15  66  72\n#> 3140 cedence01 1981     1  HOU NL  82 306  42  83  19   0  5  34  12  7  24  31\n#> 3141 cedence01 1982     1  CIN NL 138 492  52 142  35   1  8  57  16 11  41  41\n#> 3142 cedence01 1983     1  CIN NL  98 332  40  77  16   0  9  39  13  9  33  53\n#> 3143 cedence01 1984     1  CIN NL 110 380  59 105  24   2 10  47  19  3  25  54\n#> 3144 cedence01 1985     1  CIN NL  83 220  24  53  12   0  3  30   9  5  19  35\n#> 3145 cedence01 1985     2  SLN NL  28  76  14  33   4   1  6  19   5  1   5   7\n#> 3146 cedence01 1986     1  LAN NL  37  78   5  18   2   1  0   6   1  1   7  13\n#> 3147 cepedor01 1958     1  SFN NL 148 603  88 188  38   4 25  96  15 11  29  84\n#> 3148 cepedor01 1959     1  SFN NL 151 605  92 192  35   4 27 105  23  9  33 100\n#> 3149 cepedor01 1960     1  SFN NL 151 569  81 169  36   3 24  96  15  6  34  91\n#> 3150 cepedor01 1961     1  SFN NL 152 585 105 182  28   4 46 142  12  8  39  91\n#> 3151 cepedor01 1962     1  SFN NL 162 625 105 191  26   1 35 114  10  4  37  97\n#> 3152 cepedor01 1963     1  SFN NL 156 579 100 183  33   4 34  97   8  3  37  70\n#> 3153 cepedor01 1964     1  SFN NL 142 529  75 161  27   2 31  97   9  4  43  83\n#> 3154 cepedor01 1965     1  SFN NL  33  34   1   6   1   0  1   5   0  0   3   9\n#> 3155 cepedor01 1966     1  SFN NL  19  49   5  14   2   0  3  15   0  1   4  11\n#> 3156 cepedor01 1966     2  SLN NL 123 452  65 137  24   0 17  58   9  8  34  68\n#> 3157 cepedor01 1967     1  SLN NL 151 563  91 183  37   0 25 111  11  2  62  75\n#> 3158 cepedor01 1968     1  SLN NL 157 600  71 149  26   2 16  73   8  6  43  96\n#> 3159 cepedor01 1969     1  ATL NL 154 573  74 147  28   2 22  88  12  5  55  76\n#> 3160 cepedor01 1970     1  ATL NL 148 567  87 173  33   0 34 111   6  5  47  75\n#> 3161 cepedor01 1971     1  ATL NL  71 250  31  69  10   1 14  44   3  6  22  29\n#> 3162 cepedor01 1972     2  OAK AL   3   3   0   0   0   0  0   0   0  0   0   0\n#> 3163 cepedor01 1972     1  ATL NL  28  84   6  25   3   0  4   9   0  0   7  17\n#> 3164 cepedor01 1973     1  BOS AL 142 550  51 159  25   0 20  86   0  2  50  81\n#> 3165 cepedor01 1974     1  KCA AL  33 107   3  23   5   0  1  18   1  0   9  16\n#> 3166 ceronri01 1975     1  CLE AL   7  12   1   3   1   0  0   0   0  0   1   0\n#> 3167 ceronri01 1976     1  CLE AL   7  16   1   2   0   0  0   1   0  0   0   2\n#> 3168 ceronri01 1977     1  TOR AL  31 100   7  20   4   0  1  10   0  0   6  12\n#> 3169 ceronri01 1978     1  TOR AL  88 282  25  63   8   2  3  20   0  3  23  32\n#> 3170 ceronri01 1979     1  TOR AL 136 469  47 112  27   4  7  61   1  4  37  40\n#> 3171 ceronri01 1980     1  NYA AL 147 519  70 144  30   4 14  85   1  3  32  56\n#> 3172 ceronri01 1981     1  NYA AL  71 234  23  57  13   2  2  21   0  2  12  24\n#> 3173 ceronri01 1982     1  NYA AL  89 300  29  68  10   0  5  28   0  2  19  27\n#> 3174 ceronri01 1983     1  NYA AL  80 246  18  54   7   0  2  22   0  0  15  29\n#> 3175 ceronri01 1984     1  NYA AL  38 120   8  25   3   0  2  13   1  0   9  15\n#> 3176 ceronri01 1985     1  ATL NL  96 282  15  61   9   0  3  25   0  3  29  25\n#> 3177 ceronri01 1986     1  ML4 AL  68 216  22  56  14   0  4  18   1  1  15  28\n#> 3178 ceronri01 1987     1  NYA AL 113 284  28  69  12   1  4  23   0  1  30  46\n#> 3179 ceronri01 1988     1  BOS AL  84 264  31  71  13   1  3  27   0  0  20  32\n#> 3180 ceronri01 1989     1  BOS AL 102 296  28  72  16   1  4  48   0  0  34  40\n#> 3181 ceronri01 1990     1  NYA AL  49 139  12  42   6   0  2  11   0  0   5  13\n#> 3182 ceronri01 1991     1  NYN NL  90 227  18  62  13   0  2  16   1  1  30  24\n#> 3183 ceronri01 1992     1  MON NL  33  63  10  17   4   0  1   7   1  2   3   5\n#> 3184  cervbo01 1951     1  NYA AL  12  28   4   6   1   0  0   2   0  0   4   6\n#> 3185  cervbo01 1952     1  NYA AL  36  87  11  21   3   2  1   8   0  1   9  22\n#> 3186  cervbo01 1953     1  NYA AL   8   6   0   0   0   0  0   0   0  0   1   1\n#> 3187  cervbo01 1954     1  NYA AL  56 100  14  26   6   0  5  13   0  2  11  17\n#> 3188  cervbo01 1955     1  NYA AL  55  85  17  29   4   2  3  22   4  0   7  16\n#> 3189  cervbo01 1956     1  NYA AL  54 115  16  35   5   6  3  25   0  1  18  13\n#> 3190  cervbo01 1957     1  KC1 AL 124 345  35  94  14   2 11  44   1  1  20  57\n#> 3191  cervbo01 1958     1  KC1 AL 141 515  93 157  20   7 38 104   3  3  50  82\n#> 3192  cervbo01 1959     1  KC1 AL 125 463  61 132  22   4 20  87   3  2  35  87\n#> 3193  cervbo01 1960     1  KC1 AL  23  78  14  20   1   1  6  12   0  0  10  17\n#> 3194  cervbo01 1960     2  NYA AL  87 216  32  54  11   1  8  28   0  0  30  36\n#> 3195  cervbo01 1961     1  LAA AL  18  57   3   9   3   0  2   6   0  0   1   8\n#> 3196  cervbo01 1961     2  NYA AL  57 118  17  32   5   1  6  20   1  0  12  17\n#> 3197  cervbo01 1962     1  NYA AL  14  17   1   2   1   0  0   0   0  0   2   3\n#> 3198  cervbo01 1962     2  HOU NL  19  31   2   7   0   0  2   3   0  0   2  10\n#> 3199   ceyro01 1971     1  LAN NL   2   2   0   0   0   0  0   0   0  0   0   2\n#> 3200   ceyro01 1972     1  LAN NL  11  37   3  10   1   0  1   3   0  0   7  10\n#> 3201   ceyro01 1973     1  LAN NL 152 507  60 124  18   4 15  80   1  1  74  77\n#> 3202   ceyro01 1974     1  LAN NL 159 577  88 151  20   2 18  97   1  1  76  68\n#> 3203   ceyro01 1975     1  LAN NL 158 566  72 160  29   2 25 101   5  2  78  74\n#> 3204   ceyro01 1976     1  LAN NL 145 502  69 139  18   3 23  80   0  4  89  74\n#> 3205   ceyro01 1977     1  LAN NL 153 564  77 136  22   3 30 110   3  4  93 106\n#> 3206   ceyro01 1978     1  LAN NL 159 555  84 150  32   0 23  84   2  5  96  96\n#> 3207   ceyro01 1979     1  LAN NL 150 487  77 137  20   1 28  81   3  3  86  85\n#> 3208   ceyro01 1980     1  LAN NL 157 551  81 140  25   0 28  77   2  2  69  92\n#> 3209   ceyro01 1981     1  LAN NL  85 312  42  90  15   2 13  50   0  2  40  55\n#> 3210   ceyro01 1982     1  LAN NL 150 556  62 141  23   1 24  79   3  2  57  99\n#> 3211   ceyro01 1983     1  CHN NL 159 581  73 160  33   1 24  90   0  0  62  85\n#> 3212   ceyro01 1984     1  CHN NL 146 505  71 121  27   0 25  97   3  2  61 108\n#> 3213   ceyro01 1985     1  CHN NL 145 500  64 116  18   2 22  63   1  1  58 106\n#> 3214   ceyro01 1986     1  CHN NL  97 256  42  70  21   0 13  36   0  0  44  66\n#> 3215   ceyro01 1987     1  OAK AL  45 104  12  23   6   0  4  11   0  0  22  32\n#> 3216 chambch01 1971     1  CLE AL 111 415  49 114  20   4  9  48   2  0  40  83\n#> 3217 chambch01 1972     1  CLE AL 121 466  51 136  27   2  6  44   3  4  26  63\n#> 3218 chambch01 1973     1  CLE AL 155 572  70 156  30   2 11  53   4  8  58  76\n#> 3219 chambch01 1974     1  CLE AL  17  67   8  22   4   0  0   7   0  1   5   5\n#> 3220 chambch01 1974     2  NYA AL 110 400  38  97  16   3  6  43   0  0  23  43\n#> 3221 chambch01 1975     1  NYA AL 150 562  66 171  38   4  9  72   0  1  29  50\n#> 3222 chambch01 1976     1  NYA AL 156 641  79 188  32   6 17  96   1  0  27  80\n#> 3223 chambch01 1977     1  NYA AL 157 600  90 172  32   6 17  90   4  0  45  73\n#> 3224 chambch01 1978     1  NYA AL 162 625  81 171  26   3 12  90   2  1  41  60\n#> 3225 chambch01 1979     1  NYA AL 149 554  61 155  27   3 18  63   3  2  34  53\n#> 3226 chambch01 1980     1  ATL NL 158 602  83 170  37   2 18  72   7  3  49  73\n#> 3227 chambch01 1981     1  ATL NL 107 404  44 110  25   2  8  51   4  1  44  41\n#> 3228 chambch01 1982     1  ATL NL 157 534  57 144  25   2 20  86   7  3  57  57\n#> 3229 chambch01 1983     1  ATL NL 131 447  59 125  24   3 20  78   2  7  63  68\n#> 3230 chambch01 1984     1  ATL NL 135 389  47 100  14   0  9  44   1  2  58  54\n#> 3231 chambch01 1985     1  ATL NL 101 170  16  40   7   0  3  21   0  0  18  22\n#> 3232 chambch01 1986     1  ATL NL  97 122  13  38   8   0  2  14   0  2  15  24\n#> 3233 chambch01 1988     1  NYA AL   1   1   0   0   0   0  0   0   0  0   0   1\n#> 3234 chancfr01 1898     1  CHN NL  53 147  32  41   4   3  1  14   7 NA   7  NA\n#> 3235 chancfr01 1899     1  CHN NL  64 192  37  55   6   2  1  22  10 NA  15  NA\n#> 3236 chancfr01 1900     1  CHN NL  56 149  26  44   9   3  0  13   8 NA  15  NA\n#> 3237 chancfr01 1901     1  CHN NL  69 241  38  67  12   4  0  36  27 NA  29  NA\n#> 3238 chancfr01 1902     1  CHN NL  75 240  39  69   9   4  1  31  27 NA  35  NA\n#> 3239 chancfr01 1903     1  CHN NL 125 441  83 144  24  10  2  81  67 NA  78  NA\n#> 3240 chancfr01 1904     1  CHN NL 124 451  89 140  16  10  6  49  42 NA  36  NA\n#> 3241 chancfr01 1905     1  CHN NL 118 392  92 124  16  12  2  70  38 NA  78  NA\n#> 3242 chancfr01 1906     1  CHN NL 136 474 103 151  24  10  3  71  57 NA  70  NA\n#> 3243 chancfr01 1907     1  CHN NL 111 382  58 112  19   2  1  49  35 NA  51  NA\n#> 3244 chancfr01 1908     1  CHN NL 129 452  65 123  27   4  2  55  27 NA  37  NA\n#> 3245 chancfr01 1909     1  CHN NL  93 324  53  88  16   4  0  46  29 NA  30  NA\n#> 3246 chancfr01 1910     1  CHN NL  88 295  54  88  12   8  0  36  16 NA  37  15\n#> 3247 chancfr01 1911     1  CHN NL  31  88  23  21   6   3  1  17   9 NA  25  13\n#> 3248 chancfr01 1912     1  CHN NL   2   5   2   1   0   0  0   0   1 NA   3   0\n#> 3249 chancfr01 1913     1  NYA AL  12  24   3   5   0   0  0   6   1 NA   8   1\n#> 3250 chancfr01 1914     1  NYA AL   1   0   0   0   0   0  0   0   0 NA   0   0\n#> 3251 chapmbe01 1930     1  NYA AL 138 513  74 162  31  10 10  81  14  6  43  58\n#> 3252 chapmbe01 1931     1  NYA AL 149 600 120 189  28  11 17 122  61 23  75  77\n#> 3253 chapmbe01 1932     1  NYA AL 151 581 101 174  41  15 10 107  38 18  71  55\n#> 3254 chapmbe01 1933     1  NYA AL 147 565 112 176  36   4  9  98  27 18  72  45\n#> 3255 chapmbe01 1934     1  NYA AL 149 588  82 181  21  13  5  86  26 16  67  68\n#> 3256 chapmbe01 1935     1  NYA AL 140 553 118 160  38   8  8  74  17 10  61  39\n#> 3257 chapmbe01 1936     1  NYA AL  36 139  19  37  14   3  1  21   1  2  15  20\n#> 3258 chapmbe01 1936     2  WS1 AL  97 401  91 133  36   7  4  60  19  7  69  18\n#> 3259 chapmbe01 1937     1  WS1 AL  35 130  23  34   7   1  0  12   8  0  26   7\n#> 3260 chapmbe01 1937     2  BOS AL 113 423  76 130  23  11  7  57  27 12  57  35\n#> 3261 chapmbe01 1938     1  BOS AL 127 480  92 163  40   8  6  80  13  6  65  33\n#> 3262 chapmbe01 1939     1  CLE AL 149 545 101 158  31   9  6  82  18  6  87  30\n#> 3263 chapmbe01 1940     1  CLE AL 143 548  82 157  40   6  4  50  13  7  78  45\n#> 3264 chapmbe01 1941     1  WS1 AL  28 110   9  28   6   0  1  10   2  2  10   6\n#> 3265 chapmbe01 1941     2  CHA AL  57 190  26  43   9   1  2  19   2  2  19  14\n#> 3266 chapmbe01 1944     1  BRO NL  20  38  11  14   4   0  0  11   1 NA   5   4\n#> 3267 chapmbe01 1945     1  BRO NL  13  22   2   3   0   0  0   3   0 NA   2   1\n#> 3268 chapmbe01 1945     2  PHI NL  24  51   4  16   2   0  0   4   0 NA   2   1\n#> 3269 chapmbe01 1946     1  PHI NL   1   1   1   0   0   0  0   0   0 NA   0   0\n#> 3270 charlno01 1988     1  CIN NL  10  15   1   0   0   0  0   0   0  0   0  12\n#> 3271 charlno01 1989     1  CIN NL  69   5   0   0   0   0  0   0   0  0   0   4\n#> 3272 charlno01 1990     1  CIN NL  57  37   4   5   0   0  0   0   0  0   3  21\n#> 3273 charlno01 1991     1  CIN NL  41  23   1   1   1   0  0   0   0  0   0  10\n#> 3274 charlno01 1992     1  CIN NL  64   5   0   1   0   0  0   0   0  0   0   3\n#> 3275 charlno01 1993     1  SEA AL  34   0   0   0   0   0  0   0   0  0   0   0\n#> 3276 charlno01 1995     2  SEA AL  30   0   0   0   0   0  0   0   0  0   0   0\n#> 3277 charlno01 1995     1  PHI NL  25   1   0   1   1   0  0   1   0  0   0   0\n#> 3278 charlno01 1996     1  SEA AL  70   0   0   0   0   0  0   0   0  0   0   0\n#> 3279 charlno01 1997     1  SEA AL  71   0   0   0   0   0  0   0   0  0   0   0\n#> 3280 charlno01 1998     1  BAL AL  36   0   0   0   0   0  0   0   0  0   0   0\n#> 3281 charlno01 1998     2  ATL NL  13   1   0   0   0   0  0   0   0  0   0   0\n#> 3282 charlno01 1999     1  TBA AL  42   0   0   0   0   0  0   0   0  0   0   0\n#> 3283 charlno01 2000     1  CIN NL   2   0   0   0   0   0  0   0   0  0   0   0\n#> 3284 charlno01 2001     1  SEA AL   1   0   0   0   0   0  0   0   0  0   0   0\n#> 3285 chaseha01 1905     1  NYA AL 128 465  60 116  16   6  3  49  22 NA  15  NA\n#> 3286 chaseha01 1906     1  NYA AL 151 597  84 193  23  10  0  76  28 NA  13  NA\n#> 3287 chaseha01 1907     1  NYA AL 125 498  72 143  23   3  2  68  32 NA  19  NA\n#> 3288 chaseha01 1908     1  NYA AL 106 405  50 104  11   3  1  36  27 NA  15  NA\n#> 3289 chaseha01 1909     1  NYA AL 118 474  60 134  17   3  4  63  25 NA  20  NA\n#> 3290 chaseha01 1910     1  NYA AL 130 524  67 152  20   5  3  73  40 NA  16  NA\n#> 3291 chaseha01 1911     1  NYA AL 133 527  82 166  32   7  3  62  36 NA  21  NA\n#> 3292 chaseha01 1912     1  NYA AL 131 522  61 143  21   9  4  58  33 NA  17  NA\n#> 3293 chaseha01 1913     1  NYA AL  39 146  15  31   2   4  0   9   5 NA  11  13\n#> 3294 chaseha01 1913     2  CHA AL 102 384  49 110  11  10  2  39   9 NA  16  41\n#> 3295 chaseha01 1914     1  CHA AL  58 206  27  55  10   5  0  20   9  4  23  19\n#> 3296 chaseha01 1914     2  BUF FL  75 291  43 101  19   9  3  48  10 NA   6  31\n#> 3297 chaseha01 1915     1  BUF FL 145 567  85 165  31  10 17  89  23 NA  20  50\n#> 3298 chaseha01 1916     1  CIN NL 142 542  66 184  29  12  4  82  22 11  19  48\n#> 3299 chaseha01 1917     1  CIN NL 152 602  71 167  28  15  4  86  21 NA  15  49\n#> 3300 chaseha01 1918     1  CIN NL  74 259  30  78  12   6  2  38   5 NA  13  15\n#> 3301 chaseha01 1919     1  NY1 NL 110 408  58 116  17   7  5  45  16 NA  17  40\n#> 3302 cicoted01 1905     1  DET AL   3   7   1   3   0   0  0   0   0 NA   0  NA\n#> 3303 cicoted01 1908     1  BOS AL  40  72  10  17   2   1  0   6   1 NA   3  NA\n#> 3304 cicoted01 1909     1  BOS AL  27  51   4  12   0   0  0   1   2 NA   7  NA\n#> 3305 cicoted01 1910     1  BOS AL  36  85   9  12   3   0  0   4   0 NA   8  NA\n#> 3306 cicoted01 1911     1  BOS AL  35  71   7  10   1   0  0   3   0 NA   8  NA\n#> 3307 cicoted01 1912     1  BOS AL   9  13   1   2   0   0  0   1   0 NA   4  NA\n#> 3308 cicoted01 1912     2  CHA AL  20  53  10  13   2   0  0   3   0 NA   2  NA\n#> 3309 cicoted01 1913     1  CHA AL  41  91   7  13   2   0  0   2   0 NA   4  16\n#> 3310 cicoted01 1914     1  CHA AL  45  86   5  14   2   0  0   4   0 NA   3  18\n#> 3311 cicoted01 1915     1  CHA AL  40  67  10  14   1   0  0   4   0 NA   7  16\n#> 3312 cicoted01 1916     1  CHA AL  44  57   6  12   2   0  0   4   0 NA   4  16\n#> 3313 cicoted01 1917     1  CHA AL  49 112   6  20   2   0  0   8   1 NA  12  23\n#> 3314 cicoted01 1918     1  CHA AL  38  86   6  14   5   1  0   4   0 NA  12  12\n#> 3315 cicoted01 1919     1  CHA AL  40  99   5  20   0   1  0   8   0 NA   9  18\n#> 3316 cicoted01 1920     1  CHA AL  37 112  10  22   2   0  0   6   2  0   5  10\n#> 3317 cirilje01 1994     1  ML4 AL  39 126  17  30   9   0  3  12   0  1  11  16\n#> 3318 cirilje01 1995     1  ML4 AL 125 328  57  91  19   4  9  39   7  2  47  42\n#> 3319 cirilje01 1996     1  ML4 AL 158 566 101 184  46   5 15  83   4  9  58  69\n#> 3320 cirilje01 1997     1  ML4 AL 154 580  74 167  46   2 10  82   4  3  60  74\n#> 3321 cirilje01 1998     1  MIL NL 156 604  97 194  31   1 14  68  10  4  79  88\n#> 3322 cirilje01 1999     1  MIL NL 157 607  98 198  35   1 15  88   7  4  75  83\n#> 3323 cirilje01 2000     1  COL NL 157 598 111 195  53   2 11 115   3  4  67  72\n#> 3324 cirilje01 2001     1  COL NL 138 528  72 165  26   4 17  83  12  2  43  63\n#> 3325 cirilje01 2002     1  SEA AL 146 485  51 121  20   0  6  54   8  4  31  67\n#> 3326 cirilje01 2003     1  SEA AL  87 258  24  53  11   0  2  23   1  1  24  32\n#> 3327 cirilje01 2004     1  SDN NL  33  75  12  16   3   0  1   7   0  0   5  14\n#> 3328 cirilje01 2006     1  MIL NL 112 263  33  84  16   0  3  23   1  1  21  33\n#> 3329 cirilje01 2005     1  MIL NL  77 185  29  52  15   0  4  23   4  2  23  22\n#> 3330 cirilje01 2007     2  ARI NL  28  40   6   8   4   0  0   6   0  0   4   6\n#> 3331 cirilje01 2007     1  MIN AL  50 153  18  40   9   2  2  21   2  0  15  13\n#> 3332 clancji01 1977     1  TOR AL  13   0   0   0   0   0  0   0   0  0   0   0\n#> 3333 clancji01 1978     1  TOR AL  31   0   0   0   0   0  0   0   0  0   0   0\n#> 3334 clancji01 1979     1  TOR AL  12   0   0   0   0   0  0   0   0  0   0   0\n#> 3335 clancji01 1980     1  TOR AL  34   0   0   0   0   0  0   0   0  0   0   0\n#> 3336 clancji01 1981     1  TOR AL  22   0   0   0   0   0  0   0   0  0   0   0\n#> 3337 clancji01 1982     1  TOR AL  40   0   0   0   0   0  0   0   0  0   0   0\n#> 3338 clancji01 1983     1  TOR AL  34   0   0   0   0   0  0   0   0  0   0   0\n#> 3339 clancji01 1984     1  TOR AL  36   0   0   0   0   0  0   0   0  0   0   0\n#> 3340 clancji01 1985     1  TOR AL  23   0   0   0   0   0  0   0   0  0   0   0\n#> 3341 clancji01 1986     1  TOR AL  34   0   0   0   0   0  0   0   0  0   0   0\n#> 3342 clancji01 1987     1  TOR AL  37   0   0   0   0   0  0   0   0  0   0   0\n#> 3343 clancji01 1988     1  TOR AL  36   0   0   0   0   0  0   0   0  0   0   0\n#> 3344 clancji01 1989     1  HOU NL  33  41   3   6   1   0  0   0   0  0   1  14\n#> 3345 clancji01 1990     1  HOU NL  33  14   1   3   0   0  0   2   0  0   0   4\n#> 3346 clancji01 1991     1  HOU NL  30   3   0   0   0   0  0   0   0  0   0   1\n#> 3347 clancji01 1991     2  ATL NL  24   3   0   0   0   0  0   0   0  0   0   1\n#> 3348 clarkfr01 1894     1  LS3 NL  75 310  54  83  11   7  7  48  25 NA  25  27\n#> 3349 clarkfr01 1895     1  LS3 NL 132 550  96 191  21   5  4  82  40 NA  34  24\n#> 3350 clarkfr01 1896     1  LS3 NL 131 517  96 168  15  18  9  79  34 NA  43  34\n#> 3351 clarkfr01 1897     1  LS3 NL 128 518 120 202  30  13  6  67  57 NA  45  NA\n#> 3352 clarkfr01 1898     1  LS3 NL 149 599 116 184  23  12  3  47  40 NA  48  NA\n#> 3353 clarkfr01 1899     1  LS3 NL 148 602 122 206  23   9  5  70  49 NA  49  NA\n#> 3354 clarkfr01 1900     1  PIT NL 106 399  84 110  15  12  3  32  21 NA  51  NA\n#> 3355 clarkfr01 1901     1  PIT NL 129 527 118 171  24  15  6  60  23 NA  51  NA\n#> 3356 clarkfr01 1902     1  PIT NL 113 459 103 145  27  14  2  53  29 NA  51  NA\n#> 3357 clarkfr01 1903     1  PIT NL 104 427  88 150  32  15  5  70  21 NA  41  NA\n#> 3358 clarkfr01 1904     1  PIT NL  72 278  51  85   7  11  0  25  11 NA  22  NA\n#> 3359 clarkfr01 1905     1  PIT NL 141 525  95 157  18  15  2  51  24 NA  55  NA\n#> 3360 clarkfr01 1906     1  PIT NL 118 417  69 129  14  13  1  39  18 NA  40  NA\n#> 3361 clarkfr01 1907     1  PIT NL 148 501  97 145  18  13  2  59  37 NA  68  NA\n#> 3362 clarkfr01 1908     1  PIT NL 151 551  83 146  18  15  2  53  24 NA  65  NA\n#> 3363 clarkfr01 1909     1  PIT NL 152 550  97 158  16  11  3  68  31 NA  80  NA\n#> 3364 clarkfr01 1910     1  PIT NL 123 429  57 113  23   9  2  63  12 NA  53  23\n#> 3365 clarkfr01 1911     1  PIT NL 110 392  73 127  25  13  5  49  10 NA  53  27\n#> 3366 clarkfr01 1913     1  PIT NL   9  13   0   1   1   0  0   0   0 NA   0   0\n#> 3367 clarkfr01 1914     1  PIT NL   2   2   0   0   0   0  0   0   0 NA   0   0\n#> 3368 clarkfr01 1915     1  PIT NL   1   2   0   1   0   0  0   0   0 NA   0   0\n#> 3369 clarkja01 1975     1  SFN NL   8  17   3   4   0   0  0   2   1  0   1   2\n#> 3370 clarkja01 1976     1  SFN NL  26 102  14  23   6   2  2  10   6  2   8  18\n#> 3371 clarkja01 1977     1  SFN NL 136 413  64 104  17   4 13  51  12  4  49  73\n#> 3372 clarkja01 1978     1  SFN NL 156 592  90 181  46   8 25  98  15 11  50  72\n#> 3373 clarkja01 1979     1  SFN NL 143 527  84 144  25   2 26  86  11  8  63  95\n#> 3374 clarkja01 1980     1  SFN NL 127 437  77 124  20   8 22  82   2  5  74  52\n#> 3375 clarkja01 1981     1  SFN NL  99 385  60 103  19   2 17  53   1  1  45  45\n#> 3376 clarkja01 1982     1  SFN NL 157 563  90 154  30   3 27 103   6  9  90  91\n#> 3377 clarkja01 1983     1  SFN NL 135 492  82 132  25   0 20  66   5  3  74  79\n#> 3378 clarkja01 1984     1  SFN NL  57 203  33  65   9   1 11  44   1  1  43  29\n#> 3379 clarkja01 1985     1  SLN NL 126 442  71 124  26   3 22  87   1  4  83  88\n#> 3380 clarkja01 1986     1  SLN NL  65 232  34  55  12   2  9  23   1  1  45  61\n#> 3381 clarkja01 1987     1  SLN NL 131 419  93 120  23   1 35 106   1  2 136 139\n#> 3382 clarkja01 1988     1  NYA AL 150 496  81 120  14   0 27  93   3  2 113 141\n#> 3383 clarkja01 1989     1  SDN NL 142 455  76 110  19   1 26  94   6  2 132 145\n#> 3384 clarkja01 1990     1  SDN NL 115 334  59  89  12   1 25  62   4  3 104  91\n#> 3385 clarkja01 1991     1  BOS AL 140 481  75 120  18   1 28  87   0  2  96 133\n#> 3386 clarkja01 1992     1  BOS AL  81 257  32  54  11   0  5  33   1  1  56  87\n#> 3387 clarkwi02 1986     1  SFN NL 111 408  66 117  27   2 11  41   4  7  34  76\n#> 3388 clarkwi02 1987     1  SFN NL 150 529  89 163  29   5 35  91   5 17  49  98\n#> 3389 clarkwi02 1988     1  SFN NL 162 575 102 162  31   6 29 109   9  1 100 129\n#> 3390 clarkwi02 1989     1  SFN NL 159 588 104 196  38   9 23 111   8  3  74 103\n#> 3391 clarkwi02 1990     1  SFN NL 154 600  91 177  25   5 19  95   8  2  62  97\n#> 3392 clarkwi02 1991     1  SFN NL 148 565  84 170  32   7 29 116   4  2  51  91\n#> 3393 clarkwi02 1992     1  SFN NL 144 513  69 154  40   1 16  73  12  7  73  82\n#> 3394 clarkwi02 1993     1  SFN NL 132 491  82 139  27   2 14  73   2  2  63  68\n#> 3395 clarkwi02 1994     1  TEX AL 110 389  73 128  24   2 13  80   5  1  71  59\n#> 3396 clarkwi02 1995     1  TEX AL 123 454  85 137  27   3 16  92   0  1  68  50\n#> 3397 clarkwi02 1996     1  TEX AL 117 436  69 124  25   1 13  72   2  1  64  67\n#> 3398 clarkwi02 1997     1  TEX AL 110 393  56 128  29   1 12  51   0  0  49  62\n#> 3399 clarkwi02 1998     1  TEX AL 149 554  98 169  41   1 23 102   1  0  72  97\n#> 3400 clarkwi02 1999     1  BAL AL  77 251  40  76  15   0 10  29   2  2  38  42\n#> 3401 clarkwi02 2000     1  BAL AL  79 256  49  77  15   1  9  28   4  2  47  45\n#> 3402 clarkwi02 2000     2  SLN NL  51 171  29  59  15   1 12  42   1  0  22  24\n#> 3403 claytro01 1991     1  SFN NL   9  26   0   3   1   0  0   2   0  0   1   6\n#> 3404 claytro01 1992     1  SFN NL  98 321  31  72   7   4  4  24   8  4  26  63\n#> 3405 claytro01 1993     1  SFN NL 153 549  54 155  21   5  6  70  11 10  38  91\n#> 3406 claytro01 1994     1  SFN NL 108 385  38  91  14   6  3  30  23  3  30  74\n#> 3407 claytro01 1995     1  SFN NL 138 509  56 124  29   3  5  58  24  9  38 109\n#> 3408 claytro01 1996     1  SLN NL 129 491  64 136  20   4  6  35  33 15  33  89\n#> 3409 claytro01 1997     1  SLN NL 154 576  75 153  39   5  9  61  30 10  33 109\n#> 3410 claytro01 1998     2  TEX AL  52 186  30  53  12   1  5  24   5  5  13  32\n#> 3411 claytro01 1998     1  SLN NL  90 355  59  83  19   1  4  29  19  6  40  51\n#> 3412 claytro01 1999     1  TEX AL 133 465  69 134  21   5 14  52   8  6  39 100\n#> 3413 claytro01 2000     1  TEX AL 148 513  70 124  21   5 14  54  11  7  42  92\n#> 3414 claytro01 2001     1  CHA AL 135 433  62 114  21   4  9  60  10  7  33  72\n#> 3415 claytro01 2002     1  CHA AL 112 342  51  86  14   2  7  35   5  1  20  67\n#> 3416 claytro01 2003     1  MIL NL 146 483  49 110  16   1 11  39   5  2  49  92\n#> 3417 claytro01 2004     1  COL NL 146 574  95 160  36   4  8  54  10  5  48 125\n#> 3418 claytro01 2005     1  ARI NL 143 522  59 141  28   4  2  44  13  3  38 105\n#> 3419 claytro01 2006     1  WAS NL  87 305  36  82  22   1  0  27   8  3  19  53\n#> 3420 claytro01 2006     2  CIN NL  50 149  13  35   8   0  2  13   6  3  11  32\n#> 3421 claytro01 2007     2  BOS AL   8   6   1   0   0   0  0   0   0  0   0   3\n#> 3422 claytro01 2007     1  TOR AL  69 189  23  48  14   0  1  12   2  1  14  50\n#> 3423 clemeja01 1884     2  PHI NL   9  30   3   7   0   0  0   0  NA NA   4   8\n#> 3424 clemeja01 1884     1  PHU UA  41 177  37  50  13   2  3  NA   0 NA   9  NA\n#> 3425 clemeja01 1885     1  PHI NL  52 188  14  36  11   3  1  14  NA NA   2  30\n#> 3426 clemeja01 1886     1  PHI NL  54 185  15  38   5   1  0  11   4 NA   7  34\n#> 3427 clemeja01 1887     1  PHI NL  66 246  48  69  13   7  1  47   7 NA   9  24\n#> 3428 clemeja01 1888     1  PHI NL  86 326  26  80   8   4  1  32   3 NA  10  36\n#> 3429 clemeja01 1889     1  PHI NL  78 310  51  88  17   1  4  35   3 NA  29  21\n#> 3430 clemeja01 1890     1  PHI NL  97 381  64 120  23   8  7  74  10 NA  45  30\n#> 3431 clemeja01 1891     1  PHI NL 107 423  58 131  29   4  4  75   3 NA  43  19\n#> 3432 clemeja01 1892     1  PHI NL 109 402  50 106  25   6  8  76   7 NA  43  40\n#> 3433 clemeja01 1893     1  PHI NL  94 376  64 107  20   3 17  80   3 NA  39  29\n#> 3434 clemeja01 1894     1  PHI NL  45 159  26  55   6   5  3  36   6 NA  24   7\n#> 3435 clemeja01 1895     1  PHI NL  88 322  64 127  27   2 13  75   3 NA  22   7\n#> 3436 clemeja01 1896     1  PHI NL  57 184  35  66   5   7  5  45   2 NA  17  14\n#> 3437 clemeja01 1897     1  PHI NL  55 185  18  44   4   2  6  36   3 NA  12  NA\n#> 3438 clemeja01 1898     1  SLN NL  99 335  39  86  19   5  3  41   1 NA  21  NA\n#> 3439 clemeja01 1899     1  CL4 NL   4  12   1   3   0   0  0   0   0 NA   0  NA\n#> 3440 clemeja01 1900     1  BSN NL  16  42   6  13   1   0  1  10   0 NA   3  NA\n#> 3441 clemero01 1955     1  PIT NL 124 474  48 121  23  11  5  47   2  5  18  60\n#> 3442 clemero01 1956     1  PIT NL 147 543  66 169  30   7  7  60   6  6  13  58\n#> 3443 clemero01 1957     1  PIT NL 111 451  42 114  17   7  4  30   0  4  23  45\n#> 3444 clemero01 1958     1  PIT NL 140 519  69 150  24  10  6  50   8  2  31  41\n#> 3445 clemero01 1959     1  PIT NL 105 432  60 128  17   7  4  50   2  3  15  51\n#> 3446 clemero01 1960     1  PIT NL 144 570  89 179  22   6 16  94   4  5  39  72\n#> 3447 clemero01 1961     1  PIT NL 146 572 100 201  30  10 23  89   4  1  35  59\n#> 3448 clemero01 1962     1  PIT NL 144 538  95 168  28   9 10  74   6  4  35  73\n#> 3449 clemero01 1963     1  PIT NL 152 600  77 192  23   8 17  76  12  2  31  64\n#> 3450 clemero01 1964     1  PIT NL 155 622  95 211  40   7 12  87   5  2  51  87\n#> 3451 clemero01 1965     1  PIT NL 152 589  91 194  21  14 10  65   8  0  43  78\n#> 3452 clemero01 1966     1  PIT NL 154 638 105 202  31  11 29 119   7  5  46 109\n#> 3453 clemero01 1967     1  PIT NL 147 585 103 209  26  10 23 110   9  1  41 103\n#> 3454 clemero01 1968     1  PIT NL 132 502  74 146  18  12 18  57   2  3  51  77\n#> 3455 clemero01 1969     1  PIT NL 138 507  87 175  20  12 19  91   4  1  56  73\n#> 3456 clemero01 1970     1  PIT NL 108 412  65 145  22  10 14  60   3  0  38  66\n#> 3457 clemero01 1971     1  PIT NL 132 522  82 178  29   8 13  86   1  2  26  65\n#> 3458 clemero01 1972     1  PIT NL 102 378  68 118  19   7 10  60   0  0  29  49\n#> 3459 clemero02 1984     1  BOS AL  21   0   0   0   0   0  0   0   0  0   0   0\n#> 3460 clemero02 1985     1  BOS AL  15   0   0   0   0   0  0   0   0  0   0   0\n#> 3461 clemero02 1986     1  BOS AL  33   0   0   0   0   0  0   0   0  0   0   0\n#> 3462 clemero02 1987     1  BOS AL  36   0   0   0   0   0  0   0   0  0   0   0\n#> 3463 clemero02 1988     1  BOS AL  35   0   0   0   0   0  0   0   0  0   0   0\n#> 3464 clemero02 1989     1  BOS AL  35   0   0   0   0   0  0   0   0  0   0   0\n#> 3465 clemero02 1990     1  BOS AL  31   0   0   0   0   0  0   0   0  0   0   0\n#> 3466 clemero02 1991     1  BOS AL  35   0   0   0   0   0  0   0   0  0   0   0\n#> 3467 clemero02 1992     1  BOS AL  32   0   0   0   0   0  0   0   0  0   0   0\n#> 3468 clemero02 1993     1  BOS AL  29   0   0   0   0   0  0   0   0  0   0   0\n#> 3469 clemero02 1994     1  BOS AL  24   0   0   0   0   0  0   0   0  0   0   0\n#> 3470 clemero02 1995     1  BOS AL  23   0   0   0   0   0  0   0   0  0   0   0\n#> 3471 clemero02 1996     1  BOS AL  34   1   0   1   0   0  0   0   0  0   0   0\n#> 3472 clemero02 1997     1  TOR AL   1   2   1   1   1   0  0   0   0  0   1   0\n#> 3473 clemero02 1998     1  TOR AL   2   4   0   0   0   0  0   0   0  0   1   0\n#> 3474 clemero02 1999     1  NYA AL   2   4   0   0   0   0  0   0   0  0   0   3\n#> 3475 clemero02 2000     1  NYA AL   1   3   0   0   0   0  0   0   0  0   0   1\n#> 3476 clemero02 2001     1  NYA AL   1   2   0   0   0   0  0   0   0  0   0   2\n#> 3477 clemero02 2002     1  NYA AL   3   3   1   2   1   0  0   1   0  0   0   1\n#> 3478 clemero02 2003     1  NYA AL   1   1   0   0   0   0  0   0   0  0   0   1\n#> 3479 clemero02 2004     1  HOU NL  32  72   1  12   1   0  0   7   0  0   3  24\n#> 3480 clemero02 2006     1  HOU NL  19  27   0   2   1   0  0   0   0  0   3  11\n#> 3481 clemero02 2005     1  HOU NL  32  58   2  12   2   0  0   4   0  0   5  18\n#> 3482 clemero02 2007     1  NYA AL   2   2   0   1   0   0  0   0   0  0   0   0\n#> 3483 clinety01 1960     1  CLE AL   7  26   2   8   1   1  0   2   0  0   0   4\n#> 3484 clinety01 1961     1  CLE AL  12  43   9   9   2   1  0   1   1  0   6   1\n#> 3485 clinety01 1962     1  CLE AL 118 375  53  93  15   5  2  28   5  4  28  50\n#> 3486 clinety01 1963     1  ML1 NL  72 174  17  41   2   1  0  10   2  1  10  31\n#> 3487 clinety01 1964     1  ML1 NL 101 116  22  35   4   2  1  13   0  1   8  22\n#> 3488 clinety01 1965     1  ML1 NL 123 220  27  42   5   3  0  10   2  2  16  50\n#> 3489 clinety01 1966     1  CHN NL   7  17   3   6   0   0  0   2   1  0   0   2\n#> 3490 clinety01 1966     2  ATL NL  42  71  12  18   0   0  0   6   2  1   3  11\n#> 3491 clinety01 1967     1  ATL NL  10   8   0   0   0   0  0   0   0  0   0   3\n#> 3492 clinety01 1967     2  SFN NL  64 122  18  33   5   5  0   4   2  1   9  13\n#> 3493 clinety01 1968     1  SFN NL 116 291  37  65   6   3  1  28   0  2  11  26\n#> 3494 clinety01 1969     1  MON NL 101 209  26  50   5   3  2  12   4  3  32  22\n#> 3495 clinety01 1970     1  MON NL   2   2   0   1   0   0  0   0   0  0   0   0\n#> 3496 clinety01 1970     2  CIN NL  48  63  13  17   7   1  0   8   1  2  12  11\n#> 3497 clinety01 1971     1  CIN NL  69  97  12  19   1   0  0   1   2  2  18  16\n#> 3498  cobbty01 1905     1  DET AL  41 150  19  36   6   0  1  15   2 NA  10  NA\n#> 3499  cobbty01 1906     1  DET AL  98 358  45 113  15   5  1  34  23 NA  19  NA\n#> 3500  cobbty01 1907     1  DET AL 150 605  97 212  28  14  5 119  49 NA  24  NA\n#> 3501  cobbty01 1908     1  DET AL 150 581  88 188  36  20  4 108  39 NA  34  NA\n#> 3502  cobbty01 1909     1  DET AL 156 573 116 216  33  10  9 107  76 NA  48  NA\n#> 3503  cobbty01 1910     1  DET AL 140 506 106 194  35  13  8  91  65 NA  64  NA\n#> 3504  cobbty01 1911     1  DET AL 146 591 147 248  47  24  8 127  83 NA  44  NA\n#> 3505  cobbty01 1912     1  DET AL 140 553 120 226  30  23  7  83  61 NA  43  NA\n#> 3506  cobbty01 1913     1  DET AL 122 428  70 167  18  16  4  67  51 NA  58  31\n#> 3507  cobbty01 1914     1  DET AL  98 345  69 127  22  11  2  57  35 17  57  22\n#> 3508  cobbty01 1915     1  DET AL 156 563 144 208  31  13  3  99  96 38 118  43\n#> 3509  cobbty01 1916     1  DET AL 145 542 113 201  31  10  5  68  68 24  78  39\n#> 3510  cobbty01 1917     1  DET AL 152 588 107 225  44  24  6 102  55 NA  61  34\n#> 3511  cobbty01 1918     1  DET AL 111 421  83 161  19  14  3  64  34 NA  41  21\n#> 3512  cobbty01 1919     1  DET AL 124 497  92 191  36  13  1  70  28 NA  38  22\n#> 3513  cobbty01 1920     1  DET AL 112 428  86 143  28   8  2  63  15 10  58  28\n#> 3514  cobbty01 1921     1  DET AL 128 507 124 197  37  16 12 101  22 15  56  19\n#> 3515  cobbty01 1922     1  DET AL 137 526  99 211  42  16  4  99   9 13  55  24\n#> 3516  cobbty01 1923     1  DET AL 145 556 103 189  40   7  6  88   9 10  66  14\n#> 3517  cobbty01 1924     1  DET AL 155 625 115 211  38  10  4  78  23 14  85  18\n#> 3518  cobbty01 1925     1  DET AL 121 415  97 157  31  12 12 102  13  9  65  12\n#> 3519  cobbty01 1926     1  DET AL  79 233  48  79  18   5  4  62   9  4  26   2\n#> 3520  cobbty01 1927     1  PHA AL 134 490 104 175  32   7  5  93  22 16  67  12\n#> 3521  cobbty01 1928     1  PHA AL  95 353  54 114  27   4  1  40   5  8  34  16\n#> 3522 coffmdi01 1927     1  WS1 AL   5   3   1   1   0   0  0   0   0  0   1   2\n#> 3523 coffmdi01 1928     1  SLA AL  29  23   0   1   0   0  0   1   0  0   1   7\n#> 3524 coffmdi01 1929     1  SLA AL  27   7   0   0   0   0  0   0   0  0   0   0\n#> 3525 coffmdi01 1930     1  SLA AL  38  66   4   9   3   0  0   2   0  0   2  18\n#> 3526 coffmdi01 1931     1  SLA AL  32  51   4   4   1   0  0   0   0  0   2  20\n#> 3527 coffmdi01 1932     1  SLA AL   9  22   0   1   0   0  0   0   0  0   3   6\n#> 3528 coffmdi01 1932     2  WS1 AL  22  22   2   2   1   1  0   1   0  0   1   7\n#> 3529 coffmdi01 1933     1  SLA AL  21  27   0   1   1   0  0   3   0  0   2  14\n#> 3530 coffmdi01 1934     1  SLA AL  40  51   3  11   1   0  0   5   0  0   1  23\n#> 3531 coffmdi01 1935     1  SLA AL  41  41   4   6   2   0  0   2   0  0   6  13\n#> 3532 coffmdi01 1936     1  NY1 NL  42  20   1   4   0   0  0   0   0 NA   1   7\n#> 3533 coffmdi01 1937     1  NY1 NL  42  19   1   7   2   0  0   2   0 NA   0   8\n#> 3534 coffmdi01 1938     1  NY1 NL  51  28   0   2   0   0  0   0   0 NA   0  15\n#> 3535 coffmdi01 1939     1  NY1 NL  28   4   0   0   0   0  0   0   0 NA   0   3\n#> 3536 coffmdi01 1940     1  BSN NL  31  12   0   1   0   0  0   0   0 NA   1   7\n#> 3537 coffmdi01 1945     1  PHI NL  14   4   1   1   0   0  0   0   0 NA   1   1\n#> 3538 colavro01 1955     1  CLE AL   5   9   3   4   2   0  0   0   0  0   0   2\n#> 3539 colavro01 1956     1  CLE AL 101 322  55  89  11   4 21  65   0  1  49  46\n#> 3540 colavro01 1957     1  CLE AL 134 461  66 116  26   0 25  84   1  6  71  80\n#> 3541 colavro01 1958     1  CLE AL 143 489  80 148  26   3 41 113   0  2  84  89\n#> 3542 colavro01 1959     1  CLE AL 154 588  90 151  24   0 42 111   3  3  71  86\n#> 3543 colavro01 1960     1  DET AL 145 555  67 138  18   1 35  87   3  6  53  80\n#> 3544 colavro01 1961     1  DET AL 163 583 129 169  30   2 45 140   1  2 113  75\n#> 3545 colavro01 1962     1  DET AL 161 601  90 164  30   2 37 112   2  0  96  68\n#> 3546 colavro01 1963     1  DET AL 160 597  91 162  29   2 22  91   0  0  84  78\n#> 3547 colavro01 1964     1  KC1 AL 160 588  89 161  31   2 34 102   3  1  83  56\n#> 3548 colavro01 1965     1  CLE AL 162 592  92 170  25   2 26 108   1  1  93  63\n#> 3549 colavro01 1966     1  CLE AL 151 533  68 127  13   0 30  72   2  1  76  81\n#> 3550 colavro01 1967     1  CLE AL  63 191  10  46   9   0  5  21   2  2  24  31\n#> 3551 colavro01 1967     2  CHA AL  60 190  20  42   4   1  3  29   1  1  25  10\n#> 3552 colavro01 1968     2  NYA AL  39  91  13  20   2   2  5  13   0  0  14  17\n#> 3553 colavro01 1968     1  LAN NL  40 113   8  23   3   0  3  11   0  1  15  18\n#> 3554 colbrgr01 1992     1  MON NL  52 168  12  45   8   0  2  18   3  2   6  34\n#> 3555 colbrgr01 1993     1  MON NL  70 153  15  39   9   0  4  23   4  2   6  33\n#> 3556 colbrgr01 1994     1  FLO NL  47 155  17  47  10   0  6  31   1  1   9  27\n#> 3557 colbrgr01 1995     1  FLO NL 138 528  70 146  22   1 23  89  11  3  22  69\n#> 3558 colbrgr01 1996     1  FLO NL 141 511  60 146  26   2 16  69   4  5  25  76\n#> 3559 colbrgr01 1997     1  MIN AL  70 217  24  61  14   0  5  26   1  2   8  38\n#> 3560 colbrgr01 1997     2  ATL NL  28  54   3  15   3   0  2   9   0  0   2  11\n#> 3561 colbrgr01 1998     1  COL NL  62 122  12  38   8   2  2  13   3  3   8  23\n#> 3562 colbrgr01 1998     2  ATL NL  28  44   6  13   3   0  1  10   1  0   2  11\n#> 3563 colbrgr01 1999     1  ARI NL  67 135  20  44   5   3  5  24   1  1  12  23\n#> 3564 colbrgr01 2000     1  ARI NL 116 329  48 103  22   1 15  57   0  1  43  45\n#> 3565 colbrgr01 2001     1  ARI NL  59  97  12  28   8   0  4  18   0  0   9  14\n#> 3566 colbrgr01 2002     1  ARI NL  72 171  30  57  16   2 10  27   0  0  13  19\n#> 3567 colbrgr01 2003     1  SEA AL  22  58   7  16   1   1  3   7   0  1   4  16\n#> 3568 colbrgr01 2004     1  ARI NL  20  27   1   3   0   0  0   1   0  0   1   5\n#> 3569 colemjo05 1965     1  WS2 AL   2   6   0   0   0   0  0   0   0  0   0   5\n#> 3570 colemjo05 1966     1  WS2 AL   1   3   0   0   0   0  0   0   0  0   0   2\n#> 3571 colemjo05 1967     1  WS2 AL  28  36   3   2   1   0  0   3   0  0   3  22\n#> 3572 colemjo05 1968     1  WS2 AL  34  70   2   9   2   0  0   3   0  0   2  22\n#> 3573 colemjo05 1969     1  WS2 AL  40  84   2   9   1   0  0   4   0  0   4  40\n#> 3574 colemjo05 1970     1  WS2 AL  39  67   5   8   1   0  0   6   0  0  12  28\n#> 3575 colemjo05 1971     1  DET AL  39  96   1   9   2   0  0   2   0  0   6  39\n#> 3576 colemjo05 1972     1  DET AL  40  82   5   9   0   0  0   5   0  1   5  30\n#> 3577 colemjo05 1973     1  DET AL  40   0   0   0   0   0  0   0   0  0   0   0\n#> 3578 colemjo05 1974     1  DET AL  41   0   0   0   0   0  0   0   0  0   0   0\n#> 3579 colemjo05 1975     1  DET AL  31   0   0   0   0   0  0   0   0  0   0   0\n#> 3580 colemjo05 1976     1  DET AL  12   0   0   0   0   0  0   0   0  0   0   0\n#> 3581 colemjo05 1976     2  CHN NL  39  13   0   2   0   0  0   0   0  0   0   4\n#> 3582 colemjo05 1977     1  OAK AL  43   0   0   0   0   0  0   0   0  0   0   0\n#> 3583 colemjo05 1978     1  OAK AL  10   0   0   0   0   0  0   0   0  0   0   0\n#> 3584 colemjo05 1978     2  TOR AL  31   0   0   0   0   0  0   0   0  0   0   0\n#> 3585 colemjo05 1979     1  SFN NL   5   0   0   0   0   0  0   0   0  0   0   0\n#> 3586 colemjo05 1979     2  PIT NL  10   5   0   1   1   0  0   0   0  0   0   3\n#> 3587 colesda01 1983     1  SEA AL  27  92   9  26   7   0  1   6   0  3   7  12\n#> 3588 colesda01 1984     1  SEA AL  48 143  15  23   3   1  0   6   2  1  17  26\n#> 3589 colesda01 1985     1  SEA AL  27  59   8  14   4   0  1   5   0  1   9  17\n#> 3590 colesda01 1986     1  DET AL 142 521  67 142  30   2 20  86   6  2  45  84\n#> 3591 colesda01 1987     1  DET AL  53 149  14  27   5   1  4  15   0  1  15  23\n#> 3592 colesda01 1987     2  PIT NL  40 119  20  27   8   0  6  24   1  3  19  20\n#> 3593 colesda01 1988     2  SEA AL  55 195  32  57  10   1 10  34   3  2  17  26\n#> 3594 colesda01 1988     1  PIT NL  68 211  20  49  13   1  5  36   1  1  20  41\n#> 3595 colesda01 1989     1  SEA AL 146 535  54 135  21   3 10  59   5  4  27  61\n#> 3596 colesda01 1990     1  SEA AL  37 107   9  23   5   1  2  16   0  0   4  17\n#> 3597 colesda01 1990     2  DET AL  52 108  13  22   2   0  1   4   0  4  12  21\n#> 3598 colesda01 1991     1  SFN NL  11  14   1   3   0   0  0   0   0  0   0   2\n#> 3599 colesda01 1992     1  CIN NL  55 141  16  44  11   2  3  18   1  0   3  15\n#> 3600 colesda01 1993     1  TOR AL  64 194  26  49   9   1  4  26   1  1  16  29\n#> 3601 colesda01 1994     1  TOR AL  48 143  15  30   6   1  4  15   0  0  10  25\n#> 3602 colesda01 1995     1  SLN NL  63 138  13  31   7   0  3  16   0  0  16  20\n#> 3603 colesda01 1997     1  COL NL  21  22   1   7   1   0  1   2   0  0   0   6\n#> 3604 collida02 1975     1  CAL AL  93 319  41  85  13   4  3  29  24 10  36  55\n#> 3605 collida02 1976     1  CAL AL  99 365  45  96  12   1  4  28  32 19  40  55\n#> 3606 collida02 1977     1  SEA AL 120 402  46  96   9   3  5  28  25 10  33  66\n#> 3607 collida02 1978     1  CIN NL 102 102  13  22   1   0  0   7   7  7  15  18\n#> 3608 collida02 1979     1  CIN NL 122 396  59 126  16   4  3  35  16  9  27  48\n#> 3609 collida02 1980     1  CIN NL 144 551  94 167  20   4  3  35  79 21  53  68\n#> 3610 collida02 1981     1  CIN NL  95 360  63  98  18   6  3  23  26 10  41  41\n#> 3611 collida02 1982     1  NYA AL 111 348  41  88  12   3  3  25  13  8  28  49\n#> 3612 collida02 1983     1  TOR AL 118 402  55 109  12   4  1  34  31  7  43  67\n#> 3613 collida02 1984     1  TOR AL 128 441  59 136  24  15  2  44  60 14  33  41\n#> 3614 collida02 1985     1  OAK AL 112 379  52  95  16   4  4  29  29  8  29  37\n#> 3615 collida02 1986     1  DET AL 124 419  44 113  18   2  1  27  27 12  44  49\n#> 3616 collida02 1987     1  CIN NL  57  85  19  25   5   0  0   5   9  0  11  12\n#> 3617 collida02 1988     1  CIN NL  99 174  12  41   6   2  0  14   7  2  11  27\n#> 3618 collida02 1989     1  CIN NL  78 106  12  25   4   0  0   7   3  1  10  17\n#> 3619 collida02 1990     1  SLN NL  99  58  12  13   1   0  0   3   7  1  13  10\n#> 3620 collied01 1906     1  PHA AL   6  15   2   3   0   0  0   0   0 NA   0  NA\n#> 3621 collied01 1907     1  PHA AL  14  23   0   8   0   1  0   2   0 NA   0  NA\n#> 3622 collied01 1908     1  PHA AL 102 330  39  90  18   7  1  40   8 NA  16  NA\n#> 3623 collied01 1909     1  PHA AL 153 571 104 198  30  10  3  56  67 NA  62  NA\n#> 3624 collied01 1910     1  PHA AL 153 581  81 188  16  15  3  81  81 NA  49  NA\n#> 3625 collied01 1911     1  PHA AL 132 493  92 180  22  13  3  73  38 NA  62  NA\n#> 3626 collied01 1912     1  PHA AL 153 543 137 189  25  11  0  64  63 NA 101  NA\n#> 3627 collied01 1913     1  PHA AL 148 534 125 184  23  13  3  73  55 NA  85  37\n#> 3628 collied01 1914     1  PHA AL 152 526 122 181  23  14  2  85  58 30  97  31\n#> 3629 collied01 1915     1  CHA AL 155 521 118 173  22  10  4  77  46 30 119  27\n#> 3630 collied01 1916     1  CHA AL 155 545  87 168  14  17  0  52  40 21  86  36\n#> 3631 collied01 1917     1  CHA AL 156 564  91 163  18  12  0  67  53 NA  89  16\n#> 3632 collied01 1918     1  CHA AL  97 330  51  91   8   2  2  30  22 NA  73  13\n#> 3633 collied01 1919     1  CHA AL 140 518  87 165  19   7  4  80  33 NA  68  27\n#> 3634 collied01 1920     1  CHA AL 153 602 117 224  38  13  3  76  20  8  69  19\n#> 3635 collied01 1921     1  CHA AL 139 526  79 177  20  10  2  58  12 10  66  11\n#> 3636 collied01 1922     1  CHA AL 154 598  92 194  20  12  1  69  20 12  73  16\n#> 3637 collied01 1923     1  CHA AL 145 505  89 182  22   5  5  67  48 29  84   8\n#> 3638 collied01 1924     1  CHA AL 152 556 108 194  27   7  6  86  42 17  89  16\n#> 3639 collied01 1925     1  CHA AL 118 425  80 147  26   3  3  80  19  6  87   8\n#> 3640 collied01 1926     1  CHA AL 106 375  66 129  32   4  1  62  13  8  62   8\n#> 3641 collied01 1927     1  PHA AL  95 226  50  76  12   1  1  15   6  2  56   9\n#> 3642 collied01 1928     1  PHA AL  36  33   3  10   3   0  0   7   0  0   4   4\n#> 3643 collied01 1929     1  PHA AL   9   7   0   0   0   0  0   0   0  0   2   0\n#> 3644 collied01 1930     1  PHA AL   3   2   1   1   0   0  0   0   0  0   0   0\n#> 3645 colliji01 1895     1  LS3 NL  96 373  65 104  17   5  6  49  12 NA  33  16\n#> 3646 colliji01 1895     2  BSN NL  11  38  10   8   3   0  1   8   0 NA   4   4\n#> 3647 colliji01 1896     1  BSN NL  84 304  48  90  10   9  1  46  10 NA  30  12\n#> 3648 colliji01 1897     1  BSN NL 134 529 103 183  28  13  6 132  14 NA  41  NA\n#> 3649 colliji01 1898     1  BSN NL 152 597 107 196  35   5 15 111  12 NA  40  NA\n#> 3650 colliji01 1899     1  BSN NL 151 599  98 166  28  11  5  92  12 NA  40  NA\n#> 3651 colliji01 1900     1  BSN NL 142 586 104 178  25   5  6  95  23 NA  34  NA\n#> 3652 colliji01 1901     1  BOS AL 138 564 108 187  42  16  6  94  19 NA  34  NA\n#> 3653 colliji01 1902     1  BOS AL 108 429  71 138  21  10  6  61  18 NA  24  NA\n#> 3654 colliji01 1903     1  BOS AL 130 540  88 160  33  17  5  72  23 NA  24  NA\n#> 3655 colliji01 1904     1  BOS AL 156 631  85 171  33  13  3  67  19 NA  27  NA\n#> 3656 colliji01 1905     1  BOS AL 131 508  66 140  26   5  4  65  18 NA  37  NA\n#> 3657 colliji01 1906     1  BOS AL  37 142  17  39   8   4  1  16   1 NA   4  NA\n#> 3658 colliji01 1907     1  BOS AL  41 158  13  46   8   0  0  10   4 NA  10  NA\n#> 3659 colliji01 1907     2  PHA AL  99 364  38  99  21   0  0  35   4 NA  24  NA\n#> 3660 colliji01 1908     1  PHA AL 115 433  34  94  14   3  0  30   5 NA  20  NA\n#> 3661 collish01 1910     1  CHA AL  97 315  29  62  10   8  1  24  10 NA  25  NA\n#> 3662 collish01 1911     1  CHA AL 106 370  48  97  16  12  4  48  14 NA  20  NA\n#> 3663 collish01 1912     1  CHA AL 153 579  75 168  34  10  2  81  26 NA  29  NA\n#> 3664 collish01 1913     1  CHA AL 148 535  53 128  26   9  1  47  22 NA  32  60\n#> 3665 collish01 1914     1  CHA AL 154 598  61 164  34   9  3  65  30 24  27  49\n#> 3666 collish01 1915     1  CHA AL 153 576  73 148  24  17  2  85  38 19  28  50\n#> 3667 collish01 1916     1  CHA AL 143 527  74 128  28  12  0  42  16 NA  59  51\n#> 3668 collish01 1917     1  CHA AL  82 252  38  59  13   3  1  14  14 NA  10  27\n#> 3669 collish01 1918     1  CHA AL 103 365  30 100  18  11  1  56   7 NA  17  19\n#> 3670 collish01 1919     1  CHA AL  63 179  21  50   6   3  1  16   3 NA   7  11\n#> 3671 collish01 1920     1  CHA AL 133 495  70 150  21  10  1  63  12  9  23  24\n#> 3672 collish01 1921     1  BOS AL 141 542  63 155  29  12  4  69  15  8  18  38\n#> 3673 collish01 1922     1  BOS AL 135 472  33 128  24   7  1  52   7  9   7  30\n#> 3674 collish01 1923     1  BOS AL  97 342  41  79  10   5  0  18   7  8  11  29\n#> 3675 collish01 1924     1  BOS AL  89 240  37  70  17   5  0  28   4  6  18  17\n#> 3676 collish01 1925     1  BOS AL   2   3   1   1   0   0  0   1   0  0   0   0\n#> 3677 conceda01 1970     1  CIN NL 101 265  38  69   6   3  1  19  10  2  23  45\n#> 3678 conceda01 1971     1  CIN NL 130 327  24  67   4   4  1  20   9  3  18  51\n#> 3679 conceda01 1972     1  CIN NL 119 378  40  79  13   2  2  29  13  6  32  65\n#> 3680 conceda01 1973     1  CIN NL  89 328  39  94  18   3  8  46  22  5  21  55\n#> 3681 conceda01 1974     1  CIN NL 160 594  70 167  25   1 14  82  41  6  44  79\n#> 3682 conceda01 1975     1  CIN NL 140 507  62 139  23   1  5  49  33  6  39  51\n#> 3683 conceda01 1976     1  CIN NL 152 576  74 162  28   7  9  69  21 10  49  68\n#> 3684 conceda01 1977     1  CIN NL 156 572  59 155  26   3  8  64  29  7  46  77\n#> 3685 conceda01 1978     1  CIN NL 153 565  75 170  33   4  6  67  23 10  51  83\n#> 3686 conceda01 1979     1  CIN NL 149 590  91 166  25   3 16  84  19  7  64  73\n#> 3687 conceda01 1980     1  CIN NL 156 622  72 162  31   8  5  77  12  2  37 107\n#> 3688 conceda01 1981     1  CIN NL 106 421  57 129  28   0  5  67   4  5  37  61\n#> 3689 conceda01 1982     1  CIN NL 147 572  48 164  25   4  5  53  13  6  45  61\n#> 3690 conceda01 1983     1  CIN NL 143 528  54 123  22   0  1  47  14  9  56  81\n#> 3691 conceda01 1984     1  CIN NL 154 531  46 130  26   1  4  58  22  6  52  72\n#> 3692 conceda01 1985     1  CIN NL 155 560  59 141  19   2  7  48  16 12  50  67\n#> 3693 conceda01 1986     1  CIN NL  90 311  42  81  13   2  3  30  13  2  26  43\n#> 3694 conceda01 1987     1  CIN NL 104 279  32  89  15   0  1  33   4  3  28  24\n#> 3695 conceda01 1988     1  CIN NL  84 197  11  39   9   0  0   8   3  2  18  23\n#> 3696  coneda01 1986     1  KCA AL  11   0   0   0   0   0  0   0   0  0   0   0\n#> 3697  coneda01 1987     1  NYN NL  21  31   0   2   1   0  0   0   0  0   0  14\n#> 3698  coneda01 1988     1  NYN NL  35  80   2  12   3   0  0   2   0  1   3  14\n#> 3699  coneda01 1989     1  NYN NL  34  77   9  18   2   0  0   4   0  0   2  13\n#> 3700  coneda01 1990     1  NYN NL  32  70   7  14   1   0  0   5   0  0   5  12\n#> 3701  coneda01 1991     1  NYN NL  34  72   3   9   0   0  0   5   0  0   3  14\n#> 3702  coneda01 1992     2  TOR AL   8   0   0   0   0   0  0   0   0  0   0   0\n#> 3703  coneda01 1992     1  NYN NL  27  65   5   6   1   0  0   4   0  0   3  19\n#> 3704  coneda01 1993     1  KCA AL  34   0   0   0   0   0  0   0   0  0   0   0\n#> 3705  coneda01 1994     1  KCA AL  23   0   0   0   0   0  0   0   0  0   0   0\n#> 3706  coneda01 1995     1  TOR AL  17   0   0   0   0   0  0   0   0  0   0   0\n#> 3707  coneda01 1995     2  NYA AL  13   0   0   0   0   0  0   0   0  0   0   0\n#> 3708  coneda01 1996     1  NYA AL  11   0   0   0   0   0  0   0   0  0   0   0\n#> 3709  coneda01 1997     1  NYA AL   1   3   0   0   0   0  0   0   0  0   0   2\n#> 3710  coneda01 1998     1  NYA AL   1   3   1   0   0   0  0   1   0  0   0   0\n#> 3711  coneda01 1999     1  NYA AL   1   3   1   1   1   0  0   1   0  0   0   0\n#> 3712  coneda01 2000     1  NYA AL   1   3   0   1   0   0  0   0   0  0   0   1\n#> 3713  coneda01 2001     1  BOS AL   1   1   0   0   0   0  0   0   0  0   0   1\n#> 3714  coneda01 2003     1  NYN NL   5   4   0   1   0   0  0   0   0  0   0   1\n#> 3715 coninje01 1990     1  KCA AL   9  20   3   5   2   0  0   2   0  0   2   5\n#> 3716 coninje01 1992     1  KCA AL  28  91  10  23   5   2  0   9   0  0   8  23\n#> 3717 coninje01 1993     1  FLO NL 162 595  75 174  24   3 12  79   2  2  52 135\n#> 3718 coninje01 1994     1  FLO NL 115 451  60 144  27   6 18  82   1  2  40  92\n#> 3719 coninje01 1995     1  FLO NL 133 483  72 146  26   2 25 105   2  0  66  94\n#> 3720 coninje01 1996     1  FLO NL 157 597  84 175  32   2 26  95   1  4  62 121\n#> 3721 coninje01 1997     1  FLO NL 151 405  46  98  13   1 17  61   2  0  57  89\n#> 3722 coninje01 1998     1  KCA AL  93 309  30  79  26   0  8  43   3  0  26  68\n#> 3723 coninje01 1999     1  BAL AL 139 444  54 129  31   1 13  75   0  3  30  40\n#> 3724 coninje01 2000     1  BAL AL 119 409  53 116  20   2 13  46   4  3  36  53\n#> 3725 coninje01 2001     1  BAL AL 139 524  75 163  23   2 14  97  12  8  64  75\n#> 3726 coninje01 2002     1  BAL AL 116 451  44 123  26   4 15  63   8  0  25  66\n#> 3727 coninje01 2003     2  FLO NL  25  84  13  20   3   0  5  15   0  0  13  10\n#> 3728 coninje01 2003     1  BAL AL 124 493  75 143  33   3 15  80   5  0  37  60\n#> 3729 coninje01 2004     1  FLO NL 140 521  55 146  35   1 14  83   5  5  48  78\n#> 3730 coninje01 2005     1  FLO NL 131 335  42 102  20   2  3  33   2  0  38  58\n#> 3731 coninje01 2006     2  PHI NL  28 100  11  28   6   1  1  17   0  0   5  12\n#> 3732 coninje01 2006     1  BAL AL 114 389  43 103  20   3  9  49   3  2  35  53\n#> 3733 coninje01 2007     2  NYN NL  21  41   2   8   2   0  0   5   0  0   7   8\n#> 3734 coninje01 2007     1  CIN NL  80 215  23  57  11   1  6  32   4  0  20  28\n#> 3735 connoro01 1880     1  TRN NL  83 340  53 113  18   8  3  47  NA NA  13  21\n#> 3736 connoro01 1881     1  TRN NL  85 367  55 107  17   6  2  31  NA NA  15  20\n#> 3737 connoro01 1882     1  TRN NL  81 349  65 115  22  18  4  42  NA NA  13  20\n#> 3738 connoro01 1883     1  NY1 NL  98 409  80 146  28  15  1  50  NA NA  25  16\n#> 3739 connoro01 1884     1  NY1 NL 116 477  98 151  28   4  4  82  NA NA  38  32\n#> 3740 connoro01 1885     1  NY1 NL 110 455 102 169  23  15  1  65  NA NA  51   8\n#> 3741 connoro01 1886     1  NY1 NL 118 485 105 172  29  20  7  71  17 NA  41  15\n#> 3742 connoro01 1887     1  NY1 NL 127 471 113 134  26  22 17 104  43 NA  75  50\n#> 3743 connoro01 1888     1  NY1 NL 134 481  98 140  15  17 14  71  27 NA  73  44\n#> 3744 connoro01 1889     1  NY1 NL 131 496 117 157  32  17 13 130  21 NA  93  46\n#> 3745 connoro01 1890     1  NYP PL 123 484 133 169  24  15 14 103  22 NA  88  32\n#> 3746 connoro01 1891     1  NY1 NL 129 479 112 139  29  13  7  94  27 NA  83  39\n#> 3747 connoro01 1892     1  PHI NL 155 564 123 166  37  11 12  73  22 NA 116  39\n#> 3748 connoro01 1893     1  NY1 NL 135 511 111 156  25   8 11 105  24 NA  91  26\n#> 3749 connoro01 1894     1  NY1 NL  22  82  10  24   7   0  1  14   2 NA   8   0\n#> 3750 connoro01 1894     2  SLN NL  99 380  83 122  28  25  7  79  17 NA  51  17\n#> 3751 connoro01 1895     1  SLN NL 103 398  78 131  29   9  8  77   9 NA  63  10\n#> 3752 connoro01 1896     1  SLN NL 126 483  71 137  21   9 11  72  10 NA  52  14\n#> 3753 connoro01 1897     1  SLN NL  22  83  13  19   3   1  1  12   3 NA  13  NA\n#> 3754  cookde01 1988     1  SFN NL   4   4   1   0   0   0  0   0   0  0   3   1\n#> 3755  cookde01 1989     1  SFN NL   2   6   1   1   0   1  0   1   0  0   0   2\n#> 3756  cookde01 1989     2  PHI NL  22  36   3   8   1   0  0   2   0  0   0   4\n#> 3757  cookde01 1990     1  PHI NL  43  42   6  13   0   0  1   4   0  0   0   4\n#> 3758  cookde01 1990     2  LAN NL   5   7   2   2   1   0  0   0   0  0   0   0\n#> 3759  cookde01 1991     1  LAN NL  20   1   0   0   0   0  0   0   0  0   0   1\n#> 3760  cookde01 1992     1  CLE AL  32   0   0   0   0   0  0   0   0  0   0   0\n#> 3761  cookde01 1993     1  CLE AL  25   0   0   0   0   0  0   0   0  0   0   0\n#> 3762  cookde01 1994     1  CHA AL  38   0   0   0   0   0  0   0   0  0   0   0\n#> 3763  cookde01 1995     1  CLE AL  11   0   0   0   0   0  0   0   0  0   0   0\n#> 3764  cookde01 1995     2  TEX AL  35   0   0   0   0   0  0   0   0  0   0   0\n#> 3765  cookde01 1996     1  TEX AL  60   0   0   0   0   0  0   0   0  0   0   0\n#> 3766  cookde01 1997     1  FLO NL  59   9   2   5   0   0  1   2   0  0   0   0\n#> 3767  cookde01 1998     1  NYN NL  70   3   0   0   0   0  0   0   0  0   0   0\n#> 3768  cookde01 1999     1  NYN NL  66   1   0   0   0   0  0   0   0  0   0   1\n#> 3769  cookde01 2000     1  NYN NL  63   0   0   0   0   0  0   0   0  0   0   0\n#> 3770  cookde01 2001     1  NYN NL  40   1   0   0   0   0  0   0   0  0   0   0\n#> 3771  cookde01 2001     2  PHI NL  19   0   0   0   0   0  0   0   0  0   0   0\n#> 3772  cookde01 2002     1  ANA AL   4   0   0   0   0   0  0   0   0  0   0   0\n#> 3773 coonejo01 1921     1  BSN NL   8   5   0   1   0   0  0   0   0  0   0   1\n#> 3774 coonejo01 1922     1  BSN NL   4   8   0   0   0   0  0   0   0  0   0   1\n#> 3775 coonejo01 1923     1  BSN NL  42  66   7  25   1   0  0   3   0  1   4   2\n#> 3776 coonejo01 1924     1  BSN NL  55 130  10  33   2   1  0   4   0  4   9   5\n#> 3777 coonejo01 1925     1  BSN NL  54 103  17  33   7   0  0  13   1  0   3   6\n#> 3778 coonejo01 1926     1  BSN NL  64 126  17  38   3   2  0  18   6 NA  13   7\n#> 3779 coonejo01 1927     1  BSN NL  10   1   4   0   0   0  0   0   0 NA   0   0\n#> 3780 coonejo01 1928     1  BSN NL  33  41   2   7   0   0  0   2   0 NA   4   3\n#> 3781 coonejo01 1929     1  BSN NL  41  72  10  23   4   1  0   6   1 NA   3   3\n#> 3782 coonejo01 1930     1  BSN NL   4   3   0   0   0   0  0   0   0 NA   0   0\n#> 3783 coonejo01 1935     1  BRO NL  10  29   3   9   0   1  0   1   0 NA   3   2\n#> 3784 coonejo01 1936     1  BRO NL 130 507  71 143  17   5  0  30   3 NA  24  15\n#> 3785 coonejo01 1937     1  BRO NL 120 430  61 126  18   5  0  37   5 NA  22  10\n#> 3786 coonejo01 1938     1  BSN NL 120 432  45 117  25   5  0  17   2 NA  22  12\n#> 3787 coonejo01 1939     1  BSN NL 118 368  39 101   8   1  2  27   2 NA  21   8\n#> 3788 coonejo01 1940     1  BSN NL 108 365  40 116  14   3  0  21   4 NA  25   9\n#> 3789 coonejo01 1941     1  BSN NL 123 442  52 141  25   2  0  29   3 NA  27  15\n#> 3790 coonejo01 1942     1  BSN NL  74 198  23  41   6   0  0   7   2 NA  23   5\n#> 3791 coonejo01 1943     1  BRO NL  37  34   7   7   0   0  0   2   1 NA   4   3\n#> 3792 coonejo01 1944     2  NYA AL  10   8   1   1   0   0  0   1   0  0   1   0\n#> 3793 coonejo01 1944     1  BRO NL   7   4   0   3   0   0  0   1   0 NA   0   0\n#> 3794 coopece01 1971     1  BOS AL  14  42   9  13   4   1  0   3   1  0   5   4\n#> 3795 coopece01 1972     1  BOS AL  12  17   0   4   1   0  0   2   0  0   2   5\n#> 3796 coopece01 1973     1  BOS AL  30 101  12  24   2   0  3  11   1  2   7  12\n#> 3797 coopece01 1974     1  BOS AL 121 414  55 114  24   1  8  43   2  5  32  74\n#> 3798 coopece01 1975     1  BOS AL 106 305  49  95  17   6 14  44   1  4  19  33\n#> 3799 coopece01 1976     1  BOS AL 123 451  66 127  22   6 15  78   7  1  16  62\n#> 3800 coopece01 1977     1  ML4 AL 160 643  86 193  31   7 20  78  13  8  28 110\n#> 3801 coopece01 1978     1  ML4 AL 107 407  60 127  23   2 13  54   3  4  32  72\n#> 3802 coopece01 1979     1  ML4 AL 150 590  83 182  44   1 24 106  15  3  56  77\n#> 3803 coopece01 1980     1  ML4 AL 153 622  96 219  33   4 25 122  17  6  39  42\n#> 3804 coopece01 1981     1  ML4 AL 106 416  70 133  35   1 12  60   5  4  28  30\n#> 3805 coopece01 1982     1  ML4 AL 155 654 104 205  38   3 32 121   2  3  32  53\n#> 3806 coopece01 1983     1  ML4 AL 160 661 106 203  37   3 30 126   2  1  37  63\n#> 3807 coopece01 1984     1  ML4 AL 148 603  63 166  28   3 11  67   8  2  27  59\n#> 3808 coopece01 1985     1  ML4 AL 154 631  82 185  39   8 16  99  10  3  30  77\n#> 3809 coopece01 1986     1  ML4 AL 134 542  46 140  24   1 12  75   1  2  41  87\n#> 3810 coopece01 1987     1  ML4 AL  63 250  25  62  13   0  6  36   1  1  17  51\n#> 3811 coopewa01 1940     1  SLN NL   6  19   3   6   1   0  0   2   1 NA   2   2\n#> 3812 coopewa01 1941     1  SLN NL  68 200  19  49   9   1  1  20   1 NA  13  14\n#> 3813 coopewa01 1942     1  SLN NL 125 438  58 123  32   7  7  65   4 NA  29  29\n#> 3814 coopewa01 1943     1  SLN NL 122 449  52 143  30   4  9  81   1 NA  19  19\n#> 3815 coopewa01 1944     1  SLN NL 112 397  56 126  25   5 13  72   4 NA  20  19\n#> 3816 coopewa01 1945     1  SLN NL   4  18   3   7   0   0  0   1   0 NA   0   1\n#> 3817 coopewa01 1946     1  NY1 NL  87 280  29  75  10   1  8  46   0 NA  17  12\n#> 3818 coopewa01 1947     1  NY1 NL 140 515  79 157  24   8 35 122   2 NA  24  43\n#> 3819 coopewa01 1948     1  NY1 NL  91 290  40  77  12   0 16  54   1 NA  28  29\n#> 3820 coopewa01 1949     1  NY1 NL  42 147  14  31   4   2  4  21   0 NA   7   8\n#> 3821 coopewa01 1949     2  CIN NL  82 307  34  86   9   2 16  62   0 NA  21  24\n#> 3822 coopewa01 1950     1  CIN NL  15  47   3   9   3   0  0   4   0 NA   0   5\n#> 3823 coopewa01 1950     2  BSN NL 102 337  52 111  19   3 14  60   1 NA  30  26\n#> 3824 coopewa01 1951     1  BSN NL 109 342  42 107  14   1 18  59   1  1  28  18\n#> 3825 coopewa01 1952     1  BSN NL 102 349  33  82  12   1 10  55   1  0  22  32\n#> 3826 coopewa01 1953     1  ML1 NL  53 137  12  30   6   0  3  16   1  0  12  15\n#> 3827 coopewa01 1954     1  PIT NL  14  15   0   3   2   0  0   1   0  0   2   1\n#> 3828 coopewa01 1954     2  CHN NL  57 158  21  49  10   2  7  32   0  0  21  23\n#> 3829 coopewa01 1955     1  CHN NL  54 111  11  31   8   1  7  15   0  0   6  19\n#> 3830 coopewa01 1956     1  SLN NL  40  68   5  18   5   1  2  14   0  0   3   8\n#> 3831 coopewa01 1957     1  SLN NL  48  78   7  21   5   1  3  10   0  0   5  10\n#> 3832 coopewi01 1912     1  PIT NL   6  13   0   2   0   0  0   1   0 NA   1   2\n#> 3833 coopewi01 1913     1  PIT NL  30  26   2   2   0   0  0   1   0 NA   3   9\n#> 3834 coopewi01 1914     1  PIT NL  40  92   5  19   1   1  0  16   0 NA   2  17\n#> 3835 coopewi01 1915     1  PIT NL  38  60   1   7   1   0  0   3   0 NA   1   5\n#> 3836 coopewi01 1916     1  PIT NL  44  79   4  17   2   0  0   4   0 NA   0  20\n#> 3837 coopewi01 1917     1  PIT NL  41 103   8  21   5   1  0   5   0 NA   6  20\n#> 3838 coopewi01 1918     1  PIT NL  38  95   8  23   2   2  0   5   2 NA   3   6\n#> 3839 coopewi01 1919     1  PIT NL  36 101   9  29   2   2  0   7   5 NA   4   9\n#> 3840 coopewi01 1920     1  PIT NL  44 113  11  25   1   3  0   2   0  3   5  19\n#> 3841 coopewi01 1921     1  PIT NL  38 122  11  31   5   2  0   9   0  1   3   7\n#> 3842 coopewi01 1922     1  PIT NL  41 108  18  29   5   1  4  15   0  0   6   6\n#> 3843 coopewi01 1923     1  PIT NL  39 107   9  28   3   1  0  10   2  2   5   8\n#> 3844 coopewi01 1924     1  PIT NL  38 104  11  36   5   2  0  15   2  2   5   8\n#> 3845 coopewi01 1925     1  CHN NL  32  82  12  17   2   1  2  10   0  1   1   4\n#> 3846 coopewi01 1926     2  DET AL   8   4   0   0   0   0  0   1   0  0   0   0\n#> 3847 coopewi01 1926     1  CHN NL   8  18   2   7   0   1  0   2   1 NA   2   0\n#> 3848 corcoto01 1890     1  PTP PL 123 503  80 117  14  13  1  61  43 NA  38  45\n#> 3849 corcoto01 1891     1  PH4 AA 133 511  84 130  11  15  7  71  30 NA  29  56\n#> 3850 corcoto01 1892     1  BRO NL 151 613  77 145  11   6  1  74  39 NA  34  51\n#> 3851 corcoto01 1893     1  BRO NL 115 459  61 126  11  10  2  58  14 NA  27  12\n#> 3852 corcoto01 1894     1  BRO NL 129 576 123 173  21  20  5  92  33 NA  25  17\n#> 3853 corcoto01 1895     1  BRO NL 127 535  81 142  17  10  2  69  17 NA  23  11\n#> 3854 corcoto01 1896     1  BRO NL 132 532  63 154  15   7  3  73  16 NA  15  13\n#> 3855 corcoto01 1897     1  CIN NL 109 445  76 128  30   5  3  57  15 NA  13  NA\n#> 3856 corcoto01 1898     1  CIN NL 153 619  80 155  28  15  2  87  19 NA  26  NA\n#> 3857 corcoto01 1899     1  CIN NL 137 537  91 149  11   8  0  81  32 NA  28  NA\n#> 3858 corcoto01 1900     1  CIN NL 127 523  64 128  21   9  1  54  27 NA  22  NA\n#> 3859 corcoto01 1901     1  CIN NL  31 115  14  24   3   3  0  15   6 NA  11  NA\n#> 3860 corcoto01 1902     1  CIN NL 138 538  54 136  18   4  0  54  20 NA  11  NA\n#> 3861 corcoto01 1903     1  CIN NL 115 459  61 113  18   7  2  73  12 NA  12  NA\n#> 3862 corcoto01 1904     1  CIN NL 150 578  55 133  17   9  2  74  19 NA  19  NA\n#> 3863 corcoto01 1905     1  CIN NL 151 605  70 150  21  11  2  85  28 NA  23  NA\n#> 3864 corcoto01 1906     1  CIN NL 117 430  29  89  13   1  1  33   8 NA  19  NA\n#> 3865 corcoto01 1907     1  NY1 NL  62 226  21  60   9   2  0  24   9 NA   7  NA\n#> 3866 cordewi01 1992     1  MON NL  45 126  17  38   4   1  2   8   0  0   9  31\n#> 3867 cordewi01 1993     1  MON NL 138 475  56 118  32   2 10  58  12  3  34  60\n#> 3868 cordewi01 1994     1  MON NL 110 415  65 122  30   3 15  63  16  3  41  62\n#> 3869 cordewi01 1995     1  MON NL 131 514  64 147  35   2 10  49   9  5  36  88\n#> 3870 cordewi01 1996     1  BOS AL  59 198  29  57  14   0  3  37   2  1  11  31\n#> 3871 cordewi01 1997     1  BOS AL 140 570  82 160  26   3 18  72   1  3  31 122\n#> 3872 cordewi01 1998     1  CHA AL  96 341  58  91  18   2 13  49   2  1  22  66\n#> 3873 cordewi01 1999     1  CLE AL  54 194  35  58  15   0  8  32   2  0  15  37\n#> 3874 cordewi01 2000     2  CLE AL  38 148  18  39  11   2  0  17   0  0   7  18\n#> 3875 cordewi01 2000     1  PIT NL  89 348  46  98  24   3 16  51   1  2  25  58\n#> 3876 cordewi01 2001     1  CLE AL  89 268  30  67  11   1  4  21   0  0  22  50\n#> 3877 cordewi01 2002     2  MON NL  66 143  21  39   9   0  6  29   2  0  17  26\n#> 3878 cordewi01 2002     1  CLE AL   6  18   1   4   0   0  0   1   0  0   0   3\n#> 3879 cordewi01 2003     1  MON NL 130 436  57 121  27   0 16  71   1  1  49  90\n#> 3880 cordewi01 2004     1  FLO NL  27  66   6  13   3   0  1   6   1  0   3  19\n#> 3881 cordewi01 2005     1  WAS NL  29  51   2   6   2   0  0   2   0  0   3  14\n#> 3882 cormirh01 1991     1  SLN NL  11  21   2   5   0   0  0   1   0  0   0   5\n#> 3883 cormirh01 1992     1  SLN NL  31  59   3   6   2   0  0   2   0  0   0  13\n#> 3884 cormirh01 1993     1  SLN NL  38  47   5  11   2   0  0   4   0  0   0  11\n#> 3885 cormirh01 1994     1  SLN NL   8  14   2   4   0   0  0   1   0  0   1   2\n#> 3886 cormirh01 1995     1  BOS AL  48   0   0   0   0   0  0   0   0  0   0   0\n#> 3887 cormirh01 1996     1  MON NL  33  43   2   8   0   1  0   4   0  0   2  12\n#> 3888 cormirh01 1997     1  MON NL   1   0   0   0   0   0  0   0   0  0   0   0\n#> 3889 cormirh01 1999     1  BOS AL  60   0   0   0   0   0  0   0   0  0   0   0\n#> 3890 cormirh01 2000     1  BOS AL   4   0   0   0   0   0  0   0   0  0   0   0\n#> 3891 cormirh01 2001     1  PHI NL  55   1   0   0   0   0  0   0   0  0   0   0\n#> 3892 cormirh01 2002     1  PHI NL  53   3   0   1   0   0  0   0   0  0   1   0\n#> 3893 cormirh01 2003     1  PHI NL  61   2   1   1   0   0  0   0   0  0   1   0\n#> 3894 cormirh01 2004     1  PHI NL  79   1   0   0   0   0  0   0   0  0   0   1\n#> 3895 cormirh01 2006     1  PHI NL  43   0   0   0   0   0  0   0   0  0   0   0\n#> 3896 cormirh01 2006     2  CIN NL  21   0   0   0   0   0  0   0   0  0   0   0\n#> 3897 cormirh01 2005     1  PHI NL  57   1   0   0   0   0  0   0   0  0   0   1\n#> 3898 cormirh01 2007     1  CIN NL   6   0   0   0   0   0  0   0   0  0   0   0\n#> 3899 covinwe01 1956     1  ML1 NL  75 138  17  39   4   0  2  16   1  0  16  20\n#> 3900 covinwe01 1957     1  ML1 NL  96 328  51  93   4   8 21  65   4  1  29  44\n#> 3901 covinwe01 1958     1  ML1 NL  90 294  43  97  12   1 24  74   0  0  20  35\n#> 3902 covinwe01 1959     1  ML1 NL 103 373  38 104  17   3  7  45   0  1  26  41\n#> 3903 covinwe01 1960     1  ML1 NL  95 281  25  70  16   1 10  35   1  2  15  37\n#> 3904 covinwe01 1961     2  CHA AL  22  59   5  17   1   0  4  15   0  0   4   5\n#> 3905 covinwe01 1961     3  KC1 AL  17  44   3   7   0   0  1   6   0  0   4   7\n#> 3906 covinwe01 1961     1  ML1 NL   9  21   3   4   1   0  0   0   0  0   2   4\n#> 3907 covinwe01 1961     4  PHI NL  57 165  23  50   9   0  7  26   0  0  15  17\n#> 3908 covinwe01 1962     1  PHI NL 116 304  36  86  12   1  9  44   0  0  19  44\n#> 3909 covinwe01 1963     1  PHI NL 119 353  46 107  24   1 17  64   1  0  26  56\n#> 3910 covinwe01 1964     1  PHI NL 129 339  37  95  18   0 13  58   0  0  38  50\n#> 3911 covinwe01 1965     1  PHI NL 101 235  27  58  10   1 15  45   0  0  26  47\n#> 3912 covinwe01 1966     1  CHN NL   9  11   0   1   0   0  0   0   0  0   1   2\n#> 3913 covinwe01 1966     2  LAN NL  37  33   1   4   0   1  1   6   0  0   6   5\n#> 3914 cramedo01 1929     1  PHA AL   2   6   0   0   0   0  0   0   0  0   0   2\n#> 3915 cramedo01 1930     1  PHA AL  30  82  12  19   1   1  0   6   0  0   2   8\n#> 3916 cramedo01 1931     1  PHA AL  65 223  37  58   8   2  2  20   2  1  11  15\n#> 3917 cramedo01 1932     1  PHA AL  92 384  73 129  27   6  3  46   3  1  17  27\n#> 3918 cramedo01 1933     1  PHA AL 152 661 109 195  27   8  8  75   5  4  36  24\n#> 3919 cramedo01 1934     1  PHA AL 153 649  99 202  29   9  6  46   1  5  40  35\n#> 3920 cramedo01 1935     1  PHA AL 149 644  96 214  37   4  3  70   6  7  37  34\n#> 3921 cramedo01 1936     1  BOS AL 154 643  99 188  31   7  0  41   4  6  49  20\n#> 3922 cramedo01 1937     1  BOS AL 133 560  90 171  22  11  0  51   8  6  35  14\n#> 3923 cramedo01 1938     1  BOS AL 148 658 116 198  36   8  0  71   4  9  51  19\n#> 3924 cramedo01 1939     1  BOS AL 137 589 110 183  30   6  0  56   3  3  36  17\n#> 3925 cramedo01 1940     1  BOS AL 150 661  94 200  27  12  1  51   3  5  36  29\n#> 3926 cramedo01 1941     1  WS1 AL 154 660  93 180  25   6  2  66   4  1  37  15\n#> 3927 cramedo01 1942     1  DET AL 151 630  71 166  26   4  0  43   4  4  43  18\n#> 3928 cramedo01 1943     1  DET AL 140 606  79 182  18   4  1  43   4  3  31  13\n#> 3929 cramedo01 1944     1  DET AL 143 578  69 169  20   9  2  42   6  5  37  21\n#> 3930 cramedo01 1945     1  DET AL 141 541  62 149  22   8  6  58   2  9  36  21\n#> 3931 cramedo01 1946     1  DET AL  68 204  26  60   8   2  1  26   3  0  15   8\n#> 3932 cramedo01 1947     1  DET AL  73 157  21  42   2   2  2  30   0  4  20   5\n#> 3933 cramedo01 1948     1  DET AL   4   4   1   0   0   0  0   1   0  0   3   0\n#> 3934 crandde01 1949     1  BSN NL  67 228  21  60  10   1  4  34   2 NA   9  18\n#> 3935 crandde01 1950     1  BSN NL  79 255  21  56  11   0  4  37   0 NA  13  24\n#> 3936 crandde01 1953     1  ML1 NL 116 382  55 104  13   1 15  51   2  1  33  47\n#> 3937 crandde01 1954     1  ML1 NL 138 463  60 112  18   2 21  64   0  3  40  56\n#> 3938 crandde01 1955     1  ML1 NL 133 440  61 104  15   2 26  62   2  1  40  56\n#> 3939 crandde01 1956     1  ML1 NL 112 311  37  74  14   2 16  48   1  2  35  30\n#> 3940 crandde01 1957     1  ML1 NL 118 383  45  97  11   2 15  46   1  2  30  38\n#> 3941 crandde01 1958     1  ML1 NL 131 427  50 116  23   1 18  63   4  1  48  38\n#> 3942 crandde01 1959     1  ML1 NL 150 518  65 133  19   2 21  72   5  1  46  48\n#> 3943 crandde01 1960     1  ML1 NL 142 537  81 158  14   1 19  77   4  6  34  36\n#> 3944 crandde01 1961     1  ML1 NL  15  30   3   6   3   0  0   1   0  0   1   0\n#> 3945 crandde01 1962     1  ML1 NL 107 350  35 104  12   3  8  45   3  4  27  24\n#> 3946 crandde01 1963     1  ML1 NL  86 259  18  52   4   0  3  28   1  4  18  22\n#> 3947 crandde01 1964     1  SFN NL  69 195  12  45   8   1  3  11   0  3  22  21\n#> 3948 crandde01 1965     1  PIT NL  60 140  11  30   2   0  2  10   1  0  14  10\n#> 3949 crandde01 1966     1  CLE AL  50 108  10  25   2   0  4   8   0  0  14   9\n#> 3950 crawfsa01 1899     1  CIN NL  31 127  25  39   3   7  1  20   6 NA   2  NA\n#> 3951 crawfsa01 1900     1  CIN NL 101 389  68 101  15  15  7  59  14 NA  28  NA\n#> 3952 crawfsa01 1901     1  CIN NL 131 515  91 170  20  16 16 104  13 NA  37  NA\n#> 3953 crawfsa01 1902     1  CIN NL 140 555  92 185  18  22  3  78  16 NA  47  NA\n#> 3954 crawfsa01 1903     1  DET AL 137 550  88 184  23  25  4  89  18 NA  25  NA\n#> 3955 crawfsa01 1904     1  DET AL 150 562  49 143  22  16  2  73  20 NA  44  NA\n#> 3956 crawfsa01 1905     1  DET AL 154 575  73 171  38  10  6  75  22 NA  50  NA\n#> 3957 crawfsa01 1906     1  DET AL 145 563  65 166  25  16  2  72  24 NA  38  NA\n#> 3958 crawfsa01 1907     1  DET AL 144 582 102 188  34  17  4  81  18 NA  37  NA\n#> 3959 crawfsa01 1908     1  DET AL 152 591 102 184  33  16  7  80  15 NA  37  NA\n#> 3960 crawfsa01 1909     1  DET AL 156 589  83 185  35  14  6  97  30 NA  47  NA\n#> 3961 crawfsa01 1910     1  DET AL 154 588  83 170  26  19  5 120  20 NA  37  NA\n#> 3962 crawfsa01 1911     1  DET AL 146 574 109 217  36  14  7 115  37 NA  61  NA\n#> 3963 crawfsa01 1912     1  DET AL 149 581  81 189  30  21  4 109  41 NA  42  NA\n#> 3964 crawfsa01 1913     1  DET AL 153 609  78 193  32  23  9  83  13 NA  52  28\n#> 3965 crawfsa01 1914     1  DET AL 157 582  74 183  22  26  8 104  25 16  69  31\n#> 3966 crawfsa01 1915     1  DET AL 156 612  81 183  31  19  4 112  24 14  66  29\n#> 3967 crawfsa01 1916     1  DET AL 100 322  41  92  11  13  0  42  10 NA  37  10\n#> 3968 crawfsa01 1917     1  DET AL  61 104   6  18   4   0  2  12   0 NA   4   6\n#> 3969 crawfwi01 1964     1  LAN NL  10  16   3   5   1   0  0   0   1  1   1   7\n#> 3970 crawfwi01 1965     1  LAN NL  52  27  10   4   0   0  0   0   2  0   2   8\n#> 3971 crawfwi01 1966     1  LAN NL   6   0   1   0   0   0  0   0   0  0   0   0\n#> 3972 crawfwi01 1967     1  LAN NL   4   4   0   1   0   0  0   0   0  0   1   3\n#> 3973 crawfwi01 1968     1  LAN NL  61 175  25  44  12   1  4  14   1  3  20  64\n#> 3974 crawfwi01 1969     1  LAN NL 129 389  64  96  17   5 11  41   4  5  49  85\n#> 3975 crawfwi01 1970     1  LAN NL 109 299  48  70   8   6  8  40   4  4  33  88\n#> 3976 crawfwi01 1971     1  LAN NL 114 342  64  96  16   6  9  40   5  2  28  49\n#> 3977 crawfwi01 1972     1  LAN NL  96 243  28  61   7   3  8  27   4  2  35  55\n#> 3978 crawfwi01 1973     1  LAN NL 145 457  75 135  26   2 14  66  12  5  78  91\n#> 3979 crawfwi01 1974     1  LAN NL 139 468  73 138  23   4 11  61   7  8  64  88\n#> 3980 crawfwi01 1975     1  LAN NL 124 373  46  98  15   2  9  46   5  5  49  43\n#> 3981 crawfwi01 1976     1  SLN NL 120 392  49 119  17   5  9  50   2  1  37  53\n#> 3982 crawfwi01 1977     2  OAK AL  59 136   7  25   7   1  1  16   0  0  18  20\n#> 3983 crawfwi01 1977     1  HOU NL  42 114  14  29   3   0  2  18   0  0  16  10\n#> 3984 crigelo01 1896     1  CL4 NL   2   5   0   0   0   0  0   0   1 NA   1   0\n#> 3985 crigelo01 1897     1  CL4 NL  39 138  15  31   4   1  0  22   5 NA  23  NA\n#> 3986 crigelo01 1898     1  CL4 NL  84 287  43  80  13   4  1  32   2 NA  40  NA\n#> 3987 crigelo01 1899     1  SLN NL  77 258  39  66   4   5  2  44  14 NA  28  NA\n#> 3988 crigelo01 1900     1  SLN NL  80 288  31  78   8   6  2  38   5 NA   4  NA\n#> 3989 crigelo01 1901     1  BOS AL  76 268  26  62   6   3  0  24   7 NA  11  NA\n#> 3990 crigelo01 1902     1  BOS AL  83 266  32  68  16   6  0  28   7 NA  27  NA\n#> 3991 crigelo01 1903     1  BOS AL  96 317  41  61   7  10  3  31   5 NA  26  NA\n#> 3992 crigelo01 1904     1  BOS AL  98 299  34  63  10   5  2  34   1 NA  27  NA\n#> 3993 crigelo01 1905     1  BOS AL 109 313  33  62   6   7  1  36   5 NA  54  NA\n#> 3994 crigelo01 1906     1  BOS AL   7  17   0   3   1   0  0   1   1 NA   1  NA\n#> 3995 crigelo01 1907     1  BOS AL  75 226  12  41   4   0  0  14   2 NA  19  NA\n#> 3996 crigelo01 1908     1  BOS AL  84 237  12  45   4   2  0  25   1 NA  13  NA\n#> 3997 crigelo01 1909     1  SLA AL  74 212  15  36   1   1  0   9   2 NA  25  NA\n#> 3998 crigelo01 1910     1  NYA AL  27  69   3  13   2   0  0   4   0 NA  10  NA\n#> 3999 crigelo01 1912     1  SLA AL   1   2   1   0   0   0  0   0   0 NA   0  NA\n#> 4000 cronijo01 1926     1  PIT NL  38  83   9  22   2   2  0  11   0 NA   6  15\n#> 4001 cronijo01 1927     1  PIT NL  12  22   2   5   1   0  0   3   0 NA   2   3\n#> 4002 cronijo01 1928     1  WS1 AL  63 227  23  55  10   4  0  25   4  0  22  27\n#> 4003 cronijo01 1929     1  WS1 AL 145 494  72 139  29   8  8  61   5  9  85  37\n#> 4004 cronijo01 1930     1  WS1 AL 154 587 127 203  41   9 13 126  17 10  72  36\n#> 4005 cronijo01 1931     1  WS1 AL 156 611 103 187  44  13 12 126  10  9  81  52\n#> 4006 cronijo01 1932     1  WS1 AL 143 557  95 177  43  18  6 116   7  5  66  45\n#> 4007 cronijo01 1933     1  WS1 AL 152 602  89 186  45  11  5 118   5  4  87  49\n#> 4008 cronijo01 1934     1  WS1 AL 127 504  68 143  30   9  7 101   8  0  53  28\n#> 4009 cronijo01 1935     1  BOS AL 144 556  70 164  37  14  9  95   3  3  63  40\n#> 4010 cronijo01 1936     1  BOS AL  81 295  36  83  22   4  2  43   1  3  32  21\n#> 4011 cronijo01 1937     1  BOS AL 148 570 102 175  40   4 18 110   5  3  84  73\n#> 4012 cronijo01 1938     1  BOS AL 143 530  98 172  51   5 17  94   7  5  91  60\n#> 4013 cronijo01 1939     1  BOS AL 143 520  97 160  33   3 19 107   6  6  87  48\n#> 4014 cronijo01 1940     1  BOS AL 149 548 104 156  35   6 24 111   7  5  83  65\n#> 4015 cronijo01 1941     1  BOS AL 143 518  98 161  38   8 16  95   1  4  82  55\n#> 4016 cronijo01 1942     1  BOS AL  45  79   7  24   3   0  4  24   0  1  15  21\n#> 4017 cronijo01 1943     1  BOS AL  59  77   8  24   4   0  5  29   0  0  11   4\n#> 4018 cronijo01 1944     1  BOS AL  76 191  24  46   7   0  5  28   1  4  34  19\n#> 4019 cronijo01 1945     1  BOS AL   3   8   1   3   0   0  0   1   0  0   3   2\n#> 4020 crosefr01 1932     1  NYA AL 116 398  47  96  20   9  5  57   3  2  51  51\n#> 4021 crosefr01 1933     1  NYA AL 136 451  71 114  20   5  9  60   4  1  55  40\n#> 4022 crosefr01 1934     1  NYA AL 138 554  85 147  22  10 11  67   5  6  61  58\n#> 4023 crosefr01 1935     1  NYA AL  87 305  49  78  17   6  8  50   3  1  41  27\n#> 4024 crosefr01 1936     1  NYA AL 151 632 137 182  35   7 15  78  18  7  90  83\n#> 4025 crosefr01 1937     1  NYA AL 149 611 127 143  29   5 11  49  13  7  86 105\n#> 4026 crosefr01 1938     1  NYA AL 157 631 113 166  35   3  9  55  27 12 106  97\n#> 4027 crosefr01 1939     1  NYA AL 152 656 109 153  25   5 10  56  11  7  65  81\n#> 4028 crosefr01 1940     1  NYA AL 145 546  84 106  23   4  4  31  14  8  72  77\n#> 4029 crosefr01 1941     1  NYA AL  50 148  13  33   2   2  1  22   0  2  18  14\n#> 4030 crosefr01 1942     1  NYA AL  74 285  50  69   5   5  4  23   1  1  31  31\n#> 4031 crosefr01 1943     1  NYA AL  95 348  36  81   8   1  2  20   4  4  36  47\n#> 4032 crosefr01 1944     1  NYA AL  55 197  20  47   4   2  5  30   3  0  11  21\n#> 4033 crosefr01 1945     1  NYA AL 130 441  57 105  12   0  4  48   7  1  59  65\n#> 4034 crosefr01 1946     1  NYA AL  28  59   4  17   3   0  0   3   0  3   8   2\n#> 4035 crosefr01 1947     1  NYA AL   3   1   0   0   0   0  0   0   0  0   0   0\n#> 4036 crosefr01 1948     1  NYA AL  17  14   4   4   0   1  0   0   0  0   2   0\n#> 4037 crossla01 1887     1  LS2 AA  54 203  32  54   8   3  0  26  15 NA  15  NA\n#> 4038 crossla01 1888     1  LS2 AA  47 181  20  41   3   0  0  15  10 NA   2  NA\n#> 4039 crossla01 1889     1  PH4 AA  55 199  22  44   8   2  0  23  11 NA  14   9\n#> 4040 crossla01 1890     1  PHP PL  63 245  42  73   7   8  3  47   5 NA  12   6\n#> 4041 crossla01 1891     1  PH4 AA 110 402  66 121  20  14  5  52  14 NA  38  23\n#> 4042 crossla01 1892     1  PHI NL 140 541  84 149  15  10  4  69  18 NA  39  16\n#> 4043 crossla01 1893     1  PHI NL  96 415  81 124  17   6  4  78  18 NA  26   7\n#> 4044 crossla01 1894     1  PHI NL 119 529 123 204  34   9  7 125  21 NA  29   7\n#> 4045 crossla01 1895     1  PHI NL 125 535  95 145  26   9  2 101  21 NA  35   8\n#> 4046 crossla01 1896     1  PHI NL 106 406  63 104  23   5  1  73   8 NA  32  14\n#> 4047 crossla01 1897     1  PHI NL  88 344  37  89  17   5  3  51  10 NA  10  NA\n#> 4048 crossla01 1898     1  SLN NL 151 602  71 191  28   8  3  79  14 NA  28  NA\n#> 4049 crossla01 1899     1  CL4 NL  38 154  15  44   5   0  1  20   2 NA   8  NA\n#> 4050 crossla01 1899     2  SLN NL 103 403  61 122  14   5  4  64  11 NA  17  NA\n#> 4051 crossla01 1900     1  SLN NL  16  61   6  18   1   0  0   6   1 NA   1  NA\n#> 4052 crossla01 1900     2  BRO NL 117 461  73 135  14   6  4  67  20 NA  25  NA\n#> 4053 crossla01 1901     1  PHA AL 100 424  82 139  28  12  2  73  23 NA  19  NA\n#> 4054 crossla01 1902     1  PHA AL 137 559  90 191  39   8  0 108  25 NA  27  NA\n#> 4055 crossla01 1903     1  PHA AL 137 559  60 163  22   4  2  90  14 NA  10  NA\n#> 4056 crossla01 1904     1  PHA AL 155 607  73 176  31  10  1  71  10 NA  13  NA\n#> 4057 crossla01 1905     1  PHA AL 147 587  69 156  29   5  0  77   8 NA  26  NA\n#> 4058 crossla01 1906     1  WS1 AL 130 494  55 130  14   6  1  46  19 NA  28  NA\n#> 4059 crossla01 1907     1  WS1 AL  41 161  13  32   8   0  0  10   3 NA  10  NA\n#> 4060 crossmo01 1892     1  BLN NL  15  50   5   8   0   0  0   2   2 NA   4  10\n#> 4061 crossmo01 1894     1  PIT NL  13  43  14  19   1   5  2  13   6 NA   5   4\n#> 4062 crossmo01 1895     1  PIT NL 108 393  67 101  14  13  3  54  39 NA  38  38\n#> 4063 crossmo01 1896     1  SLN NL 125 427  66 104  10   6  6  52  40 NA  58  48\n#> 4064 crossmo01 1897     1  SLN NL 131 462  59 132  17  11  4  55  38 NA  62  NA\n#> 4065 crossmo01 1898     1  PHI NL 149 525  68 135  25   5  1  50  20 NA  55  NA\n#> 4066 crossmo01 1899     1  PHI NL 154 557  85 143  25   6  3  65  26 NA  56  NA\n#> 4067 crossmo01 1900     1  PHI NL 131 466  59  94  11   3  3  62  19 NA  51  NA\n#> 4068 crossmo01 1901     1  PHI NL 139 483  49  95  14   1  1  44  24 NA  52  NA\n#> 4069 crossmo01 1902     1  PHA AL 137 497  72 115  22   2  3  59  17 NA  32  NA\n#> 4070 crossmo01 1903     1  PHA AL 137 470  44 116  21   2  3  45  31 NA  49  NA\n#> 4071 crossmo01 1904     1  PHA AL 153 503  33  95  23   4  1  38  19 NA  46  NA\n#> 4072 crossmo01 1905     1  PHA AL  79 252  28  67  17   2  0  24   8 NA  19  NA\n#> 4073 crossmo01 1906     1  PHA AL 134 445  32  89  23   3  1  40  22 NA  50  NA\n#> 4074 crossmo01 1907     1  PHA AL  77 248  37  51   9   5  0  18  17 NA  39  NA\n#> 4075 crowlte01 1969     1  BAL AL   7  18   2   6   0   0  0   3   0  0   1   4\n#> 4076 crowlte01 1970     1  BAL AL  83 152  25  39   5   0  5  20   2  0  35  26\n#> 4077 crowlte01 1971     1  BAL AL  18  23   2   4   0   0  0   1   0  0   3   4\n#> 4078 crowlte01 1972     1  BAL AL  97 247  30  57  10   0 11  29   0  0  32  26\n#> 4079 crowlte01 1973     1  BAL AL  54 131  16  27   4   0  3  15   0  0  16  14\n#> 4080 crowlte01 1974     1  CIN NL  84 125  11  30  12   0  1  20   1  0  10  16\n#> 4081 crowlte01 1975     1  CIN NL  66  71   8  19   6   0  1  11   0  0   7   6\n#> 4082 crowlte01 1976     2  BAL AL  33  61   5  15   1   0  0   5   0  0   7  11\n#> 4083 crowlte01 1976     1  ATL NL   7   6   0   0   0   0  0   1   0  0   0   0\n#> 4084 crowlte01 1977     1  BAL AL  18  22   3   8   1   0  1   9   0  0   1   3\n#> 4085 crowlte01 1978     1  BAL AL  62  95   9  24   2   0  0  12   0  0   8  12\n#> 4086 crowlte01 1979     1  BAL AL  61  63   8  20   5   1  1   8   0  0  14  13\n#> 4087 crowlte01 1980     1  BAL AL  92 233  33  67   8   0 12  50   0  0  29  21\n#> 4088 crowlte01 1981     1  BAL AL  68 134  12  33   6   0  4  25   0  0  29  12\n#> 4089 crowlte01 1982     1  BAL AL  65  93   8  22   2   0  3  17   0  0  21   9\n#> 4090 crowlte01 1983     1  MON NL  50  44   2   8   0   0  0   3   0  0   9   4\n#> 4091  cruzjo01 1970     1  SLN NL   6  17   2   6   1   0  0   1   0  0   4   0\n#> 4092  cruzjo01 1971     1  SLN NL  83 292  46  80  13   2  9  27   6  3  49  35\n#> 4093  cruzjo01 1972     1  SLN NL 117 332  33  78  14   4  2  23   9  3  36  54\n#> 4094  cruzjo01 1973     1  SLN NL 132 406  51  92  22   5 10  57  10  4  51  66\n#> 4095  cruzjo01 1974     1  SLN NL 107 161  24  42   4   3  5  20   4  2  20  27\n#> 4096  cruzjo01 1975     1  HOU NL 120 315  44  81  15   2  9  49   6  3  52  44\n#> 4097  cruzjo01 1976     1  HOU NL 133 439  49 133  21   5  4  61  28 11  53  46\n#> 4098  cruzjo01 1977     1  HOU NL 157 579  87 173  31  10 17  87  44 23  69  67\n#> 4099  cruzjo01 1978     1  HOU NL 153 565  79 178  34   9 10  83  37  9  57  57\n#> 4100  cruzjo01 1979     1  HOU NL 157 558  73 161  33   7  9  72  36 14  72  66\n#> 4101  cruzjo01 1980     1  HOU NL 160 612  79 185  29   7 11  91  36 11  60  66\n#> 4102  cruzjo01 1981     1  HOU NL 107 409  53 109  16   5 13  55   5  7  35  49\n#> 4103  cruzjo01 1982     1  HOU NL 155 570  62 157  27   2  9  68  21 11  60  67\n#> 4104  cruzjo01 1983     1  HOU NL 160 594  85 189  28   8 14  92  30 16  65  86\n#> 4105  cruzjo01 1984     1  HOU NL 160 600  96 187  28  13 12  95  22  8  73  68\n#> 4106  cruzjo01 1985     1  HOU NL 141 544  69 163  34   4  9  79  16  5  43  74\n#> 4107  cruzjo01 1986     1  HOU NL 141 479  48 133  22   4 10  72   3  4  55  86\n#> 4108  cruzjo01 1987     1  HOU NL 126 365  47  88  17   4 11  38   4  1  36  65\n#> 4109  cruzjo01 1988     1  NYA AL  38  80   9  16   2   0  1   7   0  1   8   8\n#> 4110 cuccito01 1930     1  CIN NL 125 443  64 138  22   5 10  78   5 NA  47  44\n#> 4111 cuccito01 1931     1  CIN NL 154 575  67 181  39  11  2  93   1 NA  54  28\n#> 4112 cuccito01 1932     1  BRO NL 154 597  76 168  32   6 12  77   5 NA  46  47\n#> 4113 cuccito01 1933     1  BRO NL 134 485  58 122  31   4  9  65   4 NA  44  40\n#> 4114 cuccito01 1934     1  BRO NL 140 528  59 138  32   2 14  94   0 NA  49  45\n#> 4115 cuccito01 1935     1  BRO NL 102 360  49 105  20   3  8  53   3 NA  40  35\n#> 4116 cuccito01 1936     1  BSN NL 150 565  68 174  26   3  7  86   1 NA  58  49\n#> 4117 cuccito01 1937     1  BSN NL 152 575  77 156  36   4 11  80   2 NA  61  40\n#> 4118 cuccito01 1938     1  BSN NL 147 555  62 147  25   2  9  76   4 NA  52  32\n#> 4119 cuccito01 1939     1  BSN NL  81 310  42  95  17   1  2  40   5 NA  26  26\n#> 4120 cuccito01 1940     1  BSN NL  34 126  14  34   9   0  0  19   1 NA   8   9\n#> 4121 cuccito01 1940     2  NY1 NL  88 307  26  64   9   2  5  36   1 NA  16  42\n#> 4122 cuccito01 1942     1  BSN NL  40 104   8  21   3   0  1   8   1 NA   9  11\n#> 4123 cuccito01 1943     2  CHA AL  34 103   5  28   5   0  2  11   3  1  13  13\n#> 4124 cuccito01 1943     1  BSN NL  13  19   0   0   0   0  0   2   0 NA   3   1\n#> 4125 cuccito01 1944     1  CHA AL  38 130   5  34   3   0  0  17   0  0   8  16\n#> 4126 cuccito01 1945     1  CHA AL 118 402  50 124  25   3  2  49   6  2  45  19\n#> 4127 cuellmi01 1959     1  CIN NL   2   1   0   0   0   0  0   0   0  0   0   1\n#> 4128 cuellmi01 1964     1  SLN NL  32  18   0   0   0   0  0   0   0  0   0   8\n#> 4129 cuellmi01 1965     1  HOU NL  25  12   0   0   0   0  0   0   0  0   1   8\n#> 4130 cuellmi01 1966     1  HOU NL  38  71   4   8   1   0  1   1   0  0   2  37\n#> 4131 cuellmi01 1967     1  HOU NL  38  93   6  13   3   2  0   5   0  0   2  42\n#> 4132 cuellmi01 1968     1  HOU NL  28  57   3  11   1   0  1   3   0  0   0  25\n#> 4133 cuellmi01 1969     1  BAL AL  39 103   6  12   1   2  0   5   0  0   0  43\n#> 4134 cuellmi01 1970     1  BAL AL  41 112   6  10   1   0  2   7   0  0   2  48\n#> 4135 cuellmi01 1971     1  BAL AL  38 107   7  11   1   0  1   5   0  0   2  54\n#> 4136 cuellmi01 1972     1  BAL AL  35  87   5  11   0   0  2   7   0  0   0  38\n#> 4137 cuellmi01 1973     1  BAL AL  38   0   0   0   0   0  0   0   0  0   0   0\n#> 4138 cuellmi01 1974     1  BAL AL  38   0   0   0   0   0  0   0   0  0   0   0\n#> 4139 cuellmi01 1975     1  BAL AL  36   0   0   0   0   0  0   0   0  0   0   0\n#> 4140 cuellmi01 1976     1  BAL AL  26   0   0   0   0   0  0   0   0  0   0   0\n#> 4141 cuellmi01 1977     1  CAL AL   2   0   0   0   0   0  0   0   0  0   0   0\n#> 4142 curtijo01 1970     1  BOS AL   1   0   0   0   0   0  0   0   0  0   0   0\n#> 4143 curtijo01 1971     1  BOS AL   5   9   0   1   0   0  0   0   0  0   0   5\n#> 4144 curtijo01 1972     1  BOS AL  27  53   2   5   0   0  0   1   0  0   2  23\n#> 4145 curtijo01 1973     1  BOS AL  35   0   0   0   0   0  0   0   0  0   0   0\n#> 4146 curtijo01 1974     1  SLN NL  34  63   7  10   1   0  0   2   0  0   4  30\n#> 4147 curtijo01 1975     1  SLN NL  39  38   6   8   0   0  0   1   0  0   5  16\n#> 4148 curtijo01 1976     1  SLN NL  38  35   3   7   1   1  0   0   0  0   2  13\n#> 4149 curtijo01 1977     1  SFN NL  44  13   4   3   0   1  0   0   0  0   1   8\n#> 4150 curtijo01 1978     1  SFN NL  46   2   0   0   0   0  0   0   0  0   0   1\n#> 4151 curtijo01 1979     1  SFN NL  29  34   3   5   1   0  0   3   0  0   2   9\n#> 4152 curtijo01 1980     1  SDN NL  31  62   2  12   1   0  0   2   0  0   2  31\n#> 4153 curtijo01 1981     1  SDN NL  28  13   1   1   0   0  0   2   0  0   0   6\n#> 4154 curtijo01 1982     2  CAL AL   8   0   0   0   0   0  0   0   0  0   0   0\n#> 4155 curtijo01 1982     1  SDN NL  26  37   1  11   0   1  0   5   0  0   0  15\n#> 4156 curtijo01 1983     1  CAL AL  37   0   0   0   0   0  0   0   0  0   0   0\n#> 4157 curtijo01 1984     1  CAL AL  17   0   0   0   0   0  0   0   0  0   0   0\n#> 4158 cuyleki01 1921     1  PIT NL   1   3   0   0   0   0  0   0   0  0   0   1\n#> 4159 cuyleki01 1922     1  PIT NL   1   0   0   0   0   0  0   0   0  0   0   0\n#> 4160 cuyleki01 1923     1  PIT NL  11  40   4  10   1   1  0   2   2  3   5   3\n#> 4161 cuyleki01 1924     1  PIT NL 117 466  94 165  27  16  9  85  32 11  30  62\n#> 4162 cuyleki01 1925     1  PIT NL 153 617 144 220  43  26 18 102  41 13  58  56\n#> 4163 cuyleki01 1926     1  PIT NL 157 614 113 197  31  15  8  92  35 NA  50  66\n#> 4164 cuyleki01 1927     1  PIT NL  85 285  60  88  13   7  3  31  20 NA  37  36\n#> 4165 cuyleki01 1928     1  CHN NL 133 499  92 142  25   9 17  79  37 NA  51  61\n#> 4166 cuyleki01 1929     1  CHN NL 139 509 111 183  29   7 15 102  43 NA  66  56\n#> 4167 cuyleki01 1930     1  CHN NL 156 642 155 228  50  17 13 134  37 NA  72  49\n#> 4168 cuyleki01 1931     1  CHN NL 154 613 110 202  37  12  9  88  13 NA  72  54\n#> 4169 cuyleki01 1932     1  CHN NL 110 446  58 130  19   9 10  77   9 NA  29  43\n#> 4170 cuyleki01 1933     1  CHN NL  70 262  37  83  13   3  5  35   4 NA  21  29\n#> 4171 cuyleki01 1934     1  CHN NL 142 559  80 189  42   8  6  69  15 NA  31  62\n#> 4172 cuyleki01 1935     1  CHN NL  45 157  22  42   5   1  4  18   3 NA  10  16\n#> 4173 cuyleki01 1935     2  CIN NL  62 223  36  56   8   3  2  22   5 NA  27  18\n#> 4174 cuyleki01 1936     1  CIN NL 144 567  96 185  29  11  7  74  16 NA  47  67\n#> 4175 cuyleki01 1937     1  CIN NL 117 406  48 110  12   4  0  32  10 NA  36  50\n#> 4176 cuyleki01 1938     1  BRO NL  82 253  45  69  10   8  2  23   6 NA  34  23\n#> 4177 dahlebi01 1891     1  CHN NL 135 549 114 143  18  13  9  76  21 NA  67  60\n#> 4178 dahlebi01 1892     1  CHN NL 143 581 114 169  23  19  5  58  60 NA  45  56\n#> 4179 dahlebi01 1893     1  CHN NL 116 485 113 146  28  15  5  64  31 NA  58  30\n#> 4180 dahlebi01 1894     1  CHN NL 121 502 149 179  32  14 15 107  42 NA  76  33\n#> 4181 dahlebi01 1895     1  CHN NL 129 516 106 131  19  10  7  62  38 NA  61  51\n#> 4182 dahlebi01 1896     1  CHN NL 125 474 137 167  30  19  9  74  51 NA  64  36\n#> 4183 dahlebi01 1897     1  CHN NL  75 276  67  80  18   8  6  40  15 NA  43  NA\n#> 4184 dahlebi01 1898     1  CHN NL 142 521  96 151  35   8  1  79  27 NA  58  NA\n#> 4185 dahlebi01 1899     1  BRO NL 121 428  87 121  22   7  4  76  29 NA  67  NA\n#> 4186 dahlebi01 1900     1  BRO NL 133 483  87 125  16  11  1  69  31 NA  73  NA\n#> 4187 dahlebi01 1901     1  BRO NL 131 511  69 136  17   9  4  82  23 NA  30  NA\n#> 4188 dahlebi01 1902     1  BRO NL 138 527  67 139  25   8  2  74  20 NA  43  NA\n#> 4189 dahlebi01 1903     1  BRO NL 138 474  71 124  17   9  1  64  34 NA  82  NA\n#> 4190 dahlebi01 1904     1  NY1 NL 145 523  70 140  26   2  2  80  47 NA  44  NA\n#> 4191 dahlebi01 1905     1  NY1 NL 148 520  67 126  20   4  7  81  37 NA  62  NA\n#> 4192 dahlebi01 1906     1  NY1 NL 143 471  63 113  18   3  1  49  16 NA  76  NA\n#> 4193 dahlebi01 1907     1  NY1 NL 143 464  40  96  20   1  0  34  11 NA  51  NA\n#> 4194 dahlebi01 1908     1  BSN NL 144 524  50 125  23   2  3  48  10 NA  35  NA\n#> 4195 dahlebi01 1909     1  BSN NL  69 197  22  46   6   1  2  16   4 NA  29  NA\n#> 4196 dahlebi01 1910     1  BRO NL   3   2   0   0   0   0  0   0   0 NA   0   0\n#> 4197 dahlebi01 1911     1  BRO NL   1   3   0   0   0   0  0   0   0 NA   0   3\n#> 4198 dahlgba01 1935     1  BOS AL 149 525  77 138  27   7  9  63   6  5  56  67\n#> 4199 dahlgba01 1936     1  BOS AL  16  57   6  16   3   1  1   7   2  1   7   1\n#> 4200 dahlgba01 1937     1  NYA AL   1   1   0   0   0   0  0   0   0  0   0   0\n#> 4201 dahlgba01 1938     1  NYA AL  27  43   8   8   1   0  0   1   0  0   1   7\n#> 4202 dahlgba01 1939     1  NYA AL 144 531  71 125  18   6 15  89   2  3  57  54\n#> 4203 dahlgba01 1940     1  NYA AL 155 568  51 150  24   4 12  73   1  1  46  54\n#> 4204 dahlgba01 1941     1  BSN NL  44 166  20  39   8   1  7  30   0 NA  16  13\n#> 4205 dahlgba01 1941     2  CHN NL  99 359  50 101  20   1 16  59   2 NA  43  39\n#> 4206 dahlgba01 1942     2  SLA AL   2   2   0   0   0   0  0   0   0  0   0   0\n#> 4207 dahlgba01 1942     1  CHN NL  17  56   4  12   1   0  0   6   0 NA   4   2\n#> 4208 dahlgba01 1942     3  BRO NL  17  19   2   1   0   0  0   0   0 NA   4   5\n#> 4209 dahlgba01 1943     1  PHI NL 136 508  55 146  19   2  5  56   2 NA  50  39\n#> 4210 dahlgba01 1944     1  PIT NL 158 599  67 173  28   7 12 101   2 NA  47  56\n#> 4211 dahlgba01 1945     1  PIT NL 144 531  57 133  24   8  5  75   1 NA  51  51\n#> 4212 dahlgba01 1946     1  SLA AL  28  80   2  14   1   0  0   9   0  1   8  13\n#> 4213  dalyto01 1887     1  CHN NL  74 256  45  53  10   4  2  17  29 NA  22  25\n#> 4214  dalyto01 1888     1  CHN NL  65 219  34  42   2   6  0  29  10 NA  10  26\n#> 4215  dalyto01 1889     1  WS8 NL  71 250  39  75  13   5  1  40  18 NA  38  28\n#> 4216  dalyto01 1890     1  BRO NL  82 292  55  71   9   4  5  43  20 NA  32  43\n#> 4217  dalyto01 1891     1  BRO NL  58 200  29  50  11   5  2  27   7 NA  21  34\n#> 4218  dalyto01 1892     1  BRO NL 124 446  76 114  15   6  4  51  34 NA  64  61\n#> 4219  dalyto01 1893     1  BRO NL 126 470  94 136  21  14  8  70  32 NA  76  65\n#> 4220  dalyto01 1894     1  BRO NL 123 492 135 168  22  10  8  82  51 NA  77  42\n#> 4221  dalyto01 1895     1  BRO NL 120 455  89 128  17   8  2  68  28 NA  52  52\n#> 4222  dalyto01 1896     1  BRO NL  67 224  43  63  13   6  3  29  19 NA  33  25\n#> 4223  dalyto01 1898     1  BRO NL  23  73  11  24   3   1  0  11   6 NA  14  NA\n#> 4224  dalyto01 1899     1  BRO NL 141 498  95 156  24   9  5  88  43 NA  69  NA\n#> 4225  dalyto01 1900     1  BRO NL  97 343  72 107  17   3  4  55  27 NA  46  NA\n#> 4226  dalyto01 1901     1  BRO NL 133 520  88 164  38  10  3  90  31 NA  42  NA\n#> 4227  dalyto01 1902     1  CHA AL 137 489  57 110  22   3  1  54  19 NA  55  NA\n#> 4228  dalyto01 1903     1  CHA AL  43 150  20  31  11   0  0  19   6 NA  20  NA\n#> 4229  dalyto01 1903     2  CIN NL  80 307  42  90  14   9  1  38   5 NA  16  NA\n#> 4230  darkal01 1946     1  BSN NL  15  13   0   3   3   0  0   1   0 NA   0   3\n#> 4231  darkal01 1948     1  BSN NL 137 543  85 175  39   6  3  48   4 NA  24  36\n#> 4232  darkal01 1949     1  BSN NL 130 529  74 146  23   5  3  53   5 NA  31  43\n#> 4233  darkal01 1950     1  NY1 NL 154 587  79 164  36   5 16  67   9 NA  39  60\n#> 4234  darkal01 1951     1  NY1 NL 156 646 114 196  41   7 14  69  12  7  42  39\n#> 4235  darkal01 1952     1  NY1 NL 151 589  92 177  29   3 14  73   6  6  47  39\n#> 4236  darkal01 1953     1  NY1 NL 155 647 126 194  41   6 23  88   7  2  28  34\n#> 4237  darkal01 1954     1  NY1 NL 154 644  98 189  26   6 20  70   5  3  27  40\n#> 4238  darkal01 1955     1  NY1 NL 115 475  77 134  20   3  9  45   2  1  22  32\n#> 4239  darkal01 1956     1  NY1 NL  48 206  19  52  12   0  2  17   0  0   8  13\n#> 4240  darkal01 1956     2  SLN NL 100 413  54 118  14   7  4  37   3  1  21  33\n#> 4241  darkal01 1957     1  SLN NL 140 583  80 169  25   8  4  64   3  4  29  56\n#> 4242  darkal01 1958     1  SLN NL  18  64   7  19   0   0  1   5   0  0   2   6\n#> 4243  darkal01 1958     2  CHN NL 114 464  54 137  16   4  3  43   1  1  29  23\n#> 4244  darkal01 1959     1  CHN NL 136 477  60 126  22   9  6  45   1  1  55  50\n#> 4245  darkal01 1960     1  PHI NL  55 198  29  48   5   1  3  14   1  1  19  14\n#> 4246  darkal01 1960     2  ML1 NL  50 141  16  42   6   2  1  18   0  0   7  13\n#> 4247 darliro01 1983     1  NYN NL   5  10   0   1   0   0  0   0   0  0   0   3\n#> 4248 darliro01 1984     1  NYN NL  39  67   7  10   1   0  0   3   0  0   1  19\n#> 4249 darliro01 1985     1  NYN NL  42  76   9  13   4   0  0   0   1  0   4  25\n#> 4250 darliro01 1986     1  NYN NL  34  81   4   8   2   0  0   0   0  0   3  29\n#> 4251 darliro01 1987     1  NYN NL  32  65   5   8   5   0  0   4   0  0   2  22\n#> 4252 darliro01 1988     1  NYN NL  34  82   4  18   4   2  0   4   0  0   1  21\n#> 4253 darliro01 1989     1  NYN NL  35  73   8   9   1   0  2   5   0  0   1  28\n#> 4254 darliro01 1990     1  NYN NL  34  31   2   4   0   0  0   2   0  0   3  12\n#> 4255 darliro01 1991     3  OAK AL  12   0   0   0   0   0  0   0   0  0   0   0\n#> 4256 darliro01 1991     1  NYN NL  17  34   0   4   3   0  0   1   0  0   0  14\n#> 4257 darliro01 1991     2  MON NL   3   6   0   1   1   0  0   2   0  0   0   2\n#> 4258 darliro01 1992     1  OAK AL  34   0   0   0   0   0  0   0   0  0   0   0\n#> 4259 darliro01 1993     1  OAK AL  32   0   0   0   0   0  0   0   0  0   0   0\n#> 4260 darliro01 1994     1  OAK AL  27   1   0   0   0   0  0   0   0  0   0   0\n#> 4261 darliro01 1995     1  OAK AL  22   0   0   0   0   0  0   0   0  0   0   0\n#> 4262 darwida01 1978     1  TEX AL   3   0   0   0   0   0  0   0   0  0   0   0\n#> 4263 darwida01 1979     1  TEX AL  20   0   0   0   0   0  0   0   0  0   0   0\n#> 4264 darwida01 1980     1  TEX AL  53   0   0   0   0   0  0   0   0  0   0   0\n#> 4265 darwida01 1981     1  TEX AL  22   0   0   0   0   0  0   0   0  0   0   0\n#> 4266 darwida01 1982     1  TEX AL  56   0   0   0   0   0  0   0   0  0   0   0\n#> 4267 darwida01 1983     1  TEX AL  28   0   0   0   0   0  0   0   0  0   0   0\n#> 4268 darwida01 1984     1  TEX AL  35   0   0   0   0   0  0   0   0  0   0   0\n#> 4269 darwida01 1985     1  ML4 AL  39   0   0   0   0   0  0   0   0  0   0   0\n#> 4270 darwida01 1986     1  ML4 AL  27   0   0   0   0   0  0   0   0  0   0   0\n#> 4271 darwida01 1986     2  HOU NL  12  16   0   1   0   0  0   0   0  0   0  12\n#> 4272 darwida01 1987     1  HOU NL  35  66   2  12   2   1  0   4   1  0   2  40\n#> 4273 darwida01 1988     1  HOU NL  44  56   3   4   2   0  1   7   0  0   1  22\n#> 4274 darwida01 1989     1  HOU NL  68  17   1   2   0   0  0   2   0  0   0   8\n#> 4275 darwida01 1990     1  HOU NL  52  38   5   5   1   1  0   3   0  0   2  21\n#> 4276 darwida01 1991     1  BOS AL  12   0   0   0   0   0  0   0   0  0   0   0\n#> 4277 darwida01 1992     1  BOS AL  51   0   0   0   0   0  0   0   0  0   0   0\n#> 4278 darwida01 1993     1  BOS AL  34   0   0   0   0   0  0   0   0  0   0   0\n#> 4279 darwida01 1994     1  BOS AL  13   0   0   0   0   0  0   0   0  0   0   0\n#> 4280 darwida01 1995     1  TOR AL  13   0   0   0   0   0  0   0   0  0   0   0\n#> 4281 darwida01 1995     2  TEX AL   7   0   0   0   0   0  0   0   0  0   0   0\n#> 4282 darwida01 1996     1  PIT NL  19  39   2   8   4   0  1   3   0  0   0  19\n#> 4283 darwida01 1996     2  HOU NL  15  10   0   1   0   0  0   0   1  0   0   8\n#> 4284 darwida01 1997     1  CHA AL  21   3   0   0   0   0  0   0   0  0   0   3\n#> 4285 darwida01 1997     2  SFN NL  10  15   0   2   1   0  0   2   0  0   0   8\n#> 4286 darwida01 1998     1  SFN NL  32  45   2   4   1   0  0   1   0  0   1  30\n#> 4287 daubeja01 1910     1  BRO NL 144 552  67 146  15  15  8  50  23 NA  47  53\n#> 4288 daubeja01 1911     1  BRO NL 149 573  89 176  17   8  5  45  32 NA  51  56\n#> 4289 daubeja01 1912     1  BRO NL 145 559  81 172  19  16  3  66  29 NA  48  45\n#> 4290 daubeja01 1913     1  BRO NL 139 508  76 178  17   7  2  52  25 NA  44  40\n#> 4291 daubeja01 1914     1  BRO NL 126 474  89 156  17   7  6  45  25 NA  30  34\n#> 4292 daubeja01 1915     1  BRO NL 150 544  62 164  21   8  2  47  11 13  57  48\n#> 4293 daubeja01 1916     1  BRO NL 127 478  75 151  16   7  3  33  21  7  38  39\n#> 4294 daubeja01 1917     1  BRO NL 125 468  59 122   4   4  2  30  11 NA  51  30\n#> 4295 daubeja01 1918     1  BRO NL 108 396  50 122  12  15  2  47  10 NA  27  18\n#> 4296 daubeja01 1919     1  CIN NL 140 537  79 148  10  12  2  44  11 NA  35  23\n#> 4297 daubeja01 1920     1  CIN NL 142 553  97 168  28  13  4  48  11 13  47  29\n#> 4298 daubeja01 1921     1  CIN NL 136 516  69 158  18  12  2  64  12  6  24  16\n#> 4299 daubeja01 1922     1  CIN NL 156 610 114 205  15  22 12  66  14 17  56  21\n#> 4300 daubeja01 1923     1  CIN NL 125 500  63 146  27  10  2  54  11 12  40  20\n#> 4301 daubeja01 1924     1  CIN NL 102 405  47 114  14   9  1  31   5 10  28  17\n#> 4302 daultda01 1983     1  PHI NL   2   3   1   1   0   0  0   0   0  0   1   1\n#> 4303 daultda01 1985     1  PHI NL  36 103  14  21   3   1  4  11   3  0  16  37\n#> 4304 daultda01 1986     1  PHI NL  49 138  18  31   4   0  8  21   2  3  38  41\n#> 4305 daultda01 1987     1  PHI NL  53 129  10  25   6   0  3  13   0  0  16  37\n#> 4306 daultda01 1988     1  PHI NL  58 144  13  30   6   0  1  12   2  1  17  26\n#> 4307 daultda01 1989     1  PHI NL 131 368  29  74  12   2  8  44   2  1  52  58\n#> 4308 daultda01 1990     1  PHI NL 143 459  62 123  30   1 12  57   7  1  72  72\n#> 4309 daultda01 1991     1  PHI NL  89 285  36  56  12   0 12  42   5  0  41  66\n#> 4310 daultda01 1992     1  PHI NL 145 485  80 131  32   5 27 109  11  2  88 103\n#> 4311 daultda01 1993     1  PHI NL 147 510  90 131  35   4 24 105   5  0 117 111\n#> 4312 daultda01 1994     1  PHI NL  69 257  43  77  17   1 15  56   4  1  33  43\n#> 4313 daultda01 1995     1  PHI NL  98 342  44  85  19   3  9  55   3  0  55  52\n#> 4314 daultda01 1996     1  PHI NL   5  12   3   2   0   0  0   0   0  0   7   5\n#> 4315 daultda01 1997     1  PHI NL  84 269  46  71  13   6 11  42   4  0  54  57\n#> 4316 daultda01 1997     2  FLO NL  52 126  22  33   8   2  3  21   2  1  22  17\n#> 4317 daussho01 1912     1  DET AL   2   4   0   1   1   0  0   0   0 NA   1  NA\n#> 4318 daussho01 1913     1  DET AL  33  79  15  14   3   2  0   7   0 NA   9  14\n#> 4319 daussho01 1914     1  DET AL  46  97   8  21   4   0  1   7   0 NA  11  24\n#> 4320 daussho01 1915     1  DET AL  46 103   9  15   2   2  0   6   2 NA  16  26\n#> 4321 daussho01 1916     1  DET AL  39  72   8  16   3   2  1   5   0 NA  15  30\n#> 4322 daussho01 1917     1  DET AL  38  87   7  11   3   0  0   2   0 NA  13  24\n#> 4323 daussho01 1918     1  DET AL  33  77   3  14   2   2  0  11   0 NA  11  13\n#> 4324 daussho01 1919     1  DET AL  34  97   7  14   2   1  0  14   1 NA   5  24\n#> 4325 daussho01 1920     1  DET AL  38  83   7  14   2   2  0   5   0  0  14  27\n#> 4326 daussho01 1921     1  DET AL  32  88   8  23   2   1  1  11   0  0   4  15\n#> 4327 daussho01 1922     1  DET AL  39  72   4  15   3   0  1   7   0  0   8  20\n#> 4328 daussho01 1923     1  DET AL  50 104  10  24   5   0  0  13   0  1  17  27\n#> 4329 daussho01 1924     1  DET AL  40  38   5   5   1   0  0   2   0  0   4  15\n#> 4330 daussho01 1925     1  DET AL  35  81  10  15   3   1  1  12   0  0  10  18\n#> 4331 daussho01 1926     1  DET AL  35  42   6  10   5   1  1   5   0  0   3  11\n#> 4332 davalvi01 1963     1  CLE AL  90 370  44 108  18   5  7  36   3  3  16  41\n#> 4333 davalvi01 1964     1  CLE AL 150 577  64 156  26   2  6  51  21 11  34  77\n#> 4334 davalvi01 1965     1  CLE AL 142 505  67 152  19   1  5  40  26  7  35  50\n#> 4335 davalvi01 1966     1  CLE AL 121 344  42  86   6   4  3  19   8  6  24  37\n#> 4336 davalvi01 1967     1  CLE AL 139 359  47 103  17   5  2  22   6  7  10  30\n#> 4337 davalvi01 1968     1  CLE AL  51 180  15  43   2   3  2  13   8  6   3  19\n#> 4338 davalvi01 1968     2  CAL AL  93 339  34 101  15   4  1  18  17 10  15  34\n#> 4339 davalvi01 1969     1  CAL AL  33  71  10  11   1   1  0   1   3  0   6   5\n#> 4340 davalvi01 1969     2  SLN NL  63  98  15  26   3   0  2  10   1  1   7   8\n#> 4341 davalvi01 1970     1  SLN NL 111 183  29  57  14   3  1  33   4  1  13  19\n#> 4342 davalvi01 1971     1  PIT NL  99 295  48  84  14   6  1  33  10  2  11  31\n#> 4343 davalvi01 1972     1  PIT NL 117 368  59 117  19   2  4  28  14  1  26  44\n#> 4344 davalvi01 1973     2  OAK AL  38  64   5  12   1   0  0   4   0  0   3   4\n#> 4345 davalvi01 1973     1  PIT NL  59  83   9  15   1   0  1   3   0  2   2   7\n#> 4346 davalvi01 1974     1  OAK AL  17  23   0   4   0   0  0   1   0  0   2   2\n#> 4347 davalvi01 1977     1  LAN NL  24  48   3  15   2   0  0   4   0  0   0   6\n#>      ibb hbp sh sf gidp cyear\n#> 1     NA   3  6  4   13     1\n#> 2      5   3  7  4   20     2\n#> 3      6   2  5  7   21     3\n#> 4     15   0  0  3   13     4\n#> 5     16   1  0  3   21     5\n#> 6     17   4  0  9   19     6\n#> 7     13   2  0 12    8     7\n#> 8     20   2  1  9   16     8\n#> 9     14   3  0  6   14     9\n#> 10    18   0  0  5   11    10\n#> 11     9   0  0  2   22    11\n#> 12    10   1  0  8   15    12\n#> 13    15   1  0  8   14    13\n#> 14    19   0  0  6   11    14\n#> 15    23   1  0  5   21    15\n#> 16    19   2  0  3   14    16\n#> 17    15   2  0  6   13    17\n#> 18    21   2  0  5    9    18\n#> 19    15   1  0  2   17    19\n#> 20    13   1  0  4    7    20\n#> 21     6   0  1  2    6    21\n#> 22     3   1  1  6   15    22\n#> 23     1   0  0  2    8    23\n#> 24     0   0  4  0    1     1\n#> 25     0   0  0  0    0     2\n#> 26     0   1  2  0    2     3\n#> 27     0   0  0  0    0     6\n#> 28     0   0  1  0    0     9\n#> 29     0   0  1  0    0    10\n#> 30     0   1  3  0    0    11\n#> 31     0   0  0  0    0    12\n#> 32     0   0  0  0    0    12\n#> 33     0   0  0  0    1    13\n#> 34     0   0  0  0    0    14\n#> 35     0   0  0  0    0    15\n#> 36     0   0  3  0    0    16\n#> 37     0   0  0  0    0    16\n#> 38     0   0  0  0    0    16\n#> 39     0   0  1  0    0    17\n#> 40     0   0  0  0    0    18\n#> 41     0   0  0  0    0     1\n#> 42     0   0  0  0    0     2\n#> 43     0   0  0  0    0     3\n#> 44     4   2  1  4    6     4\n#> 45     1   2  4  3   15     5\n#> 46     2   2  3  5   17     6\n#> 47    10   1  4  3   20     7\n#> 48     7   2  4  2   26     8\n#> 49     0   0  1  1    1     9\n#> 50     0   1  9  5   14     9\n#> 51     0   1  2  1    5    10\n#> 52     0   2  4  2   10    10\n#> 53     2   1  6  0   10    11\n#> 54     4   3  2  4   24    12\n#> 55     1   0  1  0    1    13\n#> 56    NA   0  0 NA   NA     1\n#> 57    NA   0  0 NA   NA     2\n#> 58    NA   0  5 NA   NA     4\n#> 59    NA   0  5 NA   NA     5\n#> 60    NA   0  1 NA   NA     6\n#> 61    NA   0  1 NA   NA     7\n#> 62    NA   0  3 NA   NA     8\n#> 63    NA   1  2 NA   NA     9\n#> 64    NA   0  2 NA   NA    10\n#> 65    NA   0  1 NA   NA    11\n#> 66    NA   0  0 NA   NA    13\n#> 67    NA   0  3 NA   NA    14\n#> 68    NA   0  2 NA   NA    15\n#> 69    NA   0  2 NA   NA    16\n#> 70    NA   0  5 NA   NA    17\n#> 71    NA   0  1 NA   NA    18\n#> 72    NA   0  1 NA   NA    19\n#> 73    NA   0  1 NA   NA    20\n#> 74    NA   0  0 NA   NA    21\n#> 75    NA   3 14 NA    7     1\n#> 76    NA   4  7 NA    2     2\n#> 77    NA   1  7 NA    5     3\n#> 78    NA   0  5 NA    6     4\n#> 79    NA   0  3 NA    2     5\n#> 80    NA   1  3 NA    6     6\n#> 81    NA   0  8 NA   15     7\n#> 82    NA   0 12 NA    7     8\n#> 83    NA   3  4  2    4     9\n#> 84     0   0  0  0    0    10\n#> 85     1   3  2  1    3    10\n#> 86     0   0  5  2    1    11\n#> 87     0   2  5  0    2    12\n#> 88     0   0  3  0    2    13\n#> 89     0   0  0  0    0    14\n#> 90    NA   0  3 NA   12     1\n#> 91    NA   1  2 NA   25     2\n#> 92    NA   1  1 NA   10     3\n#> 93    NA   2  6 NA   22     4\n#> 94    NA   3 11  4    7     5\n#> 95     3   2  2  1   13     6\n#> 96     6   1 11  2   11     7\n#> 97     3   1  0  1    7     8\n#> 98     1   1  2  5   14     9\n#> 99     6   0  2  6    8    10\n#> 100    7   1  5  4   13    11\n#> 101    4   2  4  2   22    12\n#> 102    8   1  2  3   18    13\n#> 103    4   0  1  3    7    14\n#> 104    4   0  0  1   13    15\n#> 105    3   1  0  0   10    16\n#> 106    6   0  0  3   11    17\n#> 107    0   0  0  0    0     1\n#> 108    0   0  0  0    0     2\n#> 109    0   0  0  0    0     3\n#> 110    0   0  0  0    0     4\n#> 111    0   0  0  0    0     5\n#> 112    0   0  0  0    0     6\n#> 113    0   0  0  0    0     6\n#> 114    0   0  0  0    0     7\n#> 115    0   0  1  0    0     8\n#> 116    0   0  0  0    0     9\n#> 117    0   0  0  0    0    10\n#> 118    0   0  0  0    0    11\n#> 119    0   0  0  0    0    12\n#> 120    0   0  0  0    0    12\n#> 121    0   0  0  0    0    13\n#> 122    0   0  7  0    1     1\n#> 123    0   0  3  0    0     2\n#> 124    0   0  6  0    0     3\n#> 125    0   0  0  0    0     4\n#> 126    0   0  0  0    0     5\n#> 127    0   0  0  0    0     5\n#> 128    0   0  0  0    0     6\n#> 129    0   0  0  0    0     7\n#> 130    0   0  0  0    0     8\n#> 131    0   0  0  0    0     9\n#> 132    0   0  0  0    0    10\n#> 133    0   0  0  0    0    11\n#> 134    0   0  0  0    0    11\n#> 135    0   0  0  0    0    12\n#> 136    0   0  0  0    0    13\n#> 137    0   0  0  0    0    14\n#> 138    0   0  0  0    0    15\n#> 139    0   0  0  0    0    15\n#> 140    0   0  0  0    0    16\n#> 141    0   0  0  0    0     1\n#> 142    0   0  3  0    0     2\n#> 143    0   0  0  0    0     3\n#> 144    0   0  0  0    0     4\n#> 145    0   0  0  0    0     5\n#> 146    0   0  2  0    0     6\n#> 147    0   0  3  1    0     7\n#> 148    0   0  4  0    1     8\n#> 149    0   0  2  0    0     9\n#> 150    0   0  4  0    2    10\n#> 151    0   0  4  0    1    11\n#> 152    0   0  2  0    0    12\n#> 153    0   0  0  0    0    13\n#> 154    0   0  0  0    0    14\n#> 155    0   0  0  0    0    15\n#> 156    0   0  0  0    0    16\n#> 157   NA   0  1 NA   NA     1\n#> 158   NA   1  3 NA   NA     2\n#> 159   NA   0 11 NA   NA     3\n#> 160   NA   3  2 NA   NA     4\n#> 161   NA   1  1 NA   NA     5\n#> 162   NA   1  4 NA   NA     6\n#> 163   NA   0  8 NA   NA     7\n#> 164   NA   3 16 NA   NA     8\n#> 165   NA   0  9 NA   NA     9\n#> 166   NA   1 12 NA   NA    10\n#> 167   NA   0  7 NA   NA    11\n#> 168   NA   0  4 NA   NA    12\n#> 169   NA   0  1 NA   NA    12\n#> 170   NA   1 10 NA   NA    13\n#> 171   NA   1 10 NA   NA    14\n#> 172   NA   0  0 NA   NA    14\n#> 173   NA   0  0 NA   NA    15\n#> 174    0   0  1  0    1     1\n#> 175    0   0  3  0    1     2\n#> 176    0   0  0  0    0     3\n#> 177    0   0  0  0    0     4\n#> 178    0   0  0  0    0     5\n#> 179    0   0  0  0    0     6\n#> 180    0   0  0  0    0     6\n#> 181    0   0  0  0    0     7\n#> 182    0   0  0  0    0     8\n#> 183    0   0  0  0    0     9\n#> 184    0   0  3  0    1    10\n#> 185    0   0  4  1    2    11\n#> 186    0   0  0  0    0    12\n#> 187    0   0  0  0    0    13\n#> 188    0   0  0  0    0    13\n#> 189    0   0  0  0    0    14\n#> 190    0   0  0  0    0    15\n#> 191    0   0  0  0    0    16\n#> 192    0   0  6  1    2    16\n#> 193    0   0  0  0    0    17\n#> 194    0   1  6  0    0    17\n#> 195    0   0  0  0    0    18\n#> 196    0   0  0  0    0    19\n#> 197   NA   0  0 NA   NA     1\n#> 198   NA   0  9 NA   NA     2\n#> 199   NA   0  3 NA   NA     3\n#> 200   NA   1  2 NA   NA     4\n#> 201   NA   0  5 NA   NA     5\n#> 202   NA   0  3 NA   NA     6\n#> 203   NA   0  7 NA   NA     7\n#> 204   NA   0  0 NA   NA     8\n#> 205   NA   0  4 NA   NA     9\n#> 206   NA   0  6 NA   NA    10\n#> 207   NA   0  5 NA   NA    11\n#> 208   NA   0  4 NA   NA    12\n#> 209   NA   0  7 NA   NA    13\n#> 210   NA   0  4 NA   NA    14\n#> 211   NA   0  9 NA   NA    15\n#> 212   NA   0  3 NA   NA    16\n#> 213   NA   0  3 NA   NA    16\n#> 214   NA   0  3 NA   NA    17\n#> 215   NA   0  8 NA   NA    18\n#> 216   NA   1  3 NA   NA    19\n#> 217   NA   0  0 NA   NA    20\n#> 218    0   0  0  1    2     1\n#> 219   13   0  6  3    8     2\n#> 220    6   2  6  6   13     3\n#> 221   13   3  0  4    9     4\n#> 222   18   1  1  0    9     5\n#> 223   15   1  2  7    7     6\n#> 224   10   0  0  4   10     7\n#> 225   16   2  0  1    9     8\n#> 226   13   1  1  5   23     9\n#> 227   16   1  0  3   13    10\n#> 228    3   1  1  3    9    11\n#> 229    9   1  0  5   16    12\n#> 230    4   2  1  4   19    13\n#> 231    2   0  1  3   13    14\n#> 232    0   1  0  4    4    15\n#> 233   NA   0  0 NA   NA     1\n#> 234   NA   2 13 NA   NA     2\n#> 235   NA   1 14 NA   NA     3\n#> 236   NA   0 10 NA   NA     4\n#> 237   NA   0  2 NA   NA     5\n#> 238   NA   0  8 NA   NA     5\n#> 239   NA   1  7 NA   NA     6\n#> 240   NA   2  1 NA   NA     7\n#> 241   NA   1  6 NA    4     8\n#> 242   NA   3 16 NA   16     9\n#> 243   NA   1 11 NA    5    10\n#> 244   NA   0  3 NA    4    11\n#> 245   NA   2 11 NA    9    11\n#> 246   NA   1  7 NA   NA    12\n#> 247   NA   0  1 NA   NA    13\n#> 248   NA   0  3 NA   NA     1\n#> 249   NA   0  2 NA   NA     2\n#> 250   NA   0  2 NA   NA     3\n#> 251   NA   0  3 NA   NA     4\n#> 252   NA   0  8 NA   NA     5\n#> 253   NA   0  4 NA   NA     6\n#> 254   NA   0  3 NA   NA     7\n#> 255   NA   0  2 NA    2     8\n#> 256   NA   0  0 NA    1     9\n#> 257   NA   0  1 NA    2    10\n#> 258   NA   0  1 NA    0    10\n#> 259   NA   0  4 NA    2    11\n#> 260   NA   0  2 NA    0    12\n#> 261   NA   0  1 NA    0    12\n#> 262   NA   0  0 NA    1    13\n#> 263    0   0  0  0    0     1\n#> 264    0   0  0  0    0     2\n#> 265    0   0  1  0    0     3\n#> 266    1   0 20  0   14     4\n#> 267   10   0  3  1    6     5\n#> 268    7   0  5  2    1     6\n#> 269    0   0  0  1    2     7\n#> 270    1   0  0  0    0     7\n#> 271    0   2  2  3    4     8\n#> 272    0   1  1  1    4     9\n#> 273    3   2  5 11    8    10\n#> 274    0   0  0  4    3    11\n#> 275    0   1  4  3    6    12\n#> 276    2   0  1  3    5    13\n#> 277    0   0  0  0    0    14\n#> 278    0   0  0  0    0    14\n#> 279    0   0  2  0    0    15\n#> 280    5   3 16  0   15     1\n#> 281    4   1 17  8   10     2\n#> 282    1   2  5  5   16     3\n#> 283    3   4 16  5    5     4\n#> 284    5   5  6  2    8     5\n#> 285    5   5  4  5   13     6\n#> 286    2   2  7  3   14     7\n#> 287    3   0  6  7   16     8\n#> 288   10   1  8 12   14     9\n#> 289    2   3  7  7   10    10\n#> 290    3   2  3  5   11    11\n#> 291    3   7 12 13   13    12\n#> 292    4   6 11  6   19    13\n#> 293    5   4  9  9    9    14\n#> 294    4   1  6  1   12    15\n#> 295    2   2  4  4    8    16\n#> 296    1   1  8  4    9    16\n#> 297    0   0  1  1    2    17\n#> 298    0   1  2  0    2    17\n#> 299    0   0  0  0    1     1\n#> 300    1   0  4  0    5     2\n#> 301    1   0  0  0    0     3\n#> 302    0   0  1  0    1     4\n#> 303    0   0  0  0    1     4\n#> 304    1   1  8  3    6     5\n#> 305    0   0  2  0    0     6\n#> 306    2   0  3  0    5     6\n#> 307    2   1 11  2    7     7\n#> 308    4   0  7  2    7     8\n#> 309    5   0  6  3    8     9\n#> 310    1   0 12  3    2    10\n#> 311    0   0  1  0    1    11\n#> 312    0   0  4  2    6    11\n#> 313    0   0 11  2    6    12\n#> 314    0   0  2  0    2    13\n#> 315    0   1  4  1    0    14\n#> 316    0   0  1  0    0    15\n#> 317    0   0  0  0    0     1\n#> 318    1   0  0  0    1     2\n#> 319    2   2  5  6   10     3\n#> 320    1   4  2  1    4     4\n#> 321    3   5  3  0    7     5\n#> 322    0   6  1  4    3     6\n#> 323    2   2  0  1    7     7\n#> 324    0   3  4  1    8     8\n#> 325    0   3  2  2   20     9\n#> 326    2   3  6  1   16    10\n#> 327    0   3  5  3   15    11\n#> 328    0   0  1  2    1    12\n#> 329    1   4  4  4    9    13\n#> 330    1   2  3  2    6    14\n#> 331    0   0  0  0    6    15\n#> 332    0   1  1  2    5    15\n#> 333    0   0  5  1    4    16\n#> 334    2   2  3  2    4    17\n#> 335    0   1  3  0    3    18\n#> 336    0   0  0  0    3    19\n#> 337    0   0  0  2    0    19\n#> 338    0   0  0  0    0    20\n#> 339    2   1  1  1    1     1\n#> 340    1   0  1  3    5     2\n#> 341    1   2  3  4    9     3\n#> 342    2   2  2  2   11     4\n#> 343    2   5  2  5    4     5\n#> 344    3   6  5  4   13     6\n#> 345    5   4  1  5    5     7\n#> 346    4   5  4  4    6     8\n#> 347    6  12  2  2   11     9\n#> 348    7   7  1  3   10    10\n#> 349   14   4  0  4   10    11\n#> 350    4   4  4  2    7    12\n#> 351    6   1  4  6   13    13\n#> 352    0   0  1  0    0    14\n#> 353    3   2  1  5   15    14\n#> 354    1   2  1  2    8    15\n#> 355    5   0  0  4    4    16\n#> 356    1   0  0  0    3    16\n#> 357    0   0  0  0    0    17\n#> 358    0   1  0  0    1     1\n#> 359    2   4  5  0    9     2\n#> 360    0   3  6  2   21     3\n#> 361    1   2  4  2   14     4\n#> 362    2   4  6  0   10     5\n#> 363    3   1  5  2   20     6\n#> 364    6   4  2  3   13     7\n#> 365    4   1  3  4   15     8\n#> 366    3   4  3  2   11     9\n#> 367    4   1  1  0    3    10\n#> 368    1   0  1  0    2    11\n#> 369    1   2  0  0    3    11\n#> 370    1   2  3  2    9    12\n#> 371    2   1  1  0    4    13\n#> 372    1   0  4  3    4    16\n#> 373    1   0  0  0    4    17\n#> 374    0   0  0  0    0     1\n#> 375    2   0  1  1    4     2\n#> 376    0   3  1  0    3     3\n#> 377    0   1  1  0    1     4\n#> 378    3   3  2  1    3     5\n#> 379    2   2  8  0   15     6\n#> 380    4   4 12  3    3     7\n#> 381    1   6  3  1    3     8\n#> 382    6   2  7  4   10     9\n#> 383    9   2  1  3    5    10\n#> 384    3   4  4  3    9    11\n#> 385    3   4  6  7    9    12\n#> 386    1   1  1  2    1    13\n#> 387    2   1  1  1   12    13\n#> 388    0   3  6  2   18    14\n#> 389    1   0  0  0    2    14\n#> 390    1   0  1  1    3    15\n#> 391    0   0  0  0    1     1\n#> 392    0   0  1  0    0     1\n#> 393    0   1  5  5    5     3\n#> 394    9   5  3  7    9     4\n#> 395   10   2  0  5    7     5\n#> 396    6   9  0  4    9     6\n#> 397    7   2  0  7   15     7\n#> 398    9   4  0  7   13     8\n#> 399   11   5  0  6   14     9\n#> 400    4   2  0  9   21    11\n#> 401   14   3  0  8   18    12\n#> 402    4   0  0  3   15    13\n#> 403    7   7  0  3   16    14\n#> 404    2   0  0  6   12    15\n#> 405    1   3  0  4   11    16\n#> 406    2   1  0  4   15    17\n#> 407    5   2  0  3   13    18\n#> 408   NA   1  0 NA   NA     1\n#> 409   NA   0  0 NA   NA     5\n#> 410   NA   0  0 NA   NA     6\n#> 411   NA   0  0 NA   NA     6\n#> 412   NA   2  6 NA   NA     7\n#> 413   NA   3  5 NA   NA     8\n#> 414   NA   0  2 NA   NA     9\n#> 415   NA   2  0 NA   NA    10\n#> 416   NA   2  1 NA   NA    11\n#> 417   NA   0  0 NA   NA    12\n#> 418   NA   1  0 NA   NA    12\n#> 419   NA   0  0 NA   NA    15\n#> 420   NA   0  0 NA   NA    16\n#> 421    0   0  0  0    0    17\n#> 422   NA   0  0 NA   NA    18\n#> 423   NA   0  1 NA   NA    21\n#> 424    0   0  0  0    0    22\n#> 425   NA   0  0 NA   NA    27\n#> 426   NA   0  0 NA   NA    32\n#> 427   NA   0  0 NA   NA    34\n#> 428   NA   0  0 NA   NA    36\n#> 429    0   0  0  0    0     1\n#> 430    0   0  0  0    0     3\n#> 431    0   0  0  0    0     4\n#> 432    0   0  0  0    0     5\n#> 433    0   0  0  0    0     6\n#> 434    0   0  0  0    0     7\n#> 435    0   0  0  0    0     8\n#> 436    0   0  0  0    0     9\n#> 437    0   0  1  0    0     9\n#> 438    0   0  0  0    0    10\n#> 439    0   0  0  0    0    11\n#> 440    0   0  0  0    0    14\n#> 441    0   0  1  0    2    15\n#> 442    0   0  2  0    2    16\n#> 443    0   0  1  0    0    17\n#> 444   NA   0  0 NA   NA     1\n#> 445   NA   0  0 NA   NA     2\n#> 446   NA   0  6 NA   NA     3\n#> 447   NA   0  1 NA   NA     4\n#> 448   NA   0  4 NA   NA     5\n#> 449   NA   0  4 NA   NA     6\n#> 450   NA   0  3 NA   NA     7\n#> 451   NA   0  2 NA   NA     8\n#> 452   NA   0  3 NA   NA     9\n#> 453   NA   0  1 NA   NA    10\n#> 454   NA   0  1 NA   NA    11\n#> 455   NA   0  4 NA   NA    11\n#> 456   NA   0  5 NA   NA    12\n#> 457   NA   0  0 NA   NA    13\n#> 458   NA   0  3 NA   NA    13\n#> 459   NA   0  2 NA   NA    14\n#> 460   NA   0  3 NA   NA    15\n#> 461   NA   0  4 NA   NA    16\n#> 462   NA   0  1 NA   NA    17\n#> 463   NA   0  0 NA   NA    17\n#> 464    0   4  4  1    2     1\n#> 465    0   0  7  0    1     1\n#> 466    6   3  5  0    4     2\n#> 467    2   5  4  5    4     3\n#> 468    0   5 11  3    1     4\n#> 469   14   9 10  9    2     5\n#> 470    4  10  6  6    4     6\n#> 471    3  10  3  2    7     7\n#> 472    4  10  4  2    3     8\n#> 473    1  22  6  4   11     9\n#> 474    6  19  2  1    1    10\n#> 475    1  15  4  1    7    11\n#> 476    7  24  1  7    6    12\n#> 477    5   8  5  7    4    13\n#> 478    4   8  2  1    3    14\n#> 479    2   2  0  1    5    15\n#> 480   NA   0 NA NA   NA     1\n#> 481   NA   5  1 NA   NA     2\n#> 482   NA   2  1 NA   NA     3\n#> 483   NA   7 11 NA   NA     4\n#> 484   NA   1  0 NA   NA     5\n#> 485   NA  12  6 NA   NA     5\n#> 486    0   1  0  0   NA     5\n#> 487   NA   4  2 NA   NA     6\n#> 488   NA   3  4 NA   NA     8\n#> 489   NA   3  3 NA   NA     9\n#> 490   NA   0  4 NA   NA    10\n#> 491   NA   6 11 NA   NA    11\n#> 492   NA   1  0 NA   NA    12\n#> 493   NA   2  4 NA   NA    12\n#> 494   NA   2  3 NA   NA    13\n#> 495   NA   3  1 NA   NA    14\n#> 496   NA   1 13 NA   NA    15\n#> 497    0   0  0  0    0     1\n#> 498    0   0  0  0    0     3\n#> 499    0   0  0  0    0     5\n#> 500    0   0  0  0    0     7\n#> 501    0   0  0  0    0     8\n#> 502    0   0  0  0    0     9\n#> 503    0   0  0  0    0    10\n#> 504    0   0  1  0    0    11\n#> 505    0   0  1  0    0    12\n#> 506    0   0  0  0    0    12\n#> 507    0   0  0  0    0    13\n#> 508    0   0  0  0    0    14\n#> 509    0   0  1  0    0    15\n#> 510    0   0  0  0    0    16\n#> 511    0   0  1  0    0    16\n#> 512    0   0  0  0    0    17\n#> 513    0   0  0  0    0    18\n#> 514    0   0  0  0    0    19\n#> 515    0   0  0  0    0    20\n#> 516   NA  NA NA NA   NA     1\n#> 517   NA  NA NA NA   NA     2\n#> 518   NA  NA NA NA   NA     3\n#> 519   NA  NA NA NA   NA     4\n#> 520   NA  NA NA NA   NA     5\n#> 521   NA  NA NA NA   NA     6\n#> 522   NA  NA NA NA   NA     7\n#> 523   NA  NA NA NA   NA     8\n#> 524   NA  NA NA NA   NA     9\n#> 525   NA  NA NA NA   NA    10\n#> 526   NA  NA NA NA   NA    11\n#> 527   NA  NA NA NA   NA    12\n#> 528   NA  NA NA NA   NA    13\n#> 529   NA  NA NA NA   NA    14\n#> 530   NA  NA NA NA   NA    15\n#> 531   NA  NA NA NA   NA    16\n#> 532   NA   1 NA NA   NA    17\n#> 533   NA   1 NA NA   NA    18\n#> 534   NA   5 NA NA   NA    19\n#> 535   NA   6 NA NA   NA    20\n#> 536   NA   1 NA NA   NA    21\n#> 537   NA   4 NA NA   NA    22\n#> 538   NA   1 NA NA   NA    23\n#> 539   NA   3 NA NA   NA    24\n#> 540   NA   3 13 NA   NA    25\n#> 541   NA   3  5 NA   NA    26\n#> 542   NA   4  9 NA   NA    27\n#> 543    2   1 14  1    9     1\n#> 544    1   0  9  4    7     2\n#> 545    2   1  8  3    8     3\n#> 546    1   3 11  7   11     4\n#> 547    3   1 20  6   12     5\n#> 548    0   1  4  4   12     6\n#> 549    1   1  4  4   11     7\n#> 550    2   2  6  6   10     8\n#> 551    0   3  7  5   13     9\n#> 552    0   3 14  2   11    10\n#> 553    2   1 12  2   10    11\n#> 554    2   1  6  5    8    12\n#> 555    3   2  5  2   10    13\n#> 556    1   2 10  4   14    14\n#> 557    1   1  5  5   11    15\n#> 558    0   2  9  4    7    16\n#> 559    0   2  5  5    8    17\n#> 560    1   0 12  7   12    18\n#> 561    0   0  0  0    0     1\n#> 562    0   0  0  0    0     2\n#> 563    0   0  0  0    0     3\n#> 564    0   0  0  0    0     4\n#> 565    0   0  0  0    0     5\n#> 566    0   0  0  0    0     6\n#> 567    0   0  0  0    0     7\n#> 568    0   0  0  0    0     8\n#> 569    0   0  0  0    0     9\n#> 570    0   0  0  0    0    10\n#> 571    0   0  0  0    0    11\n#> 572    0   0  0  0    0    11\n#> 573    0   0  0  0    0    12\n#> 574    0   1  3  0    0    13\n#> 575    0   0  2  0    0    14\n#> 576    0   0  0  0    0    15\n#> 577    0   0  0  0    0    15\n#> 578    0   0  0  0    0    16\n#> 579   NA   0  0 NA   NA     1\n#> 580   NA   0  2 NA   NA     2\n#> 581   NA   0  1 NA   NA     4\n#> 582   NA   0  1 NA   NA     5\n#> 583    0   0  0  0    0     6\n#> 584   NA   0  0 NA   NA     6\n#> 585    0   0  0  0    0     7\n#> 586   NA   0  1 NA   NA    10\n#> 587   NA   0  1 NA   NA    11\n#> 588   NA   0  2 NA   NA    12\n#> 589   NA   0  3 NA    2    13\n#> 590   NA   0  1 NA    0    14\n#> 591   NA   0  0 NA    0    15\n#> 592    0   0  0  0    0    16\n#> 593   NA   0  0 NA    0    16\n#> 594    0   0  0  0    0    19\n#> 595   NA   0  0 NA    0    19\n#> 596   NA   0  0 NA   NA     1\n#> 597   NA   1  3 NA   NA     2\n#> 598   NA   0  3 NA   NA     3\n#> 599   NA   0  2 NA   NA     4\n#> 600   NA   0  5 NA   NA     5\n#> 601   NA   0  7 NA   NA     6\n#> 602   NA   1  6 NA   NA     7\n#> 603   NA   1  4 NA   NA     8\n#> 604   NA   1  1 NA   NA     9\n#> 605   NA   0  9 NA   11    10\n#> 606   NA   1  3 NA   11    11\n#> 607   NA   1  2 NA   10    12\n#> 608   NA   3  4 NA    7    13\n#> 609   NA   1  1 NA   13    14\n#> 610   NA   0  1 NA    0    16\n#> 611   NA   0  6 NA   15    17\n#> 612   NA   1  4 NA   15    18\n#> 613   NA   0  3 NA   17    19\n#> 614   NA   0  6 NA   23    20\n#> 615   NA   0  4 NA    7    21\n#> 616   NA   1  6 NA    1     1\n#> 617   NA   1  7 NA    7     2\n#> 618   NA   2 11 NA   11     3\n#> 619   NA   2 17 NA    4     4\n#> 620   NA   2 11 NA    7     5\n#> 621   NA   5 14 NA    3     6\n#> 622   NA   4 14  1    3     7\n#> 623    5   3  2  1    3     8\n#> 624    3   5  6  1    4     9\n#> 625    1   4  1  4   10    10\n#> 626    7   4  7  2    8    11\n#> 627    4   6  7  4   10    12\n#> 628    1   1  7  1    4    13\n#> 629    2   3  1  2    4    14\n#> 630    2   0  1  2    4    15\n#> 631    0   0  0  0    0     1\n#> 632    0   0  0  0    0     2\n#> 633    1   1 16  0   10     3\n#> 634    4   0  6  3    6     4\n#> 635    3   2 10  1   14     5\n#> 636    4   1  4  1   10     6\n#> 637   10   2  3  3    8     7\n#> 638   12   0  2  5   11     8\n#> 639    6   0  3  2    6     9\n#> 640    4   1  2  3    7    10\n#> 641    4   0  1  4   12    11\n#> 642    2   1  4  3    4    12\n#> 643    2   1  1  1    9    13\n#> 644    9   0  1  6    7    14\n#> 645    2   1  0  4   14    15\n#> 646    3   0  1  4    5    16\n#> 647    0   1  1  1    2    17\n#> 648    0   0  1  0    0     1\n#> 649    0   0  2  0    0     2\n#> 650    0   0  0  0    0     3\n#> 651    0   0  2  0    0     3\n#> 652    0   0  9  0    2     4\n#> 653    0   0 17  0    0     5\n#> 654    0   0  9  1    0     6\n#> 655    0   0  7  0    1     7\n#> 656    0   0  9  0    0     8\n#> 657    0   0  7  0    1     9\n#> 658    0   0  5  0    0    10\n#> 659    0   0  4  0    1    10\n#> 660    0   0  2  0    0    11\n#> 661    0   0  6  0    0    12\n#> 662    0   0  3  0    0    13\n#> 663    0   0  0  0    0    14\n#> 664    0   0  0  0    0     1\n#> 665    0   0  2  0    0     2\n#> 666    0   0  1  0    0     3\n#> 667    0   0  0  0    1     4\n#> 668    0   0  0  0    0     4\n#> 669    0   0  2  0    0     5\n#> 670    0   0  0  0    0     6\n#> 671    0   0  2  0    0     7\n#> 672    0   0  0  0    0     8\n#> 673    0   0  0  0    0     8\n#> 674    0   0  0  0    0     9\n#> 675    0   0  0  0    0    10\n#> 676    0   0  0  0    0    11\n#> 677    0   0  0  0    0    12\n#> 678    0   0  0  0    0    13\n#> 679    0   0  0  0    0    14\n#> 680    0   0  5  0    0     1\n#> 681    0   0  7  0    0     2\n#> 682    0   0  4  0    0     3\n#> 683    0   0  2  0    1     4\n#> 684    0   0  8  0    0     5\n#> 685    0   0 10  0    0     6\n#> 686    0   0  1  0    0     6\n#> 687    0   2 11  0    1     7\n#> 688    0   0  8  0    0     8\n#> 689    0   0  1  0    1     9\n#> 690    0   0 10  0    0    10\n#> 691    0   0  1  0    0    10\n#> 692    0   1  6  0    0    11\n#> 693    0   0  3  0    0    12\n#> 694    0   0  0  0    0    13\n#> 695    0   2  7  0    0    15\n#> 696    0   0  5  0    2    14\n#> 697    0   0  0  0    0    14\n#> 698    0   0  0  0    2     1\n#> 699   12   1  6  2    8     2\n#> 700    3   2  4  4    6     3\n#> 701    1   2  5  2    4     4\n#> 702    0   3  1  0    4     4\n#> 703    4   3  6  6    8     5\n#> 704   11   3  3  1   18     6\n#> 705    0  14  3  1   11     7\n#> 706    0   6  4  2   19     8\n#> 707    6   1  6  2   13     9\n#> 708    3   6  2  3   30    10\n#> 709    1   4  4  5    8    11\n#> 710   11   2  7  3   13    12\n#> 711    8   5  7  1   17    13\n#> 712    2   6  9  3   21    14\n#> 713    3   6  4  1   11    15\n#> 714   NA   1 30 NA   NA     1\n#> 715   NA   7 25 NA   NA     2\n#> 716   NA   6 34 NA   NA     3\n#> 717   NA   4 26 NA   NA     4\n#> 718   NA   8 17 NA   NA     5\n#> 719   NA   1 16 NA   NA     6\n#> 720   NA   2 35 NA   NA     7\n#> 721   NA   4 19 NA   NA     8\n#> 722   NA   3 26 NA   NA     9\n#> 723   NA   1 21 NA   NA    10\n#> 724   NA   2 10 NA   NA    11\n#> 725   NA   4 15 NA   NA    12\n#> 726   NA   1  4 NA   NA    13\n#> 727   NA   0  0 NA   NA    14\n#> 728   NA   0  0 NA   NA    15\n#> 729   NA   0  0 NA   NA    17\n#> 730   NA   0  0 NA   NA    18\n#> 731   NA   0  0 NA   NA    21\n#> 732    0   0  0  0    0     1\n#> 733    7   3  1  4    3     3\n#> 734    0   0  0  0    0     4\n#> 735    1   0  1  3   13     4\n#> 736    2   2  1  4    4     5\n#> 737    8   3  2  4   15     6\n#> 738    5   2  1  5    6     7\n#> 739    0   3  1  3    8     8\n#> 740    5   0  2  2    9     9\n#> 741    0   0  0  0    0    10\n#> 742    1   0  0  0    3    10\n#> 743   11   2  1  4   14    10\n#> 744    4   2  1  3   12    11\n#> 745    0   0  0  0    0    13\n#> 746    1   0  0  0    0    13\n#> 747    2   4  1  5    4     1\n#> 748    5   6  4  3   12     2\n#> 749   10  13  2  9   15     3\n#> 750    7   6  3 13   17     4\n#> 751    1   6  3  8   10     5\n#> 752    6   3  0  5   15     6\n#> 753    0   7  2  4   15     7\n#> 754    0   2  0  1    8     7\n#> 755    1   3  3  5   13     8\n#> 756    6   6  3  7   21     9\n#> 757    1   0  1  1    3    10\n#> 758    0   2  1  0    2    10\n#> 759    1   2  1  2    6    13\n#> 760    1   2  1  3    6    14\n#> 761    0   3  0  0    7    15\n#> 762    0   8  1  0    4    16\n#> 763    5  13  1  7   12     1\n#> 764   13  12  2 13   17     2\n#> 765    6   3  0  9   20     3\n#> 766   14   4  0 10   12     4\n#> 767   12   6  0  6    9     5\n#> 768   20  10  0  6   15     6\n#> 769   27  16  0  8   10     7\n#> 770    8   7  0  5   14     8\n#> 771   16  11  0  7   18     9\n#> 772   11  15  0  7   19    10\n#> 773    5   6  0  5   20    11\n#> 774    8  10  0  9   16    12\n#> 775    3   6  0  3   25    13\n#> 776    6   8  0  3   12    14\n#> 777    1   1  0  4    2    15\n#> 778    0   0  0  0    0     1\n#> 779    0   0 10  1    0     3\n#> 780    0   0  9  0    1     4\n#> 781    0   0  8  0    0     5\n#> 782    0   0  8  0    0     6\n#> 783    0   1  3  0    1     7\n#> 784    0   0  0  0    0     8\n#> 785    0   0  0  0    0     9\n#> 786    0   0  0  0    0    10\n#> 787    0   0  0  0    0    10\n#> 788    0   0  0  0    0    11\n#> 789    0   0  0  0    0    12\n#> 790    0   0  4  0    1    12\n#> 791    0   0  1  0    0    13\n#> 792    0   0  0  0    0    14\n#> 793    0   0  0  0    1    15\n#> 794    0   0  0  0    0    16\n#> 795    0   0  0  0    0    17\n#> 796    0   0  0  0    0    17\n#> 797    0   0  2  0    0     1\n#> 798    2   5  4  3    9     2\n#> 799    1   1  5  2   16     3\n#> 800    1   0  4  2   16     4\n#> 801    4   2  2  2   12     5\n#> 802    4   1  4  5   14     6\n#> 803    4   1  1  3    8     7\n#> 804    3   1  1  5   12     8\n#> 805    8   1  2  2   12     9\n#> 806    8   0  3  9   19    10\n#> 807    7   1  7  4   13    11\n#> 808   10   1  3  2   23    12\n#> 809    9   1  1  5   22    13\n#> 810    3   1  1  4    8    14\n#> 811    1   0  0  1    7    15\n#> 812    0   0  0  0    0    16\n#> 813    2   0  0  1    2    16\n#> 814    0   1  0  2    2    17\n#> 815   NA   0  0 NA    0     1\n#> 816   NA   0  3  1    2     2\n#> 817    0   3  0  0    2     3\n#> 818   11   3  4  4    7     4\n#> 819    9   2  2  4    8     5\n#> 820   10   1  4  2    5     6\n#> 821    6   2  4  0   10     7\n#> 822    9   2  1  7    9     8\n#> 823    1   0  0  0    0     9\n#> 824    6   4  1  6    8     9\n#> 825    5   6  0  3    6    10\n#> 826   11   1  0  2    6    11\n#> 827    2   1  0  3    7    12\n#> 828    1   0  1  2    3    13\n#> 829    6   0  0  3    8    13\n#> 830    0   0  0  0    0    14\n#> 831    7   1  2  5   15     1\n#> 832    4   2  0  2    6     2\n#> 833   10   0  2  9   12     3\n#> 834   13   1  3  6   15     4\n#> 835    9   0  1  5   12     5\n#> 836    8   1  0 10   23     6\n#> 837    9   2  0  8   14     7\n#> 838    2   1  0  2   12     8\n#> 839   14   1  0  7   21     9\n#> 840   13   1  0  3   11    10\n#> 841    0   0  0  1    4    10\n#> 842    9   0  0  3   13    11\n#> 843    1   0  0  4    4    11\n#> 844   22   1  0  5   12    12\n#> 845    6   0  0  6   11    13\n#> 846    9   0  1  6   14    14\n#> 847    6   1  0  0    9    15\n#> 848   13   0  0  4   17    16\n#> 849    7   1  0  3   20    17\n#> 850   10   0  0  2    9    18\n#> 851    1   0  0  1    3    18\n#> 852    4   1  0  2   17    19\n#> 853    3   0  0  2   14    20\n#> 854    0   0  0  0    2    20\n#> 855    6   0  0  1    6    21\n#> 856    1   0  0  0    0    21\n#> 857    0   0  0  2    2    22\n#> 858    0   0  0  0    0     1\n#> 859    0   0  0  0    0     2\n#> 860    0   0  1  0    0     3\n#> 861    0   0  0  0    0     4\n#> 862    0   0  0  0    0     5\n#> 863    0   0  0  0    0     6\n#> 864    0   0  0  0    0     6\n#> 865    0   0  2  0    0     7\n#> 866    0   0  0  0    0     8\n#> 867    0   0  0  0    0     8\n#> 868    0   0  0  0    0     9\n#> 869    0   0  0  0    0    10\n#> 870    0   0  0  0    0    10\n#> 871    0   0  0  0    0    11\n#> 872    0   0  1  0    0    12\n#> 873    0   0  0  0    0    13\n#> 874    0   0  0  0    0    14\n#> 875    0   0  0  0    0    15\n#> 876    0   0  0  0    0     1\n#> 877    0   0  0  0    0     2\n#> 878    0   0  0  1    1     3\n#> 879    1   0  1  0    1     4\n#> 880    2   4  2  6    9     5\n#> 881    8   5  1  9   14     6\n#> 882    9   1  3  7   12     7\n#> 883    7   0  1  5   10     8\n#> 884    3   1  1  4   15     9\n#> 885    6   6  2  5    9    10\n#> 886    2   3  4  3   10    11\n#> 887    0   1  2  3   16    12\n#> 888    4   3  1 12   11    13\n#> 889    1   1  3  5    9    14\n#> 890    5   3  2  9    7    15\n#> 891    2   2  4  7    9    16\n#> 892    1   0  0  4    5    17\n#> 893    0   0  0  3   12    18\n#> 894    1   0  0  2    8    19\n#> 895   NA   0  1 NA    1     1\n#> 896   NA   0  2 NA    1     2\n#> 897   NA   0  3 NA    1     3\n#> 898   NA   0  2 NA    0     4\n#> 899   NA   0  2 NA    5     5\n#> 900   NA   2  2 NA    5     6\n#> 901   NA   0  2 NA    3     7\n#> 902   NA   0  5 NA    5     8\n#> 903   NA   0  1 NA    4     9\n#> 904   NA   2  3 NA    1    10\n#> 905   NA   1  0 NA    0    11\n#> 906   NA   1  2 NA    5    11\n#> 907   NA   0  0  0    0    12\n#> 908   NA   0  1  0    0    12\n#> 909    0   0  0  0    2    13\n#> 910   NA   2 23 NA   NA     1\n#> 911   NA   4 16 NA   NA     2\n#> 912   NA   0 18 NA   NA     3\n#> 913   NA   1  7 NA   NA     4\n#> 914   NA   0  9 NA   NA     5\n#> 915   NA   1  4 NA   NA     6\n#> 916   NA   1 12 NA   NA     6\n#> 917   NA   4 22 NA   NA     7\n#> 918   NA   3 12 NA   NA     8\n#> 919   NA   1  6 NA   NA     9\n#> 920   NA   1  5 NA   NA    10\n#> 921   NA   0 17 NA   NA    11\n#> 922   NA   2 22 NA   NA    12\n#> 923   NA   1  8 NA   NA    13\n#> 924   NA   2 15 NA   NA    14\n#> 925   NA   0 16 NA   NA    15\n#> 926   NA   0  0 NA   NA    16\n#> 927    0   0  1  0    0     1\n#> 928    0   3  3  0    0     2\n#> 929    6   7  6  5   12     3\n#> 930    5  11  2  1   12     4\n#> 931    5   6  7  3   12     5\n#> 932   11   8  6  5   14     6\n#> 933   17   9  6  3   13     7\n#> 934    5   4  6  5   13     8\n#> 935    4   5  1 13   10     9\n#> 936    2   5  2  2   10    10\n#> 937    1   4  7  3    7    11\n#> 938    3   3  3  5   10    12\n#> 939    4   6  4  7   11    13\n#> 940    3   3  6  1   17    14\n#> 941    2   1  3  4    7    15\n#> 942    1   0  2  0    1    16\n#> 943   NA   0  0 NA    0     1\n#> 944   NA   7  5  4   11     2\n#> 945    6   2  0  3   16     3\n#> 946   18   0  0  3    7     4\n#> 947   11   3  2  5   12     5\n#> 948   12   4  1  8   14     6\n#> 949   20   7  2  9   18     7\n#> 950   28   4  0  6   14     8\n#> 951   21   2  0  6   11     9\n#> 952    3   7  0 10   19    10\n#> 953   16   4  1  8    7    11\n#> 954   11   3  1  6   16    12\n#> 955   19   6  0  7   16    13\n#> 956   10   5  4  5   15    14\n#> 957    8   3  8  4   20    15\n#> 958    4   5  9  2   12    16\n#> 959    7   7  8  7   15    17\n#> 960    3   1  1  3    5    18\n#> 961    1   0  3  0    1    19\n#> 962    0   0  6  0    1     1\n#> 963    0   0  5  0    0     2\n#> 964    0   0  0  0    0     3\n#> 965    0   0  0  0    0     4\n#> 966    0   0  0  0    0     5\n#> 967    0   0  0  0    0     6\n#> 968    0   0  0  0    0     7\n#> 969    0   0  0  0    0     8\n#> 970    0   0  0  0    0     9\n#> 971    0   0  0  0    0    10\n#> 972    0   0  0  0    0    11\n#> 973    0   0  0  0    0    12\n#> 974    0   0  0  0    0    13\n#> 975    0   0  0  0    0    15\n#> 976    0   0  0  0    0    16\n#> 977    0   0  4  0    0     1\n#> 978    0   1  9  0    0     2\n#> 979    0   1  5  0    0     3\n#> 980    0   0  5  0    0     4\n#> 981    0   0  1  0    1     5\n#> 982    0   0  6  1    0     6\n#> 983    0   0  7  0    0     7\n#> 984    0   0  1  0    1     8\n#> 985    0   0  2  0    0     8\n#> 986    0   0  2  0    0     9\n#> 987    0   0  1  0    0    10\n#> 988    0   0  0  0    0    11\n#> 989    0   0  0  0    0    11\n#> 990    0   0  0  0    0    12\n#> 991    0   0  2  0    0    13\n#> 992    0   0  0  0    0    13\n#> 993    0   0  0  0    0    14\n#> 994    0   0  0  0    0    15\n#> 995   NA   3  4 NA   NA     1\n#> 996   NA   2  8 NA   NA     2\n#> 997   NA   1  0 NA   NA     3\n#> 998   NA   2 12 NA   NA     3\n#> 999   NA   2 17 NA   NA     4\n#> 1000  NA   6 14 NA   NA     5\n#> 1001  NA   2  3 NA   NA     6\n#> 1002  NA   1  9 NA   NA     6\n#> 1003  NA   1  1 NA   NA     7\n#> 1004  NA   5 24 NA   NA     7\n#> 1005  NA   3 11 NA   NA     8\n#> 1006  NA   2  5 NA   NA     8\n#> 1007  NA   3 15 NA   NA     9\n#> 1008  NA   3  8 NA   NA    10\n#> 1009  NA   1  4 NA   NA    10\n#> 1010  NA   0  0 NA   NA     1\n#> 1011  NA   6 11 NA   NA     2\n#> 1012  NA   2 22 NA   NA     3\n#> 1013  NA   5 22 NA   NA     4\n#> 1014  NA   3 30 NA   NA     5\n#> 1015  NA   6 35 NA   NA     6\n#> 1016  NA   5 37 NA    8     7\n#> 1017  NA   9  9 NA   11     8\n#> 1018  NA   6 21 NA    9     9\n#> 1019  NA   5 18 NA    9    10\n#> 1020  NA  10 14 NA    9    11\n#> 1021  NA   8  9 NA   10    12\n#> 1022  NA   7 10 NA   10    13\n#> 1023  NA   5 11 NA   11    14\n#> 1024  NA   1  1 NA    0    15\n#> 1025  NA   4  9 NA   11    15\n#> 1026  NA   8  5 NA    6    16\n#> 1027  NA   7  5 NA    8    17\n#> 1028  NA   0  0 NA    0    20\n#> 1029   0   0  1  0    0     1\n#> 1030   0   0  0  0    1     1\n#> 1031   1   0  4  1    2     2\n#> 1032   1   3  2  0    2     3\n#> 1033   1   6  4  2   10     4\n#> 1034  11   6  1  4   15     5\n#> 1035  13   4  0  5   15     6\n#> 1036  10   6  3  3   16     7\n#> 1037   3   1  1  4    2     8\n#> 1038   3   2  2  1    5     9\n#> 1039   8   4  2  3   12    10\n#> 1040   1   1  1  2    6    11\n#> 1041   2   0  0  1    2    11\n#> 1042   3   1  2  0    4    12\n#> 1043   6   1  1  2    5    13\n#> 1044   0   2  4  2   15    14\n#> 1045   0   0  0  1    0     1\n#> 1046   0   1  0  0    0     2\n#> 1047   0   9  2  3    9     3\n#> 1048   3  13  0  6   11     4\n#> 1049   6  10  3  4   10     5\n#> 1050   8  13  4  4   12     6\n#> 1051   4  20  1 11   11     7\n#> 1052   7  12  2  8   16     8\n#> 1053   9  18  0 12   15     9\n#> 1054   6  11  0 12   10    10\n#> 1055   4  11  0  5    9    11\n#> 1056   1   7  0  6   13    12\n#> 1057   7   7  0  8   18    13\n#> 1058  11  13  2  8   10    14\n#> 1059   6  23  1  3   10    15\n#> 1060   6  24  1 10   10    16\n#> 1061   8  35  0  5   12    17\n#> 1062   3  24  0  6   10    18\n#> 1063   0   4  0  0    3    18\n#> 1064   2  12  0  3    7    19\n#> 1065  NA   2 NA NA   NA     1\n#> 1066  NA   6 NA NA   NA     2\n#> 1067  NA   6 NA NA   NA     3\n#> 1068  NA   8 NA NA   NA     4\n#> 1069  NA  14 NA NA   NA     5\n#> 1070  NA  20 NA NA   NA     6\n#> 1071  NA  19 NA NA   NA     7\n#> 1072  NA  21 15 NA   NA     8\n#> 1073  NA  10  9 NA   NA     9\n#> 1074  NA   5  1 NA   NA     9\n#> 1075  NA   3  0 NA   NA    10\n#> 1076  NA  12  4 NA   NA    10\n#> 1077  NA  10  9 NA   NA    11\n#> 1078  NA  10 16 NA   NA    12\n#> 1079  NA   4 12 NA   NA    13\n#> 1080  NA   7 20 NA   NA    14\n#> 1081  NA   6  8 NA   NA    15\n#> 1082  NA   1 10 NA   NA    16\n#> 1083  NA   9 15 NA   NA    17\n#> 1084  NA   6  8 NA   NA    18\n#> 1085  NA   3 13 NA   NA    19\n#> 1086  NA   1  5 NA   NA    20\n#> 1087   0   0  0  0    0     1\n#> 1088   0   0  4  0    0     2\n#> 1089   0   0  1  0    0     3\n#> 1090   0   0  1  0    0     4\n#> 1091   0   0  6  0    0     5\n#> 1092   0   0  0  0    0     6\n#> 1093   0   0  0  0    0     7\n#> 1094   0   0  0  0    0     8\n#> 1095   0   0  0  0    0     9\n#> 1096   0   0  0  0    0     9\n#> 1097   0   0  0  0    0    10\n#> 1098   0   0  0  0    0    11\n#> 1099   0   0  0  0    0    13\n#> 1100   0   0  0  0    0    14\n#> 1101   0   0  0  0    0    15\n#> 1102   0   0  0  0    0     1\n#> 1103   0   0  1  0    0     2\n#> 1104   1   0  9  0    3     3\n#> 1105   2   4  9  6    9     4\n#> 1106   5   2  4  5   13     5\n#> 1107   3   5  9  2    4     6\n#> 1108   6   7  6  4    9     7\n#> 1109   1   2  4  4    3     8\n#> 1110   1   5 15  5    9     9\n#> 1111   0   2 20  4    4    10\n#> 1112   0   1 23  0    2    11\n#> 1113   0   2 11  3    6    12\n#> 1114   1   3  8  2    7    13\n#> 1115   1   6  7  7    4    14\n#> 1116   0   1 11  3    3    15\n#> 1117   0   0 11  0    1    16\n#> 1118   0   2  5  0    4    17\n#> 1119   1   0  2  0    2    18\n#> 1120   0   0  0  0    0     1\n#> 1121   0   0  5  0    0     2\n#> 1122   0   1 10  0    2     3\n#> 1123   0   2  9  0    1     4\n#> 1124   0   0  7  0    1     5\n#> 1125   0   0  7  0    1     6\n#> 1126   0   0  0  0    0     7\n#> 1127   0   1  3  0    0     7\n#> 1128   0   0  0  0    0     8\n#> 1129   0   0  0  0    0     9\n#> 1130   0   0  0  0    0    10\n#> 1131   0   0  0  0    1    11\n#> 1132   0   0  1  0    0    12\n#> 1133   0   0  0  0    0    13\n#> 1134   0   0  0  0    0    14\n#> 1135   8   3  1  1    5     1\n#> 1136   2   6  0  3   13     2\n#> 1137   1   3  8  2   14     3\n#> 1138   6   1 10  4   11     4\n#> 1139   3   2  5  6   12     5\n#> 1140   5   1  8  5   14     6\n#> 1141   1   0  9  2   24     7\n#> 1142   4   3  7 10   16     8\n#> 1143  11   0  4  0   16     9\n#> 1144  10   3  0 10    6    10\n#> 1145   8   2  0  5   13    11\n#> 1146   5   4  0  6   24    12\n#> 1147   8   3  2  9   21    13\n#> 1148   1   1  0  4   14    14\n#> 1149   2   0  1  2   10    14\n#> 1150   4   5  3  6   14    15\n#> 1151   3   1  1  2   14    16\n#> 1152   1   0  0  2    2    17\n#> 1153   1   0  0  1    8    17\n#> 1154   0   0  1  0    4    18\n#> 1155   0   0  0  0    0     1\n#> 1156   0   2  0  1    0     1\n#> 1157   2   1  0  1    3     2\n#> 1158   2   0  2  1    2     3\n#> 1159   4   2  1  5    8     4\n#> 1160   0   0  0  0    3     4\n#> 1161   0   0  0  0    0     4\n#> 1162   0   2  3  7    7     5\n#> 1163   0   6  6  4   11     6\n#> 1164   1   3  5  4    8     7\n#> 1165   2   9  6  7   18     8\n#> 1166   1   4  0  6    7     9\n#> 1167   4   6  2  5   14    10\n#> 1168   2   3  3  3   11    12\n#> 1169   1   1  0  2    7    12\n#> 1170   6   5  4  4   24    11\n#> 1171  NA   4  2 NA    4     1\n#> 1172  NA   4  1 NA    9     2\n#> 1173  NA   2  4 NA    6     3\n#> 1174  NA   3  4 NA   14     4\n#> 1175  NA   4  5  8   13     5\n#> 1176   2   0  2  6    6     6\n#> 1177   4   3  7  3   10     7\n#> 1178   5   3  6  6   10     8\n#> 1179   7   1  6  5    7     9\n#> 1180   1   2  1  8   13    10\n#> 1181   3   1  4  5    7    11\n#> 1182   3   0  0  9    4    12\n#> 1183   0   0  2  2    2    13\n#> 1184   2   0  1  1    3    13\n#> 1185   0   0  0  0    0    14\n#> 1186   0   0  0  0    1    15\n#> 1187   0   0  0  0    0     1\n#> 1188   0   0  0  0    0     2\n#> 1189   0   0  0  0    0     3\n#> 1190   0   0  0  0    0     4\n#> 1191   6   3 11  1    8     5\n#> 1192   6   3  2  1    4     6\n#> 1193   3   4  5  0   10     7\n#> 1194   2   0  3  0    1     8\n#> 1195   0   1  1  0    2     9\n#> 1196   2   2  7  1    4    10\n#> 1197   4   3 13  0    6    11\n#> 1198   0   3  3  0    1    12\n#> 1199   1   2  2  1    4    13\n#> 1200   2   2  4  0    4    14\n#> 1201   0   0  3  1    6    15\n#> 1202   0   0  4  1    1    16\n#> 1203   0   0  0  0    2    17\n#> 1204   0   0  0  0    0     1\n#> 1205   0   1  3  0    0     2\n#> 1206   0   1  1  2    3     3\n#> 1207   0   1 10  2    9     4\n#> 1208   0   3 39  6   14     5\n#> 1209   1   4 30  3   15     6\n#> 1210   0   4 19  2   12     7\n#> 1211   6   6 13  1   16     8\n#> 1212   1   3  8  3   15     9\n#> 1213   1   4  3  1   13    10\n#> 1214   5   5  6  6   10    11\n#> 1215   2   4  3  9   13    12\n#> 1216   3   7  5  3   14    13\n#> 1217   2   4  4  9    9    14\n#> 1218   0   3  6  5    7    15\n#> 1219   3   4  8  4    9    16\n#> 1220   0   1  0  1    2    17\n#> 1221   1   2  1  1    4    18\n#> 1222   0   0  1  1    4     1\n#> 1223   8   2  2  8   14     2\n#> 1224   7   4  0  7    7     3\n#> 1225   9   0  1 11   12     4\n#> 1226   7   0  0  2   20     5\n#> 1227  23   2  0 12   18     6\n#> 1228  14   0  1 10   22     7\n#> 1229  15   3  0  4   13     8\n#> 1230  12   2  0  8   12     9\n#> 1231   6   2  0  4    9    10\n#> 1232   8   1  0  7   10    11\n#> 1233  10   1  1  6    9    12\n#> 1234   8   0  3  4   11    13\n#> 1235   2   2  0  4    9    14\n#> 1236   3   0  1  0    4    15\n#> 1237   2   0  1  2   14    16\n#> 1238   1   0  0  0   13    17\n#> 1239  NA   2  4 NA   NA     1\n#> 1240  NA   1  2 NA   NA     2\n#> 1241  NA   0  2 NA   NA     3\n#> 1242  NA   3  2 NA   NA     4\n#> 1243  NA   0  4 NA   NA     5\n#> 1244  NA   0  1 NA   NA     6\n#> 1245  NA   0  5 NA   NA     7\n#> 1246  NA   3  4 NA   NA     8\n#> 1247  NA   1  5 NA   NA     9\n#> 1248  NA   0  3 NA   NA    10\n#> 1249  NA   0  5 NA   NA    11\n#> 1250  NA   0  4 NA   NA    12\n#> 1251  NA   0  0 NA   NA    13\n#> 1252  NA   0  1 NA   NA    14\n#> 1253  NA   0  0 NA   NA    15\n#> 1254   0   0  0  0    0    23\n#> 1255   0   0  1  0    1     1\n#> 1256   0   0  5  1    1     2\n#> 1257   0   2  7  0    2     3\n#> 1258   0   0  5  1    1     4\n#> 1259   0   1 14  0    0     5\n#> 1260   0   0 13  0    3     6\n#> 1261   0   0  0  0    0     7\n#> 1262   0   0  3  0    1     7\n#> 1263   0   0  9  2    0     8\n#> 1264   0   1  8  0    0     9\n#> 1265   0   1 10  0    0    10\n#> 1266   0   1 10  0    1    11\n#> 1267   0   0  6  0    3    12\n#> 1268   0   0  2  0    0    13\n#> 1269   0   0  2  0    1    14\n#> 1270   0   0  3  0    3     1\n#> 1271   0   0  0  2    2     2\n#> 1272   2   1  7  1    9     4\n#> 1273   1   2  6  1    7     5\n#> 1274   1   3  5  1   10     6\n#> 1275   0   1  8  2   13     7\n#> 1276   1   3 10  4   10     8\n#> 1277   0   2  1  4    5     9\n#> 1278   0   0  3  1   10    10\n#> 1279   0   1  4  1    6    11\n#> 1280   1   1 16  0    4    12\n#> 1281   0   4  6  1   10    13\n#> 1282   0   3  4  3   12    14\n#> 1283   3   5  9  1   16    15\n#> 1284   1   3  2  6   12    16\n#> 1285   1   1  2  2    9    17\n#> 1286   0   1  0  1    3    17\n#> 1287   0   0  1  1    4    18\n#> 1288   0   0  0  0    0     1\n#> 1289   0   0  0  0    0     2\n#> 1290   0   0  0  0    0     3\n#> 1291   0   0  0  0    0     4\n#> 1292   0   0  0  0    0     5\n#> 1293   0   0  0  0    0     6\n#> 1294   0   0  0  0    0     7\n#> 1295   0   0  0  0    0     8\n#> 1296   0   0  0  0    0     9\n#> 1297   0   0  0  0    0    10\n#> 1298   0   0  0  0    0    10\n#> 1299   0   0  0  0    0    10\n#> 1300   0   0  0  0    0    11\n#> 1301   0   0  0  0    0    13\n#> 1302   0   0  0  0    0    12\n#> 1303   0   0  0  0    0    14\n#> 1304   0   0  0  0    0    14\n#> 1305  NA  NA NA NA   NA     1\n#> 1306  NA  NA NA NA   NA     3\n#> 1307  NA  NA NA NA   NA     4\n#> 1308  NA  NA NA NA   NA     5\n#> 1309  NA  NA NA NA   NA     6\n#> 1310  NA  NA NA NA   NA     7\n#> 1311  NA  NA NA NA   NA     8\n#> 1312  NA  NA NA NA   NA     9\n#> 1313  NA   0 NA NA   NA    10\n#> 1314  NA   2 NA NA   NA    11\n#> 1315  NA   2 NA NA   NA    12\n#> 1316  NA   2 NA NA   NA    13\n#> 1317  NA   3 NA NA   NA    14\n#> 1318  NA   0 NA NA   NA    15\n#> 1319  NA   2 NA NA   NA    16\n#> 1320  NA   0  4 NA   NA     1\n#> 1321  NA   0  2 NA   NA     2\n#> 1322  NA   0  8 NA   NA     3\n#> 1323  NA   1  6 NA   NA     4\n#> 1324  NA   1  3 NA   NA     5\n#> 1325  NA   1  8 NA   NA     5\n#> 1326  NA   0  6 NA   NA     6\n#> 1327  NA   0  1 NA   NA     7\n#> 1328  NA   0  1 NA   NA     8\n#> 1329  NA   0  2 NA   NA     8\n#> 1330  NA   0  2 NA   NA     9\n#> 1331  NA   0  5 NA   NA    10\n#> 1332  NA   1  2 NA    2    11\n#> 1333  NA   0  0 NA    0    12\n#> 1334  NA   0  2 NA    0    13\n#> 1335  NA   0  0 NA   NA     1\n#> 1336  NA   0  2 NA   NA     2\n#> 1337  NA   1  3 NA   NA     3\n#> 1338  NA   0  2 NA   NA     4\n#> 1339  NA   0  3 NA   NA     5\n#> 1340  NA   0  2 NA   NA     6\n#> 1341  NA   0  1 NA   NA     6\n#> 1342  NA   0  4 NA   NA     7\n#> 1343  NA   0  5 NA   NA     8\n#> 1344  NA   0  0 NA   NA     9\n#> 1345  NA   0  3 NA   NA    10\n#> 1346  NA   0  4 NA   NA    11\n#> 1347  NA   0  2 NA   NA    12\n#> 1348  NA   1  3 NA   NA    14\n#> 1349  NA   0  0 NA   NA    15\n#> 1350  NA   0  4 NA   NA    16\n#> 1351   0   0  0  0    0     1\n#> 1352   0   0  1  0    0     2\n#> 1353   0   0  0  0    0     3\n#> 1354   0   0  0  0    0     4\n#> 1355   0   0  0  0    0     4\n#> 1356   0   0  0  0    0     5\n#> 1357   0   0  0  0    0     6\n#> 1358   0   0  0  0    0     7\n#> 1359   0   0  0  0    0     8\n#> 1360   0   0  3  0    0     9\n#> 1361   0   0  0  0    0    10\n#> 1362   0   0  0  0    0    11\n#> 1363   0   0  0  0    0    12\n#> 1364   0   0  0  0    0    13\n#> 1365   0   0  0  0    0    14\n#> 1366   0   0  0  0    0    15\n#> 1367   0   0  0  0    0    15\n#> 1368   0   0  0  0    0     1\n#> 1369   0   0  0  1    0     3\n#> 1370   9   0  1  2    5     4\n#> 1371   0   0  0  0    0     5\n#> 1372   2   0  3  0    1     6\n#> 1373   0   0  0  0    0     7\n#> 1374   3   0  2  1    4     7\n#> 1375   3   0  0  1    1     8\n#> 1376   2   1  2  0    5     9\n#> 1377   2   3  3  6    4    10\n#> 1378   0   0  1  2    6    11\n#> 1379   0   0  0  0    3    12\n#> 1380   4   1  1  3    1    13\n#> 1381   2   0  2  4    7    14\n#> 1382   3   2  4  1    5    15\n#> 1383   3   0  1  2    7    16\n#> 1384   2   0  0  2    2    17\n#> 1385   1   0  1  2    4    18\n#> 1386  NA   0  7 NA   NA     1\n#> 1387  NA   0  5 NA   NA     4\n#> 1388  NA   0  4 NA   NA     5\n#> 1389  NA   4 13 NA   NA     6\n#> 1390  NA   2 12 NA   NA     7\n#> 1391  NA   0  0 NA   NA     8\n#> 1392  NA   0  0 NA   NA     9\n#> 1393  NA   0  5 NA   NA    10\n#> 1394  NA   0  3 NA   NA    11\n#> 1395  NA   1  2 NA   NA    12\n#> 1396  NA   0  2 NA   NA    12\n#> 1397  NA   0  2 NA   NA    13\n#> 1398  NA   2  4 NA   NA    14\n#> 1399  NA   0  2 NA   NA    15\n#> 1400  NA   0  0 NA   NA    16\n#> 1401  NA   0  0 NA    1    17\n#> 1402  NA   0  0 NA    0     1\n#> 1403  NA   0  0 NA    7     2\n#> 1404  NA   1  2 NA    9     3\n#> 1405  NA   6  0 NA    6     4\n#> 1406  NA   4  0 NA   11     5\n#> 1407  NA   3  0 NA   16     6\n#> 1408  NA   4  1 NA    8     7\n#> 1409  NA   3  1 NA    7     8\n#> 1410  NA   4  1  7    9     9\n#> 1411   6   7  2  5   13    10\n#> 1412   7   5  1  5    8    11\n#> 1413  10   1  1  4   11    12\n#> 1414   5   2  0  6    6    13\n#> 1415   5   4  0  2    6    14\n#> 1416   6   3  0  4   11    15\n#> 1417   4   2  0  5    7    16\n#> 1418   4   2  0  5    7    17\n#> 1419   2   1  0  1    4    18\n#> 1420   0   0  0  0    0    20\n#> 1421   1   0  1  3    4     1\n#> 1422   1   0  0  0    1     2\n#> 1423   1   1  3  4    7     3\n#> 1424   0   1  0  0    3     4\n#> 1425   1   0  0  0    3     4\n#> 1426   1   1  7  2    6     5\n#> 1427   0   0  0  0    0     6\n#> 1428   1   0  0  2    6     7\n#> 1429   0   0  2  3    8     8\n#> 1430   2   0  5  6   13     9\n#> 1431   0   0  1  1    1    10\n#> 1432   0   1  0  0    2    10\n#> 1433   0   0  1  2    1    11\n#> 1434   4   0  1  4    5    12\n#> 1435   1   0  2  1    3    13\n#> 1436   1   1  0  0    6    14\n#> 1437   5   0  1  3    3    15\n#> 1438   0   0  0  4    0     1\n#> 1439   0   0  0  2    3     2\n#> 1440   1   3  1  2    9     3\n#> 1441   4   1  1  6    9     4\n#> 1442   3   3  2  3   13     5\n#> 1443   2   7  0  8    7     6\n#> 1444   3   4  0  2   17     7\n#> 1445   5   4  0  7   16     8\n#> 1446   4   6  0 10   18     9\n#> 1447   1   3  0  7   13    10\n#> 1448   2   1  0  4   22    11\n#> 1449   3   2  0 10   15    12\n#> 1450   0   0  0  0    3    13\n#> 1451   3   4  1  7   18    13\n#> 1452   1   3  0  1   13    14\n#> 1453   0   0  0  0    0     1\n#> 1454   0   0  1  0    0     2\n#> 1455   0   0  4  0    0     3\n#> 1456   0   0  2  0    0     4\n#> 1457   0   0  0  0    0     5\n#> 1458   0   0  9  0    0     6\n#> 1459   0   0 10  0    0     7\n#> 1460   0   0  4  0    1     8\n#> 1461   0   0  0  0    0     8\n#> 1462   0   0  4  0    1     9\n#> 1463   0   0  0  0    0    10\n#> 1464   0   0  1  0    0    11\n#> 1465   0   0  0  0    0    12\n#> 1466   0   0  0  0    0    13\n#> 1467   0   0  0  0    0    14\n#> 1468   2   0  1  0    1     1\n#> 1469   8   6  6  5    7     2\n#> 1470   1   3  9  1   11     3\n#> 1471   3   2  5  3    2     4\n#> 1472   9   7  5  2    5     5\n#> 1473   7  10  4  5   10     6\n#> 1474   1   8  2  2    5     7\n#> 1475   1  22 11  7    6     8\n#> 1476   0  27  8  8   10     9\n#> 1477   6  34  0  7    0    10\n#> 1478   6  23  1  4   10    11\n#> 1479   9  11  5  6    5    12\n#> 1480   3  16  7  5   10    13\n#> 1481   4  28  0  6   11    14\n#> 1482   2  17  9  2   15    15\n#> 1483   3  27  3  2    4    16\n#> 1484   0  15  9  3    8    17\n#> 1485   2  17  4  3   10    18\n#> 1486   1   9  5  5   16    19\n#> 1487   0   3  7  5    5    20\n#> 1488   0   0  0  0    0     1\n#> 1489   3   1  0  1    7     2\n#> 1490   5   2  6  3    7     3\n#> 1491   0   1  1  1    8     4\n#> 1492   0   0  1  0    0     5\n#> 1493   8   0  4  0   12     6\n#> 1494   0   0  0  0    2     7\n#> 1495   3   1  2  0    4     7\n#> 1496   2   1  1  2   17     8\n#> 1497   4   1  1  6    8     9\n#> 1498   1   0  0  2   10    10\n#> 1499   2   2  0  6    6    11\n#> 1500   1   0  0  1    3    12\n#> 1501   2   2  2  3    9    13\n#> 1502   5   0  0  2    0    14\n#> 1503   0   0  0  0    0     1\n#> 1504   0   0  0  0    0     2\n#> 1505   0   0  0  0    0     3\n#> 1506   0   0  0  0    0     4\n#> 1507   0   0  0  0    0     5\n#> 1508   0   0  0  0    0     6\n#> 1509   0   0  0  0    0     7\n#> 1510   0   0  0  0    0     8\n#> 1511   0   0  0  0    0     8\n#> 1512   0   0  0  0    0     9\n#> 1513   0   0  0  0    0    10\n#> 1514   0   0  0  0    0    10\n#> 1515   0   0  9  0    0    11\n#> 1516   0   0 10  0    0    12\n#> 1517   0   0  3  0    1    13\n#> 1518   0   0  5  0    0    14\n#> 1519   0   0  0  0    0    15\n#> 1520   0   0  0  0    0     1\n#> 1521   3   4  8  1    6     2\n#> 1522   0   0  5  2    4     3\n#> 1523   3   5  5  7   11     4\n#> 1524   4   2  5  2    4     5\n#> 1525   0   2 13  5   11     6\n#> 1526   1   3  5  4    9     7\n#> 1527   2   1  6  0    8     8\n#> 1528   0   0  5  7   16     9\n#> 1529   4   0  6  5   10    10\n#> 1530   0   2 11  7   11    11\n#> 1531   0   0 17  5    7    12\n#> 1532   2   2 13  1   14    13\n#> 1533   1   2  5  3    7    14\n#> 1534   0   0  2  0    4    15\n#> 1535   0   0  0  0    0    16\n#> 1536   3   0  2  2    4    16\n#> 1537   0   0  0  0    0    17\n#> 1538   1   0  1  0    0     1\n#> 1539   0   3  2  1    3     2\n#> 1540   4   1  5  1    4     3\n#> 1541   2   1  2  1   14     4\n#> 1542   2   2  7  0    3     5\n#> 1543   1   2  7  2    4     6\n#> 1544   0   0  0  0    0     7\n#> 1545   0   2  9  2    7     7\n#> 1546   2   2  9  2    4     8\n#> 1547   1   0  0  0    1     9\n#> 1548   0   0  0  0    0     9\n#> 1549   1   0  9  1    1    10\n#> 1550   1   2  7  3    2    11\n#> 1551   0   0  4  0    0    12\n#> 1552   0   0  0  0    0    12\n#> 1553  NA   2  1 NA   NA     1\n#> 1554  NA   8 21 NA   NA     2\n#> 1555  NA   9 15 NA   NA     3\n#> 1556  NA   2 24 NA   NA     4\n#> 1557  NA   5 22 NA   NA     5\n#> 1558  NA   5 18 NA   NA     6\n#> 1559  NA   8 16 NA   NA     7\n#> 1560  NA   1  6 NA   NA     8\n#> 1561  NA   8 27 NA   NA     9\n#> 1562  NA   5  9 NA   NA    10\n#> 1563  NA   4 20 NA   NA    11\n#> 1564  NA   3 21 NA   NA    12\n#> 1565  NA   2  4 NA   NA    13\n#> 1566  NA   1  5 NA   NA    14\n#> 1567  NA   6  5 NA   NA    15\n#> 1568  NA   1  1 NA   NA    16\n#> 1569  NA   1  3 NA   NA    17\n#> 1570  NA   0  0 NA    2    18\n#> 1571   0   0  0  0    0     1\n#> 1572   0   0  1  0    1     2\n#> 1573   0   2 13  0    0     3\n#> 1574   0   0  2  0    0     4\n#> 1575   0   0  0  0    0     5\n#> 1576   0   0  0  0    0     6\n#> 1577   0   0  0  0    0     7\n#> 1578   0   0  0  0    0     8\n#> 1579   0   0  0  0    0     9\n#> 1580   0   1  5  0    0    10\n#> 1581   0   0  8  0    0    11\n#> 1582   0   0  7  1    0    12\n#> 1583   0   0  5  0    1    13\n#> 1584   0   0  0  0    0    14\n#> 1585   0   0  0  0    0    15\n#> 1586   0   0  8  0    0    17\n#> 1587   0   0  4  0    0    18\n#> 1588   0   0  7  0    0     1\n#> 1589   0   1  7  0    0     2\n#> 1590   0   0 11  0    1     3\n#> 1591   0   0  0  0    0     4\n#> 1592   0   0  0  0    0     5\n#> 1593   0   0  0  0    0     6\n#> 1594   0   0  0  0    0     7\n#> 1595   0   0  0  0    0     7\n#> 1596   0   0  0  0    0     8\n#> 1597   0   0  7  0    0     9\n#> 1598   0   0 15  0    2    10\n#> 1599   0   1  9  0    1    11\n#> 1600   0   0  0  0    0    12\n#> 1601   0   0  0  0    0    13\n#> 1602   0   0  0  0    0    14\n#> 1603   0   0  0  0    0    15\n#> 1604   0   0  0  0    0    16\n#> 1605   0   0  0  0    0    16\n#> 1606   0   0  0  0    0    17\n#> 1607   0   0  0  0    0    18\n#> 1608   0   0  0  0    0    19\n#> 1609   0   0  0  0    0    20\n#> 1610   0   0  0  0    0    21\n#> 1611   0   0  0  0    0    23\n#> 1612   0   0  0  0    0     1\n#> 1613   0   0  0  0    0     2\n#> 1614   0   0  0  0    0     3\n#> 1615   0   0  0  0    0     4\n#> 1616   0   0  0  0    0     5\n#> 1617   0   0  0  0    0     6\n#> 1618   0   0  0  0    0     7\n#> 1619   0   0  0  0    0     8\n#> 1620   0   0  0  0    0     9\n#> 1621   0   0  0  0    0     9\n#> 1622   0   0  0  0    0    10\n#> 1623   0   0  0  0    0    11\n#> 1624   0   0  0  0    0    12\n#> 1625   0   0  0  0    0    13\n#> 1626   0   0  0  0    0    14\n#> 1627   4   0  4  4    9     1\n#> 1628   2   1  3  7   15     2\n#> 1629   6   0  8  4   13     3\n#> 1630   5   4  3  2   20     4\n#> 1631  14   0  4  4   11     5\n#> 1632  19   2  1  8   13     6\n#> 1633  18   3  0  7   23     7\n#> 1634  19   7  0  7   19     8\n#> 1635  19   1  0  6   14     9\n#> 1636  25   0  0  6   16    10\n#> 1637  19   4  0  6   10    11\n#> 1638   4   0  1  9   10    12\n#> 1639   3   1  2  4   10    13\n#> 1640   5   0  0  7   13    14\n#> 1641   7   0  1  5   10    15\n#> 1642   3   0  2  4    3    16\n#> 1643   6   0  0  2   13    17\n#> 1644   2   0  0  4   14    18\n#> 1645   2   2  2  2    4     1\n#> 1646   3   3  0  3    4     2\n#> 1647  14   2  0  2    3     3\n#> 1648  22   1  1  4    9     4\n#> 1649  15   3  0  6    8     5\n#> 1650  25   4  0 13    8     6\n#> 1651  32   5  0  7    9     7\n#> 1652  43   2  0  7   11     8\n#> 1653  18   6  0  3    3     9\n#> 1654  22   5  0  4   12    10\n#> 1655  30   1  0  6   11    11\n#> 1656  34   8  0  5   13    12\n#> 1657  29   8  1  6   15    13\n#> 1658   9   3  0  3    6    14\n#> 1659  22   3  0  7    6    15\n#> 1660  35   9  0  2    5    16\n#> 1661  68   9  0  2    4    17\n#> 1662  61  10  0  2    7    18\n#> 1663 120   9  0  3    5    19\n#> 1664  38  10  0  1    9    21\n#> 1665   3   0  0  1    0    20\n#> 1666  43   3  0  2   13    22\n#> 1667   0   1  1  2    0     1\n#> 1668   3  10  3  4    9     2\n#> 1669   7   2  1  2    6     3\n#> 1670   6   5  0  5   10     4\n#> 1671   4   5  1  5   13     5\n#> 1672   9   4  0  4    8     6\n#> 1673   8   4  0  4    4     7\n#> 1674   8   3  0  5   10     8\n#> 1675   6   3  0  5    7     9\n#> 1676   5   2  1 10    9    10\n#> 1677   1   0  1  1    2    11\n#> 1678   6   2  2  7   12    11\n#> 1679   4   8  4  7    9    12\n#> 1680   3   2  1  3    4    13\n#> 1681   5   2  1  0    4    14\n#> 1682   2   1  2  1    4     1\n#> 1683   1   1  3  0    5     1\n#> 1684   4   2  0  8    8     2\n#> 1685  19   4  0  8    4     3\n#> 1686  20   1  0  5   10     4\n#> 1687   9   1  0 15   11     5\n#> 1688   8   2  0 11   14     6\n#> 1689  10   1  0  1   11     7\n#> 1690  11   0  0  8   12     8\n#> 1691   9   0  0  2   10     9\n#> 1692   0   1  0  2   11    10\n#> 1693  10   1  0  2   11    10\n#> 1694   7   5  0 17   13    11\n#> 1695   8   5  0  8   18    12\n#> 1696   1   0  0  1    6    13\n#> 1697   3   0  0  5   10    13\n#> 1698   1   1  0  2    4    14\n#> 1699   2   1  0  1    3    15\n#> 1700   3   1  0  0    4    16\n#> 1701   2   0  0  1    2     1\n#> 1702   8   0  5  8    7     2\n#> 1703   9   4  9  5   16     3\n#> 1704   6   1  6  1    8     4\n#> 1705  14   1  4  7   10     5\n#> 1706   5   2  3  8    8     6\n#> 1707  10   1  5  8   13     7\n#> 1708   9   2  4  1    9     8\n#> 1709  12   1  4  2    9     9\n#> 1710   2   0  2  2    6    10\n#> 1711   2   0 23  5    9    11\n#> 1712   1   0 10  7   19    12\n#> 1713   1   0  6  5   11    13\n#> 1714   2   3 16  4   12    14\n#> 1715   1   0 12  6   15    15\n#> 1716   0   1 14  3   10    16\n#> 1717   2   2  9  0    9    17\n#> 1718   4   2  8  5   16    18\n#> 1719   0   0  2  0    2    19\n#> 1720   0   1  1  0    4     1\n#> 1721   1   4  6  4    6     2\n#> 1722   1   8  5  6   10     3\n#> 1723   0   6  5  5   14     4\n#> 1724   0   3  5  9    9     5\n#> 1725   4   4  4  5   11     6\n#> 1726   3   4  9  4   23     7\n#> 1727   0   5  9  2   11     8\n#> 1728   7   5  0  7   11     9\n#> 1729   5   9  5 13   11    10\n#> 1730   4   6  2  6   11    11\n#> 1731   3   7  1  7   17    12\n#> 1732   2   3  2  4   18    13\n#> 1733   2   3  1  1    9    14\n#> 1734   0   1  0  0    3    14\n#> 1735  NA   0  0 NA    0     1\n#> 1736  NA   2  9 NA   11     2\n#> 1737  NA   2  2 NA   10     3\n#> 1738  NA   5  6 NA   13     4\n#> 1739  NA   2  4 NA   11     5\n#> 1740  NA   0  3 NA    3     6\n#> 1741  NA   5  5 NA    6     6\n#> 1742  NA   2  2  4   18     7\n#> 1743   2   1  2  7   16     8\n#> 1744   8   3  2  5   13     9\n#> 1745   6   3  4  5   16    10\n#> 1746   1   1  2  1    3    11\n#> 1747   1   1  1  3    6    11\n#> 1748   0   0  0  2    0    12\n#> 1749   2   0  2  0    4    12\n#> 1750   0   0  1  0    1    12\n#> 1751   0   0  0  1    2    13\n#> 1752   0   0  0  0    0    13\n#> 1753   0   0  2  1    5     1\n#> 1754   2   1  1  2    7     2\n#> 1755   2   0  1  3   17     3\n#> 1756   1   1  6  3    8     4\n#> 1757   3   2  1  5   11     5\n#> 1758   2   2  7  3   18     6\n#> 1759   0   0  1  0    7     7\n#> 1760   1   0  0  0    1     8\n#> 1761   1   0  0  0    2     8\n#> 1762   0   0  1  0    1     9\n#> 1763   0   0  3  0    2     9\n#> 1764   0   0  1  0    1     9\n#> 1765   0   2  0  0    5    10\n#> 1766   0   2  2  1    3    11\n#> 1767   0   0  0  0    0    12\n#> 1768   0   0  0  0    0    12\n#> 1769   0   0  1  0    0    14\n#> 1770   0   0  0  0    0    15\n#> 1771   0   0  0  0    0    16\n#> 1772   0   0  1  0    2    17\n#> 1773   0   1  1  0    0    17\n#> 1774   1   1  2  1    4    18\n#> 1775   0   0  0  0    0     1\n#> 1776   0   3 12  1    3     2\n#> 1777   2   9 14  5   10     3\n#> 1778   2  11 10  6    9     4\n#> 1779   1   3  3  5    9     5\n#> 1780   2   5  7  3    8     6\n#> 1781   0   1  4  5    8     7\n#> 1782   1   2 12  4   23     8\n#> 1783   0  10 15  4   13     9\n#> 1784   1   5  8 10   25    10\n#> 1785   0   1  2  5   12    11\n#> 1786   0   2  2  0    4    11\n#> 1787   0   6  2  3    4    12\n#> 1788   0   3  6  2    9    13\n#> 1789   0   2  0  1    8    14\n#> 1790   0   1  4  2    4     1\n#> 1791   1   0  2  2    4     2\n#> 1792   0   0  0  0    1     3\n#> 1793   3   0  4  1    5     4\n#> 1794   0   0  1  0    4     5\n#> 1795   0   0  0  0    1     6\n#> 1796   1   0  0  1    0     7\n#> 1797   2   0  0  1    1     8\n#> 1798   1   0  0  2    3     9\n#> 1799   3   0  1  0    3    10\n#> 1800   2   0  1  2    2    11\n#> 1801   1   0  0  1    0    12\n#> 1802   0   0  1  3    2    12\n#> 1803   0   0  0  1    2    13\n#> 1804   1   0  0  0    1    14\n#> 1805  NA   2  2 NA   NA     1\n#> 1806  NA   4 15 NA   NA     2\n#> 1807  NA   3 17 NA   NA     3\n#> 1808  NA   2 13 NA   NA     4\n#> 1809  NA   4 19 NA   NA     5\n#> 1810  NA   5 26 NA   NA     6\n#> 1811  NA   3 17 NA   NA     7\n#> 1812  NA   1 17 NA   NA     8\n#> 1813  NA   5 24 NA   NA     9\n#> 1814  NA   1  2 NA   NA    10\n#> 1815  NA   1  2 NA   NA    11\n#> 1816  NA   7 11 NA   13    12\n#> 1817  NA   0  3 NA    9    13\n#> 1818  NA   2  4 NA   11    14\n#> 1819  NA   3  5 NA   NA    15\n#> 1820  NA   0  0 NA   NA    16\n#> 1821  NA   0  0 NA   NA     1\n#> 1822  NA   0  3 NA    5     2\n#> 1823  NA   2  4 NA   23     3\n#> 1824  NA   3 14 NA   11     4\n#> 1825  NA   4 19 NA   12     5\n#> 1826  NA   0 20 NA   12     6\n#> 1827  NA   5 19 NA   10     7\n#> 1828  NA   2 20 NA    9     8\n#> 1829  NA   1 15 NA   11     9\n#> 1830  NA   4 14 NA    9    10\n#> 1831  NA   2 16 NA   15    11\n#> 1832  NA   4 12 NA   19    12\n#> 1833  NA   1  3 NA    9    13\n#> 1834  NA   6  4 NA   10    14\n#> 1835  NA   0  1 NA    0    15\n#> 1836   1   0  6  3    8     1\n#> 1837   2   5  4  1    4     2\n#> 1838   1   2 18  2    8     3\n#> 1839   8   1  4  1    5     4\n#> 1840   0   1 20  4   11     5\n#> 1841   0   2 17  2    9     6\n#> 1842   3   0 11  5   11     7\n#> 1843   2   0 13  6   11     8\n#> 1844   1   1 11  2    6     9\n#> 1845   5   1 12  6   11    10\n#> 1846   7   3  7  3    9    11\n#> 1847   2   0  4  1    8    12\n#> 1848   5   1  9  1   10    13\n#> 1849   1   0  6  4    3    14\n#> 1850   5   0  3  1    4    15\n#> 1851   2   0  5  1    3    16\n#> 1852   0   0  1  0    0    16\n#> 1853  NA   0  0 NA   NA     1\n#> 1854  NA   0  0 NA   NA     2\n#> 1855  NA   2  1 NA   NA     3\n#> 1856  NA   1  0 NA   NA     4\n#> 1857  NA   1  3 NA   NA     4\n#> 1858  NA   5 13 NA   NA     5\n#> 1859  NA   4  2 NA   NA     6\n#> 1860  NA   2  3 NA   NA     7\n#> 1861  NA   0  5 NA   NA     8\n#> 1862  NA   3  4 NA   NA     9\n#> 1863  NA   7  7 NA   NA    10\n#> 1864  NA  11  7 NA   NA    11\n#> 1865  NA   3  7 NA   NA    12\n#> 1866  NA   5 14 NA   NA    13\n#> 1867  NA   3  4 NA   NA    14\n#> 1868  NA   0  1 NA   NA    15\n#> 1869   0   0  0  0    3     1\n#> 1870   1   1  2  0    2     2\n#> 1871   0   0  0  0    0     3\n#> 1872   2   0  3  1    2     5\n#> 1873   1   3  7  5    7     6\n#> 1874   4   2  1  8   13     7\n#> 1875   8   3  5  8   17     8\n#> 1876  11   2  2  2    5     9\n#> 1877  11   1  3  4   12    10\n#> 1878  10   2  2  4   16    11\n#> 1879   4   2  4  6    9    12\n#> 1880   3   2  0  6   14    13\n#> 1881   3   2  0  0    8    14\n#> 1882   6   4  4  3   16    15\n#> 1883   8   1  3  5   11    16\n#> 1884   2   0  1  1    1    17\n#> 1885   5   1  1  5    6     1\n#> 1886   7   1  2  3   18     2\n#> 1887   8   1  4  5   11     3\n#> 1888   8   3  1  8   15     4\n#> 1889   7   2  0  1    7     5\n#> 1890  10   4  0  4   13     6\n#> 1891   9   1  0  5   11     7\n#> 1892   7   1  2  2   15     8\n#> 1893  10   2  0  4   20     9\n#> 1894  12   2  0  4   22    10\n#> 1895   3   1  4  7   16    11\n#> 1896   5   0  1  7   15    12\n#> 1897   0   0  2  1    4    13\n#> 1898   3   0  0  2    6    13\n#> 1899   0   0  0  0    2    14\n#> 1900   3   1  0  5    2    14\n#> 1901   0   0  0  0    2    15\n#> 1902   4   5  2  4    8     1\n#> 1903   1   2  2  4   14     2\n#> 1904   8   3  1  1    9     3\n#> 1905   4   2  4  1    6     4\n#> 1906   5   1  2  4    8     5\n#> 1907   2   1  2  4    5     6\n#> 1908   2   2  8  3   14     7\n#> 1909   1   0  0  1    4     8\n#> 1910   1   0  1  1    1     8\n#> 1911   2   0  1  0    2     9\n#> 1912   0   0  0  0    0    10\n#> 1913   1   0  0  0    2    10\n#> 1914   0   0  1  0    1    11\n#> 1915   0   0  0  0    2    12\n#> 1916   0   0  0  1    1    13\n#> 1917   0   0  0  0    0    14\n#> 1918   1   1  0  1    0    15\n#> 1919  NA   0  0 NA   NA     1\n#> 1920  NA   0  0 NA   NA     4\n#> 1921  NA   1  4 NA   NA     5\n#> 1922  NA   2  4 NA   NA     6\n#> 1923  NA   2  6 NA   NA     6\n#> 1924  NA   7 12 NA   NA     7\n#> 1925  NA   5  3 NA   NA     8\n#> 1926  NA  11  7 NA   NA     9\n#> 1927  NA  15  5 NA   NA    10\n#> 1928  NA   6  6 NA   NA    11\n#> 1929  NA   6 24 NA   NA    12\n#> 1930  NA   1  7 NA   NA    13\n#> 1931  NA   2  8 NA   NA    14\n#> 1932  NA   3  6 NA   NA    15\n#> 1933  NA   2  0 NA   NA    16\n#> 1934  NA   2  4 NA   NA    17\n#> 1935  NA   2 12 NA   NA    18\n#> 1936  NA   0  4 NA   NA    19\n#> 1937  NA   1  2 NA   NA     1\n#> 1938  NA   1  3 NA   NA     2\n#> 1939  NA   0  1 NA   NA     3\n#> 1940  NA   0  0 NA   NA     4\n#> 1941  NA   0  1 NA   NA     5\n#> 1942  NA   2  7 NA   NA     6\n#> 1943  NA   0  1 NA   NA     7\n#> 1944  NA   2 17 NA   NA     8\n#> 1945  NA   0  1 NA   NA     9\n#> 1946  NA   4  2 NA   NA    10\n#> 1947  NA   4  6 NA   NA    11\n#> 1948  NA   2  7 NA   NA    12\n#> 1949  NA   3 13 NA   NA    13\n#> 1950  NA   1 24 NA   NA    14\n#> 1951  NA   5 23 NA   NA    15\n#> 1952  NA   1 15 NA   NA    16\n#> 1953  NA   2 11 NA   NA    17\n#> 1954  NA   0  3 NA   NA    18\n#> 1955  NA   0  1 NA   NA    19\n#> 1956  NA   0  2 NA   NA    19\n#> 1957   0   0  1  0    0     1\n#> 1958   3   0  6  2    9     2\n#> 1959   6   2  9  6    8     3\n#> 1960   4   1  2  8    8     4\n#> 1961   9   2  3  3   12     5\n#> 1962   6   1  3  5    6     6\n#> 1963  14   0  1  4    8     7\n#> 1964  16   1  0  7   11     8\n#> 1965   7   1  0  4    7     9\n#> 1966  14   1  0  5   12    10\n#> 1967  13   1  0  3    9    11\n#> 1968   6   0  0  7   11    12\n#> 1969  31   3  0  9   12    13\n#> 1970  18   4  0  4    6    14\n#> 1971  14   1  0  8   10    15\n#> 1972  15   3  0  7   15    16\n#> 1973  14   3  0  9   18    17\n#> 1974  14   0  0  7   18    18\n#> 1975  10   0  1  8   20    19\n#> 1976   6   6  0  4   15    20\n#> 1977   9   3  0 10   20    21\n#> 1978   0   0  0  0    0     1\n#> 1979   0   0  2  0    2     3\n#> 1980   0   1  1  0    1     4\n#> 1981   0   0  1  0    0     5\n#> 1982   0   0  1  0    0     6\n#> 1983   0   0  0  1    0     7\n#> 1984   0   0  3  1    0     8\n#> 1985   0   0  1  0    1     9\n#> 1986   0   0  0  0    0    10\n#> 1987   0   0  0  0    1    10\n#> 1988   0   0  0  0    0    11\n#> 1989   0   0  0  0    0    11\n#> 1990   0   0  0  0    0    12\n#> 1991   0   0  0  0    0    13\n#> 1992   0   0  0  0    1    13\n#> 1993   0   0  0  0    0    14\n#> 1994   0   0  0  0    0    15\n#> 1995   0   0  0  0    0     1\n#> 1996   0   0  1  0    0     2\n#> 1997   0   0  0  0    0     3\n#> 1998   0   0  1  0    0     4\n#> 1999   0   0  0  0    0     5\n#> 2000   0   1  0  0    0     6\n#> 2001   0   0  0  0    0     7\n#> 2002   0   0  1  0    1     8\n#> 2003   0   0  1  0    0     9\n#> 2004   0   0  0  0    0    10\n#> 2005   0   0  1  0    0    11\n#> 2006   0   0  0  0    0    12\n#> 2007   0   0  0  0    0    13\n#> 2008   0   0  2  0    0    14\n#> 2009   0   0  0  0    0    15\n#> 2010   0   0  0  0    0    16\n#> 2011   0   0  0  0    0    16\n#> 2012   0   0  0  0    0    17\n#> 2013  NA   0  2 NA   NA     1\n#> 2014  NA   0  5 NA   NA     2\n#> 2015  NA   0  5 NA   NA     3\n#> 2016  NA   0  7 NA   NA     4\n#> 2017  NA   0  8 NA   NA     5\n#> 2018  NA   0  4 NA   NA     6\n#> 2019  NA   0  6 NA   NA     7\n#> 2020  NA   0  3 NA   NA     8\n#> 2021  NA   0  4 NA   NA     9\n#> 2022  NA   0  8 NA    0    10\n#> 2023  NA   0  4 NA    1    11\n#> 2024  NA   0  4 NA    1    12\n#> 2025  NA   0  1 NA    2    13\n#> 2026  NA   0  4 NA    2    14\n#> 2027  NA   0  0 NA    0    16\n#> 2028  NA   0  0 NA    0    17\n#> 2029   0   0  0  0    0     1\n#> 2030   0   0  1  0    1     2\n#> 2031   0   0  5  0    0     3\n#> 2032   0   1  9  1    2     4\n#> 2033   0   0  5  0    2     5\n#> 2034   0   0  3  0    0     6\n#> 2035   0   0  3  0    0     7\n#> 2036   0   0  5  1    0     8\n#> 2037   0   1  6  1    0     9\n#> 2038   0   0  0  0    0    10\n#> 2039   0   0  0  0    0    11\n#> 2040   0   0  0  0    0    12\n#> 2041   0   0  0  0    0    13\n#> 2042   0   0  0  0    0    13\n#> 2043   0   0  0  0    0    14\n#> 2044   0   0  0  0    0     1\n#> 2045   0   0  0  1    6     2\n#> 2046   4   4  4  2    6     3\n#> 2047   1   4  2  3    6     4\n#> 2048   7   2  5  2   11     5\n#> 2049   4   0  9  5   17     6\n#> 2050   1   4  5  1    4     7\n#> 2051   5   0  3  0    6     8\n#> 2052   3   5  5  3   23     9\n#> 2053   0   5  1  4   15    10\n#> 2054   7   7  6  5   14    11\n#> 2055   9   3  7  7   14    12\n#> 2056   1   1 14  2   22    13\n#> 2057   0   3  9  3   12    14\n#> 2058   0   0  0  0    0    15\n#> 2059   0   1  1  0    3    15\n#> 2060   2   1  0  2    3    15\n#> 2061   0   0  0  0    0     1\n#> 2062   4   3  0  5    5     2\n#> 2063   2   4  2  4    2     3\n#> 2064   0   2  1  0    3     4\n#> 2065   0   2 12  4    2     4\n#> 2066   6  10 11  0    2     5\n#> 2067   6   3  0  1    7     6\n#> 2068   6   6  2  3    6     7\n#> 2069   7   3  1  2    4     8\n#> 2070  15   2  2  1    2     9\n#> 2071  12   1  1  3   10    10\n#> 2072   5   1  1  2    5    11\n#> 2073  12   1  3  3    6    12\n#> 2074  15   0  1  5    9    13\n#> 2075  16   2  2  1    8    14\n#> 2076   6   3  3  0    7    15\n#> 2077   7   1  4  6   19    16\n#> 2078   2   2  0  0    6    17\n#> 2079   2   0  1  1    4    18\n#> 2080   1   3  0  5    7    19\n#> 2081   0   2  1  0    1     1\n#> 2082   2   1  1  6    9     2\n#> 2083   5   5  3  5   11     3\n#> 2084   2   4  7  3   14     4\n#> 2085  15   2  0  2   17     5\n#> 2086   6   5  0  8   20     6\n#> 2087   3   2  0  5   11     7\n#> 2088   2   1  0  4    7     8\n#> 2089   3   1  0  4   21     9\n#> 2090   2   4  0  8   15    10\n#> 2091  10   6  0 11   13    11\n#> 2092   8   3  0  3    7    12\n#> 2093   3   1  0  1   10    13\n#> 2094   1   1  0  1    5    14\n#> 2095   0   0  0  4    2    15\n#> 2096  NA  NA NA NA   NA     1\n#> 2097  NA  NA NA NA   NA     2\n#> 2098  NA  NA NA NA   NA     3\n#> 2099  NA  NA NA NA   NA     4\n#> 2100  NA  NA NA NA   NA     5\n#> 2101  NA  NA NA NA   NA     6\n#> 2102  NA  NA NA NA   NA     7\n#> 2103  NA  NA NA NA   NA     8\n#> 2104  NA   6 NA NA   NA     9\n#> 2105  NA  12 NA NA   NA    10\n#> 2106  NA  14 NA NA   NA    11\n#> 2107  NA  18 NA NA   NA    12\n#> 2108  NA  24 NA NA   NA    13\n#> 2109  NA  16 NA NA   NA    14\n#> 2110  NA   6 NA NA   NA    15\n#> 2111  NA   5 NA NA   NA    16\n#> 2112  NA   0  1 NA   NA    17\n#> 2113  NA   0  0 NA   NA    17\n#> 2114  NA   4  1 NA   NA    18\n#> 2115  NA   0  0 NA   NA    26\n#> 2116  NA   0  0 NA   NA     1\n#> 2117  NA   0  0 NA   NA     2\n#> 2118  NA   0  3 NA   NA     3\n#> 2119  NA   1  3 NA   NA     4\n#> 2120  NA   1  5 NA   NA     5\n#> 2121  NA   0  3 NA   NA     6\n#> 2122  NA   0  0 NA   NA     7\n#> 2123  NA   0  0 NA   NA     8\n#> 2124  NA   0  2 NA   NA     9\n#> 2125  NA   0  1 NA   NA    10\n#> 2126  NA   0  0 NA   NA    11\n#> 2127  NA   0  4 NA    2    12\n#> 2128  NA   0  3 NA    1    13\n#> 2129  NA   0  0 NA    0    14\n#> 2130  NA   0  0 NA    0    15\n#> 2131  NA   1  0 NA   NA     1\n#> 2132  NA   2  6 NA   NA     2\n#> 2133  NA   3  6 NA   NA     2\n#> 2134  NA   4 14 NA   NA     3\n#> 2135  NA   4 22 NA   NA     4\n#> 2136  NA   2 11 NA   NA     5\n#> 2137  NA   0 25 NA   NA     6\n#> 2138  NA   1 24 NA   NA     7\n#> 2139  NA   0 18 NA   NA     8\n#> 2140  NA   3  8 NA   NA     9\n#> 2141  NA   0  1 NA   NA     9\n#> 2142  NA   0  0 NA   NA    10\n#> 2143  NA   0  3 NA   NA    10\n#> 2144  NA   0  0 NA   NA    11\n#> 2145  NA   0  0 NA   NA    12\n#> 2146  NA   0  0 NA    0     1\n#> 2147  NA   0  1 NA    0     2\n#> 2148  NA   1  4 NA    0     3\n#> 2149  NA   0  1  0    0     4\n#> 2150   0   0  0  0    0     5\n#> 2151   0   0  0  0    0     5\n#> 2152   0   1  3  0    0     6\n#> 2153   0   0  6  1    0     7\n#> 2154   0   1  1  0    1     8\n#> 2155   0   0  9  0    1     9\n#> 2156   0   1  5  0    0    10\n#> 2157   0   0  3  1    1    11\n#> 2158   0   0  2  0    1    12\n#> 2159   0   0  0  0    0    12\n#> 2160   0   0  3  0    3    13\n#> 2161   0   0  2  0    1    14\n#> 2162   0   0  0  0    0     1\n#> 2163   0   0  0  0    0     3\n#> 2164   0   0  0  0    0     4\n#> 2165   0   0  0  0    0     5\n#> 2166   0   0  0  0    0     6\n#> 2167   0   0  0  0    0     7\n#> 2168   0   0  0  0    0     8\n#> 2169   0   0  0  0    0     9\n#> 2170   0   0  0  0    0    10\n#> 2171   0   0  4  0    1    11\n#> 2172   0   0  6  0    0    12\n#> 2173   0   0  7  0    0    13\n#> 2174   0   0 13  1    0    14\n#> 2175   0   2 14  0    0    15\n#> 2176   0   3  2  0    0    16\n#> 2177   0   0  2  0    0    17\n#> 2178   0   0  6  1    1    18\n#> 2179   0   0  0  0    0    19\n#> 2180   0   0  0  0    0    20\n#> 2181  NA   1  2 NA   NA     1\n#> 2182  NA   0  1 NA   NA     2\n#> 2183  NA   0  7 NA   NA     3\n#> 2184  NA   0  5 NA   NA     4\n#> 2185  NA   0  5 NA   NA     5\n#> 2186  NA   0  5 NA   NA     6\n#> 2187  NA   0  5 NA   NA     7\n#> 2188  NA   0  6 NA   NA     8\n#> 2189  NA   0  3 NA   NA     9\n#> 2190  NA   0  1 NA   NA    10\n#> 2191  NA   0  3 NA   NA    11\n#> 2192  NA   0  0 NA   NA    12\n#> 2193  NA   0  2 NA   NA    12\n#> 2194  NA   0  4 NA   NA    13\n#> 2195  NA   0  0 NA   NA    14\n#> 2196   0   0  0  0    0     1\n#> 2197   7   2  3  0   14     2\n#> 2198   7   4  1  4   15     3\n#> 2199   0   2  0  0    1     4\n#> 2200   3   3  4  2   12     5\n#> 2201   8   0  3  6   14     6\n#> 2202   5   3  1  2   10     7\n#> 2203   1   0  0  0    0     8\n#> 2204   3   1  1  2   10     8\n#> 2205   2   0  0  1    1     8\n#> 2206   1   2  1  1    8     9\n#> 2207   0   0  0  0    2    10\n#> 2208   1   0  0  0    5    10\n#> 2209   1   0  1  0    1    11\n#> 2210   5   0  1  4    1    12\n#> 2211   1   0  0  1    3    13\n#> 2212  NA  NA NA NA   NA     1\n#> 2213  NA  NA NA NA   NA     2\n#> 2214  NA   2 NA NA   NA     3\n#> 2215  NA   0 NA NA   NA     4\n#> 2216  NA   7 NA NA   NA     5\n#> 2217  NA   8 NA NA   NA     6\n#> 2218  NA   4 NA NA   NA     7\n#> 2219  NA   0 NA NA   NA     8\n#> 2220  NA   3 NA NA   NA     9\n#> 2221  NA   1 NA NA   NA    10\n#> 2222  NA   2 NA NA   NA    10\n#> 2223  NA   0 NA NA   NA    11\n#> 2224  NA   0 NA NA   NA    11\n#> 2225  NA   2 NA NA   NA    12\n#> 2226  NA   0 NA NA   NA    13\n#> 2227  NA   0 NA NA   NA    13\n#> 2228  NA  NA NA NA   NA     1\n#> 2229  NA  NA NA NA   NA     2\n#> 2230  NA   4 NA NA   NA     3\n#> 2231  NA   7 NA NA   NA     4\n#> 2232  NA   2 NA NA   NA     5\n#> 2233  NA   1 NA NA   NA     6\n#> 2234  NA   1 NA NA   NA     6\n#> 2235  NA   1 NA NA   NA     7\n#> 2236  NA   1 NA NA   NA     8\n#> 2237  NA   3 NA NA   NA     9\n#> 2238  NA   4 NA NA   NA    10\n#> 2239  NA   5 NA NA   NA    11\n#> 2240  NA   5 NA NA   NA    12\n#> 2241  NA   3 NA NA   NA    13\n#> 2242  NA   2  2 NA   NA    14\n#> 2243  NA   0  1 NA   NA    14\n#> 2244  NA   6 14 NA   NA    15\n#> 2245  NA   1  8 NA   NA    16\n#> 2246  NA   0  0 NA   NA    17\n#> 2247   0   0  0  0    0     1\n#> 2248   0   8  1  2   12     2\n#> 2249   4   4  1  3   13     3\n#> 2250   2   0  0  4   15     4\n#> 2251   7   0  0 13   12     5\n#> 2252   4   1  1  7   15     6\n#> 2253   5   4  0  4   12     7\n#> 2254   0   0  0  0    0     8\n#> 2255   6   4  1  6   17     8\n#> 2256   3   2  0  5   10     9\n#> 2257   7   3  0  8   12    10\n#> 2258   0   1  0  1    1    10\n#> 2259   2   3  0  8    8    11\n#> 2260   2   0  2  7   11    12\n#> 2261   0   0  2  0    5    13\n#> 2262   0   0  0  0    1    14\n#> 2263   1   0  0  4    2    14\n#> 2264   0   0  0  0    0     1\n#> 2265   0   0  0  0    0     2\n#> 2266   0   0  0  0    0     4\n#> 2267   0   0  0  0    0     5\n#> 2268   0   0  0  0    0     5\n#> 2269   0   0  0  0    0     6\n#> 2270   0   0  1  0    0     7\n#> 2271   0   0  0  0    0     8\n#> 2272   0   0  0  0    0     8\n#> 2273   0   1  1  0    1     9\n#> 2274   0   0  6  0    1    10\n#> 2275   0   0  1  0    1    11\n#> 2276   0   0  4  0    2    12\n#> 2277   0   1  4  0    3    13\n#> 2278   0   0  2  0    1    14\n#> 2279   0   0  0  0    0    14\n#> 2280   0   1  4  0    0    15\n#> 2281   0   0  0  0    0    15\n#> 2282   0   0  0  0    0    16\n#> 2283   0   0  0  0    0     1\n#> 2284   1   0  0  0    0     2\n#> 2285   4   5  7  2    6     3\n#> 2286   2   1  3  1   13     4\n#> 2287   5   3  6  5   15     5\n#> 2288  10   4  4  2   13     6\n#> 2289   7   2  4  4   11     7\n#> 2290   6   1  6  5    8     8\n#> 2291   2   1  2  7   16     9\n#> 2292   5   0  1  5   16    10\n#> 2293   6   2  1  4   16    11\n#> 2294  11   0  0  6   13    12\n#> 2295   9   1  0  5   17    13\n#> 2296   7   5  1 10   14    14\n#> 2297   5   5  4  5   10    15\n#> 2298   5   5  0  3   11    16\n#> 2299   1   1  0  1    1    16\n#> 2300   5   2  2 11   16    17\n#> 2301   9   4  0  8   25    18\n#> 2302   1   0  0  5   10    19\n#> 2303   1   0  1  1    3    19\n#> 2304   0   0  0  1    2    20\n#> 2305   5   0  4  4    6    20\n#> 2306   2   0  0  1    4    21\n#> 2307   2   0  1  1    1    22\n#> 2308  NA   0  5 NA    1     1\n#> 2309  NA   0  0  0    0     2\n#> 2310   0   0  7  0    2     3\n#> 2311   0   0  6  0    0     4\n#> 2312   0   0  3  0    1     5\n#> 2313   0   0  1  0    0     6\n#> 2314   0   0  2  0    1     7\n#> 2315   0   0  3  0    2     8\n#> 2316   0   0  2  0    1     9\n#> 2317   0   0  0  0    0    10\n#> 2318   0   1  7  1    0    10\n#> 2319   0   0  7  0    1    11\n#> 2320   0   0  5  1    1    12\n#> 2321   0   0  2  0    0    13\n#> 2322   0   0  0  0    0    14\n#> 2323   0   1  3  0    0    14\n#> 2324   0   0  0  0    0    15\n#> 2325   0   0  0  0    1     1\n#> 2326   0   3  0  1    1     2\n#> 2327   1   3  1  2    4     2\n#> 2328   0   2  0  1    0     3\n#> 2329   1   4  0  1    6     4\n#> 2330   5   6  2  4   10     5\n#> 2331   2   6  1  8   12     6\n#> 2332  11   2  2  8   12     7\n#> 2333   3   5  2  5    7     8\n#> 2334   7   1  2  6   15     9\n#> 2335   5   9  0 10   11    10\n#> 2336   3   5  0  1   23    11\n#> 2337   0   1  1  2    2    12\n#> 2338   0   5  0  3    6    13\n#> 2339   3   4  1  2   10    14\n#> 2340   0   0  0  0    3    15\n#> 2341   0   0  2  0    0     1\n#> 2342   0   0  2  0    1     2\n#> 2343   0   0  5  0    6     3\n#> 2344   0   0  6  0    3     4\n#> 2345   0   0  8  0    5     5\n#> 2346   0   0  8  1    1     6\n#> 2347   0   0  2  0    3     7\n#> 2348   0   1  4  1    1     8\n#> 2349   0   0  6  0    4     9\n#> 2350   0   0  9  1    2    10\n#> 2351   0   0  4  0    0    11\n#> 2352   0   0  4  1    3    12\n#> 2353   0   0  7  0    1    13\n#> 2354   0   0  2  0    1    14\n#> 2355   0   0  7  0    2    15\n#> 2356   0   0  3  0    1    15\n#> 2357   0   0  3  1    2    16\n#> 2358   0   0  3  1    0    17\n#> 2359   0   0  0  0    0     1\n#> 2360   0   0  0  0    0     2\n#> 2361   0   0  3  0    0     3\n#> 2362   0   0  3  0    1     4\n#> 2363   0   0  0  0    0     5\n#> 2364   0   0  0  0    0     6\n#> 2365   0   0  4  0    0     6\n#> 2366   0   0  3  0    2     7\n#> 2367   0   2  4  0    1     8\n#> 2368   0   0  0  0    0     9\n#> 2369   0   0  0  0    0    10\n#> 2370   0   0  2  0    0    11\n#> 2371   0   0  2  0    0    12\n#> 2372   0   0  0  0    0    13\n#> 2373   0   0  0  0    0    13\n#> 2374   0   0  1  0    1    14\n#> 2375   0   0  0  0    0    15\n#> 2376   0   0  0  0    0    15\n#> 2377   0   0  0  0    0     1\n#> 2378  NA   0  0 NA    0     2\n#> 2379  NA   1  6 NA    2     3\n#> 2380  NA   0  5 NA    0     4\n#> 2381  NA   2  5  2    0     5\n#> 2382   0   0  3  0    0     6\n#> 2383   0   1 11  2    1     7\n#> 2384   0   1  4  1    4     8\n#> 2385   0   1  5  0    4     9\n#> 2386   0   1  5  0    0    10\n#> 2387   0   1  2  1    2    11\n#> 2388   0   0  3  0    0    12\n#> 2389   0   1  2  0    1    13\n#> 2390   0   2  4  0    0    14\n#> 2391   0   0  3  0    0    14\n#> 2392   0   0  0  0    0    15\n#> 2393   0   1  3  0    0    15\n#> 2394   0   0  0  0    0    16\n#> 2395   0   0  2  0    0    16\n#> 2396   0   0  0  0    0    17\n#> 2397   0   0  0  0    0    18\n#> 2398  NA  NA NA NA   NA     1\n#> 2399  NA  NA NA NA   NA     2\n#> 2400  NA  NA NA NA   NA     3\n#> 2401  NA  NA NA NA   NA     4\n#> 2402  NA  NA NA NA   NA     5\n#> 2403  NA  NA NA NA   NA     6\n#> 2404  NA  NA NA NA   NA     7\n#> 2405  NA  NA NA NA   NA     8\n#> 2406  NA  NA NA NA   NA     9\n#> 2407  NA  NA NA NA   NA    10\n#> 2408  NA  NA NA NA   NA    11\n#> 2409  NA  NA NA NA   NA    12\n#> 2410  NA  NA NA NA   NA    13\n#> 2411  NA  NA NA NA   NA    14\n#> 2412  NA  NA NA NA   NA    15\n#> 2413  NA   4 NA NA   NA    16\n#> 2414  NA   5 NA NA   NA    17\n#> 2415  NA   1 NA NA   NA    17\n#> 2416  NA   0 NA NA   NA    20\n#> 2417  NA   0  0 NA    1     1\n#> 2418  NA   0  0 NA   10     3\n#> 2419  NA   1  3 NA    4     4\n#> 2420  NA   2  0 NA   11     5\n#> 2421  NA   0  1  4   10     6\n#> 2422   1   0  0  0    3     7\n#> 2423   4   1  2  6   11     7\n#> 2424   4   0  1  2    5     8\n#> 2425   5   0  0  3    4     9\n#> 2426   3   1  0  0    8    10\n#> 2427   9   2  2  6   10    11\n#> 2428  12   0  0  4    6    12\n#> 2429   8   2  0  1    7    13\n#> 2430   9   0  2  6    6    14\n#> 2431   8   1  0  4   12    15\n#> 2432   2   0  0  0    0    16\n#> 2433   3   1  2  0    9    16\n#> 2434   4   0  0  1    2    17\n#> 2435   2   1  0  1    0    18\n#> 2436   6   1  0  1    2    19\n#> 2437   0   0  0  0    0     1\n#> 2438   0   0  0  0    0     2\n#> 2439   0   0  1  0    0     3\n#> 2440   0   0  0  0    0     4\n#> 2441   0   0  0  0    0     5\n#> 2442   0   0  0  0    0     6\n#> 2443   0   0  0  0    0     7\n#> 2444   0   0  0  0    0     8\n#> 2445   0   0  0  0    0     9\n#> 2446   0   0  0  0    0    10\n#> 2447   0   0  0  0    0    11\n#> 2448   0   0  0  0    0    12\n#> 2449   0   0  0  0    0    13\n#> 2450   0   0  0  0    0    14\n#> 2451   0   0  0  0    0    15\n#> 2452   0   0  0  0    0    16\n#> 2453   0   0  0  0    0    17\n#> 2454  NA   3 NA NA   NA     1\n#> 2455  NA   0 NA NA   NA     2\n#> 2456  NA   1 NA NA   NA     3\n#> 2457  NA   7 NA NA   NA     4\n#> 2458  NA   1 NA NA   NA     5\n#> 2459  NA   8  7 NA   NA     6\n#> 2460  NA   7  5 NA   NA     7\n#> 2461  NA   7 10 NA   NA     8\n#> 2462  NA   9  4 NA   NA     9\n#> 2463  NA   2  8 NA   NA    10\n#> 2464  NA   3 19 NA   NA    11\n#> 2465  NA  10  3 NA   NA    12\n#> 2466  NA   5  7 NA   NA    13\n#> 2467  NA   3  4 NA   NA    14\n#> 2468  NA   5  3 NA   NA    15\n#> 2469  NA   4 10 NA   NA    16\n#> 2470   0   0  0  0    0     1\n#> 2471   0   0  8  0    0     4\n#> 2472   0   0  9  0    0     5\n#> 2473   0   0  8  0    1     6\n#> 2474   0   0 12  0    4     7\n#> 2475   0   0  3  0    1     8\n#> 2476   0   1  4  0    1     9\n#> 2477   0   0  0  0    0    10\n#> 2478   0   0  3  0    0    10\n#> 2479   0   0  0  0    0    11\n#> 2480   0   0  0  0    0    12\n#> 2481   0   0  0  0    0    13\n#> 2482   0   0  6  0    0    14\n#> 2483   0   0  7  0    5    15\n#> 2484   0   0  1  0    0    16\n#> 2485   0   0  1  0    0    17\n#> 2486   0   2  4  1    1     1\n#> 2487   1   3  4  6    8     2\n#> 2488   2   5  2  4    8     3\n#> 2489   4   1  2  2   18     4\n#> 2490   2   6  2  3    7     5\n#> 2491   2   1  0  2    5     6\n#> 2492   2   4  3  8   11     7\n#> 2493   3   0  0  0    3     8\n#> 2494   0   2  1  1    7     9\n#> 2495   2   6  3  2   19    10\n#> 2496   0   3  1  2   17    11\n#> 2497   0   2  2  5   10    12\n#> 2498   1   3  4  4    2    12\n#> 2499   2   6  0  4   11    13\n#> 2500   5   1  0  8   10    14\n#> 2501   2   5  0  9   16    15\n#> 2502   3   6  1  1   13    16\n#> 2503   2   3  0  0    4    17\n#> 2504   0   1  0  0    1    18\n#> 2505   4   1  2  2    2     1\n#> 2506   0   1  1  0    2     2\n#> 2507   0   0  0  0    0     3\n#> 2508   1   2  0  0    3     4\n#> 2509   1   2  0  2    1     4\n#> 2510   8   5  3  0    8     5\n#> 2511   7   4  1  7    9     6\n#> 2512   7  16  0  6   11     7\n#> 2513  10  14  0  9   12     8\n#> 2514   9   5  0  4    8     9\n#> 2515   5  10  1  2   11    10\n#> 2516   6   4  0  0    4    11\n#> 2517   3   1  0  1    1    11\n#> 2518   7   5  0  3    7    12\n#> 2519   4   5  0  2    8    14\n#> 2520   3   3  1  5   12    13\n#> 2521  NA   0  1 NA   NA     1\n#> 2522  NA   1  0 NA   NA     2\n#> 2523  NA   4  9 NA   NA     3\n#> 2524  NA   5 14 NA   NA     4\n#> 2525  NA   1  9 NA   NA     5\n#> 2526  NA   1  9 NA   NA     6\n#> 2527  NA   1  5 NA   NA     7\n#> 2528  NA   3 11 NA   NA     8\n#> 2529  NA   0  8 NA   NA     9\n#> 2530  NA   2  5 NA   NA    10\n#> 2531  NA   6  7 NA   NA    11\n#> 2532  NA   2 12 NA   NA    12\n#> 2533  NA   0  9 NA   NA    13\n#> 2534  NA   0  6 NA   NA    14\n#> 2535  NA   0  7 NA   NA    15\n#> 2536  NA  12 22 NA   NA     1\n#> 2537  NA   5 17 NA   NA     2\n#> 2538  NA   7 19 NA   NA     3\n#> 2539  NA   6 14 NA   NA     4\n#> 2540  NA   8  8 NA   NA     5\n#> 2541  NA  12  6 NA   NA     6\n#> 2542  NA   1  1 NA   NA     7\n#> 2543  NA   2  2 NA   NA     7\n#> 2544  NA   2  6 NA   NA     8\n#> 2545  NA   9 15 NA   NA     9\n#> 2546  NA   7 12 NA   NA    10\n#> 2547  NA  15 23 NA   NA    11\n#> 2548  NA   3  8 NA   NA    12\n#> 2549  NA   8 18 NA   NA    13\n#> 2550  NA   7  9 NA   NA    14\n#> 2551  NA   6  6 NA   NA    15\n#> 2552  NA   0  0 NA   NA    15\n#> 2553  NA   0  0 NA   NA    16\n#> 2554  NA   0  1 NA   NA    16\n#> 2555   0   0  1  0    0     1\n#> 2556   0   0  1  0    0     2\n#> 2557   0   0  7  0    1     3\n#> 2558   0   0  8  1    1     4\n#> 2559   0   1  9  0    0     5\n#> 2560   0   0  7  0    1     6\n#> 2561   0   0  0  0    0     7\n#> 2562   0   0  0  0    0     7\n#> 2563   0   0  1  0    0     7\n#> 2564   0   0  3  0    0     8\n#> 2565   0   0  7  1    0     9\n#> 2566   0   0  4  0    0    10\n#> 2567   0   0  2  0    0    11\n#> 2568   0   0  0  0    0    12\n#> 2569   0   0  0  0    0    13\n#> 2570   0   0  0  0    0    14\n#> 2571   0   0  0  0    0    15\n#> 2572   0   0  0  0    0     1\n#> 2573   0   1  0  0    4     2\n#> 2574   0   0  0  0    2     3\n#> 2575   3   1  0 11    8     4\n#> 2576  12   5  0 12   17     5\n#> 2577  11   1  0  7   13     6\n#> 2578   4   2  2  4   22     7\n#> 2579   2   0  0  6    8     8\n#> 2580  12   0  0  6   16     9\n#> 2581   7   3  0  2   14    10\n#> 2582   6   2  1  2    4    11\n#> 2583   3   0  0  0    7    12\n#> 2584   0   0  1  3    8    13\n#> 2585   4   0  0  7   16    14\n#> 2586   0   0  0  1    2    15\n#> 2587   1   0  0  2    7    16\n#> 2588  NA   0  1 NA    1     1\n#> 2589  NA   4  3 NA   15     2\n#> 2590  NA   0  2 NA    1     3\n#> 2591  NA   4  8 NA   11     3\n#> 2592  NA   4  7 NA    8     4\n#> 2593  NA   3  5  7    8     5\n#> 2594   1   0  4  0    4     6\n#> 2595   0   0  6  2    6     6\n#> 2596   2   4  5  0   13     7\n#> 2597   0   0  3  0    3     8\n#> 2598   0   0  6  2    3     8\n#> 2599   0   3  1  2    2     9\n#> 2600   0   1  1  1    3    10\n#> 2601   0   0  0  0    0    11\n#> 2602   1   0  4  0    4    11\n#> 2603   0   0  1  1    1    12\n#> 2604   0   0  0  0    0    13\n#> 2605  NA   0  4 NA   NA     1\n#> 2606  NA   4 52 NA   NA     2\n#> 2607  NA   2 30 NA   NA     3\n#> 2608  NA   3 30 NA   NA     4\n#> 2609  NA   3 12 NA   NA     5\n#> 2610  NA   4 13 NA   NA     6\n#> 2611  NA   3 10 NA   NA     7\n#> 2612  NA   2 22 NA   NA     8\n#> 2613  NA   1 27 NA   NA     9\n#> 2614  NA   2 10 NA   NA    10\n#> 2615  NA   1 13 NA   NA    11\n#> 2616  NA   2 16 NA   NA    12\n#> 2617  NA   1 48 NA   NA    13\n#> 2618  NA   1 40 NA   NA    14\n#> 2619  NA   0  1 NA   NA    14\n#> 2620  NA   0  4 NA   NA    15\n#> 2621  NA   0  5 NA   NA    16\n#> 2622   0   0  0  0    0     1\n#> 2623  NA   0  0 NA   NA     2\n#> 2624  NA   0  3 NA   NA     3\n#> 2625  NA   0  3 NA   NA     4\n#> 2626  NA   0  5 NA   NA     5\n#> 2627  NA   0  4 NA   NA     6\n#> 2628  NA   0 10 NA   NA     7\n#> 2629  NA   0  3 NA   NA     8\n#> 2630  NA   0  5 NA   NA     9\n#> 2631  NA   0  6 NA   NA    10\n#> 2632  NA   0  5 NA    3    11\n#> 2633  NA   0  6 NA    4    12\n#> 2634  NA   1  3 NA    1    13\n#> 2635  NA   0  0 NA    0    14\n#> 2636  NA   0  6 NA    1    14\n#> 2637  NA   0  2 NA    1    15\n#> 2638   0   0  0  0    0    16\n#> 2639   0   0  0  0    0    23\n#> 2640  NA   0  0 NA   NA     1\n#> 2641  NA   0  2 NA   NA     2\n#> 2642  NA   0  4 NA   NA     3\n#> 2643  NA   0  2 NA   NA     4\n#> 2644  NA   0  2 NA   NA     5\n#> 2645  NA   0  0 NA   NA     6\n#> 2646  NA   0  1 NA   NA     7\n#> 2647  NA   0  0 NA   NA     8\n#> 2648  NA   0  3 NA   NA     9\n#> 2649  NA   0  3 NA   NA    10\n#> 2650  NA   0  5 NA   NA    11\n#> 2651  NA   0  0 NA   NA    12\n#> 2652  NA   0  1 NA   NA    13\n#> 2653  NA   0  1 NA   NA    14\n#> 2654  NA   0  0 NA   NA    15\n#> 2655  NA   0  0 NA   NA    15\n#> 2656  NA   0  0 NA   NA    16\n#> 2657  NA   0  0 NA   NA    16\n#> 2658  NA   0  0 NA   NA    17\n#> 2659   0   0  0  0    0     1\n#> 2660   0   0  3  0    1     2\n#> 2661   3   2  3  5    5     3\n#> 2662   1   4 11  6    6     4\n#> 2663   2   1  8  3    8     5\n#> 2664   1   4 17  5    8     6\n#> 2665   0   1  2  2    3     7\n#> 2666   4   4  8  2    2     8\n#> 2667   2   3 13  3    4     9\n#> 2668   1   6  7  7    3    10\n#> 2669   4   1  4  2    3    11\n#> 2670   2   3 24  1    4    12\n#> 2671   1   5 14  4    6    13\n#> 2672   0   2  7  2    2    14\n#> 2673   2   0  6  2    4    15\n#> 2674   0   0  4  4    1    15\n#> 2675   0   1  1  3    1    16\n#> 2676   0   1 15  0    1    17\n#> 2677  NA   0  1 NA    1     1\n#> 2678  NA   0  0 NA    0     4\n#> 2679  NA   0  0 NA    0     5\n#> 2680  NA   1  4 NA    0     6\n#> 2681  NA   0  1 NA    2     7\n#> 2682  NA   2  0 NA    0     8\n#> 2683  NA   0  0 NA    0     9\n#> 2684  NA   0  2 NA    3     9\n#> 2685  NA   0  0 NA    1    10\n#> 2686  NA   0  0 NA    0    11\n#> 2687  NA   0  0 NA    0    11\n#> 2688  NA   0  0  0    0    12\n#> 2689   0   0  1  2    3    13\n#> 2690   1   0  2  0    1    14\n#> 2691   0   0  0  0    0    15\n#> 2692   0   0  0  0    0     1\n#> 2693   0   0  1  2    1     2\n#> 2694   1   0  1  1    6     3\n#> 2695   1   3  1  4    9     4\n#> 2696   1   2  3  2   13     5\n#> 2697   2   3  2  3    8     6\n#> 2698   1   5  3  4   14     7\n#> 2699   7   3  2  1   18     8\n#> 2700   6   1  1  5   13     9\n#> 2701   0   1  4  2    6    10\n#> 2702   2   1  2  2   10    11\n#> 2703   2   1  5  6   14    12\n#> 2704   5   1  3  3   12    13\n#> 2705   0   0  0  0    5    14\n#> 2706   1   0  2  0    0    14\n#> 2707   2   2  2  3    5    15\n#> 2708   0   0  0  0    0     1\n#> 2709   0   0  4  1    3     2\n#> 2710   0   0  3  0    2     3\n#> 2711   0   0  7  0    1     4\n#> 2712   0   0  7  0    2     5\n#> 2713   0   0  1  0    0     6\n#> 2714   0   0  0  0    0     7\n#> 2715   0   0  0  0    0     7\n#> 2716   0   0  0  0    0     8\n#> 2717   0   0  0  0    0     9\n#> 2718   0   0  0  0    0    10\n#> 2719   0   0  0  0    0    11\n#> 2720   0   0  0  0    0    12\n#> 2721   0   0  0  0    0    13\n#> 2722   0   0  0  0    0    14\n#> 2723   0   0  0  1    1     1\n#> 2724   0   1  0  0    5     2\n#> 2725   2   0  2  0    1     3\n#> 2726   5   3  6  5    7     4\n#> 2727   1   6  8  1    8     5\n#> 2728   4   2 13  1    8     6\n#> 2729   3   6  6  3    5     7\n#> 2730   2   6  4  5    5     8\n#> 2731   4   3  2  4   11     9\n#> 2732  17   3  3  3    7    10\n#> 2733   4   3  3  2    6    11\n#> 2734  11   3  1  4    6    12\n#> 2735  11   3  0  3   10    13\n#> 2736   8   2  1  4    6    14\n#> 2737   1   0  2  5    6    15\n#> 2738   0   0  0  2    6    16\n#> 2739   1   0  2  1    6     1\n#> 2740   0   0  0  1    3     2\n#> 2741   9   3  3  4    8     3\n#> 2742   7   0  3  4   15     4\n#> 2743   7   5  3  4   18     5\n#> 2744  13   1  2  4   14     6\n#> 2745  10   0  1  3   15     7\n#> 2746  13   2  0  3    8     8\n#> 2747   8   1  0  6   11     9\n#> 2748  16   4  0 10   15    10\n#> 2749   9   3  0  7   12    11\n#> 2750   4   4  0  8    6    12\n#> 2751   3   3  0  7    7    13\n#> 2752   8   1  0  2    7    14\n#> 2753   2   2  0  2    5    15\n#> 2754   1   0  0  1    2    15\n#> 2755   0   4  2  0    3     1\n#> 2756   0   9  3  3    5     2\n#> 2757   1   5  1  2    6     3\n#> 2758   2   7  3  2    3     4\n#> 2759   2   4  8  3    5     5\n#> 2760   2   4 10  1    5     6\n#> 2761   1   4  3  4    5     7\n#> 2762   1   2  3  6    7     8\n#> 2763   0   2 20  2    9     9\n#> 2764   1   4  9  7   10    10\n#> 2765   2   0 11  2    6    11\n#> 2766   2   7 19  3    9    12\n#> 2767   0   3 18 11    4    13\n#> 2768   1   4 40  5    7    14\n#> 2769   0   2 25  3    6    15\n#> 2770   0   0  0  0    0    16\n#> 2771   0   2 11  2    8    16\n#> 2772   0   1  7  2    4    17\n#> 2773   0   0  3  1    0    18\n#> 2774   0   0  3  1    4    20\n#> 2775   0   0  0  0    0     1\n#> 2776   0   0  0  0    0     2\n#> 2777   0   0  0  0    0     3\n#> 2778   0   0  0  0    0     4\n#> 2779   0   0  0  0    0     5\n#> 2780   0   0  0  0    0     6\n#> 2781   0   0  0  0    0     7\n#> 2782   0   0  0  0    0     8\n#> 2783   0   0  0  0    0     9\n#> 2784   0   0  0  0    0    10\n#> 2785   0   0  0  0    1    11\n#> 2786   0   0  0  0    0    12\n#> 2787   0   0  0  0    0    13\n#> 2788   0   0  0  0    0    14\n#> 2789   0   0  0  0    0    15\n#> 2790   0   0  0  0    0     1\n#> 2791   0   0  5  0    4     2\n#> 2792   0   0  4  0    0     3\n#> 2793   0   2  7  0    2     4\n#> 2794   0   0  8  0    4     5\n#> 2795   0   0  3  1    2     6\n#> 2796   0   0  2  1    0     7\n#> 2797   0   0  3  1    1     8\n#> 2798   0   0  5  0    3     9\n#> 2799   0   0  4  0    3    10\n#> 2800   0   0  0  0    0    11\n#> 2801   0   0  2  0    0    11\n#> 2802   0   0  0  0    0    12\n#> 2803   0   0  0  0    0    13\n#> 2804   0   0  0  0    0    13\n#> 2805   0   0  0  0    0    14\n#> 2806   0   0  0  0    0    15\n#> 2807   0   0  0  0    0    15\n#> 2808   0   0  0  0    0    16\n#> 2809   0   0  0  0    0    16\n#> 2810   0   0  0  0    0    17\n#> 2811   0   0  0  0    0    18\n#> 2812   0   0  0  0    0    19\n#> 2813   0   0  0  0    0     1\n#> 2814   0   0  0  0    0     2\n#> 2815   0   0  0  0    0     4\n#> 2816   0   0  0  0    0     5\n#> 2817   0   0  0  0    0     6\n#> 2818   0   0  0  0    0     7\n#> 2819   0   0  0  0    0     8\n#> 2820   0   0  0  0    0     9\n#> 2821   0   0  0  0    0     9\n#> 2822   0   0 12  0    5    10\n#> 2823   0   0  9  0    2    11\n#> 2824   0   0  7  0    0    12\n#> 2825   0   0  5  0    1    13\n#> 2826   0   1  9  1    1    14\n#> 2827   0   0  9  0    1    15\n#> 2828   0   0  1  0    0    16\n#> 2829   0   0  0  0    0    17\n#> 2830   0   0  0  0    0    17\n#> 2831   0   0  0  0    1     1\n#> 2832   1   8  0  9   12     2\n#> 2833   2   2  0  9   16     3\n#> 2834  10  10  1  6   15     4\n#> 2835   4   2  0  6    4     5\n#> 2836   8   5  0  5    9     6\n#> 2837   8   9  0  6   16     7\n#> 2838   1   3  0  4   15     8\n#> 2839   1   3  0  0    1     8\n#> 2840   2   3  0  3    6     9\n#> 2841   8   5  0  2   20    10\n#> 2842   4   7  0  5    9    11\n#> 2843   3   6  0  3    7    12\n#> 2844   1   3  0  4   15    13\n#> 2845   5   6  0  4    7    14\n#> 2846   3   7  0  7   14    15\n#> 2847   1   4  0  1    5    16\n#> 2848   1   0  0  3    2    16\n#> 2849   1   1  0  4    4    17\n#> 2850   0   0  0  0    0     1\n#> 2851   9   4  2  2    6     2\n#> 2852   4   2  2  1    6     3\n#> 2853   1   1  0  0    0     4\n#> 2854   9   5  1  3    7     4\n#> 2855   7   1  1  3    6     5\n#> 2856   7   4  1  1    9     6\n#> 2857   5   1  1  3    6     7\n#> 2858   1   0  0  0    0     8\n#> 2859   3   0  3  0    5     8\n#> 2860   3   0  0  1    4     9\n#> 2861   0   0  0  0    3    10\n#> 2862   1   1  1  1    6    10\n#> 2863   0   0  0  2    0    11\n#> 2864   0   0  1  0    0    12\n#> 2865   0   0  0  0    0    12\n#> 2866   0   0  0  0    0     1\n#> 2867   0   0  0  0    0     2\n#> 2868   1   2  3  6    5     3\n#> 2869   5   4  3  4    6     4\n#> 2870   0   2  6  1    4     5\n#> 2871   3   2  2  3    3     6\n#> 2872   3   0  4  6   18     7\n#> 2873   0   1  1  0   14     8\n#> 2874   0   1  0  7    4     9\n#> 2875   1   0  2  7    8     9\n#> 2876   3   1  1  3   15    10\n#> 2877   9   5  4  4   16    11\n#> 2878   3   1  2  3   18    12\n#> 2879   5   4  4  7   11    13\n#> 2880   0   1  3  3    5    14\n#> 2881   2   1  2  1    9    15\n#> 2882   2   0  0  2    5    16\n#> 2883   1   0  0  0    3    17\n#> 2884   0   1  0  0    0    17\n#> 2885   0   0  0  3    0    18\n#> 2886   0   0  0  1    3    18\n#> 2887   0   0  5  0    1     1\n#> 2888   1   0  1  2    5     2\n#> 2889   4   5 10  4   17     3\n#> 2890   6   4  8  1   13     4\n#> 2891  10   2  6  6   10     5\n#> 2892  25   1  4  4   17     6\n#> 2893  18   1  6  4   19     7\n#> 2894  16   2  2  1    8     8\n#> 2895  18   2  6  3   16     9\n#> 2896  12   4  8  9   19    10\n#> 2897   2   4 13  2   11    11\n#> 2898   5   1  7 11   16    12\n#> 2899   4   2 13  1   15    13\n#> 2900   0   0  4  0    5    14\n#> 2901   1   0  1  0    2    15\n#> 2902   0   0  3  0    0    16\n#> 2903   0   1  3  0    0     1\n#> 2904   0   0  1  0    0     2\n#> 2905   0   1  1  0    1     3\n#> 2906   0   0  2  0    0     4\n#> 2907   0   0  0  0    1     4\n#> 2908   0   1  4  0    0     5\n#> 2909   0   0  4  0    2     6\n#> 2910   0   1  3  0    0     7\n#> 2911   0   0  0  0    0     8\n#> 2912   0   1 10  1    2     9\n#> 2913   0   0  1  0    0    10\n#> 2914   0   0  0  0    1    11\n#> 2915   0   0  3  0    3    12\n#> 2916   0   1  2  1    0    13\n#> 2917   0   0  0  1    0    14\n#> 2918   0   0  0  0    0    14\n#> 2919   4   2  7  1   12     1\n#> 2920   1   1  2  2   11     2\n#> 2921   0   3  6  0    7     3\n#> 2922   0   2  0  0    1     4\n#> 2923   1   1  6  3   23     5\n#> 2924   9   2  9  2   11     6\n#> 2925   9   2  7  6   16     7\n#> 2926   9   1 13  3   17     8\n#> 2927  18   1  7 10   10     9\n#> 2928  14   1  8  6   12    10\n#> 2929  15   3  1  5    6    11\n#> 2930  19   1  2  6   18    12\n#> 2931   7   0  8  3    9    13\n#> 2932   7   1  9  3   15    14\n#> 2933   7   0 10  2    8    15\n#> 2934   5   2 16  4    9    16\n#> 2935   9   1  3  3   15    17\n#> 2936   1   0  5  4    8    18\n#> 2937   9   1  9  1    8    19\n#> 2938  NA   0  0 NA   NA     1\n#> 2939  NA   7 25 NA   NA     2\n#> 2940  NA   5 37 NA   NA     3\n#> 2941  NA   3 14 NA   NA     4\n#> 2942  NA   2 10 NA   NA     5\n#> 2943  NA   4  5 NA   NA     6\n#> 2944  NA   7 14 NA   NA     7\n#> 2945  NA  10 12 NA   NA     8\n#> 2946  NA   4 15 NA   NA     9\n#> 2947  NA   2  4 NA   NA    10\n#> 2948  NA   3 20 NA   NA    11\n#> 2949  NA   4 30 NA   NA    12\n#> 2950  NA   4 19 NA   NA    13\n#> 2951  NA   7  9 NA   NA    14\n#> 2952  NA   7 19 NA   NA    15\n#> 2953  NA   4  8 NA   NA    16\n#> 2954  NA   0 16 NA   NA    17\n#> 2955  NA   0  5 NA   NA    17\n#> 2956  NA   1 20 NA   NA    18\n#> 2957  NA   2  8 NA   NA    19\n#> 2958  NA   1  0 NA   NA    20\n#> 2959  NA   0  3 NA   NA     1\n#> 2960  NA   0  0 NA   NA     2\n#> 2961  NA   1  1 NA   NA     3\n#> 2962  NA   0  2 NA   NA     4\n#> 2963  NA   0  0 NA   NA     5\n#> 2964  NA   0  4 NA   NA     6\n#> 2965  NA   0  0 NA   NA     7\n#> 2966  NA   0  2 NA   NA     8\n#> 2967  NA   0  2 NA   NA     9\n#> 2968  NA   1  3 NA   NA    10\n#> 2969  NA   0  1 NA   NA    11\n#> 2970  NA   0  3 NA   NA    11\n#> 2971  NA   0  0 NA   NA    12\n#> 2972  NA   0  3 NA   NA    13\n#> 2973  NA   0  0 NA   NA    14\n#> 2974   0   0  0  0    0     1\n#> 2975   0   1  2  0    0     2\n#> 2976   0   0  1  0    0     3\n#> 2977   0   0  6  0    1     4\n#> 2978   0   0  4  0    3     5\n#> 2979   0   4  3  0    1     6\n#> 2980   0   0  7  0    4     7\n#> 2981   0   1  7  0    0     8\n#> 2982   0   0  4  1    1     9\n#> 2983   0   0  7  3    1    10\n#> 2984   0   0  7  0    3    11\n#> 2985   0   2  7  0    1    12\n#> 2986   0   1  7  3    0    13\n#> 2987   0   0  3  1    0    14\n#> 2988   0   1  2  1    4    15\n#> 2989   0   0  6  3    4    16\n#> 2990   0   0  2  0    2    17\n#> 2991   0   0  8  0    1    18\n#> 2992   0   0  6  0    2    19\n#> 2993   0   0  3  0    1    20\n#> 2994   0   0  1  1    1    21\n#> 2995   0   0  0  0    0    22\n#> 2996   0   0  1  0    2    22\n#> 2997   0   0  0  0    1    22\n#> 2998   0   0  0  0    0    23\n#> 2999   0   0  0  0    0    23\n#> 3000   0   0  0  0    0    24\n#> 3001   0   0  0  0    0     1\n#> 3002   0   0  1  0    0     2\n#> 3003   0   0  8  0    0     3\n#> 3004   0   0  2  0    0     4\n#> 3005   0   0  0  0    0     5\n#> 3006   0   0  1  0    0     5\n#> 3007   0   0  5  0    1     6\n#> 3008   0   0  0  0    1     7\n#> 3009   0   0  3  0    0     8\n#> 3010   0   0  1  0    0     9\n#> 3011   0   0  4  0    0    10\n#> 3012   0   0  0  0    0    11\n#> 3013   0   0  2  0    0    12\n#> 3014   0   0  0  0    0    13\n#> 3015   0   0  0  0    0    14\n#> 3016   0   0  3  0    1    14\n#> 3017   0   0  0  0    0    15\n#> 3018   0   0  0  1    0     1\n#> 3019   8   1 10  4    7     2\n#> 3020   2   1  2  3    7     3\n#> 3021   5   5  3  7    9     4\n#> 3022  11   5  2  5   10     5\n#> 3023   3   5  2  7   11     6\n#> 3024  11   1  1  8    9     7\n#> 3025   4   1  3  6    6     8\n#> 3026  11   6  4  8   16     9\n#> 3027   7   7  2  8   14    10\n#> 3028   9   6  0  3    8    11\n#> 3029  16   6  0  3   18    12\n#> 3030   9   6  0 15   21    13\n#> 3031   1   1  1  6   14    14\n#> 3032   1   7  1  6    8    15\n#> 3033   0   0  0  1    5    16\n#> 3034   3   1  0  2    2    17\n#> 3035   1   7  1  2   11    18\n#> 3036   4   2  1  4    4    19\n#> 3037   0   0  1  0    1     1\n#> 3038   0   1  0  1    2     2\n#> 3039   2   2  3  4    9     3\n#> 3040   3   5  1  8    8     4\n#> 3041   6   9  1  4    8     5\n#> 3042   6   7  1  6    6     6\n#> 3043   8   8  2  5    6     7\n#> 3044  18   7  0  8   12     8\n#> 3045  12  10  0  9    6     9\n#> 3046   4  11  1 13   14    10\n#> 3047   5   9  0 10   10    11\n#> 3048   6   2  0 13    6    12\n#> 3049   5   3  0  5   11    13\n#> 3050   2   7  0  6   12    14\n#> 3051   5   7  0  9   12    15\n#> 3052   4   2  0  0    7    16\n#> 3053   0   0  0  4    2    16\n#> 3054   0   0  0  0    0     1\n#> 3055   4   3  0  4   16     2\n#> 3056   0   3  0  2    8     3\n#> 3057   7   0  0  7   15     4\n#> 3058  10   1  1  1   17     5\n#> 3059   3   0  0  3   17     7\n#> 3060   6   2  0  3   19     8\n#> 3061   4   0  0  0    8    10\n#> 3062   2   1  0  4    9    11\n#> 3063   0   0  0  0    0    11\n#> 3064   0   0  1  0    6    11\n#> 3065   0   0  0  0    4    12\n#> 3066   3   2  0  6   16    13\n#> 3067   9   0  0  9   18    14\n#> 3068   6   0  0  4   17    15\n#> 3069   5   0  1  6    7    16\n#> 3070   2   0  0  1    8    16\n#> 3071   4   1  0  4   21    17\n#> 3072   0   0  0  0    0     1\n#> 3073   3   5  1  2    0     2\n#> 3074   1   6  0  4    0     3\n#> 3075  19   9  2  2   16     4\n#> 3076  12  13  0  5   13     5\n#> 3077   8   6  2  3    9     6\n#> 3078   4   3  0  7   12     7\n#> 3079   5   4  1  4    9     8\n#> 3080   4   4  1  5   15     9\n#> 3081   9   4  1  3    7    10\n#> 3082   7   3  2  3   12    11\n#> 3083   5   6  1  3    9    12\n#> 3084   6   5  0  5   16    13\n#> 3085   7   7  1  4    5    14\n#> 3086  13   4  4  3    9    15\n#> 3087   7   8  0  2    6    16\n#> 3088   2   3  1  0    1    17\n#> 3089   0   0  1  0    0     1\n#> 3090   1   1  0  0    0     2\n#> 3091   4   2  0  5   10     3\n#> 3092   1   0  1  3    3     4\n#> 3093   2   4  4  6   15     5\n#> 3094   7   5  0  4   20     6\n#> 3095   9   8  0  4   17     7\n#> 3096   7   6  0  6   24     8\n#> 3097   7   1  0  5   15     9\n#> 3098   3   3  0  6    9    10\n#> 3099   0   1  0  0    3    11\n#> 3100   3   3  0  4   19    11\n#> 3101   4   7  0  6   22    12\n#> 3102   3   3  1  6   22    13\n#> 3103   6   6  0  8   22    14\n#> 3104   7   7  1  4   16    15\n#> 3105   0   1  0  0    2    16\n#> 3106   0   2  0  4    5    16\n#> 3107  NA   0  0 NA    0     1\n#> 3108  NA   2  6 NA    9     2\n#> 3109  NA   5  6 NA    8     3\n#> 3110  NA   0  5 NA    8     4\n#> 3111  NA   4  4 NA    6     5\n#> 3112  NA   0  0 NA    1     6\n#> 3113  NA   3  4 NA    2     7\n#> 3114  NA   2  6 NA    6     8\n#> 3115  NA   1 12 NA    2     9\n#> 3116  NA   3 12 NA   10    10\n#> 3117  NA   3  8 NA   10    11\n#> 3118  NA   4  3 NA    6    12\n#> 3119  NA   3  1 NA   16    13\n#> 3120  NA   0  5 NA    4    14\n#> 3121  NA   1  3 NA    1    15\n#> 3122  NA   1  8 NA    6    16\n#> 3123  NA   2  2 NA    5    17\n#> 3124  NA   1  3 NA    2    18\n#> 3125  NA   0  0 NA    0    19\n#> 3126  NA   0  0 NA    0    20\n#> 3127  NA   2  1  1    1    21\n#> 3128   0   0  0  0    0    22\n#> 3129   2   2  3  2    8     1\n#> 3130   5   3  3  7    9     2\n#> 3131   5   5  1  4   11     3\n#> 3132   7   7  1  2   19     4\n#> 3133   6   4  2  8    9     5\n#> 3134   9   7  2  5   12     6\n#> 3135   9   1  0  4   16     7\n#> 3136   7  11  2  8   10     8\n#> 3137   1   0  2  0    4     9\n#> 3138   8   3  3  9   15    10\n#> 3139  11   1  1  2   13    11\n#> 3140   2   1  2  5    6    12\n#> 3141   2   4  2  4   15    13\n#> 3142   2   3  1  6    2    14\n#> 3143   4   1  4  2   11    15\n#> 3144   1   3  1  2    5    16\n#> 3145   2   0  0  1    2    16\n#> 3146   0   0  2  0    0    17\n#> 3147   7   3  0  9   18     1\n#> 3148  10   5  0  4   10     2\n#> 3149   9   8  0  4   11     3\n#> 3150  11   9  0  3   21     4\n#> 3151   8   6  1  7   16     5\n#> 3152  11  10  0  3   18     6\n#> 3153   7   8  0  7   13     7\n#> 3154   1   0  0  3    1     8\n#> 3155   2   1  0  0    0     9\n#> 3156  10  13  1  9   12     9\n#> 3157  23  12  0  7   16    10\n#> 3158  13   9  0  4   13    11\n#> 3159  10   5  0  3   12    12\n#> 3160  11   9  0  4   15    13\n#> 3161   7   0  0  4   12    14\n#> 3162   0   0  0  0    0    15\n#> 3163   1   0  0  0    1    15\n#> 3164  13   3  2  3   24    16\n#> 3165   0   1  0  0    5    17\n#> 3166   0   0  1  0    0     1\n#> 3167   0   0  0  0    0     2\n#> 3168   0   0  1  0    3     3\n#> 3169   0   1  4  0    7     4\n#> 3170   1   1  3  4    5     5\n#> 3171   2   6  8 10   14     6\n#> 3172   0   0  4  4   10     7\n#> 3173   1   1  4  5   12     8\n#> 3174   1   1  4  0    5     9\n#> 3175   0   1  2  0    5    10\n#> 3176   1   1  0  4   15    11\n#> 3177   0   1  5  5    5    12\n#> 3178   0   4  5  4    8    13\n#> 3179   0   3  1  1    6    14\n#> 3180   1   2  4  5   10    15\n#> 3181   0   0  1  1    4    16\n#> 3182   2   1  0  0    9    17\n#> 3183   0   1  1  0    0    18\n#> 3184  NA   0  0 NA    1     1\n#> 3185  NA   0  0 NA    0     2\n#> 3186  NA   0  0 NA    0     3\n#> 3187  NA   0  0  1    3     4\n#> 3188   0   3  1  0    1     5\n#> 3189   0   0  1  1    3     6\n#> 3190   1   1  2  3   13     7\n#> 3191  10   5  0  2   19     8\n#> 3192   5   3  1 11   13     9\n#> 3193   1   0  0  1    2    10\n#> 3194   2   3  0  0    6    10\n#> 3195   0   0  1  1    4    11\n#> 3196   0   1  0  0    6    11\n#> 3197   0   1  0  0    0    12\n#> 3198   0   0  0  0    2    12\n#> 3199   0   0  0  0    0     1\n#> 3200   0   1  0  0    0     2\n#> 3201   7   2  4  8   19     3\n#> 3202  13   7  3 10   17     4\n#> 3203  15   7  3  8   15     5\n#> 3204  13   3  2  4   11     6\n#> 3205   6   2  3  7   11     7\n#> 3206   9   7  2  7   13     8\n#> 3207   8   2  0  4   11     9\n#> 3208   5   5  4  1   16    10\n#> 3209   3   3  1  3    7    11\n#> 3210   6   4  2  8   16    12\n#> 3211  11   5  1  9   20    13\n#> 3212  10   6  0  8   10    14\n#> 3213   9   4  0  2   10    15\n#> 3214   1   3  1  2    5    16\n#> 3215   1   1  0  1    4    17\n#> 3216   1   2  2  0    9     1\n#> 3217   2   0  3  4    8     2\n#> 3218   8   3  1  2   14     3\n#> 3219   1   0  0  0    1     4\n#> 3220   1   0  2  2    9     4\n#> 3221   9   1  4  6   19     5\n#> 3222   1   3  1  3   11     6\n#> 3223   5   2  0  5   22     7\n#> 3224   3   5  1  5    6     8\n#> 3225   4   5  1  5    9     9\n#> 3226   6   4  2  4   11    10\n#> 3227  10   1  2  3   11    11\n#> 3228  13   0  0  6   11    12\n#> 3229  15   0  0  3    8    13\n#> 3230  12   1  0  6   10    14\n#> 3231   4   0  0  1    5    15\n#> 3232   4   0  0  1    2    16\n#> 3233   0   0  0  0    0    18\n#> 3234  NA   6  2 NA   NA     1\n#> 3235  NA   4  2 NA   NA     2\n#> 3236  NA  15  8 NA   NA     3\n#> 3237  NA   9  4 NA   NA     4\n#> 3238  NA   8  2 NA   NA     5\n#> 3239  NA  10  2 NA   NA     6\n#> 3240  NA  16 11 NA   NA     7\n#> 3241  NA  17 15 NA   NA     8\n#> 3242  NA  12 18 NA   NA     9\n#> 3243  NA  13  5 NA   NA    10\n#> 3244  NA   8 16 NA   NA    11\n#> 3245  NA   4 12 NA   NA    12\n#> 3246  NA  10  6 NA   NA    13\n#> 3247  NA   5  6 NA   NA    14\n#> 3248  NA   0  1 NA   NA    15\n#> 3249  NA   0  1 NA   NA    16\n#> 3250  NA   0  0 NA   NA    17\n#> 3251  NA   2  6 NA   NA     1\n#> 3252  NA   5  6 NA   NA     2\n#> 3253  NA   5  5 NA   NA     3\n#> 3254  NA   4 10 NA   NA     4\n#> 3255  NA   3  8 NA   NA     5\n#> 3256  NA   1 14 NA   NA     6\n#> 3257  NA   0  2 NA   NA     7\n#> 3258  NA   1  1 NA   NA     7\n#> 3259  NA   0  0 NA   NA     8\n#> 3260  NA   1  6 NA   NA     8\n#> 3261  NA   0  8 NA   NA     9\n#> 3262  NA   2 20 NA   19    10\n#> 3263  NA   2  3 NA   19    11\n#> 3264  NA   0  1 NA    7    12\n#> 3265  NA   0  1 NA    2    12\n#> 3266  NA   0  1 NA    0    15\n#> 3267  NA   0  0 NA    1    16\n#> 3268  NA   0  0 NA    4    16\n#> 3269  NA   0  0 NA    0    17\n#> 3270   0   1  4  0    0     1\n#> 3271   0   0  0  0    0     2\n#> 3272   0   2  0  0    0     3\n#> 3273   0   0  4  0    0     4\n#> 3274   0   0  2  0    0     5\n#> 3275   0   0  0  0    0     6\n#> 3276   0   0  0  0    0     8\n#> 3277   0   0  0  0    0     8\n#> 3278   0   0  0  0    0     9\n#> 3279   0   0  0  0    0    10\n#> 3280   0   0  0  0    0    11\n#> 3281   0   0  0  0    0    11\n#> 3282   0   0  0  0    0    12\n#> 3283   0   0  0  0    0    13\n#> 3284   0   0  0  0    0    14\n#> 3285  NA   3 18 NA   NA     1\n#> 3286  NA   3 24 NA   NA     2\n#> 3287  NA   1 10 NA   NA     3\n#> 3288  NA   1  9 NA   NA     4\n#> 3289  NA   4 15 NA   NA     5\n#> 3290  NA   1 19 NA   NA     6\n#> 3291  NA   1 22 NA   NA     7\n#> 3292  NA   2 25 NA   NA     8\n#> 3293  NA   0  3 NA   NA     9\n#> 3294  NA   3 11 NA   NA     9\n#> 3295  NA   1  6 NA   NA    10\n#> 3296  NA   2  5 NA   NA    10\n#> 3297  NA   1  8 NA   NA    11\n#> 3298  NA   1  9 NA   NA    12\n#> 3299  NA   1 10 NA   NA    13\n#> 3300  NA   2  7 NA   NA    14\n#> 3301  NA   3 15 NA   NA    15\n#> 3302  NA   0  0 NA   NA     1\n#> 3303  NA   0  0 NA   NA     4\n#> 3304  NA   0  3 NA   NA     5\n#> 3305  NA   1  4 NA   NA     6\n#> 3306  NA   0  5 NA   NA     7\n#> 3307  NA   0  0 NA   NA     8\n#> 3308  NA   0  3 NA   NA     8\n#> 3309  NA   0  4 NA   NA     9\n#> 3310  NA   0  6 NA   NA    10\n#> 3311  NA   0 10 NA   NA    11\n#> 3312  NA   1  8 NA   NA    12\n#> 3313  NA   1  8 NA   NA    13\n#> 3314  NA   0  1 NA   NA    14\n#> 3315  NA   0 11 NA   NA    15\n#> 3316  NA   0  4 NA   NA    16\n#> 3317   0   2  0  0    4     1\n#> 3318   0   4  1  4    8     2\n#> 3319   0   7  6  6   14     3\n#> 3320   0  14  4  3   13     4\n#> 3321   3   4  5  2   26     5\n#> 3322   4   5  3  7   15     6\n#> 3323   4   6  1 12   19     7\n#> 3324   6   5  1  9   15     8\n#> 3325   0   9 13  9   12     9\n#> 3326   1   5  4  2    6    10\n#> 3327   0   0  0  1    0    11\n#> 3328   0   1  3  2    8    13\n#> 3329   0   4  7  0    3    12\n#> 3330   0   0  0  0    1    14\n#> 3331   0   1  3  2    9    14\n#> 3332   0   0  0  0    0     1\n#> 3333   0   0  0  0    0     2\n#> 3334   0   0  0  0    0     3\n#> 3335   0   0  0  0    0     4\n#> 3336   0   0  0  0    0     5\n#> 3337   0   0  0  0    0     6\n#> 3338   0   0  0  0    0     7\n#> 3339   0   0  0  0    0     8\n#> 3340   0   0  0  0    0     9\n#> 3341   0   0  0  0    0    10\n#> 3342   0   0  0  0    0    11\n#> 3343   0   0  0  0    0    12\n#> 3344   0   0  7  0    0    13\n#> 3345   0   0  2  0    1    14\n#> 3346   0   0  1  0    0    15\n#> 3347   0   0  0  0    0    15\n#> 3348  NA   4 NA NA   NA     1\n#> 3349  NA  10  3 NA   NA     2\n#> 3350  NA  14  7 NA   NA     3\n#> 3351  NA  24  3 NA   NA     4\n#> 3352  NA  15  5 NA   NA     5\n#> 3353  NA  16 10 NA   NA     6\n#> 3354  NA   7  9 NA   NA     7\n#> 3355  NA  10 13 NA   NA     8\n#> 3356  NA  14  6 NA   NA     9\n#> 3357  NA   5 13 NA   NA    10\n#> 3358  NA   5  8 NA   NA    11\n#> 3359  NA   2 22 NA   NA    12\n#> 3360  NA   1 20 NA   NA    13\n#> 3361  NA   8 16 NA   NA    14\n#> 3362  NA   6 22 NA   NA    15\n#> 3363  NA   6 24 NA   NA    16\n#> 3364  NA   4 29 NA   NA    17\n#> 3365  NA   2 13 NA   NA    18\n#> 3366  NA   0  1 NA   NA    20\n#> 3367  NA   0  0 NA   NA    21\n#> 3368  NA   0  0 NA   NA    22\n#> 3369   0   0  0  1    0     1\n#> 3370   0   0  3  2    0     2\n#> 3371   2   2  1  3    7     3\n#> 3372   8   3  3  9   15     4\n#> 3373   6   1  1  6    9     5\n#> 3374  13   2  1 10   12     6\n#> 3375   6   1  0  6   12     7\n#> 3376   7   1  0  5   20     8\n#> 3377   6   1  0  7   14     9\n#> 3378   7   0  0  3    9    10\n#> 3379  14   2  0  5   10    11\n#> 3380   4   1  0  1    4    12\n#> 3381  13   0  0  3    5    13\n#> 3382   6   2  0  5   14    14\n#> 3383  18   1  0  5   10    15\n#> 3384  11   2  0  2   12    16\n#> 3385   3   3  0  5   17    17\n#> 3386   3   2  0  5    4    18\n#> 3387  10   3  9  4    3     1\n#> 3388  11   5  3  2    2     2\n#> 3389  27   4  0 10    9     3\n#> 3390  14   5  0  8    6     4\n#> 3391   9   3  0 13    7     5\n#> 3392  12   2  0  4    5     6\n#> 3393  23   4  0 11    5     7\n#> 3394   6   6  1  6   10     8\n#> 3395  11   3  0  6    5     9\n#> 3396   6   4  0 11    7    10\n#> 3397   5   5  0  7   10    11\n#> 3398  11   3  0  5    4    12\n#> 3399   5   3  0  7   15    13\n#> 3400   2   2  0  3    5    14\n#> 3401   3   4  0  3    4    15\n#> 3402   0   3  0  1    3    15\n#> 3403   0   0  0  0    1     1\n#> 3404   3   0  3  2   11     2\n#> 3405   2   5  8  7   16     3\n#> 3406   2   3  3  2    7     4\n#> 3407   1   3  4  3    7     5\n#> 3408   4   1  2  4   13     6\n#> 3409   4   3  2  5   19     7\n#> 3410   0   1  3  3    6     8\n#> 3411   1   2  3  2   10     8\n#> 3412   1   4  9  3    6     9\n#> 3413   1   3 12  3   21    10\n#> 3414   2   3  9  7   16    11\n#> 3415   0   3  7  4    7    12\n#> 3416  10   3  4  4   25    13\n#> 3417   0   4 24  2   13    14\n#> 3418   0   1 10  2   19    15\n#> 3419   3   4  5  5    8    16\n#> 3420   0   1  2  1    3    16\n#> 3421   0   0  0  0    2    17\n#> 3422   0   1  3  3    8    17\n#> 3423  NA  NA NA NA   NA     1\n#> 3424  NA  NA NA NA   NA     1\n#> 3425  NA  NA NA NA   NA     2\n#> 3426  NA  NA NA NA   NA     3\n#> 3427  NA   4 NA NA   NA     4\n#> 3428  NA   4 NA NA   NA     5\n#> 3429  NA   1 NA NA   NA     6\n#> 3430  NA   3 NA NA   NA     7\n#> 3431  NA   5 NA NA   NA     8\n#> 3432  NA   3 NA NA   NA     9\n#> 3433  NA   5 NA NA   NA    10\n#> 3434  NA   8 NA NA   NA    11\n#> 3435  NA   8  3 NA   NA    12\n#> 3436  NA   5  6 NA   NA    13\n#> 3437  NA   6  4 NA   NA    14\n#> 3438  NA   7  8 NA   NA    15\n#> 3439  NA   1  0 NA   NA    16\n#> 3440  NA   1  0 NA   NA    17\n#> 3441   3   2  4  3   14     1\n#> 3442   2   4  8  4   14     2\n#> 3443   1   0  0  1   13     3\n#> 3444   1   0  3  3   15     4\n#> 3445   2   3  3  3   10     5\n#> 3446   4   2  4  5   21     6\n#> 3447  10   3  1  3   18     7\n#> 3448   9   1  1  6   18     8\n#> 3449   6   4  4  3   24     9\n#> 3450  16   2  3  5    9    10\n#> 3451  14   5  2  3   17    11\n#> 3452  13   0  1  5   14    12\n#> 3453  17   3  0  3   15    13\n#> 3454  27   1  0  3   13    14\n#> 3455  16   3  0  4   19    15\n#> 3456  14   2  1  2    7    16\n#> 3457   5   0  1  4   19    17\n#> 3458   7   0  0  6   15    18\n#> 3459   0   0  0  0    0     1\n#> 3460   0   0  0  0    0     2\n#> 3461   0   0  0  0    0     3\n#> 3462   0   0  0  0    0     4\n#> 3463   0   0  0  0    0     5\n#> 3464   0   0  0  0    0     6\n#> 3465   0   0  0  0    0     7\n#> 3466   0   0  0  0    0     8\n#> 3467   0   0  0  0    0     9\n#> 3468   0   0  0  0    0    10\n#> 3469   0   0  0  0    0    11\n#> 3470   0   0  0  0    0    12\n#> 3471   0   0  0  0    0    13\n#> 3472   0   0  0  0    0    14\n#> 3473   0   0  1  0    0    15\n#> 3474   0   0  1  0    0    16\n#> 3475   0   0  0  0    0    17\n#> 3476   0   0  0  0    0    18\n#> 3477   0   0  0  1    0    19\n#> 3478   0   0  1  0    0    20\n#> 3479   0   0  3  0    2    21\n#> 3480   0   1  7  0    0    23\n#> 3481   0   1  5  0    1    22\n#> 3482   0   0  0  0    0    24\n#> 3483   0   0  1  0    1     1\n#> 3484   0   2  0  0    0     2\n#> 3485   0   5  2  1    5     3\n#> 3486   0   2  3  1    1     4\n#> 3487   0   3  4  1    0     5\n#> 3488   2   0  4  0    1     6\n#> 3489   0   0  0  0    1     7\n#> 3490   0   2  1  0    2     7\n#> 3491   0   1  0  0    0     8\n#> 3492   0   1  1  0    1     8\n#> 3493   1   1  6  1    4     9\n#> 3494   1   2  1  0    3    10\n#> 3495   0   0  0  0    0    11\n#> 3496   1   0  3  0    0    11\n#> 3497   0   2  1  0    0    12\n#> 3498  NA   0  4 NA   NA     1\n#> 3499  NA   3 14 NA   NA     2\n#> 3500  NA   5 12 NA   NA     3\n#> 3501  NA   6 14 NA   NA     4\n#> 3502  NA   6 24 NA   NA     5\n#> 3503  NA   4 16 NA   NA     6\n#> 3504  NA   8 11 NA   NA     7\n#> 3505  NA   5  8 NA   NA     8\n#> 3506  NA   4 11 NA   NA     9\n#> 3507  NA   6  6 NA   NA    10\n#> 3508  NA  10  9 NA   NA    11\n#> 3509  NA   2 14 NA   NA    12\n#> 3510  NA   4 16 NA   NA    13\n#> 3511  NA   2  9 NA   NA    14\n#> 3512  NA   1  9 NA   NA    15\n#> 3513  NA   2  7 NA   NA    16\n#> 3514  NA   3 15 NA   NA    17\n#> 3515  NA   4 27 NA   NA    18\n#> 3516  NA   3 22 NA   NA    19\n#> 3517  NA   1 15 NA   NA    20\n#> 3518  NA   5  5 NA   NA    21\n#> 3519  NA   1 13 NA   NA    22\n#> 3520  NA   5 12 NA   NA    23\n#> 3521  NA   4  2 NA   NA    24\n#> 3522  NA   0  1 NA   NA     1\n#> 3523  NA   0  2 NA   NA     2\n#> 3524  NA   0  0 NA   NA     3\n#> 3525  NA   0  2 NA   NA     4\n#> 3526  NA   0  6 NA   NA     5\n#> 3527  NA   0  0 NA   NA     6\n#> 3528  NA   0  0 NA   NA     6\n#> 3529  NA   0  0 NA   NA     7\n#> 3530  NA   0  5 NA   NA     8\n#> 3531  NA   0  4 NA   NA     9\n#> 3532  NA   0  1 NA    0    10\n#> 3533  NA   0  0 NA    0    11\n#> 3534  NA   0  0 NA    0    12\n#> 3535  NA   0  0 NA    0    13\n#> 3536  NA   0  0 NA    0    14\n#> 3537  NA   0  0 NA    0    19\n#> 3538   0   0  0  0    0     1\n#> 3539   0   2  4  3    4     2\n#> 3540   0   1  4  7   12     3\n#> 3541   6   2  0  3   16     4\n#> 3542   8   2  0  3   13     5\n#> 3543   4   4  1  3   17     6\n#> 3544   2   2  2  8   14     7\n#> 3545   7   2  1  7   18     8\n#> 3546   9   1  2  8   18     9\n#> 3547   4   5  1  4   16    10\n#> 3548  11   3  0  7   14    11\n#> 3549   4   3  0  2   25    12\n#> 3550   0   1  0  0    6    13\n#> 3551   2   0  1  4    2    13\n#> 3552   0   1  0  0    1    14\n#> 3553   1   0  0  1    6    14\n#> 3554   1   2  0  4    1     1\n#> 3555   1   1  1  3    1     2\n#> 3556   0   2  0  2    3     3\n#> 3557   4   6  0  4   15     4\n#> 3558   1  14  0  5   22     5\n#> 3559   1   1  0  2    7     6\n#> 3560   0   1  1  0    1     6\n#> 3561   0   1  0  0    1     7\n#> 3562   0   3  0  0    0     7\n#> 3563   0   4  0  2    3     8\n#> 3564   2  10  0  3   13     9\n#> 3565   0   4  0  0    5    10\n#> 3566   1   0  0  1    5    11\n#> 3567   0   0  0  0    3    12\n#> 3568   0   0  0  0    0    13\n#> 3569   0   0  1  0    0     1\n#> 3570   0   0  0  0    0     2\n#> 3571   0   0  5  0    1     3\n#> 3572   0   0  6  0    3     4\n#> 3573   0   0  4  0    1     5\n#> 3574   0   1  4  0    2     6\n#> 3575   0   0  9  1    3     7\n#> 3576   0   0 15  0    3     8\n#> 3577   0   0  0  0    0     9\n#> 3578   0   0  0  0    0    10\n#> 3579   0   0  0  0    0    11\n#> 3580   0   0  0  0    0    12\n#> 3581   0   0  0  0    0    12\n#> 3582   0   0  0  0    0    13\n#> 3583   0   0  0  0    0    14\n#> 3584   0   0  0  0    0    14\n#> 3585   0   0  0  0    0    15\n#> 3586   0   0  0  0    0    15\n#> 3587   0   0  1  0    8     1\n#> 3588   0   2  3  0    5     2\n#> 3589   0   1  0  2    0     3\n#> 3590   3   6  7  8    8     4\n#> 3591   1   2  2  1    1     5\n#> 3592   2   1  3  2    3     5\n#> 3593   0   4  2  3    5     6\n#> 3594   1   3  0  7    3     6\n#> 3595   1   6  2  3   13     7\n#> 3596   1   1  0  1    1     8\n#> 3597   1   0  1  1    3     8\n#> 3598   0   0  0  0    1     9\n#> 3599   0   0  3  2    1    10\n#> 3600   1   4  1  2    3    11\n#> 3601   0   1  0  2    2    12\n#> 3602   1   3  0  1    1    13\n#> 3603   0   1  0  0    0    15\n#> 3604   1   1  3  3    4     1\n#> 3605   2   0  7  1    2     2\n#> 3606   0   3  6  3    2     3\n#> 3607   0   0  1  2    2     4\n#> 3608   2   2  3  1    6     5\n#> 3609   2   3  3  3    5     6\n#> 3610   1   6  3  2    6     7\n#> 3611   3   5  9  3    6     8\n#> 3612   1   2  2  2    7     9\n#> 3613   0   9  6  3    0    10\n#> 3614   2   1  5  4    6    11\n#> 3615   0   2  9  2    9    12\n#> 3616   0   2  2  0    1    13\n#> 3617   0   2  0  2    0    14\n#> 3618   0   0  2  0    2    15\n#> 3619   2   0  3  0    1    16\n#> 3620  NA   0  3 NA   NA     1\n#> 3621  NA   0  1 NA   NA     2\n#> 3622  NA   3 15 NA   NA     3\n#> 3623  NA   6 21 NA   NA     4\n#> 3624  NA   6 22 NA   NA     5\n#> 3625  NA  15 18 NA   NA     6\n#> 3626  NA   0 29 NA   NA     7\n#> 3627  NA   7 26 NA   NA     8\n#> 3628  NA   6 28 NA   NA     9\n#> 3629  NA   5 35 NA   NA    10\n#> 3630  NA   3 39 NA   NA    11\n#> 3631  NA   3 33 NA   NA    12\n#> 3632  NA   0 22 NA   NA    13\n#> 3633  NA   2 40 NA   NA    14\n#> 3634  NA   2 33 NA   NA    15\n#> 3635  NA   2 13 NA   NA    16\n#> 3636  NA   3 27 NA   NA    17\n#> 3637  NA   4 39 NA   NA    18\n#> 3638  NA   3 28 NA   NA    19\n#> 3639  NA   4 17 NA   NA    20\n#> 3640  NA   3 15 NA   NA    21\n#> 3641  NA   0  8 NA   NA    22\n#> 3642  NA   0  0 NA   NA    23\n#> 3643  NA   0  0 NA   NA    24\n#> 3644  NA   0  0 NA   NA    25\n#> 3645  NA   9  3 NA   NA     1\n#> 3646  NA   1  1 NA   NA     1\n#> 3647  NA   8  8 NA   NA     2\n#> 3648  NA   7  8 NA   NA     3\n#> 3649  NA   7 13 NA   NA     4\n#> 3650  NA  12  9 NA   NA     5\n#> 3651  NA  10  9 NA   NA     6\n#> 3652  NA   5 12 NA   NA     7\n#> 3653  NA   2 19 NA   NA     8\n#> 3654  NA   2 13 NA   NA     9\n#> 3655  NA   5 13 NA   NA    10\n#> 3656  NA   4  9 NA   NA    11\n#> 3657  NA   0  2 NA   NA    12\n#> 3658  NA   0  6 NA   NA    13\n#> 3659  NA   8  9 NA   NA    13\n#> 3660  NA   4 13 NA   NA    14\n#> 3661  NA   1 13 NA   NA     1\n#> 3662  NA   5 19 NA   NA     2\n#> 3663  NA   5 19 NA   NA     3\n#> 3664  NA   3 28 NA   NA     4\n#> 3665  NA   6 21 NA   NA     5\n#> 3666  NA   6 40 NA   NA     6\n#> 3667  NA   3 17 NA   NA     7\n#> 3668  NA   2  6 NA   NA     8\n#> 3669  NA   2 15 NA   NA     9\n#> 3670  NA   3  6 NA   NA    10\n#> 3671  NA   4 15 NA   NA    11\n#> 3672  NA   4 20 NA   NA    12\n#> 3673  NA   5 20 NA   NA    13\n#> 3674  NA   5  9 NA   NA    14\n#> 3675  NA   3 10 NA   NA    15\n#> 3676  NA   0  0 NA   NA    16\n#> 3677   5   3  3  2   10     1\n#> 3678   2   0  8  1   10     2\n#> 3679   8   2  5  4   11     3\n#> 3680   3   1  2  5    7     4\n#> 3681  10   6  5  4   20     5\n#> 3682   4   2  6  4   17     6\n#> 3683  11   1  4  6   11     7\n#> 3684   6   0  6  6   15     8\n#> 3685   4   1  3  4   14     9\n#> 3686   5   0  6  6   18    10\n#> 3687   2   1  2  6   20    11\n#> 3688   1   1  2  7   13    12\n#> 3689   4   0  2  4   20    13\n#> 3690   9   0  2  7   21    14\n#> 3691   5   0  8  9    9    15\n#> 3692   3   3  3  4   23    16\n#> 3693   1   0  5  4   13    17\n#> 3694   5   0  1  3   10    18\n#> 3695   5   0  1  0    4    19\n#> 3696   0   0  0  0    0     1\n#> 3697   0   1  3  0    0     2\n#> 3698   0   0  5  0    0     3\n#> 3699   0   0  6  0    1     4\n#> 3700   0   0  9  0    2     5\n#> 3701   0   2  6  1    3     6\n#> 3702   0   0  0  0    0     7\n#> 3703   0   0  7  0    1     7\n#> 3704   0   0  0  0    0     8\n#> 3705   0   0  0  0    0     9\n#> 3706   0   0  0  0    0    10\n#> 3707   0   0  0  0    0    10\n#> 3708   0   0  0  0    0    11\n#> 3709   0   0  0  0    0    12\n#> 3710   0   0  1  0    0    13\n#> 3711   0   0  0  0    1    14\n#> 3712   0   0  0  0    0    15\n#> 3713   0   0  1  0    0    16\n#> 3714   0   0  0  0    0    18\n#> 3715   0   0  0  0    1     1\n#> 3716   1   0  0  0    1     3\n#> 3717   2   5  0  6   14     4\n#> 3718   4   1  0  4    8     5\n#> 3719   5   1  0 12   13     6\n#> 3720   1   4  0  7   17     7\n#> 3721   3   2  0  2   11     8\n#> 3722   1   2  0  6    8     9\n#> 3723   0   3  1  7   12    10\n#> 3724   1   2  0  4   14    11\n#> 3725   6   5  0  8   12    12\n#> 3726   6   2  0 10   10    13\n#> 3727   0   0  1  1    2    14\n#> 3728   5   5  0 12   14    14\n#> 3729   3   2  2  6   15    15\n#> 3730   2   3  2  6   12    16\n#> 3731   2   2  0  0    1    17\n#> 3732   2   2  1  5   12    17\n#> 3733   2   0  1  1    1    18\n#> 3734   0   0  1  6    4    18\n#> 3735  NA  NA NA NA   NA     1\n#> 3736  NA  NA NA NA   NA     2\n#> 3737  NA  NA NA NA   NA     3\n#> 3738  NA  NA NA NA   NA     4\n#> 3739  NA  NA NA NA   NA     5\n#> 3740  NA  NA NA NA   NA     6\n#> 3741  NA  NA NA NA   NA     7\n#> 3742  NA   8 NA NA   NA     8\n#> 3743  NA   4 NA NA   NA     9\n#> 3744  NA   2 NA NA   NA    10\n#> 3745  NA   1 NA NA   NA    11\n#> 3746  NA   4 NA NA   NA    12\n#> 3747  NA   6 NA NA   NA    13\n#> 3748  NA   3 NA NA   NA    14\n#> 3749  NA   0 NA NA   NA    15\n#> 3750  NA   6 NA NA   NA    15\n#> 3751  NA   2  2 NA   NA    16\n#> 3752  NA   2  0 NA   NA    17\n#> 3753  NA   0  1 NA   NA    18\n#> 3754   0   0  1  0    0     1\n#> 3755   0   0  0  0    0     2\n#> 3756   0   0  2  0    0     2\n#> 3757   0   0  4  0    2     3\n#> 3758   0   0  0  0    1     3\n#> 3759   0   0  1  0    0     4\n#> 3760   0   0  0  0    0     5\n#> 3761   0   0  0  0    0     6\n#> 3762   0   0  0  0    0     7\n#> 3763   0   0  0  0    0     8\n#> 3764   0   0  0  0    0     8\n#> 3765   0   0  0  0    0     9\n#> 3766   0   0  0  0    0    10\n#> 3767   0   0  0  0    0    11\n#> 3768   0   0  0  0    0    12\n#> 3769   0   0  1  0    0    13\n#> 3770   0   0  0  0    0    14\n#> 3771   0   0  0  0    0    14\n#> 3772   0   0  0  0    0    15\n#> 3773  NA   0  0 NA   NA     1\n#> 3774  NA   0  0 NA   NA     2\n#> 3775  NA   0  3 NA   NA     3\n#> 3776  NA   0  5 NA   NA     4\n#> 3777  NA   1  5 NA   NA     5\n#> 3778  NA   0  8 NA   NA     6\n#> 3779  NA   0  0 NA   NA     7\n#> 3780  NA   0  1 NA   NA     8\n#> 3781  NA   1  0 NA   NA     9\n#> 3782  NA   0  0 NA   NA    10\n#> 3783  NA   0  0 NA    0    15\n#> 3784  NA   0 10 NA   11    16\n#> 3785  NA   0  6 NA   12    17\n#> 3786  NA   1 11 NA    9    18\n#> 3787  NA   2 11 NA    9    19\n#> 3788  NA   1 13 NA    7    20\n#> 3789  NA   0  9 NA   13    21\n#> 3790  NA   0  5 NA    5    22\n#> 3791  NA   0  1 NA    1    23\n#> 3792  NA   0  0 NA    0    24\n#> 3793  NA   0  1 NA    0    24\n#> 3794   1   1  0  1    0     1\n#> 3795   1   0  0  0    0     2\n#> 3796   1   0  0  1    1     3\n#> 3797   3   1  5  2    3     4\n#> 3798   6   3  3  3    3     5\n#> 3799   6   1  9  6    3     6\n#> 3800   4   0  1  7   13     7\n#> 3801   3   0  5  4    5     8\n#> 3802  10   0  6  8   14     9\n#> 3803  15   2  7  8   16    10\n#> 3804   2   3  1  5   16    11\n#> 3805   7   0  4  6    4    12\n#> 3806   7   1  3  8   17    13\n#> 3807   6   2  0  3   12    14\n#> 3808   3   2  1 10   24    15\n#> 3809   2   1  1  4   15    16\n#> 3810   2   0  0  3    4    17\n#> 3811  NA   0  0 NA    0     1\n#> 3812  NA   0  2 NA    7     2\n#> 3813  NA   1  6 NA   18     3\n#> 3814  NA   2  6 NA   13     4\n#> 3815  NA   1  8 NA   15     5\n#> 3816  NA   0  0 NA    0     6\n#> 3817  NA   0  3 NA   10     7\n#> 3818  NA   3  4 NA   13     8\n#> 3819  NA   1  3 NA   14     9\n#> 3820  NA   3  0 NA   10    10\n#> 3821  NA   2  1 NA    9    10\n#> 3822  NA   0  0 NA    1    11\n#> 3823  NA   3  3 NA    8    11\n#> 3824  NA   1  1 NA   10    12\n#> 3825  NA   1  3 NA    7    13\n#> 3826  NA   1  1 NA    6    14\n#> 3827  NA   0  0  0    1    15\n#> 3828  NA   2  0  0    7    15\n#> 3829   1   1  1  0    3    16\n#> 3830   1   0  1  0    2    17\n#> 3831   1   0  1  1    6    18\n#> 3832  NA   0  2 NA   NA     1\n#> 3833  NA   0  1 NA   NA     2\n#> 3834  NA   0  3 NA   NA     3\n#> 3835  NA   0  2 NA   NA     4\n#> 3836  NA   0  7 NA   NA     5\n#> 3837  NA   0  2 NA   NA     6\n#> 3838  NA   0  5 NA   NA     7\n#> 3839  NA   1  1 NA   NA     8\n#> 3840  NA   0  2 NA   NA     9\n#> 3841  NA   2  4 NA   NA    10\n#> 3842  NA   0  3 NA   NA    11\n#> 3843  NA   0  3 NA   NA    12\n#> 3844  NA   0  1 NA   NA    13\n#> 3845  NA   1  1 NA   NA    14\n#> 3846  NA   0  1 NA   NA    15\n#> 3847  NA   0  0 NA   NA    15\n#> 3848  NA   2 NA NA   NA     1\n#> 3849  NA  10 NA NA   NA     2\n#> 3850  NA   4 NA NA   NA     3\n#> 3851  NA   2 NA NA   NA     4\n#> 3852  NA   0 NA NA   NA     5\n#> 3853  NA   3 17 NA   NA     6\n#> 3854  NA   1 12 NA   NA     7\n#> 3855  NA   2 12 NA   NA     8\n#> 3856  NA   2 17 NA   NA     9\n#> 3857  NA   2 15 NA   NA    10\n#> 3858  NA   2 15 NA   NA    11\n#> 3859  NA   0  1 NA   NA    12\n#> 3860  NA   0  8 NA   NA    13\n#> 3861  NA   1  1 NA   NA    14\n#> 3862  NA   2 14 NA   NA    15\n#> 3863  NA   1 18 NA   NA    16\n#> 3864  NA   1 10 NA   NA    17\n#> 3865  NA   0  7 NA   NA    18\n#> 3866   0   1  1  0    3     1\n#> 3867   8   7  4  1   12     2\n#> 3868   3   6  2  3    8     3\n#> 3869   4   9  1  4   11     4\n#> 3870   4   2  1  1    8     5\n#> 3871   7   4  0  4   11     6\n#> 3872   0   3  1  4    7     7\n#> 3873   0   6  0  2    7     8\n#> 3874   0   3  0  0    7     9\n#> 3875   1   4  0  1   11     9\n#> 3876   2   4  2  3    8    10\n#> 3877   0   2  0  4    3    11\n#> 3878   0   0  0  0    1    11\n#> 3879   5   4  0  3   11    12\n#> 3880   0   2  0  1    2    13\n#> 3881   1   0  0  2    0    14\n#> 3882   0   0  1  0    0     1\n#> 3883   0   0 10  0    0     2\n#> 3884   0   0  6  0    1     3\n#> 3885   0   1  0  0    0     4\n#> 3886   0   0  0  0    0     5\n#> 3887   0   0 11  0    0     6\n#> 3888   0   0  0  0    0     7\n#> 3889   0   0  0  0    0     9\n#> 3890   0   0  0  0    0    10\n#> 3891   0   0  0  0    0    11\n#> 3892   0   0  0  0    0    12\n#> 3893   0   0  0  0    0    13\n#> 3894   0   0  0  0    0    14\n#> 3895   0   0  0  0    0    16\n#> 3896   0   0  0  0    0    16\n#> 3897   0   0  2  0    0    15\n#> 3898   0   0  0  0    0    17\n#> 3899   3   1  2  0    2     1\n#> 3900   7   2  5  7    5     2\n#> 3901   7   5  3  2    7     3\n#> 3902   8   3  1  2   13     4\n#> 3903   1   1  0  2    9     5\n#> 3904   1   0  2  0    2     6\n#> 3905   0   2  0  0    2     6\n#> 3906   0   0  0  0    0     6\n#> 3907   1   0  0  3    4     6\n#> 3908   1   2  1  5    9     7\n#> 3909   7   2  2  0    8     8\n#> 3910   6   3  0  3    6     9\n#> 3911   8   1  0  2    5    10\n#> 3912   1   0  0  0    0    11\n#> 3913   0   2  0  0    1    11\n#> 3914  NA   0  0 NA   NA     1\n#> 3915  NA   0  1 NA   NA     2\n#> 3916  NA   2  6 NA   NA     3\n#> 3917  NA   2  4 NA   NA     4\n#> 3918  NA   0 21 NA   NA     5\n#> 3919  NA   2 12 NA   NA     6\n#> 3920  NA   5 15 NA   NA     7\n#> 3921  NA   5 16 NA   NA     8\n#> 3922  NA   4 17 NA   NA     9\n#> 3923  NA   3  5 NA   NA    10\n#> 3924  NA   2 15 NA   16    11\n#> 3925  NA   1 14 NA   13    12\n#> 3926  NA   6  4 NA   16    13\n#> 3927  NA   3  6 NA   15    14\n#> 3928  NA   1 13 NA    8    15\n#> 3929  NA   2  9 NA    7    16\n#> 3930  NA   3 15 NA    9    17\n#> 3931  NA   0  5 NA    6    18\n#> 3932  NA   0  2 NA    9    19\n#> 3933  NA   0  0 NA    0    20\n#> 3934  NA   0  2 NA    8     1\n#> 3935  NA   0  6 NA    6     2\n#> 3936  NA   0  5 NA   13     5\n#> 3937  NA   3  6  2   14     6\n#> 3938  11   2  6  6   12     7\n#> 3939  15   1  6  5    5     8\n#> 3940   9   1  4  2   13     9\n#> 3941  18   4  2  4   14    10\n#> 3942   8   3  9  5   24    11\n#> 3943   6   4  9 12   15    12\n#> 3944   0   0  1  0    1    13\n#> 3945   2   2  6  3   16    14\n#> 3946   5   0  3  2   10    15\n#> 3947   9   0  2  0    5    16\n#> 3948   7   1  1  1    3    17\n#> 3949   5   0  0  0    3    18\n#> 3950  NA   0  4 NA   NA     1\n#> 3951  NA   3  4 NA   NA     2\n#> 3952  NA   3  4 NA   NA     3\n#> 3953  NA   1  6 NA   NA     4\n#> 3954  NA   2 25 NA   NA     5\n#> 3955  NA   0 11 NA   NA     6\n#> 3956  NA   3  3 NA   NA     7\n#> 3957  NA   1  8 NA   NA     8\n#> 3958  NA   2 11 NA   NA     9\n#> 3959  NA   3 23 NA   NA    10\n#> 3960  NA   1 25 NA   NA    11\n#> 3961  NA   1 24 NA   NA    12\n#> 3962  NA   0 13 NA   NA    13\n#> 3963  NA   2 19 NA   NA    14\n#> 3964  NA   0 10 NA   NA    15\n#> 3965  NA   1 22 NA   NA    16\n#> 3966  NA   0 16 NA   NA    17\n#> 3967  NA   0  9 NA   NA    18\n#> 3968  NA   0  4 NA   NA    19\n#> 3969   0   0  0  0    0     1\n#> 3970   0   0  0  0    0     2\n#> 3971   0   0  0  0    0     3\n#> 3972   0   0  0  0    0     4\n#> 3973   0   2  1  0    0     5\n#> 3974   3   0  2  0    5     6\n#> 3975   4   2  0  2    5     7\n#> 3976   2   1  1  3    6     8\n#> 3977   3   2  2  1    8     9\n#> 3978  12   1  3  4    6    10\n#> 3979   9   0  3  5    9    11\n#> 3980  11   0  6  4    2    12\n#> 3981   6   1  2  6   10    13\n#> 3982   4   0  2  1    5    14\n#> 3983   1   0  0  2    1    14\n#> 3984  NA   0  0 NA   NA     1\n#> 3985  NA   1  3 NA   NA     2\n#> 3986  NA   5  6 NA   NA     3\n#> 3987  NA   2  6 NA   NA     4\n#> 3988  NA   2  0 NA   NA     5\n#> 3989  NA   3  6 NA   NA     6\n#> 3990  NA   0  5 NA   NA     7\n#> 3991  NA   1 14 NA   NA     8\n#> 3992  NA   3  8 NA   NA     9\n#> 3993  NA   3  7 NA   NA    10\n#> 3994  NA   0  1 NA   NA    11\n#> 3995  NA   2 10 NA   NA    12\n#> 3996  NA   0  7 NA   NA    13\n#> 3997  NA   1 12 NA   NA    14\n#> 3998  NA   0  0 NA   NA    15\n#> 3999  NA   0  0 NA   NA    17\n#> 4000  NA   0  3 NA   NA     1\n#> 4001  NA   0  0 NA   NA     2\n#> 4002  NA   0 10 NA   NA     3\n#> 4003  NA   1 21 NA   NA     4\n#> 4004  NA   5 22 NA   NA     5\n#> 4005  NA   4  4 NA   NA     6\n#> 4006  NA   3  3 NA   NA     7\n#> 4007  NA   2  5 NA   NA     8\n#> 4008  NA   1  9 NA   NA     9\n#> 4009  NA   3  8 NA   NA    10\n#> 4010  NA   1  6 NA   NA    11\n#> 4011  NA   6 11 NA   NA    12\n#> 4012  NA   5 11 NA   NA    13\n#> 4013  NA   0 20 NA   18    14\n#> 4014  NA   1 13 NA    6    15\n#> 4015  NA   1 14 NA   20    16\n#> 4016  NA   0  1 NA    3    17\n#> 4017  NA   0  0 NA    3    18\n#> 4018  NA   1  5 NA    7    19\n#> 4019  NA   0  0 NA    0    20\n#> 4020  NA   5  7 NA   NA     1\n#> 4021  NA   2  5 NA   NA     2\n#> 4022  NA   5 12 NA   NA     3\n#> 4023  NA   4  1 NA   NA     4\n#> 4024  NA  12  6 NA   NA     5\n#> 4025  NA  12 12 NA   NA     6\n#> 4026  NA  15  5 NA   NA     7\n#> 4027  NA  13  9 NA   11     8\n#> 4028  NA  10  5 NA   17     9\n#> 4029  NA   3  0 NA    6    10\n#> 4030  NA   9  3 NA    5    11\n#> 4031  NA   7  4 NA    7    12\n#> 4032  NA   6  6 NA   10    13\n#> 4033  NA  10 14 NA    3    14\n#> 4034  NA   1  1 NA    0    15\n#> 4035  NA   0  0 NA    0    16\n#> 4036  NA   0  0 NA    0    17\n#> 4037  NA   1 NA NA   NA     1\n#> 4038  NA   1 NA NA   NA     2\n#> 4039  NA   0 NA NA   NA     3\n#> 4040  NA   0 NA NA   NA     4\n#> 4041  NA   3 NA NA   NA     5\n#> 4042  NA   3 NA NA   NA     6\n#> 4043  NA   1 NA NA   NA     7\n#> 4044  NA   3 NA NA   NA     8\n#> 4045  NA   3 16 NA   NA     9\n#> 4046  NA   1 14 NA   NA    10\n#> 4047  NA   1 11 NA   NA    11\n#> 4048  NA   0 16 NA   NA    12\n#> 4049  NA   1  2 NA   NA    13\n#> 4050  NA   1  6 NA   NA    13\n#> 4051  NA   0  3 NA   NA    14\n#> 4052  NA   2  4 NA   NA    14\n#> 4053  NA   1  6 NA   NA    15\n#> 4054  NA   2  7 NA   NA    16\n#> 4055  NA   0  8 NA   NA    17\n#> 4056  NA   5 14 NA   NA    18\n#> 4057  NA   2 15 NA   NA    19\n#> 4058  NA   0 16 NA   NA    20\n#> 4059  NA   0  5 NA   NA    21\n#> 4060  NA   0 NA NA   NA     1\n#> 4061  NA   2 NA NA   NA     3\n#> 4062  NA   3  6 NA   NA     4\n#> 4063  NA   6 11 NA   NA     5\n#> 4064  NA   7 13 NA   NA     6\n#> 4065  NA   8 11 NA   NA     7\n#> 4066  NA  10 26 NA   NA     8\n#> 4067  NA   6  7 NA   NA     9\n#> 4068  NA   5  7 NA   NA    10\n#> 4069  NA   8 22 NA   NA    11\n#> 4070  NA   6 12 NA   NA    12\n#> 4071  NA   7 17 NA   NA    13\n#> 4072  NA   6 24 NA   NA    14\n#> 4073  NA   7 23 NA   NA    15\n#> 4074  NA   1 13 NA   NA    16\n#> 4075   0   0  0  1    0     1\n#> 4076   3   0  2  1    5     2\n#> 4077   0   0  0  0    2     3\n#> 4078   5   1  1  2    8     4\n#> 4079   1   1  0  0    4     5\n#> 4080   0   1  0  4    4     6\n#> 4081   1   0  0  0    6     7\n#> 4082   1   1  0  0    1     8\n#> 4083   0   0  0  1    1     8\n#> 4084   0   0  0  0    0     9\n#> 4085   0   1  0  1    4    10\n#> 4086   2   1  0  0    2    11\n#> 4087   2   0  2  2    8    12\n#> 4088   5   0  1  2    3    13\n#> 4089   1   0  0  0    5    14\n#> 4090   0   1  0  1    2    15\n#> 4091   0   1  0  0    1     1\n#> 4092   6   1  1  3    6     2\n#> 4093   3   1  2  3    4     3\n#> 4094   4   1  6  7    8     4\n#> 4095   5   0  0  1    3     5\n#> 4096   6   1  3  6    6     6\n#> 4097   5   0  2  2    6     7\n#> 4098  13   0  3 10    4     8\n#> 4099   9   0  2  3    9     9\n#> 4100  16   0  1  5    5    10\n#> 4101  13   0  0  8   11    11\n#> 4102   4   0  0  7    7    12\n#> 4103  12   1  3  6   11    13\n#> 4104  10   1  1  3    4    14\n#> 4105  10   0  2 10    8    15\n#> 4106  10   0  0  3   11    16\n#> 4107  12   0  0  2    9    17\n#> 4108   3   0  1  3    4    18\n#> 4109   1   0  0  0    2    19\n#> 4110  NA   2 14 NA   NA     1\n#> 4111  NA   0 10 NA   NA     2\n#> 4112  NA   4  9 NA   NA     3\n#> 4113  NA   2  6 NA   20     4\n#> 4114  NA   1  9 NA    8     5\n#> 4115  NA   2  2 NA   13     6\n#> 4116  NA   2 16 NA   12     7\n#> 4117  NA   0 11 NA   11     8\n#> 4118  NA   3  6 NA   19     9\n#> 4119  NA   0  6 NA    9    10\n#> 4120  NA   1  0 NA    4    11\n#> 4121  NA   0  1 NA    9    11\n#> 4122  NA   0  1 NA    3    13\n#> 4123  NA   0  2 NA    2    14\n#> 4124  NA   0  0 NA    0    14\n#> 4125  NA   0  1 NA    2    15\n#> 4126  NA   1  2 NA    9    16\n#> 4127   0   0  0  0    0     1\n#> 4128   0   0  0  0    0     6\n#> 4129   0   0  1  0    0     7\n#> 4130   0   0  4  0    1     8\n#> 4131   0   0  3  0    1     9\n#> 4132   0   1  3  0    0    10\n#> 4133   0   0  8  2    0    11\n#> 4134   0   0  9  0    0    12\n#> 4135   0   0  8  0    2    13\n#> 4136   0   0  7  0    1    14\n#> 4137   0   0  0  0    0    15\n#> 4138   0   0  0  0    0    16\n#> 4139   0   0  0  0    0    17\n#> 4140   0   0  0  0    0    18\n#> 4141   0   0  0  0    0    19\n#> 4142   0   0  0  0    0     1\n#> 4143   0   0  0  0    0     2\n#> 4144   0   0  3  0    0     3\n#> 4145   0   0  0  0    0     4\n#> 4146   0   0  6  0    2     5\n#> 4147   0   0  5  0    1     6\n#> 4148   0   0  5  0    1     7\n#> 4149   0   0  3  0    0     8\n#> 4150   0   0  1  0    0     9\n#> 4151   0   1  6  0    0    10\n#> 4152   0   0  5  0    0    11\n#> 4153   0   0  1  2    1    12\n#> 4154   0   0  0  0    0    13\n#> 4155   0   0  4  0    0    13\n#> 4156   0   0  0  0    0    14\n#> 4157   0   0  0  0    0    15\n#> 4158  NA   0  0 NA   NA     1\n#> 4159  NA   0  0 NA   NA     2\n#> 4160  NA   1  0 NA   NA     3\n#> 4161  NA   7 12 NA   NA     4\n#> 4162  NA  13 12 NA   NA     5\n#> 4163  NA   9 21 NA   NA     6\n#> 4164  NA   3  5 NA   NA     7\n#> 4165  NA   7 24 NA   NA     8\n#> 4166  NA   5 16 NA   NA     9\n#> 4167  NA  10 17 NA   NA    10\n#> 4168  NA   5 20 NA   NA    11\n#> 4169  NA   4 10 NA   NA    12\n#> 4170  NA   4  7 NA   10    13\n#> 4171  NA   4 13 NA   10    14\n#> 4172  NA   5  5 NA    3    15\n#> 4173  NA   2  1 NA    2    15\n#> 4174  NA   2  7 NA    7    16\n#> 4175  NA   2  5 NA   15    17\n#> 4176  NA   2  1 NA    6    18\n#> 4177  NA   7 NA NA   NA     1\n#> 4178  NA   5 NA NA   NA     2\n#> 4179  NA   5 NA NA   NA     3\n#> 4180  NA   3 NA NA   NA     4\n#> 4181  NA  10  5 NA   NA     5\n#> 4182  NA   8 27 NA   NA     6\n#> 4183  NA   7 13 NA   NA     7\n#> 4184  NA  23 17 NA   NA     8\n#> 4185  NA  15  4 NA   NA     9\n#> 4186  NA   7  2 NA   NA    10\n#> 4187  NA   5  7 NA   NA    11\n#> 4188  NA   8  9 NA   NA    12\n#> 4189  NA   2  8 NA   NA    13\n#> 4190  NA   1 11 NA   NA    14\n#> 4191  NA  12  7 NA   NA    15\n#> 4192  NA  10  8 NA   NA    16\n#> 4193  NA   4 10 NA   NA    17\n#> 4194  NA   8 21 NA   NA    18\n#> 4195  NA   0  5 NA   NA    19\n#> 4196  NA   0  1 NA   NA    20\n#> 4197  NA   0  0 NA   NA    21\n#> 4198  NA   3 12 NA   NA     1\n#> 4199  NA   0  1 NA   NA     2\n#> 4200  NA   0  0 NA   NA     3\n#> 4201  NA   0  0 NA   NA     4\n#> 4202  NA   2 13 NA   15     5\n#> 4203  NA   5  3 NA   20     6\n#> 4204  NA   1  0 NA    7     7\n#> 4205  NA   1  0 NA    8     7\n#> 4206  NA   0  0 NA    0     8\n#> 4207  NA   0  0 NA    3     8\n#> 4208  NA   0  0 NA    1     8\n#> 4209  NA   2  5 NA   22     9\n#> 4210  NA   6  7 NA   20    10\n#> 4211  NA   2  7 NA   23    11\n#> 4212  NA   0  1 NA    2    12\n#> 4213  NA   0 NA NA   NA     1\n#> 4214  NA   1 NA NA   NA     2\n#> 4215  NA   1 NA NA   NA     3\n#> 4216  NA   4 NA NA   NA     4\n#> 4217  NA   2 NA NA   NA     5\n#> 4218  NA   5 NA NA   NA     6\n#> 4219  NA   0 NA NA   NA     7\n#> 4220  NA   5 NA NA   NA     8\n#> 4221  NA   3 10 NA   NA     9\n#> 4222  NA   5  0 NA   NA    10\n#> 4223  NA   1  0 NA   NA    12\n#> 4224  NA  12  8 NA   NA    13\n#> 4225  NA   6  5 NA   NA    14\n#> 4226  NA   4 10 NA   NA    15\n#> 4227  NA   0 15 NA   NA    16\n#> 4228  NA   1  5 NA   NA    17\n#> 4229  NA   2  7 NA   NA    17\n#> 4230  NA   0  0 NA    0     1\n#> 4231  NA   2 10 NA    4     3\n#> 4232  NA   1 11 NA   10     4\n#> 4233  NA   6 11 NA   10     5\n#> 4234  NA   6  6 NA   11     6\n#> 4235  NA   5  8 NA   10     7\n#> 4236  NA   6 12 NA   19     8\n#> 4237  NA   5 12  5   16     9\n#> 4238   2   5  4  2    5    10\n#> 4239   0   1  3  4    5    11\n#> 4240   0   2  2  4    9    11\n#> 4241   4   4  5  4    7    12\n#> 4242   0   0  0  0    3    13\n#> 4243   1   5  2  6   13    13\n#> 4244   9   3  7  3    4    14\n#> 4245   2   2  2  0    5    15\n#> 4246   2   1  0  3    3    15\n#> 4247   0   0  1  0    0     1\n#> 4248   0   0  6  1    1     2\n#> 4249   0   0 13  0    0     3\n#> 4250   0   0 10  0    0     4\n#> 4251   0   0 10  0    0     5\n#> 4252   0   0  9  0    1     6\n#> 4253   0   1  5  0    0     7\n#> 4254   0   0  5  0    0     8\n#> 4255   0   0  0  0    0     9\n#> 4256   0   0  5  0    0     9\n#> 4257   0   0  1  0    0     9\n#> 4258   0   0  0  0    0    10\n#> 4259   0   0  0  0    0    11\n#> 4260   0   0  0  0    0    12\n#> 4261   0   0  0  0    0    13\n#> 4262   0   0  0  0    0     1\n#> 4263   0   0  0  0    0     2\n#> 4264   0   0  0  0    0     3\n#> 4265   0   0  0  0    0     4\n#> 4266   0   0  0  0    0     5\n#> 4267   0   0  0  0    0     6\n#> 4268   0   0  0  0    0     7\n#> 4269   0   0  0  0    0     8\n#> 4270   0   0  0  0    0     9\n#> 4271   0   0  2  0    0     9\n#> 4272   0   0  1  0    0    10\n#> 4273   0   0  2  1    0    11\n#> 4274   0   0  0  1    0    12\n#> 4275   0   0  3  0    0    13\n#> 4276   0   0  0  0    0    14\n#> 4277   0   0  0  0    0    15\n#> 4278   0   0  0  0    0    16\n#> 4279   0   0  0  0    0    17\n#> 4280   0   0  0  0    0    18\n#> 4281   0   0  0  0    0    18\n#> 4282   0   0  5  0    1    19\n#> 4283   0   0  2  0    0    19\n#> 4284   0   0  1  0    0    20\n#> 4285   0   0  0  0    0    20\n#> 4286   0   1  4  0    0    21\n#> 4287  NA   5 31 NA   NA     1\n#> 4288  NA   2 26 NA   NA     2\n#> 4289  NA   6 14 NA   NA     3\n#> 4290  NA   3 17 NA   NA     4\n#> 4291  NA   5 33 NA   NA     5\n#> 4292  NA   1 39 NA   NA     6\n#> 4293  NA   4 35 NA   NA     7\n#> 4294  NA   6 25 NA   NA     8\n#> 4295  NA   5 17 NA   NA     9\n#> 4296  NA   2 39 NA   NA    10\n#> 4297  NA   3 27 NA   NA    11\n#> 4298  NA   3 33 NA   NA    12\n#> 4299  NA   3 31 NA   NA    13\n#> 4300  NA   4 12 NA   NA    14\n#> 4301  NA   2 13 NA   NA    15\n#> 4302   0   0  0  0    0     1\n#> 4303   0   0  0  0    1     3\n#> 4304   3   1  2  2    1     4\n#> 4305   1   0  4  1    0     5\n#> 4306   1   0  0  2    2     6\n#> 4307   8   2  1  1    4     7\n#> 4308   9   2  3  4    6     8\n#> 4309   4   2  2  5    4     9\n#> 4310  11   6  0  6    3    10\n#> 4311  12   2  0  8    2    11\n#> 4312   2   1  0  1    3    12\n#> 4313   2   5  0  2    4    13\n#> 4314   0   1  0  0    1    14\n#> 4315   4   1  0  7    3    15\n#> 4316   1   1  0  2    1    15\n#> 4317  NA   1  0 NA   NA     1\n#> 4318  NA   1  1 NA   NA     2\n#> 4319  NA   0  5 NA   NA     3\n#> 4320  NA   1  5 NA   NA     4\n#> 4321  NA   1  4 NA   NA     5\n#> 4322  NA   0  3 NA   NA     6\n#> 4323  NA   2  4 NA   NA     7\n#> 4324  NA   1  5 NA   NA     8\n#> 4325  NA   0  3 NA   NA     9\n#> 4326  NA   0  2 NA   NA    10\n#> 4327  NA   1  3 NA   NA    11\n#> 4328  NA   0  6 NA   NA    12\n#> 4329  NA   0  2 NA   NA    13\n#> 4330  NA   0  0 NA   NA    14\n#> 4331  NA   0  2 NA   NA    15\n#> 4332   0   1  5  2    4     1\n#> 4333   2   1  4  6    4     2\n#> 4334   9   0  6  4    4     3\n#> 4335   6   0  1  2    6     4\n#> 4336   0   1  4  1    5     5\n#> 4337   0   1  1  1    2     6\n#> 4338   1   0  3  2    2     6\n#> 4339   1   1  0  0    0     7\n#> 4340   0   0  0  0    3     7\n#> 4341   1   0  2  1    4     8\n#> 4342   1   2  1  3    4     9\n#> 4343   6   3  5  1    3    10\n#> 4344   1   0  0  0    0    11\n#> 4345   0   0  0  0    1    11\n#> 4346   1   0  0  1    0    12\n#> 4347   0   0  0  0    0    15\n#>  [ reached 'max' / getOption(\"max.print\") -- omitted 17352 rows ]\n\nCode using dplyr\n\nbaseball_dplyr<- baseball%>%\n  group_by(id)%>%\n  mutate(cyear = year - min(year) + 1)\nbaseball_dplyr\n#> # A tibble: 21,699 × 23\n#> # Groups:   id [1,228]\n#>    id     year stint team  lg        g    ab     r     h   X2b   X3b    hr   rbi\n#>    <chr> <int> <int> <chr> <chr> <int> <int> <int> <int> <int> <int> <int> <int>\n#>  1 anso…  1871     1 RC1   \"\"       25   120    29    39    11     3     0    16\n#>  2 forc…  1871     1 WS3   \"\"       32   162    45    45     9     4     0    29\n#>  3 math…  1871     1 FW1   \"\"       19    89    15    24     3     1     0    10\n#>  4 star…  1871     1 NY2   \"\"       33   161    35    58     5     1     1    34\n#>  5 sutt…  1871     1 CL1   \"\"       29   128    35    45     3     7     3    23\n#>  6 whit…  1871     1 CL1   \"\"       29   146    40    47     6     5     1    21\n#>  7 york…  1871     1 TRO   \"\"       29   145    36    37     5     7     2    23\n#>  8 anso…  1872     1 PH1   \"\"       46   217    60    90    10     7     0    50\n#>  9 burd…  1872     1 BR2   \"\"       37   174    26    46     3     0     0    15\n#> 10 forc…  1872     1 TRO   \"\"       25   130    40    53    11     0     0    16\n#> # … with 21,689 more rows, and 10 more variables: sb <int>, cs <int>, bb <int>,\n#> #   so <int>, ibb <int>, hbp <int>, sh <int>, sf <int>, gidp <int>, cyear <dbl>\n\n\nWhich (base R) functions do you know that support the split-apply-combine strategy? In your opinion, are these sufficient? State why or why not?\n\nI am most familiar with the base R functions split/apply/ and rbind/cbind. I don’t think these are the most efficent ways to analyze data, especially working with larger data. There can be multiple steps in code or lines of code to get the results you are looking for. However with dplyr you can use pipes to organize/clean your code. I also think that using mutate or the group_by functions are extremely useful and the base R functions can be much more difficult to get the same answers.\n\nThe ChatGPT response to the prompt “Describe the split-apply-combine paradigm” is given below. Generally, the chatbot’s answers are decent. ChatGPT does have problems getting details right. Which details would you change in the response?\n\n\nThe “split-apply-combine” paradigm is a data analysis strategy used in statistics and data science to analyze grouped data. It consists of three steps:\nSplit: The data is first split into groups based on one or more variables of interest.\nApply: A specific operation or function is applied to each group of data, usually for the purpose of aggregating, summarizing, or transforming the data within each group.\n\n\nCombine: The results of the operation applied to each group are then combined and returned as a single output.\nThe split-apply-combine paradigm is particularly useful in cases where the data cannot be analyzed as a whole and instead must be analyzed in smaller, more manageable chunks. This allows for more efficient data processing and improved scalability. The paradigm is commonly implemented using tools such as the “groupby” function in the R and Python programming languages, and the “dplyr” library in R.\n\nI’m not exactly sure what is being asked here. I think this does a pretty good generalization of the Split-apply-combine paradigm. The only issues that could happen perhaps could be the combing. When combinin the data back in our apply stage there could be shifts that could occur so we have to be careful of how we split/apply so we then can combine at the end."
  },
  {
    "objectID": "blog-2023/Blog-4-submissions/loganjohnson0/index.html",
    "href": "blog-2023/Blog-4-submissions/loganjohnson0/index.html",
    "title": "‘plyr’ to d’plyr’",
    "section": "",
    "text": "The plyr package has by now been replaced by other, even faster packages, but the idea of Split, apply, combine is as relevant as ever.\nRead the paper The Split-Apply-Combine Strategy for Data Analysis by Hadley Wickham.\nWrite a blog post addressing the following questions:\n\nThe R code for the split-apply-combine paper is posted with the paper. Pick one of the examples demonstrating plyr functionality (such as dlply or ddply, …) and rewrite the example using functionality from the package dplyr. Make sure that your example works and the results are identical."
  },
  {
    "objectID": "blog-2023/Blog-4-submissions/loganjohnson0/index.html#example-from-plyr-package",
    "href": "blog-2023/Blog-4-submissions/loganjohnson0/index.html#example-from-plyr-package",
    "title": "‘plyr’ to d’plyr’",
    "section": "Example from plyr package",
    "text": "Example from plyr package\n\nlibrary(plyr)\n\nbaseball <- baseball\n\nhead(baseball[c(\"id\",\"year\")], n = 10)\n#>            id year\n#> 4   ansonca01 1871\n#> 44  forceda01 1871\n#> 68  mathebo01 1871\n#> 99  startjo01 1871\n#> 102 suttoez01 1871\n#> 106 whitede01 1871\n#> 113  yorkto01 1871\n#> 121 ansonca01 1872\n#> 143 burdoja01 1872\n#> 167 forceda01 1872\n\nbaseball_1 <- ddply(baseball, .(id), transform, \n  cyear = year - min(year) + 1)\n\nhead(baseball_1[c(\"id\",\"year\",\"cyear\")], n = 10)\n#>           id year cyear\n#> 1  aaronha01 1954     1\n#> 2  aaronha01 1955     2\n#> 3  aaronha01 1956     3\n#> 4  aaronha01 1957     4\n#> 5  aaronha01 1958     5\n#> 6  aaronha01 1959     6\n#> 7  aaronha01 1960     7\n#> 8  aaronha01 1961     8\n#> 9  aaronha01 1962     9\n#> 10 aaronha01 1963    10\n\ntail(baseball_1[c(\"id\",\"year\",\"cyear\")], n = 10)\n#>              id year cyear\n#> 21690 zimmech01 1895    12\n#> 21691 zimmech01 1896    13\n#> 21692 zimmech01 1897    14\n#> 21693 zimmech01 1898    15\n#> 21694 zimmech01 1899    16\n#> 21695 zimmech01 1899    16\n#> 21696 zimmech01 1900    17\n#> 21697 zimmech01 1901    18\n#> 21698 zimmech01 1902    19\n#> 21699 zimmech01 1903    20"
  },
  {
    "objectID": "blog-2023/Blog-4-submissions/loganjohnson0/index.html#remade-with-dplyr-package",
    "href": "blog-2023/Blog-4-submissions/loganjohnson0/index.html#remade-with-dplyr-package",
    "title": "‘plyr’ to d’plyr’",
    "section": "Remade with dplyr package",
    "text": "Remade with dplyr package\n\nlibrary(dplyr)\n#> \n#> Attaching package: 'dplyr'\n#> The following objects are masked from 'package:plyr':\n#> \n#>     arrange, count, desc, failwith, id, mutate, rename, summarise,\n#>     summarize\n#> The following objects are masked from 'package:stats':\n#> \n#>     filter, lag\n#> The following objects are masked from 'package:base':\n#> \n#>     intersect, setdiff, setequal, union\n\nbaseball <- baseball\n\nhead(baseball[c(\"id\",\"year\")], n = 10)\n#>            id year\n#> 4   ansonca01 1871\n#> 44  forceda01 1871\n#> 68  mathebo01 1871\n#> 99  startjo01 1871\n#> 102 suttoez01 1871\n#> 106 whitede01 1871\n#> 113  yorkto01 1871\n#> 121 ansonca01 1872\n#> 143 burdoja01 1872\n#> 167 forceda01 1872\n\nbaseball_2 <- baseball %>% \n  arrange(id) %>% \n  group_by(id) %>% \n  mutate(cyear = year-min(year) + 1)\n\nhead(baseball_2[c(\"id\",\"year\",\"cyear\")], n = 10)\n#> # A tibble: 10 × 3\n#> # Groups:   id [1]\n#>    id         year cyear\n#>    <chr>     <int> <dbl>\n#>  1 aaronha01  1954     1\n#>  2 aaronha01  1955     2\n#>  3 aaronha01  1956     3\n#>  4 aaronha01  1957     4\n#>  5 aaronha01  1958     5\n#>  6 aaronha01  1959     6\n#>  7 aaronha01  1960     7\n#>  8 aaronha01  1961     8\n#>  9 aaronha01  1962     9\n#> 10 aaronha01  1963    10\n\ntail(baseball_2[c(\"id\",\"year\",\"cyear\")], n = 10)\n#> # A tibble: 10 × 3\n#> # Groups:   id [1]\n#>    id         year cyear\n#>    <chr>     <int> <dbl>\n#>  1 zimmech01  1895    12\n#>  2 zimmech01  1896    13\n#>  3 zimmech01  1897    14\n#>  4 zimmech01  1898    15\n#>  5 zimmech01  1899    16\n#>  6 zimmech01  1899    16\n#>  7 zimmech01  1900    17\n#>  8 zimmech01  1901    18\n#>  9 zimmech01  1902    19\n#> 10 zimmech01  1903    20\n\n\nWhich (base R) functions do you know that support the split-apply-combine strategy? In your opinion, are these sufficient? State why or why not?\n\n\nI’m not super familiar with base R functions in the split-apply-combine area. I know of apply and lapply, and I have heard of some of the other functions. I honestly have not used them before. I do feel like they take more work to achieve the similar function of dplyr. The coding and naming of the base R functions is confusing to me. I do think that there are probably use cases for these functions compared with the dplyr package. Overall, I do not think that the base R functions for the split-apply-combine strategy are sufficient because they are not as user accessible for normal people. It would take more time and understanding of R to be able to achieve a similar output in base R compared to dplyr.\n\n\nThe ChatGPT response to the prompt “Describe the split-apply-combine paradigm” is given below. Generally, the chatbot’s answers are decent. ChatGPT does have problems getting details right. Which details would you change in the response?\n\n\nThe “split-apply-combine” paradigm is a data analysis strategy used in statistics and data science to analyze grouped data. It consists of three steps:\nSplit: The data is first split into groups based on one or more variables of interest.\nApply: A specific operation or function is applied to each group of data, usually for the purpose of aggregating, summarizing, or transforming the data within each group.\nCombine: The results of the operation applied to each group are then combined and returned as a single output.\nThe split-apply-combine paradigm is particularly useful in cases where the data cannot be analyzed as a whole and instead must be analyzed in smaller, more manageable chunks. This allows for more efficient data processing and improved scalability. The paradigm is commonly implemented using tools such as the “groupby” function in the R and Python programming languages, and the “dplyr” library in R.\n\n\nI think I would change the last part of the response. I don’t think that the data is necessarily split into chunks but rather managed in a more efficient manner that allows for a function or modification to be applied throughout the desired parts of the data.\n\nYou can write your answers directly the README.Rmd file. Make sure that the file knits (you will need to activate any packages your use in your code chunks with a call to library(xxx), where xxx is the name of the package, such as plyr ). Commit your changes and push to your repo; add any files in the README_files directory to your repository."
  },
  {
    "objectID": "blog-2023/Blog-4-submissions/Atefeha1995/AnisiAtefeh.html",
    "href": "blog-2023/Blog-4-submissions/Atefeha1995/AnisiAtefeh.html",
    "title": "Working with ‘Plyr’ package",
    "section": "",
    "text": "The plyr package has by now been replaced by other, even faster packages, but the idea of Split, apply, combine is as relevant as ever.\nRead the paper The Split-Apply-Combine Strategy for Data Analysis by Hadley Wickham.\nWrite a blog post addressing the following questions:\n\nThe R code for the split-apply-combine paper is posted with the paper. Pick one of the examples demonstrating plyr functionality (such as dlply or ddply, …) and rewrite the example using functionality from the package dplyr. Make sure that your example works and the results are identical.\n\nFirst, we need to call libraries.\n\nlibrary(ggplot2)\nlibrary(plyr)\nlibrary(dplyr)\n#> \n#> Attaching package: 'dplyr'\n#> The following objects are masked from 'package:plyr':\n#> \n#>     arrange, count, desc, failwith, id, mutate, rename, summarise,\n#>     summarize\n#> The following objects are masked from 'package:stats':\n#> \n#>     filter, lag\n#> The following objects are masked from 'package:base':\n#> \n#>     intersect, setdiff, setequal, union"
  },
  {
    "objectID": "blog-2023/Blog-4-submissions/anphan0828/PhanAn.html",
    "href": "blog-2023/Blog-4-submissions/anphan0828/PhanAn.html",
    "title": "Split-apply-combine",
    "section": "",
    "text": "The plyr package has by now been replaced by other, even faster packages, but the idea of Split, apply, combine is as relevant as ever. Read the paper The Split-Apply-Combine Strategy for Data Analysis by Hadley Wickham. Write a blog post addressing the following questions:\n\nThe R code for the split-apply-combine paper is posted with the paper. Pick one of the examples demonstrating plyr functionality (such as dlply or ddply, …) and rewrite the example using functionality from the package dplyr. Make sure that your example works and the results are identical.\n\nI chose the 1st example on baseball dataframe where the author:\n\nSplit the dataframe based on id\nApply this calculation: year - min(year) and store in a new variable cyear. This step is done on each id group, which means the function min(year) applies to the years within each group only.\nCombine the calculated cyear from each observation of the dataframe to be a new corresponding column. The resulting dataframe has 21699 obs. of 23 variables.\n\n\nlibrary(plyr)\nbaseball1 <- ddply(baseball, .(id), transform, cyear = year - min(year) + 1)\nhead(baseball1)\n#>          id year stint team lg   g  ab   r   h X2b X3b hr rbi sb cs bb so ibb\n#> 1 aaronha01 1954     1  ML1 NL 122 468  58 131  27   6 13  69  2  2 28 39  NA\n#> 2 aaronha01 1955     1  ML1 NL 153 602 105 189  37   9 27 106  3  1 49 61   5\n#> 3 aaronha01 1956     1  ML1 NL 153 609 106 200  34  14 26  92  2  4 37 54   6\n#> 4 aaronha01 1957     1  ML1 NL 151 615 118 198  27   6 44 132  1  1 57 58  15\n#> 5 aaronha01 1958     1  ML1 NL 153 601 109 196  34   4 30  95  4  1 59 49  16\n#> 6 aaronha01 1959     1  ML1 NL 154 629 116 223  46   7 39 123  8  0 51 54  17\n#>   hbp sh sf gidp cyear\n#> 1   3  6  4   13     1\n#> 2   3  7  4   20     2\n#> 3   2  5  7   21     3\n#> 4   0  0  3   13     4\n#> 5   1  0  3   21     5\n#> 6   4  0  9   19     6\n\nUsing dplyr, I re-wrote the code as followed:\n\nlibrary(dplyr)\n#> \n#> Attaching package: 'dplyr'\n#> The following objects are masked from 'package:plyr':\n#> \n#>     arrange, count, desc, failwith, id, mutate, rename, summarise,\n#>     summarize\n#> The following objects are masked from 'package:stats':\n#> \n#>     filter, lag\n#> The following objects are masked from 'package:base':\n#> \n#>     intersect, setdiff, setequal, union\nbaseball2 <- baseball%>%\n  group_by(id)%>%\n  mutate(cyear = year - min(year)+1)%>%\n  arrange(id)\nbaseball2 <- as.data.frame(baseball2)\nhead(baseball2)\n#>          id year stint team lg   g  ab   r   h X2b X3b hr rbi sb cs bb so ibb\n#> 1 aaronha01 1954     1  ML1 NL 122 468  58 131  27   6 13  69  2  2 28 39  NA\n#> 2 aaronha01 1955     1  ML1 NL 153 602 105 189  37   9 27 106  3  1 49 61   5\n#> 3 aaronha01 1956     1  ML1 NL 153 609 106 200  34  14 26  92  2  4 37 54   6\n#> 4 aaronha01 1957     1  ML1 NL 151 615 118 198  27   6 44 132  1  1 57 58  15\n#> 5 aaronha01 1958     1  ML1 NL 153 601 109 196  34   4 30  95  4  1 59 49  16\n#> 6 aaronha01 1959     1  ML1 NL 154 629 116 223  46   7 39 123  8  0 51 54  17\n#>   hbp sh sf gidp cyear\n#> 1   3  6  4   13     1\n#> 2   3  7  4   20     2\n#> 3   2  5  7   21     3\n#> 4   0  0  3   13     4\n#> 5   1  0  3   21     5\n#> 6   4  0  9   19     6\n\nHere, split is done with group_by, then apply the same procedure with mutate to create a new variable, and combine is automatically followed. The resulting tibble baseball2 is the same, but I sorted the id alphabetically and converted it to dataframe to match baseball1. One difference is the use of pipe %>% operator instead of having all arguments inside the round brackets.\nPersonally, I prefer dplyr maybe because I have been using it more, but also I find it hard to include all steps at once. The pipe operator really helps to clarify things.\n\nWhich (base R) functions do you know that support the split-apply-combine strategy? In your opinion, are these sufficient? State why or why not?\n\nThe family of apply functions also perform the split-apply-combine strategy, but they have limitations (e.g., splitting based on MARGIN (column/row) or INDEX (factor to split)). Similarly to plyr, these apply variants also require users to pack all arguments inside the brackets, making the code cluttered.\nFor the example above, I do not think that any form of apply could split the dataframe based on id conveniently the way we wanted. One inefficient approach is to get the splitting factor (split), find the min(year) based on this split (apply), then create a new variable as a new column to the dataframe (combine).\n\n# Sort the ids to get splitting factor\nbaseball3 = baseball[order(baseball$id),]\nall_id = table(baseball3$id)\nsid = rep(1:length(all_id),times=all_id)\n# tapply to find min(year) for each group\nmin_year <- tapply(baseball3$year, INDEX=sid, FUN=function(x) min(x))\n# mapply to add new variable\nbaseball3$cyear<-mapply(function(x,y) x-y+1, baseball3$year, rep(min_year,times=all_id))\nhead(baseball3)\n#>              id year stint team lg   g  ab   r   h X2b X3b hr rbi sb cs bb so\n#> 37157 aaronha01 1954     1  ML1 NL 122 468  58 131  27   6 13  69  2  2 28 39\n#> 37795 aaronha01 1955     1  ML1 NL 153 602 105 189  37   9 27 106  3  1 49 61\n#> 38408 aaronha01 1956     1  ML1 NL 153 609 106 200  34  14 26  92  2  4 37 54\n#> 39023 aaronha01 1957     1  ML1 NL 151 615 118 198  27   6 44 132  1  1 57 58\n#> 39645 aaronha01 1958     1  ML1 NL 153 601 109 196  34   4 30  95  4  1 59 49\n#> 40291 aaronha01 1959     1  ML1 NL 154 629 116 223  46   7 39 123  8  0 51 54\n#>       ibb hbp sh sf gidp cyear\n#> 37157  NA   3  6  4   13     1\n#> 37795   5   3  7  4   20     2\n#> 38408   6   2  5  7   21     3\n#> 39023  15   0  0  3   13     4\n#> 39645  16   1  0  3   21     5\n#> 40291  17   4  0  9   19     6\n\nI believe this code using apply could be shortened, but it still has certain limitations on splitting only by MARGIN/INDEX. So, dplyr is obviously more efficient and convenient.\n\nThe ChatGPT response to the prompt “Describe the split-apply-combine paradigm” is given below. Generally, the chatbot’s answers are decent. ChatGPT does have problems getting details right. Which details would you change in the response?\n\n\nThe “split-apply-combine” paradigm is a data analysis strategy used in statistics and data science to analyze grouped data. It consists of three steps:\nSplit: The data is first split into groups based on one or more variables of interest.\nApply: A specific operation or function is applied to each group of data, usually for the purpose of aggregating, summarizing, or transforming the data within each group.\nCombine: The results of the operation applied to each group are then combined and returned as a single output.\nThe split-apply-combine paradigm is particularly useful in cases where the data cannot be analyzed as a whole and instead must be analyzed in smaller, more manageable chunks. This allows for more efficient data processing and improved scalability. The paradigm is commonly implemented using tools such as the “groupby” function in the R and Python programming languages, and the “dplyr” library in R.\n\nI would correct some details as followed:\n\nApply: A specific operation or function is applied to each group of data, or applied to each element within a group (e.g.,one row in a dataframe, one element in a list).\nCombine: The results of the operation applied to each group are either combined to a simplified output or returned/appended at the corresponding element in a group usually for the purpose of aggregating, summarizing, or transforming the data within each group. For example, the cyear returned in Question 1 is not combined to a single output, but added as a new variable to each observation in the dataframe.\nThe paradigm is commonly implemented using tools such as the “groupby” and “apply” function in the R and Python programming languages, and the “dplyr” library in R."
  },
  {
    "objectID": "blog-2023/Blog-4-submissions/hardtme/index.html",
    "href": "blog-2023/Blog-4-submissions/hardtme/index.html",
    "title": "Split-Apply-Combine",
    "section": "",
    "text": "The plyr package has by now been replaced by other, even faster packages, but the idea of Split, apply, combine is as relevant as ever.\nRead the paper The Split-Apply-Combine Strategy for Data Analysis by Hadley Wickham.\nWrite a blog post addressing the following questions:\n\nThe R code for the split-apply-combine paper is posted with the paper. Pick one of the examples demonstrating plyr functionality (such as dlply or ddply, …) and rewrite the example using functionality from the package dplyr. Make sure that your example works and the results are identical.\n\nI revisited one of the baseball case study examples from section 5.1 of the paper. The code for the original example is given below (with a modification to save the new dataset as plyr_baseball instead of baseball as in the paper):\n\nlibrary(plyr)\nbaseball_plyr <- ddply(baseball, .(id), transform, \n  cyear = year - min(year) + 1)\n\nWe’ll now look at the first fifteen rows and last fifteen rows of the new baseball_plyr dataset.\n\nhead(baseball_plyr, 15)\n#>           id year stint team lg   g  ab   r   h X2b X3b hr rbi sb cs bb so ibb\n#> 1  aaronha01 1954     1  ML1 NL 122 468  58 131  27   6 13  69  2  2 28 39  NA\n#> 2  aaronha01 1955     1  ML1 NL 153 602 105 189  37   9 27 106  3  1 49 61   5\n#> 3  aaronha01 1956     1  ML1 NL 153 609 106 200  34  14 26  92  2  4 37 54   6\n#> 4  aaronha01 1957     1  ML1 NL 151 615 118 198  27   6 44 132  1  1 57 58  15\n#> 5  aaronha01 1958     1  ML1 NL 153 601 109 196  34   4 30  95  4  1 59 49  16\n#> 6  aaronha01 1959     1  ML1 NL 154 629 116 223  46   7 39 123  8  0 51 54  17\n#> 7  aaronha01 1960     1  ML1 NL 153 590 102 172  20  11 40 126 16  7 60 63  13\n#> 8  aaronha01 1961     1  ML1 NL 155 603 115 197  39  10 34 120 21  9 56 64  20\n#> 9  aaronha01 1962     1  ML1 NL 156 592 127 191  28   6 45 128 15  7 66 73  14\n#> 10 aaronha01 1963     1  ML1 NL 161 631 121 201  29   4 44 130 31  5 78 94  18\n#> 11 aaronha01 1964     1  ML1 NL 145 570 103 187  30   2 24  95 22  4 62 46   9\n#> 12 aaronha01 1965     1  ML1 NL 150 570 109 181  40   1 32  89 24  4 60 81  10\n#> 13 aaronha01 1966     1  ATL NL 158 603 117 168  23   1 44 127 21  3 76 96  15\n#> 14 aaronha01 1967     1  ATL NL 155 600 113 184  37   3 39 109 17  6 63 97  19\n#> 15 aaronha01 1968     1  ATL NL 160 606  84 174  33   4 29  86 28  5 64 62  23\n#>    hbp sh sf gidp cyear\n#> 1    3  6  4   13     1\n#> 2    3  7  4   20     2\n#> 3    2  5  7   21     3\n#> 4    0  0  3   13     4\n#> 5    1  0  3   21     5\n#> 6    4  0  9   19     6\n#> 7    2  0 12    8     7\n#> 8    2  1  9   16     8\n#> 9    3  0  6   14     9\n#> 10   0  0  5   11    10\n#> 11   0  0  2   22    11\n#> 12   1  0  8   15    12\n#> 13   1  0  8   14    13\n#> 14   0  0  6   11    14\n#> 15   1  0  5   21    15\ntail(baseball_plyr, 15)\n#>              id year stint team lg   g  ab  r   h X2b X3b hr rbi sb cs bb so\n#> 21685 zimmech01 1890     1  CL4 NL 125 444 54  95  16   6  2  57 15 NA 46 54\n#> 21686 zimmech01 1891     1  CL4 NL 116 440 55 112  21   4  3  69 15 NA 33 49\n#> 21687 zimmech01 1892     1  CL4 NL 111 413 63 108  29  13  1  64 18 NA 32 47\n#> 21688 zimmech01 1893     1  CL4 NL  57 227 27  70  13   7  2  41  4 NA 16 15\n#> 21689 zimmech01 1894     1  CL4 NL  90 341 55  97  20   5  4  65 14 NA 17 31\n#> 21690 zimmech01 1895     1  CL4 NL  88 315 60 107  21   2  5  56 14 NA 33 30\n#> 21691 zimmech01 1896     1  CL4 NL  91 336 46  93  18   3  3  46  4 NA 31 48\n#> 21692 zimmech01 1897     1  CL4 NL  80 294 50  93  22   3  0  40  8 NA 25 NA\n#> 21693 zimmech01 1898     1  CL4 NL  20  63  5  15   2   0  0   4  2 NA  5 NA\n#> 21694 zimmech01 1899     1  CL4 NL  20  73  9  25   2   1  2  14  1 NA  5 NA\n#> 21695 zimmech01 1899     2  LS3 NL  75 262 43  78  11   3  2  29  9 NA 22 NA\n#> 21696 zimmech01 1900     1  PIT NL  82 271 27  80   7  10  0  35  4 NA 17 NA\n#> 21697 zimmech01 1901     1  PIT NL  69 236 17  52   7   3  0  21  6 NA 20 NA\n#> 21698 zimmech01 1902     1  PIT NL  42 142 13  38   4   2  0  17  4 NA 11 NA\n#> 21699 zimmech01 1903     1  PHI NL  37 118  9  26   3   1  1  19  3 NA  9 NA\n#>       ibb hbp sh sf gidp cyear\n#> 21685  NA  11 NA NA   NA     7\n#> 21686  NA   4 NA NA   NA     8\n#> 21687  NA   7 NA NA   NA     9\n#> 21688  NA   1 NA NA   NA    10\n#> 21689  NA   5 NA NA   NA    11\n#> 21690  NA   9  0 NA   NA    12\n#> 21691  NA   9  5 NA   NA    13\n#> 21692  NA   4  5 NA   NA    14\n#> 21693  NA   1  4 NA   NA    15\n#> 21694  NA   3  0 NA   NA    16\n#> 21695  NA   8 10 NA   NA    16\n#> 21696  NA  11  9 NA   NA    17\n#> 21697  NA   4  7 NA   NA    18\n#> 21698  NA   4  6 NA   NA    19\n#> 21699  NA   3  3 NA   NA    20\n\nNext, I’ll rewrite the example using functions from the dply package.\n\nlibrary(dplyr)\n#> \n#> Attaching package: 'dplyr'\n#> The following objects are masked from 'package:plyr':\n#> \n#>     arrange, count, desc, failwith, id, mutate, rename, summarise,\n#>     summarize\n#> The following objects are masked from 'package:stats':\n#> \n#>     filter, lag\n#> The following objects are masked from 'package:base':\n#> \n#>     intersect, setdiff, setequal, union\nlibrary(magrittr) # For pipe %>% \n\nbaseball_dplyr <- baseball %>% \n                    dplyr::group_by(id) %>%\n                    dplyr::mutate(cyear = year - min(year) + 1) %>% \n                    dplyr::arrange(id) # Arrange data as in baseball_plyr\n\nWe’ll now look at the first fifteen rows and last fifteen rows of the new baseball_dplyr dataset after converting it from a tibble to a dataframe to better match baseball_plyr.\n\nbaseball_dplyr <- as.data.frame(baseball_dplyr)\nhead(baseball_dplyr, 15)\n#>           id year stint team lg   g  ab   r   h X2b X3b hr rbi sb cs bb so ibb\n#> 1  aaronha01 1954     1  ML1 NL 122 468  58 131  27   6 13  69  2  2 28 39  NA\n#> 2  aaronha01 1955     1  ML1 NL 153 602 105 189  37   9 27 106  3  1 49 61   5\n#> 3  aaronha01 1956     1  ML1 NL 153 609 106 200  34  14 26  92  2  4 37 54   6\n#> 4  aaronha01 1957     1  ML1 NL 151 615 118 198  27   6 44 132  1  1 57 58  15\n#> 5  aaronha01 1958     1  ML1 NL 153 601 109 196  34   4 30  95  4  1 59 49  16\n#> 6  aaronha01 1959     1  ML1 NL 154 629 116 223  46   7 39 123  8  0 51 54  17\n#> 7  aaronha01 1960     1  ML1 NL 153 590 102 172  20  11 40 126 16  7 60 63  13\n#> 8  aaronha01 1961     1  ML1 NL 155 603 115 197  39  10 34 120 21  9 56 64  20\n#> 9  aaronha01 1962     1  ML1 NL 156 592 127 191  28   6 45 128 15  7 66 73  14\n#> 10 aaronha01 1963     1  ML1 NL 161 631 121 201  29   4 44 130 31  5 78 94  18\n#> 11 aaronha01 1964     1  ML1 NL 145 570 103 187  30   2 24  95 22  4 62 46   9\n#> 12 aaronha01 1965     1  ML1 NL 150 570 109 181  40   1 32  89 24  4 60 81  10\n#> 13 aaronha01 1966     1  ATL NL 158 603 117 168  23   1 44 127 21  3 76 96  15\n#> 14 aaronha01 1967     1  ATL NL 155 600 113 184  37   3 39 109 17  6 63 97  19\n#> 15 aaronha01 1968     1  ATL NL 160 606  84 174  33   4 29  86 28  5 64 62  23\n#>    hbp sh sf gidp cyear\n#> 1    3  6  4   13     1\n#> 2    3  7  4   20     2\n#> 3    2  5  7   21     3\n#> 4    0  0  3   13     4\n#> 5    1  0  3   21     5\n#> 6    4  0  9   19     6\n#> 7    2  0 12    8     7\n#> 8    2  1  9   16     8\n#> 9    3  0  6   14     9\n#> 10   0  0  5   11    10\n#> 11   0  0  2   22    11\n#> 12   1  0  8   15    12\n#> 13   1  0  8   14    13\n#> 14   0  0  6   11    14\n#> 15   1  0  5   21    15\ntail(baseball_dplyr, 15)\n#>              id year stint team lg   g  ab  r   h X2b X3b hr rbi sb cs bb so\n#> 21685 zimmech01 1890     1  CL4 NL 125 444 54  95  16   6  2  57 15 NA 46 54\n#> 21686 zimmech01 1891     1  CL4 NL 116 440 55 112  21   4  3  69 15 NA 33 49\n#> 21687 zimmech01 1892     1  CL4 NL 111 413 63 108  29  13  1  64 18 NA 32 47\n#> 21688 zimmech01 1893     1  CL4 NL  57 227 27  70  13   7  2  41  4 NA 16 15\n#> 21689 zimmech01 1894     1  CL4 NL  90 341 55  97  20   5  4  65 14 NA 17 31\n#> 21690 zimmech01 1895     1  CL4 NL  88 315 60 107  21   2  5  56 14 NA 33 30\n#> 21691 zimmech01 1896     1  CL4 NL  91 336 46  93  18   3  3  46  4 NA 31 48\n#> 21692 zimmech01 1897     1  CL4 NL  80 294 50  93  22   3  0  40  8 NA 25 NA\n#> 21693 zimmech01 1898     1  CL4 NL  20  63  5  15   2   0  0   4  2 NA  5 NA\n#> 21694 zimmech01 1899     1  CL4 NL  20  73  9  25   2   1  2  14  1 NA  5 NA\n#> 21695 zimmech01 1899     2  LS3 NL  75 262 43  78  11   3  2  29  9 NA 22 NA\n#> 21696 zimmech01 1900     1  PIT NL  82 271 27  80   7  10  0  35  4 NA 17 NA\n#> 21697 zimmech01 1901     1  PIT NL  69 236 17  52   7   3  0  21  6 NA 20 NA\n#> 21698 zimmech01 1902     1  PIT NL  42 142 13  38   4   2  0  17  4 NA 11 NA\n#> 21699 zimmech01 1903     1  PHI NL  37 118  9  26   3   1  1  19  3 NA  9 NA\n#>       ibb hbp sh sf gidp cyear\n#> 21685  NA  11 NA NA   NA     7\n#> 21686  NA   4 NA NA   NA     8\n#> 21687  NA   7 NA NA   NA     9\n#> 21688  NA   1 NA NA   NA    10\n#> 21689  NA   5 NA NA   NA    11\n#> 21690  NA   9  0 NA   NA    12\n#> 21691  NA   9  5 NA   NA    13\n#> 21692  NA   4  5 NA   NA    14\n#> 21693  NA   1  4 NA   NA    15\n#> 21694  NA   3  0 NA   NA    16\n#> 21695  NA   8 10 NA   NA    16\n#> 21696  NA  11  9 NA   NA    17\n#> 21697  NA   4  7 NA   NA    18\n#> 21698  NA   4  6 NA   NA    19\n#> 21699  NA   3  3 NA   NA    20\n\nThe two datasets appear to be identical. We can also compare them with all.equal:\n\nall.equal(baseball_plyr, baseball_dplyr)\n#> [1] TRUE\n\nAs we expected, baseball_plyr and baseball_dplyr are identical. This means I successfully recreated the plyr example from the paper using functions from the dplyr package.\n\nWhich (base R) functions do you know that support the split-apply-combine strategy? In your opinion, are these sufficient? State why or why not?\nIn the paper, Hadley Wickham mentioned several base R functions and how they compare to functions in the plyr package. These base R functions that support the split-apply-combine paradigm include aggregate, apply,by,lapply,mapply,replicate, and sapply.\n\nI think these base R functions are sufficient to allow people to implement the split-apply-combine paradigm in R. However, these functions may not be the most efficient and user-friendly way to implement the split-apply-combine paradigm in R.\nConsider the following analogy: you have to take a long car trip in the United States and you don’t especially care about the scenery or places you visit along the way. Since you just want to get from point A to point B in the most efficient way possible, the best route would be for you to take interstate highways and major US highways. While you could still get from point A to point B by driving along smaller roads like state highways and county roads, your journey will likely take longer and won’t be the most direct route. You also have a higher chance of getting lost along the way.\nIn the analogy above, packages like plyr and dplyr are the equivalent of driving on interstate highways and major US highways during your long car trip. The functions in these packages allow you to efficiently bring your data into the necessary form for the analyses you’d like to run. The plyr and dplyr functions are written to follow similar syntax within each package, so it’s easy to know what code you have to write. Base R functions like aggregate and apply are like driving on state highways and county roads during your road trip. While these routes can get you to your destination, they are not always straightforward and you’ll likely run into mishaps along the way.\n\nThe ChatGPT response to the prompt “Describe the split-apply-combine paradigm” is given below. Generally, the chatbot’s answers are decent. ChatGPT does have problems getting details right. Which details would you change in the response?\n\n\nThe “split-apply-combine” paradigm is a data analysis strategy used in statistics and data science to analyze grouped data. It consists of three steps:\nSplit: The data is first split into groups based on one or more variables of interest.\nApply: A specific operation or function is applied to each group of data, usually for the purpose of aggregating, summarizing, or transforming the data within each group.\nCombine: The results of the operation applied to each group are then combined and returned as a single output.\nThe split-apply-combine paradigm is particularly useful in cases where the data cannot be analyzed as a whole and instead must be analyzed in smaller, more manageable chunks. This allows for more efficient data processing and improved scalability. The paradigm is commonly implemented using tools such as the “groupby” function in the R and Python programming languages, and the “dplyr” library in R.\n\nI think that ChatGPT’s explanation that in the “apply” step, “[a] specific [emphasis added] operation or function is applied to each group of data…” almost makes it sound like each data group could have a different function applied to it. It’s my understanding that under the split-apply-combine paradigm, we do the same thing to all of the groups. Here’s how I’d rewrite this portion:\n\nApply: The same function is applied to each group in the data, usually to aggregate, summarize, or transform the data within each group.\n\nAs noted in class on February 14, 2023, ChatGPT made a mistake with the “groupby” function in the last paragraph. While the appropriate function is indeed called groupby in the pandas library for Python, the function name in the R package dplyr is group_by."
  },
  {
    "objectID": "blog-2023/Blog-4-submissions/santos-cl/index.html",
    "href": "blog-2023/Blog-4-submissions/santos-cl/index.html",
    "title": "plyr-dplyr-baseR",
    "section": "",
    "text": "The plyr package has by now been replaced by other, even faster packages, but the idea of Split, apply, combine is as relevant as ever.\nRead the paper The Split-Apply-Combine Strategy for Data Analysis by Hadley Wickham.\nWrite a blog post addressing the following questions:\n\nThe R code for the split-apply-combine paper is posted with the paper. Pick one of the examples demonstrating plyr functionality (such as dlply or ddply, …) and rewrite the example using functionality from the package dplyr. Make sure that your example works and the results are identical.\nWhich (base R) functions do you know that support the split-apply-combine strategy? In your opinion, are these sufficient? State why or why not?\nThe ChatGPT response to the prompt “Describe the split-apply-combine paradigm” is given below. Generally, the chatbot’s answers are decent. ChatGPT does have problems getting details right. Which details would you change in the response?\n\n\nThe “split-apply-combine” paradigm is a data analysis strategy used in statistics and data science to analyze grouped data. It consists of three steps:\nSplit: The data is first split into groups based on one or more variables of interest.\nApply: A specific operation or function is applied to each group of data, usually for the purpose of aggregating, summarizing, or transforming the data within each group.\nCombine: The results of the operation applied to each group are then combined and returned as a single output.\nThe split-apply-combine paradigm is particularly useful in cases where the data cannot be analyzed as a whole and instead must be analyzed in smaller, more manageable chunks. This allows for more efficient data processing and improved scalability. The paradigm is commonly implemented using tools such as the “groupby” function in the R and Python programming languages, and the “dplyr” library in R.\n\nYou can write your answers directly the README.Rmd file. Make sure that the file knits (you will need to activate any packages your use in your code chunks with a call to library(xxx), where xxx is the name of the package, such as plyr ). Commit your changes and push to your repo; add any files in the README_files directory to your repository."
  },
  {
    "objectID": "blog-2023/Blog-4-submissions/sudi007/SudeshBhagat.html",
    "href": "blog-2023/Blog-4-submissions/sudi007/SudeshBhagat.html",
    "title": "Split-apply-combine",
    "section": "",
    "text": "library(plyr)\nlibrary(dplyr)\n#> \n#> Attaching package: 'dplyr'\n#> The following objects are masked from 'package:plyr':\n#> \n#>     arrange, count, desc, failwith, id, mutate, rename, summarise,\n#>     summarize\n#> The following objects are masked from 'package:stats':\n#> \n#>     filter, lag\n#> The following objects are masked from 'package:base':\n#> \n#>     intersect, setdiff, setequal, union"
  },
  {
    "objectID": "blog-2023/Blog-4-submissions/sudi007/SudeshBhagat.html#prompt",
    "href": "blog-2023/Blog-4-submissions/sudi007/SudeshBhagat.html#prompt",
    "title": "Split-apply-combine",
    "section": "Prompt:",
    "text": "Prompt:\nThe plyr package has by now been replaced by other, even faster packages, but the idea of Split, apply, combine is as relevant as ever.\nRead the paper The Split-Apply-Combine Strategy for Data Analysis by Hadley Wickham.\nWrite a blog post addressing the following questions:\n\nThe R code for the split-apply-combine paper is posted with the paper. Pick one of the examples demonstrating plyr functionality (such as dlply or ddply, …) and rewrite the example using functionality from the package dplyr. Make sure that your example works and the results are identical. ##Example from the paper plyr package\n\n\n# Base ball case study ============================================\nbaberuth_plyr <- subset(baseball, id == \"ruthba01\")\nbaberuth_plyr <- transform(baberuth_plyr, cyear = year - min(year) + 1)\n\n# Base ball case study ============================================\nbaseball_plyr<- ddply(baseball, .(id), transform, \n  cyear = year - min(year) + 1)\n\n##Rewrite with dplyr package\n\nbaberuth_dplyr <- baseball %>% \n  filter(id == \"ruthba01\") %>% \n  mutate(cyear = year - min(year) + 1)\n\n\n########Baseball\nbaseball_dplyr <- baseball %>%\n  group_by(id) %>%\n  mutate(cyear = year - min(year) + 1)\n \n\n\nWhich (base R) functions do you know that support the split-apply-combine strategy? In your opinion, are these sufficient? State why or why not?\n\nlapply: lapply is used to iteratively apply a function to each element in a list.\nsapply: Sapply turns around the list, vector or data frame to give an output in the form of a vector,\nmatrix, or an array, depending upon the structure of the input.\ntapply: tapply applies a measure or a function to subsets within a vector and provides output in the form of an array.\nData manipulation requires functions that are more sophisticated than the ones above, as these would require writing a complex code. These functions are also not as convenient and efficient as dplyr and plyr.\n\nThe ChatGPT response to the prompt “Describe the split-apply-combine paradigm” is given below. Generally, the chatbot’s answers are decent. ChatGPT does have problems getting details right. Which details would you change in the response?\n\n\nThe “split-apply-combine” paradigm is a data analysis strategy used in statistics and data science to analyze grouped data. It consists of three steps:\nSplit: The data is first split into groups based on one or more variables of interest.\nApply: A specific operation or function is applied to each group of data, usually for the purpose of aggregating, summarizing, or transforming the data within each group.\nCombine: The results of the operation applied to each group are then combined and returned as a single output.\nThe split-apply-combine paradigm is particularly useful in cases where the data cannot be analyzed as a whole and instead must be analyzed in smaller, more manageable chunks. This allows for more efficient data processing and improved scalability. The paradigm is commonly implemented using tools such as the “groupby” function in the R and Python programming languages, and the “dplyr” library in R.\n\nChange : The aggregation, completion and modelling of data is carried out using the split-apply-combine strategy. It provides a clear, flexible and efficient way to perform complex data analysis. The split-apply-combine strategy is implemented in R packages such as plyr, dplyr, and data.table.\nYou can write your answers directly the README.Rmd file. Make sure that the file knits (you will need to activate any packages your use in your code chunks with a call to library(xxx), where xxx is the name of the package, such as plyr ). Commit your changes and push to your repo; add any files in the README_files directory to your repository."
  },
  {
    "objectID": "blog-2023/Blog-4-submissions/maxwellskinner2002/index.html",
    "href": "blog-2023/Blog-4-submissions/maxwellskinner2002/index.html",
    "title": "Title of your post",
    "section": "",
    "text": "The plyr package has by now been replaced by other, even faster packages, but the idea of Split, apply, combine is as relevant as ever.\nRead the paper The Split-Apply-Combine Strategy for Data Analysis by Hadley Wickham.\nWrite a blog post addressing the following questions:\n\nThe R code for the split-apply-combine paper is posted with the paper. Pick one of the examples demonstrating plyr functionality (such as dlply or ddply, …) and rewrite the example using functionality from the package dplyr. Make sure that your example works and the results are identical.\n\n#Previous example code using \"plyr\"\nlibrary(\"plyr\")\nbaberuth <- subset(baseball, id == \"ruthba01\")\nbaberuth <- transform(baberuth, cyear = year - min(year) + 1)\n\n\nIn this example. The author used the subset and transform method to filter the baseball dataset to only include rows that have the id “ruthba01”. There was also a column created in the subset dataframe labelled cyear with counted the consecutive years that Babe Ruth played. Both of these things can be done in the “dplyr” package as well as the “plyr” package.\n\n#Example code using \"dplyr\"\nlibrary(\"dplyr\")\nbaberuth2 <- dplyr::filter(baseball, id %in% c(\"ruthba01\"))\nbaberuth2 <- baberuth2 %>% mutate(cyear = year - min(year) + 1)\n\n\nWhich (base R) functions do you know that support the split-apply-combine strategy? In your opinion, are these sufficient? State why or why not?\nAnswer:\nThe split() function in base R is used to split a dataframe into multiple dataframes. The parameters include the datframe being split, f, meaning the grouping of vectors or selecting the column according to which we split the dataframe, and drop, which deletes or skips the specified row.\nAs the name would imply this would follow the “split” part of the split-apply-combine strategy. While this function is useful and very simple to use. There are better functions inside of better packages now. The subset() function in the “dplyr” package creates a new dataframe from an original one without much hassle. The split() function from base R outputs a list of the splitted dataframe. While would be useful for a quick readthrough of a couple of rows. Using both the subset() and View() functions creates a more seamless way of looking at as well as manipulating large datasets.\nThe apply() function in base R takes a dataframe or matrix as an input and gives the output as a vector, list, or array. This is used mainly to avoid loops. The apply function would be used in the “apply” and possibly the “combine” portion of the strategy based off of what specific function was being applied to the dataframe. While apply() is useful. Packages like “dpylr” have created more robust and efficient functions like lapply() and sapply() that applys a function to all the elements in the input more effectively than just apply() does. Using these kinds of functions as well, you have more options with outputting your results. lapply() outputs as a list, sapply() outputs to a vector or matrix.\nIn general, base R functions lack what a package like dplyr would have in terms of a “%>%” forward pipe operator. This allows the chaining of multiple functions together seamlessly. In base R you would have to save multiple intermediate results into multiple different variables in order to keep track of everything. The forward pipe operator shortens what could be multiple different variables into just one simple command. Base R functions will have you covered for the most part when it comes to any large scale data analysis. But more modern packages like dplyr and tidyverse are more efficient and effective in doing a lot with a little amount of code.\nThe ChatGPT response to the prompt “Describe the split-apply-combine paradigm” is given below. Generally, the chatbot’s answers are decent. ChatGPT does have problems getting details right. Which details would you change in the response?\n\n\nThe “split-apply-combine” paradigm is a data analysis strategy used in statistics and data science to analyze grouped data. It consists of three steps:\nSplit: The data is first split into groups based on one or more variables of interest.\nApply: A specific operation or function is applied to each group of data, usually for the purpose of aggregating, summarizing, or transforming the data within each group.\nCombine: The results of the operation applied to each group are then combined and returned as a single output.\nThe split-apply-combine paradigm is particularly useful in cases where the data cannot be analyzed as a whole and instead must be analyzed in smaller, more manageable chunks. This allows for more efficient data processing and improved scalability. The paradigm is commonly implemented using tools such as the “groupby” function in the R and Python programming languages, and the “dplyr” library in R.\n\nAnswer: I think ChatGPT did a decent job of describing the paradigm. It did a general overview of what was detailed in the paper by Wickam detailed above. I would say that for split, not all data is split entirely, most of the time one would just subset a small portion of it and focus on the problem at hand versus splitting the entire dataframe into multiple groups. Like in the code example above with filtering Babe Ruth stats from a much larger dataset. But all in all, I think ChatGPT did a decent job of explaining the paradigm. Nothing was entirely inaccurate in my view.\nYou can write your answers directly the README.Rmd file. Make sure that the file knits (you will need to activate any packages your use in your code chunks with a call to library(xxx), where xxx is the name of the package, such as plyr ). Commit your changes and push to your repo; add any files in the README_files directory to your repository."
  },
  {
    "objectID": "blog-2023/Blog-4-submissions/luobo119/index.html",
    "href": "blog-2023/Blog-4-submissions/luobo119/index.html",
    "title": "Split-apply-combine",
    "section": "",
    "text": "The plyr package has by now been replaced by other, even faster packages, but the idea of Split, apply, combine is as relevant as ever.\nRead the paper The Split-Apply-Combine Strategy for Data Analysis by Hadley Wickham.\nWrite a blog post addressing the following questions:\n\nThe R code for the split-apply-combine paper is posted with the paper. Pick one of the examples demonstrating plyr functionality (such as dlply or ddply, …) and rewrite the example using functionality from the package dplyr. Make sure that your example works and the results are identical.\n\n\nlibrary(plyr)\nlibrary(dplyr)\n\n\n#plyr example\nbaseball_plyr <- ddply(baseball, .(id), transform, \n  cyear = year - min(year) + 1)\n#using dplyr \nbaseball_dplyr = baseball %>% group_by(id) %>% mutate(cyear = year - min(year) + 1) %>%\n  arrange(id) %>% as.data.frame()\n\nHead of ‘plyr’ result\n\nhead(baseball_plyr)\n#>          id year stint team lg   g  ab   r   h X2b X3b hr rbi sb cs bb so ibb\n#> 1 aaronha01 1954     1  ML1 NL 122 468  58 131  27   6 13  69  2  2 28 39  NA\n#> 2 aaronha01 1955     1  ML1 NL 153 602 105 189  37   9 27 106  3  1 49 61   5\n#> 3 aaronha01 1956     1  ML1 NL 153 609 106 200  34  14 26  92  2  4 37 54   6\n#> 4 aaronha01 1957     1  ML1 NL 151 615 118 198  27   6 44 132  1  1 57 58  15\n#> 5 aaronha01 1958     1  ML1 NL 153 601 109 196  34   4 30  95  4  1 59 49  16\n#> 6 aaronha01 1959     1  ML1 NL 154 629 116 223  46   7 39 123  8  0 51 54  17\n#>   hbp sh sf gidp cyear\n#> 1   3  6  4   13     1\n#> 2   3  7  4   20     2\n#> 3   2  5  7   21     3\n#> 4   0  0  3   13     4\n#> 5   1  0  3   21     5\n#> 6   4  0  9   19     6\n\nHead of ‘dplyr’ result\n\nhead(baseball_dplyr)\n#>          id year stint team lg   g  ab   r   h X2b X3b hr rbi sb cs bb so ibb\n#> 1 aaronha01 1954     1  ML1 NL 122 468  58 131  27   6 13  69  2  2 28 39  NA\n#> 2 aaronha01 1955     1  ML1 NL 153 602 105 189  37   9 27 106  3  1 49 61   5\n#> 3 aaronha01 1956     1  ML1 NL 153 609 106 200  34  14 26  92  2  4 37 54   6\n#> 4 aaronha01 1957     1  ML1 NL 151 615 118 198  27   6 44 132  1  1 57 58  15\n#> 5 aaronha01 1958     1  ML1 NL 153 601 109 196  34   4 30  95  4  1 59 49  16\n#> 6 aaronha01 1959     1  ML1 NL 154 629 116 223  46   7 39 123  8  0 51 54  17\n#>   hbp sh sf gidp cyear\n#> 1   3  6  4   13     1\n#> 2   3  7  4   20     2\n#> 3   2  5  7   21     3\n#> 4   0  0  3   13     4\n#> 5   1  0  3   21     5\n#> 6   4  0  9   19     6\n\nResults are identical\n\nall.equal(baseball_plyr, baseball_dplyr)\n#> [1] TRUE\n\n\nWhich (base R) functions do you know that support the split-apply-combine strategy? In your opinion, are these sufficient? State why or why not?\n\nI know the functions ‘apply’, ‘lapply’, ‘sapply’ and ‘vapply’ support the split-apply-combine strategy. But the input of ‘apply’ can only be an array, and the inputs for ‘lapply’, ‘sapply’ and ‘vapply’ are a vector. So it’s not sufficient. Packages like ‘plyr’ and ‘dplyr’ can take in more types of data and the functions are more flexible. For example, you can specify variables on which the data is split. But you can only split the data by row or by column in ‘apply’.\n\nThe ChatGPT response to the prompt “Describe the split-apply-combine paradigm” is given below. Generally, the chatbot’s answers are decent. ChatGPT does have problems getting details right. Which details would you change in the response?\n\n\nThe “split-apply-combine” paradigm is a data analysis strategy used in statistics and data science to analyze grouped data. It consists of three steps:\nSplit: The data is first split into groups based on one or more variables of interest, or split into pieces based on a given splitting scheme.\nApply: A specific operation or function is applied to each piece group of data independently, usually for the purpose of aggregating, summarizing, modeling, or transforming the data within each group.\nCombine: The results of the operation applied to each piece group are then combined and returned as a single output.\nThe split-apply-combine paradigm is particularly useful in cases where the data cannot be analyzed as a whole and instead must be analyzed in smaller, more manageable chunks, or you want to apply the same operations on each piece of data. This allows for more efficient data processing and improved scalability. The paradigm is commonly implemented using tools such as the “groupby” function in the R and Python programming languages, and the “dplyr” library in R.\n\nYou can write your answers directly the README.Rmd file. Make sure that the file knits (you will need to activate any packages your use in your code chunks with a call to library(xxx), where xxx is the name of the package, such as plyr ). Commit your changes and push to your repo; add any files in the README_files directory to your repository."
  },
  {
    "objectID": "blog-2023/Blog-4-submissions/AArabio/AlexandraArabio.html",
    "href": "blog-2023/Blog-4-submissions/AArabio/AlexandraArabio.html",
    "title": "Split, Apply, Combine - Relevancy",
    "section": "",
    "text": "Citation used for this blog:\nWickham, H. . (2011). The Split-Apply-Combine Strategy for Data Analysis. Journal of Statistical Software, 40(1), 1–29. https://doi.org/10.18637/jss.v040.i01"
  },
  {
    "objectID": "blog-2023/Blog-4-submissions/AArabio/AlexandraArabio.html#prompt",
    "href": "blog-2023/Blog-4-submissions/AArabio/AlexandraArabio.html#prompt",
    "title": "Split, Apply, Combine - Relevancy",
    "section": "Prompt:",
    "text": "Prompt:\nThe plyr package has by now been replaced by other, even faster packages, but the idea of Split, apply, combine is as relevant as ever.\nRead the paper The Split-Apply-Combine Strategy for Data Analysis by Hadley Wickham.\nWrite a blog post addressing the following questions:\n\nThe R code for the split-apply-combine paper is posted with the paper. Pick one of the examples demonstrating plyr functionality (such as dlply or ddply, …) and rewrite the example using functionality from the package dplyr. Make sure that your example works and the results are identical.\n\n\n#plyr functionality using dplyr\nlibrary(\"plyr\")\nlibrary(\"dplyr\")\n#> \n#> Attaching package: 'dplyr'\n#> The following objects are masked from 'package:plyr':\n#> \n#>     arrange, count, desc, failwith, id, mutate, rename, summarise,\n#>     summarize\n#> The following objects are masked from 'package:stats':\n#> \n#>     filter, lag\n#> The following objects are masked from 'package:base':\n#> \n#>     intersect, setdiff, setequal, union\nlibrary(\"tidyverse\")\n#> ── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2\n#> ──\n#> ✔ ggplot2 3.4.0     ✔ purrr   1.0.1\n#> ✔ tibble  3.1.8     ✔ stringr 1.5.0\n#> ✔ tidyr   1.3.0     ✔ forcats 0.5.2\n#> ✔ readr   2.1.3     \n#> ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n#> ✖ dplyr::arrange()   masks plyr::arrange()\n#> ✖ purrr::compact()   masks plyr::compact()\n#> ✖ dplyr::count()     masks plyr::count()\n#> ✖ dplyr::desc()      masks plyr::desc()\n#> ✖ dplyr::failwith()  masks plyr::failwith()\n#> ✖ dplyr::filter()    masks stats::filter()\n#> ✖ dplyr::id()        masks plyr::id()\n#> ✖ dplyr::lag()       masks stats::lag()\n#> ✖ dplyr::mutate()    masks plyr::mutate()\n#> ✖ dplyr::rename()    masks plyr::rename()\n#> ✖ dplyr::summarise() masks plyr::summarise()\n#> ✖ dplyr::summarize() masks plyr::summarize()\n# ----------------------------\n\n# Base ball case study ============================================\nbaberuth <- subset(baseball, id == \"ruthba01\")\nbaberuth <- transform(baberuth, cyear = year - min(year) + 1)\n\n\n# ----------------------------\n\nbaseball <- ddply(baseball, .(id), transform, \n  cyear = year - min(year) + 1)\n\n\n# ----------------------------\n\n##ddply splits a data frame, applies a function, and then returns results in a data frame ...\n\nbaberuth <- subset(baseball, id == \"ruthba01\")\nbaberuth <- transform(baberuth, cyear = year - min(year) + 1)\n\nbaberuth1 <- subset(baseball, id == \"ruthba01\")\nbaberuth1 <- transform(baberuth, cyear = year - min(year) + 1)\n\n# ----------------------------\n\nbaseball <- ddply(baseball, .(id), transform, \n  cyear = year - min(year) + 1)\n\n#dplyr with do()\n\nbaseball1 <- baberuth1 %>% \n  group_by(id) %>% \n  do(cyear = baberuth1$year - min(baberuth1$year) + 1)\n\n\nWhich (base R) functions do you know that support the split-apply-combine strategy? In your opinion, are these sufficient? State why or why not?\n\nThere are many different functions within base R that support the split-apply-combine strategy. Hadley touches on this discussion in the beginning parts of her paper; one of the most commonly used functions for this in base R is probably the aggregate function. This function works by combining or grouping data by common values of a factor to then generate summary statistics or apply functions for those groups.\nAs Hadley mentions through, the readability of some base R functions are much more messy as compared to ones that could be used through other packages. In a package like dplyr, we are able to utilize the group_by and summarise functions to complete the same task but produce more readable output and workflow. Whereas the aggregate functions only allows one to apply a single names function to a grouped data the summarise function allows for more functions to be used.\nBy using this step by step method through grouping and running summaries… the dplyr functions are able to be used together to accomplish more tasks.\nIn my opinion, I think that there are many different base R functions that support the split_apply-combine strategy that Hadley discusses… however, functions in the dplyr package accomplish the same types of tasks and are generally more easily understand.\n\nThe ChatGPT response to the prompt “Describe the split-apply-combine paradigm” is given below. Generally, the chatbot’s answers are decent. ChatGPT does have problems getting details right. Which details would you change in the response?\n\n\nThe “split-apply-combine” paradigm is a data analysis strategy used in statistics and data science to analyze grouped data. It consists of three steps:\nSplit: The data is first split into groups based on one or more variables of interest.\nApply: A specific operation or function is applied to each group of data, usually for the purpose of aggregating, summarizing, or transforming the data within each group.\nCombine: The results of the operation applied to each group are then combined and returned as a single output.\nThe split-apply-combine paradigm is particularly useful in cases where the data cannot be analyzed as a whole and instead must be analyzed in smaller, more manageable chunks. This allows for more efficient data processing and improved scalability. The paradigm is commonly implemented using tools such as the “groupby” function in the R and Python programming languages, and the “dplyr” library in R.\n\nI do think that the ChatGPT response to the prompt is pretty good. The split-apply-combine does allow one to break down a larger problem into more manageable parts to work with each individually before then combining the dataset together again. Working through this format limits the chance of errors, is less time consuming, and is not as tedious as other methods may be.\nYou can write your answers directly the README.Rmd file. Make sure that the file knits (you will need to activate any packages your use in your code chunks with a call to library(xxx), where xxx is the name of the package, such as plyr ). Commit your changes and push to your repo; add any files in the README_files directory to your repository."
  },
  {
    "objectID": "blog-2023/Blog-4-submissions/Starwiiin/index.html",
    "href": "blog-2023/Blog-4-submissions/Starwiiin/index.html",
    "title": "Split-apply-combine",
    "section": "",
    "text": "The plyr package has by now been replaced by other, even faster packages, but the idea of Split, apply, combine is as relevant as ever.\nRead the paper The Split-Apply-Combine Strategy for Data Analysis by Hadley Wickham.\nWrite a blog post addressing the following questions:\n\nThe R code for the split-apply-combine paper is posted with the paper. Pick one of the examples demonstrating plyr functionality (such as dlply or ddply, …) and rewrite the example using functionality from the package dplyr. Make sure that your example works and the results are identical."
  },
  {
    "objectID": "blog-2023/Blog-7-submissions/xyzyc/index.html#prompt",
    "href": "blog-2023/Blog-7-submissions/xyzyc/index.html#prompt",
    "title": "License",
    "section": "Prompt:",
    "text": "Prompt:\nThe DESCRIPTION file of a package contains the package’s meta information. Most of the fields in this file are quite straight forward: author, version number, and a short package description. When you call library(help=\"<package name>\") for package <package name> you can see the contents of the DESCRIPTION file for that package (and some parts of the NAMESPACE file).\nRead through Colin Fay’s (short) book on Licensing R\nWrite a blog post addressing the following questions:\n\nUnder what license does R operate? What is the license for ggplot2?\n\nLicenses for R include GPL-2, GPL-3, LGPL-2.1 and LGPL-3.\nFrom library(help = \"ggplot2\"), we can find the license for ggplot2 is MIT + file LICENSE.\n\n\n\nWhat are the dependencies of the package you made?\nRead through chapter 5.2 of Licensing R. Combine and adjust the code pieces to create the dependencies for a package that is on github rather than CRAN. (Don’t forget about the package desc.) What dependencies does the package have that you created for Lab-3? Which licenses are involved? Are all of these dependencies required? Elaborate.\n\nI check the dependencies for package litr on github, there are 90 dependencies:\n\nR6, askpass, base64enc, bookdown, brew, brio, bslib, cachem, callr, cli, clipr, commonmark, crayon, credentials, curl, desc, devtools, diffobj, digest, downlit, ellipsis, evaluate, fansi, fastmap, fs, gert, gh, gitcreds, glue, grDevices, graphics, highr, htmltools, httr, ini, jquerylib, jsonlite, knitr, lifecycle, litr, magrittr, memoise, methods, mime, openssl, pillar, pkgbuild, pkgconfig, pkgdown, pkgload, praise, prettyunits, processx, ps, purrr, ragg, rappdirs, rcmdcheck, rematch2, remotes, rlang, rmarkdown, roxygen2, rprojroot, rstudioapi, rversions, sass, sessioninfo, stats, stringi, stringr, sys, systemfonts, testthat, textshaping, tibble, tinytex, tools, usethis, utf8, utils, vctrs, waldo, whisker, withr, xfun, xml2, xopen, yaml, zip.\nNot everything in litr_dep is found in cran database. Packages grDevice, graphics, methods, stats, tools and utils are now base packages so not listed in cran. I’m not sure why litr has itself as dependency.\n\nThe dependencies for Lab 3, there are 111:\n\nDBI, MASS, Matrix, PressLogTeamUNL, R6, RColorBrewer, Rcpp, askpass, assertthat, backports, base64enc, bit, bit64, blob, broom, bslib, callr, cellranger, cli, clipr, colorspace, crayon, curl, data.table, dbplyr, digest, dplyr, dtplyr, ellipsis, evaluate, fansi, farver, fastmap, forcats, fs, gargle, generics, ggplot2, glue, googledrive, googlesheets4, grDevices, graphics, grid, gtable, haven, highr, hms, htmltools, httr, ids, isoband, jquerylib, jsonlite, knitr, labeling, lattice, lifecycle, lubridate, magrittr, methods, mgcv, mime, modelr, munsell, nlme, openssl, pillar, pkgconfig, png, processx, ps, purrr, rJava, rappdirs, readr, readxl, rematch, rematch2, reprex, rlang, rmarkdown, rstudioapi, rvest, sass, scales, selectr, splines, stats, stringi, stringr, sys, tabulizer, tabulizerjars, tibble, tidyr, tidyselect, tidyverse, tinytex, tools, tzdb, utf8, utils, uuid, vctrs, viridisLite, vroom, withr, xfun, xml2, yaml.\nNot all the dependencies are needed. I think part of them are listed because we listed tidyverse as a dependency, which can be replaced by dplyr.\nLicense involved: MIT + file LICENSE, GPL-3, GPL-2 | GPL-3, BSD_3_clause + file LICENSE, MPL-2.0 | file LICENSE, LGPL (>= 2.1), GPL (>= 2), GPL, MIT + file LICENSE | Unlimited, GPL (>= 2) | file LICENCE, Apache License 2.0, LGPL-2.1, BSD_3_clause + file LICENCE, file LICENSE, Apache License (== 2.0) | file LICENSE.\nUnder which license should this blog post be published? Make sure that you are using an appropriate license. (You can change the current licenses with the help of commands from the use_license_XXX family in the usethis package)\n\nThis blog post is under CC0 1.0 Universal license, which will dedicate this blog to public domain.\n\n\n\nCan I publish an R package on CRAN under an MIT license when I have a dependency on a package that is licensed under GPL-3?\n\nNo as GPL-3 license is more restrictive than MIT license.\n\nIn section 3.1.2 in Colin Fay’s book Licensing R, it is stated that “any derivative work of GPL licensed work is to be licensed under GPL-compatible license” according to FSF. Depending on other packages should form a dynamic linking, and in most cases, be considered as a single combined program, then the GPL license is required.\nIn Hadley Wickham and Jenny Bryan’s R package (2e) book, they mention:\nBefore you bundle someone else’s code into your package, you need to first check that the bundled license is compatible with your license. When distributing code, you can add additional restrictions, but you can not remove restrictions, which means that license compatibility is not symmetric. For example, you can bundle MIT licensed code in a GPL licensed package, but you can not bundle GPL licensed code in an MIT licensed package.\nWhen confronted with the above question, ChatGPT gave two – quite different – responses, as shown below. The main point in both responses is ‘your package may be considered derivative work’. At the specific problem of the package developed for Lab 3, what is your opinion about potential copyright infringements when releasing the package with an MIT license? Make sure to take the relevant passage in Colin Fay’s book under consideration.\nThe legal implications of publishing an R package on CRAN under an MIT license while having a dependency on a package that is licensed under GPL-3 are complex and can vary depending on the specific circumstances. It is always advisable to seek legal advice from a licensed attorney if you have any doubts or concerns about licensing issues.\n\nHowever, in general, it is possible to publish an R package on CRAN under an MIT license when you have a dependency on a package that is licensed under GPL-3. This is because the MIT license is a permissive open-source license that allows for more flexibility in how the software can be used and distributed, and it is generally considered compatible with the GPL-3 license.\n\nThat being said, if your package depends on a GPL-3-licensed package, your package may be considered a derivative work and therefore subject to the terms of the GPL-3 license. This means that if you distribute your package, you may need to also distribute the source code for your package under the GPL-3 license or a compatible license, and you may need to ensure that the requirements of the GPL-3 license are met for the entire distribution, including any dependencies.\n\nIt is also worth noting that the R community has its own guidelines and recommendations for package licensing, and it is important to comply with these guidelines if you want to publish your package on CRAN. The CRAN Repository Policy states that packages should have a \"permissive\" or \"GPL-compatible\" license, but does not explicitly require that packages use the GPL license or any other specific license.\n\nIn summary, while it is possible to publish an R package on CRAN under an MIT license while having a dependency on a package that is licensed under GPL-3, it is important to understand the implications of the different licenses and to ensure that you comply with any applicable guidelines and recommendations from the R community.\nAfter harping a bit on copyright infringement in general, ChatGPT changed its response to\nTechnically, you can publish an R package on CRAN under an MIT license when you have a dependency on a package that is licensed under GPL-3, but doing so would not be compliant with the terms of the GPL-3 license.\n\nThe GPL-3 license is a strong copyleft license that requires derivative works to be released under the same license. If your package depends on a GPL-3-licensed package, your package may be considered a derivative work and therefore must be licensed under the GPL-3 license or a compatible license.\n\nThe MIT license, on the other hand, is a permissive license that allows for more flexibility in how the software is used and distributed. However, it is not compatible with the GPL-3 license, and therefore cannot be used for derivative works of GPL-3-licensed software.\n\nPublishing an R package on CRAN under an MIT license when you have a dependency on a package that is licensed under GPL-3 would be a licensing violation, and could potentially result in legal action or other consequences. It is important to comply with the licensing requirements of all dependencies in your package to avoid any legal issues.\nThe ‘harping’ questions:\n\nIs it legal to publish an R package on CRAN under an MIT license when I have a dependency on a package that is licensed under GPL-3?\nIs it illegal to publish an R package on CRAN under an MIT license when I have a dependency on a package that is licensed under GPL-3?\nIs it a copyright infringement to publish an R package on CRAN under an MIT license when I have a dependency on a package that is licensed under GPL-3?\nCan I publish an R package on CRAN under an MIT license when I have a dependency on a package that is licensed under GPL-3 without infringing copyright?"
  },
  {
    "objectID": "blog-2023/Blog-7-submissions/xyzyc/index.html#submission",
    "href": "blog-2023/Blog-7-submissions/xyzyc/index.html#submission",
    "title": "License",
    "section": "Submission",
    "text": "Submission\nWrite answers to the questions directly into the file README.Rmd. Push the blog post to your blog-7 repo. Make sure that all of the checks are passing."
  },
  {
    "objectID": "blog-2023/Blog-7-submissions/kundan7kumar/index.html#prompt",
    "href": "blog-2023/Blog-7-submissions/kundan7kumar/index.html#prompt",
    "title": "R licensing",
    "section": "Prompt:",
    "text": "Prompt:\nThe DESCRIPTION file of a package contains the package’s meta information. Most of the fields in this file are quite straight forward: author, version number, and a short package description. When you call library(help=\"<package name>\") for package <package name> you can see the contents of the DESCRIPTION file for that package (and some parts of the NAMESPACE file).\nRead through Colin Fay’s (short) book on Licensing R\nWrite a blog post addressing the following questions:\n\nUnder what license does R operate? What is the license for ggplot2?\nSolution: R operate under GPL-2 | GPL-3 license, while ggplot2 comes under MIT + file license.\n\n\nWhat are the dependencies of the package you made?\nRead through chapter 5.2 of Licensing R. Combine and adjust the code pieces to create the dependencies for a package that is on github rather than CRAN. (Don’t forget about the package desc.) What dependencies does the package have that you created for Lab-3?\nWhich licenses are involved? Are all of these dependencies required? Elaborate.\nSolution:\nThe package license is “MIT + file LICENSE”, which means that package is released under the MIT License and also there is additional terms specified in the file named “LICENSE”(YEAR: 2023 COPYRIGHT HOLDER: F. Last) included with the package.\nThe package dependencies are:\n\ndplyr\n\nlubridate\npurrr\n\nR (>= 2.10)\n\nreadr\n\ntabulizer\n\ntibble\n\nUnder which license should this blog post be published? Make sure that you are using an appropriate license. (You can change the current licenses with the help of commands from the use_license_XXX family in the usethis package)\nSolution: We could use the same license CC0 1.0 license as it is released in public domains and anyone could use, share and modify the work without any restrictions .It can be use as commercial purposes. But I think that most approriate would be MIT License which allows user users to use, copy, publish, distribute, and/or sell copies of a software or a piece of code but also ensures that authors get full credit.\n\n\nCan I publish an R package on CRAN under an MIT license when I have a dependency on a package that is licensed under GPL-3?\nWhen confronted with the above question, ChatGPT gave two – quite different – responses, as shown below. The main point in both responses is ‘your package may be considered derivative work’. At the specific problem of the package developed for Lab 3, what is your opinion about potential copyright infringements when releasing the package with an MIT license? Make sure to take the relevant passage in Colin Fay’s book under consideration.\nThe legal implications of publishing an R package on CRAN under an MIT license while having a dependency on a package that is licensed under GPL-3 are complex and can vary depending on the specific circumstances. It is always advisable to seek legal advice from a licensed attorney if you have any doubts or concerns about licensing issues.\n\nHowever, in general, it is possible to publish an R package on CRAN under an MIT license when you have a dependency on a package that is licensed under GPL-3. This is because the MIT license is a permissive open-source license that allows for more flexibility in how the software can be used and distributed, and it is generally considered compatible with the GPL-3 license.\n\nThat being said, if your package depends on a GPL-3-licensed package, your package may be considered a derivative work and therefore subject to the terms of the GPL-3 license. This means that if you distribute your package, you may need to also distribute the source code for your package under the GPL-3 license or a compatible license, and you may need to ensure that the requirements of the GPL-3 license are met for the entire distribution, including any dependencies.\n\nIt is also worth noting that the R community has its own guidelines and recommendations for package licensing, and it is important to comply with these guidelines if you want to publish your package on CRAN. The CRAN Repository Policy states that packages should have a \"permissive\" or \"GPL-compatible\" license, but does not explicitly require that packages use the GPL license or any other specific license.\n\nIn summary, while it is possible to publish an R package on CRAN under an MIT license while having a dependency on a package that is licensed under GPL-3, it is important to understand the implications of the different licenses and to ensure that you comply with any applicable guidelines and recommendations from the R community.\nAfter harping a bit on copyright infringement in general, ChatGPT changed its response to\nTechnically, you can publish an R package on CRAN under an MIT license when you have a dependency on a package that is licensed under GPL-3, but doing so would not be compliant with the terms of the GPL-3 license.\n\nThe GPL-3 license is a strong copyleft license that requires derivative works to be released under the same license. If your package depends on a GPL-3-licensed package, your package may be considered a derivative work and therefore must be licensed under the GPL-3 license or a compatible license.\n\nThe MIT license, on the other hand, is a permissive license that allows for more flexibility in how the software is used and distributed. However, it is not compatible with the GPL-3 license, and therefore cannot be used for derivative works of GPL-3-licensed software.\n\nPublishing an R package on CRAN under an MIT license when you have a dependency on a package that is licensed under GPL-3 would be a licensing violation, and could potentially result in legal action or other consequences. It is important to comply with the licensing requirements of all dependencies in your package to avoid any legal issues.\nThe ‘harping’ questions:\n\nIs it legal to publish an R package on CRAN under an MIT license when I have a dependency on a package that is licensed under GPL-3?\nIs it illegal to publish an R package on CRAN under an MIT license when I have a dependency on a package that is licensed under GPL-3?\nIs it a copyright infringement to publish an R package on CRAN under an MIT license when I have a dependency on a package that is licensed under GPL-3?\nCan I publish an R package on CRAN under an MIT license when I have a dependency on a package that is licensed under GPL-3 without infringing copyright?\n\nSolution: No, We cannot publish a package under the MIT license, as the GPL-3 license says that any derivative work which includes a work that has links or is dependent on GPL-3 should come under its license, so R-package should not come under the MIT license. It should come under a GPL-3 license.\nYes, the Package is dependent and licensed under GPL-3, so there would be a copyright infringement to publish an R package on CRAN under an MIT license.\nMoreover, We can publish an R package on CRAN under an MIT license when it depends on a package licensed under GPL-3 without infringing copyright if we re-license our Package under GPL-3 too. As we stated earlier, any derivative work or Package that depends on GPL-3 should be licensed under it. So re-licensing the R package under the GPL-3 would comply terms and conditions of the license and avoid any copyright infringement issues"
  },
  {
    "objectID": "blog-2023/Blog-7-submissions/kundan7kumar/index.html#submission",
    "href": "blog-2023/Blog-7-submissions/kundan7kumar/index.html#submission",
    "title": "R licensing",
    "section": "Submission",
    "text": "Submission\nWrite answers to the questions directly into the file README.Rmd. Push the blog post to your blog-7 repo. Make sure that all of the checks are passing."
  },
  {
    "objectID": "blog-2023/Blog-7-submissions/anyeshar/index.html#prompt",
    "href": "blog-2023/Blog-7-submissions/anyeshar/index.html#prompt",
    "title": "Licensing Blog",
    "section": "Prompt:",
    "text": "Prompt:\nThe DESCRIPTION file of a package contains the package’s meta information. Most of the fields in this file are quite straight forward: author, version number, and a short package description. When you call library(help=\"<package name>\") for package <package name> you can see the contents of the DESCRIPTION file for that package (and some parts of the NAMESPACE file).\nRead through Colin Fay’s (short) book on Licensing R\nWrite a blog post addressing the following questions:\n\nUnder what license does R operate? What is the license for ggplot2?\nR is licensed as GNU General Public License. R as a package is licensed under GPL-2 | GPL-3. The ggplot2 license is MIT + file LICENSE.\n\n\nWhat are the dependencies of the package you made?\nlibrary(lubridate, quietly = TRUE) GPL (>= 2) library(tabulizer) MIT + file LICENSE library(tidyverse, quietly = TRUE) MIT + file LICENSE library(stringr) MIT + file LICENSE\nAre packages we used.\nUnder which license should this blog post be published? Make sure that you are using an appropriate license. I would use MIT + file LICENSE because it does not matter if someone modifies anything.\n\n\nCan I publish an R package on CRAN under an MIT license when I have a dependency on a package that is licensed under GPL-3?\nI would say yes you can publish a package on CRAN under an MIT license but it might not be technically following the rules.\nThe ‘harping’ questions:\n\nIs it legal to publish an R package on CRAN under an MIT license when I have a dependency on a package that is licensed under GPL-3? No?\nIs it illegal to publish an R package on CRAN under an MIT license when I have a dependency on a package that is licensed under GPL-3? No?\nIs it a copyright infringement to publish an R package on CRAN under an MIT license when I have a dependency on a package that is licensed under GPL-3? Yes\nCan I publish an R package on CRAN under an MIT license when I have a dependency on a package that is licensed under GPL-3 without infringing copyright? No\n\nThe licensing was a little confusing. It almost sounds like it isn’t very explicitly defined so it isn’t legal, but also not illegal. I’m not sure I understood the licensing very well."
  },
  {
    "objectID": "blog-2023/Blog-7-submissions/Hiiiua/index.html#prompt",
    "href": "blog-2023/Blog-7-submissions/Hiiiua/index.html#prompt",
    "title": "Licenses",
    "section": "Prompt:",
    "text": "Prompt:\nThe DESCRIPTION file of a package contains the package’s meta information. Most of the fields in this file are quite straight forward: author, version number, and a short package description. When you call library(help=\"<package name>\") for package <package name> you can see the contents of the DESCRIPTION file for that package (and some parts of the NAMESPACE file).\nRead through Colin Fay’s (short) book on Licensing R\nWrite a blog post addressing the following questions:\n\nUnder what license does R operate? What is the license for ggplot2?\nggplot operates on MIT+file LICENSE\nR is distributed under the terms of the GNU General Public License\n\n\nWhat are the dependencies of the package you made?\nRead through chapter 5.2 of Licensing R. Combine and adjust the code pieces to create the dependencies for a package that is on github rather than CRAN. (Don’t forget about the package desc.) What dependencies does the package have that you created for Lab-3? Which licenses are involved? Are all of these dependencies required? Elaborate.\n\n# desc::desc_get_deps(system.file(\"DESCRIPTION\", package = \"litr\"))$package\n\n[1] “bookdown” “desc” “devtools” “digest” “fansi” “fs” “knitr”\n[8] “pkgdown” “rmarkdown” “stringr” “usethis” “xfun” “yaml” “dplyr”\n[15] “Rcpp” “testthat”\nIn our lab3 project, we have Depends: lubridate, purrr, R (>= 2.10), tabulizer (>= 0.2.3),tidyverse and Remotes: github::ropensci/tabulizer. Not all of them are required, because dependencies of one package could overlap with the packages we import. For example, lubridate is one of the dependencies of tidyverse.\n\npkg = tools::CRAN_package_db()\nstringr::str_detect(pkg[pkg$Package=='tidyverse', \"Imports\"], 'lubridate')\n\n[1] TRUE\n\n\nUnder which license should this blog post be published? Make sure that you are using an appropriate license. (You can change the current licenses with the help of commands from the use_license_XXX family in the usethis package) I decide to use CC BY 4.0, which means it’s free to share and adapt as long as providing the link.\n\n# usethis::use_ccby_license()\n\n\n\nCan I publish an R package on CRAN under an MIT license when I have a dependency on a package that is licensed under GPL-3?\nWhen confronted with the above question, ChatGPT gave two – quite different – responses, as shown below. The main point in both responses is ‘your package may be considered derivative work’. At the specific problem of the package developed for Lab 3, what is your opinion about potential copyright infringements when releasing the package with an MIT license? Make sure to take the relevant passage in Colin Fay’s book under consideration.\nThe legal implications of publishing an R package on CRAN under an MIT license while having a dependency on a package that is licensed under GPL-3 are complex and can vary depending on the specific circumstances. It is always advisable to seek legal advice from a licensed attorney if you have any doubts or concerns about licensing issues.\n\nHowever, in general, it is possible to publish an R package on CRAN under an MIT license when you have a dependency on a package that is licensed under GPL-3. This is because the MIT license is a permissive open-source license that allows for more flexibility in how the software can be used and distributed, and it is generally considered compatible with the GPL-3 license.\n\nThat being said, if your package depends on a GPL-3-licensed package, your package may be considered a derivative work and therefore subject to the terms of the GPL-3 license. This means that if you distribute your package, you may need to also distribute the source code for your package under the GPL-3 license or a compatible license, and you may need to ensure that the requirements of the GPL-3 license are met for the entire distribution, including any dependencies.\n\nIt is also worth noting that the R community has its own guidelines and recommendations for package licensing, and it is important to comply with these guidelines if you want to publish your package on CRAN. The CRAN Repository Policy states that packages should have a \"permissive\" or \"GPL-compatible\" license, but does not explicitly require that packages use the GPL license or any other specific license.\n\nIn summary, while it is possible to publish an R package on CRAN under an MIT license while having a dependency on a package that is licensed under GPL-3, it is important to understand the implications of the different licenses and to ensure that you comply with any applicable guidelines and recommendations from the R community.\nAfter harping a bit on copyright infringement in general, ChatGPT changed its response to\nTechnically, you can publish an R package on CRAN under an MIT license when you have a dependency on a package that is licensed under GPL-3, but doing so would not be compliant with the terms of the GPL-3 license.\n\nThe GPL-3 license is a strong copyleft license that requires derivative works to be released under the same license. If your package depends on a GPL-3-licensed package, your package may be considered a derivative work and therefore must be licensed under the GPL-3 license or a compatible license.\n\nThe MIT license, on the other hand, is a permissive license that allows for more flexibility in how the software is used and distributed. However, it is not compatible with the GPL-3 license, and therefore cannot be used for derivative works of GPL-3-licensed software.\n\nPublishing an R package on CRAN under an MIT license when you have a dependency on a package that is licensed under GPL-3 would be a licensing violation, and could potentially result in legal action or other consequences. It is important to comply with the licensing requirements of all dependencies in your package to avoid any legal issues.\nThe ‘harping’ questions:\n\nIs it legal to publish an R package on CRAN under an MIT license when I have a dependency on a package that is licensed under GPL-3?\nIs it illegal to publish an R package on CRAN under an MIT license when I have a dependency on a package that is licensed under GPL-3?\nIs it a copyright infringement to publish an R package on CRAN under an MIT license when I have a dependency on a package that is licensed under GPL-3?\nCan I publish an R package on CRAN under an MIT license when I have a dependency on a package that is licensed under GPL-3 without infringing copyright?\n\nMy answer: I agree with the first ChatGPT answer that this is a complicated and can vary depending on the specific circumstances.\nGPL3 license clearly states how the piece of software should be distributed. Distributing, unlike just launching or running, is sharing the code. Most of the time, it needs to be modified version and distributes comply compatibility. But it can be more complicated: for example, in terms of Shiny app, interacting with user through network, it’s called “conveying” without transferring a copy, which looks like affirms unlimited permission to run the unmodified Program. But if use_shinyalert() has been called, it’s not conveying any more, it’s actually distributing.\nTo publish a package with GPL-3 dependency, figure out the restrictions is important: is it accessed by internal user or public, is it commercial or non-commercial, is there any modification? Without this answers, there can be overlapping areas between “legal”, “illegal” and “copyright infringement”."
  },
  {
    "objectID": "blog-2023/Blog-7-submissions/Hiiiua/index.html#submission",
    "href": "blog-2023/Blog-7-submissions/Hiiiua/index.html#submission",
    "title": "Licenses",
    "section": "Submission",
    "text": "Submission\nWrite answers to the questions directly into the file README.Rmd. Push the blog post to your blog-7 repo. Make sure that all of the checks are passing."
  },
  {
    "objectID": "blog-2023/Blog-7-submissions/charlestbonk/index.html#prompt",
    "href": "blog-2023/Blog-7-submissions/charlestbonk/index.html#prompt",
    "title": "I’m not a lawyer",
    "section": "Prompt:",
    "text": "Prompt:\nThe DESCRIPTION file of a package contains the package’s meta information. Most of the fields in this file are quite straight forward: author, version number, and a short package description. When you call library(help=\"<package name>\") for package <package name> you can see the contents of the DESCRIPTION file for that package (and some parts of the NAMESPACE file).\nRead through Colin Fay’s (short) book on Licensing R\nWrite a blog post addressing the following questions:\n\nUnder what license does R operate? What is the license for ggplot2?\n\n\nWhat are the dependencies of the package you made?\nRead through chapter 5.2 of Licensing R. Combine and adjust the code pieces to create the dependencies for a package that is on github rather than CRAN. (Don’t forget about the package desc.) What dependencies does the package have that you created for Lab-3? Which licenses are involved? Are all of these dependencies required? Elaborate.\nUnder which license should this blog post be published? Make sure that you are using an appropriate license. (You can change the current licenses with the help of commands from the use_license_XXX family in the usethis package)\n\nlibrary(pkgnet)\nget_deps <- function(pkg){\n  DependencyReporter$new()$set_package(pkg)$nodes$node\n}\n\nbulxtr.deps <- get_deps(\"bulletxtrctr\")\n\nINFO [2023-03-19 18:09:33] Constructing dependency network for bulletxtrctr\nINFO [2023-03-19 18:09:34] ...done constructing dependency network.\n\nhead(bulxtr.deps)\n\n[1] \"MASS\"         \"Matrix\"       \"R6\"           \"RColorBrewer\" \"Rcpp\"        \n[6] \"Rdpack\"      \n\n# remotes::install_github(\"charlestbonk/lab-3-lab-3-team-unl\") # Note: This isn't working becuase the lab is private and R can't seem to see the package for that reason. :(\n\n\nAlso, regarding this blog post… As I say later (and like everyday), I disappointed my father by doing statistics instead of becoming a lawyer, so don’t take my undderstanding of copyright law as the final say. But We do use the pkgnet package. This has a BSD 3 licesnse, which is the most chill, relaxed liceense regarding free use and modification of code, so long you cite the original package. I also did look at bulletxtrctr (because apparantly that is the only package that came to mind?)(also hi Heike if you are reading this). It does have a GPL-3 license, but I didn’t actually DO anything with it? Like I didn’t even load it, and from my understanding, that isn’t using the package so I am good from that copyright infringement [see 2.2.2 for more on this.]\n\n\n\nCan I publish an R package on CRAN under an MIT license when I have a dependency on a package that is licensed under GPL-3?\nWhen confronted with the above question, ChatGPT gave two – quite different – responses, as shown below. The main point in both responses is ‘your package may be considered derivative work’. At the specific problem of the package developed for Lab 3, what is your opinion about potential copyright infringements when releasing the package with an MIT license? Make sure to take the relevant passage in Colin Fay’s book under consideration.\nThe legal implications of publishing an R package on CRAN under an MIT license while having a dependency on a package that is licensed under GPL-3 are complex and can vary depending on the specific circumstances. It is always advisable to seek legal advice from a licensed attorney if you have any doubts or concerns about licensing issues.\n\nHowever, in general, it is possible to publish an R package on CRAN under an MIT license when you have a dependency on a package that is licensed under GPL-3. This is because the MIT license is a permissive open-source license that allows for more flexibility in how the software can be used and distributed, and it is generally considered compatible with the GPL-3 license.\n\nThat being said, if your package depends on a GPL-3-licensed package, your package may be considered a derivative work and therefore subject to the terms of the GPL-3 license. This means that if you distribute your package, you may need to also distribute the source code for your package under the GPL-3 license or a compatible license, and you may need to ensure that the requirements of the GPL-3 license are met for the entire distribution, including any dependencies.\n\nIt is also worth noting that the R community has its own guidelines and recommendations for package licensing, and it is important to comply with these guidelines if you want to publish your package on CRAN. The CRAN Repository Policy states that packages should have a \"permissive\" or \"GPL-compatible\" license, but does not explicitly require that packages use the GPL license or any other specific license.\n\nIn summary, while it is possible to publish an R package on CRAN under an MIT license while having a dependency on a package that is licensed under GPL-3, it is important to understand the implications of the different licenses and to ensure that you comply with any applicable guidelines and recommendations from the R community.\nAfter harping a bit on copyright infringement in general, ChatGPT changed its response to\nTechnically, you can publish an R package on CRAN under an MIT license when you have a dependency on a package that is licensed under GPL-3, but doing so would not be compliant with the terms of the GPL-3 license.\n\nThe GPL-3 license is a strong copyleft license that requires derivative works to be released under the same license. If your package depends on a GPL-3-licensed package, your package may be considered a derivative work and therefore must be licensed under the GPL-3 license or a compatible license.\n\nThe MIT license, on the other hand, is a permissive license that allows for more flexibility in how the software is used and distributed. However, it is not compatible with the GPL-3 license, and therefore cannot be used for derivative works of GPL-3-licensed software.\n\nPublishing an R package on CRAN under an MIT license when you have a dependency on a package that is licensed under GPL-3 would be a licensing violation, and could potentially result in legal action or other consequences. It is important to comply with the licensing requirements of all dependencies in your package to avoid any legal issues.\nThe ‘harping’ questions:\n\nIs it legal to publish an R package on CRAN under an MIT license when I have a dependency on a package that is licensed under GPL-3?\nIs it illegal to publish an R package on CRAN under an MIT license when I have a dependency on a package that is licensed under GPL-3?\nIs it a copyright infringement to publish an R package on CRAN under an MIT license when I have a dependency on a package that is licensed under GPL-3?\nCan I publish an R package on CRAN under an MIT license when I have a dependency on a package that is licensed under GPL-3 without infringing copyright?\n\n\n\nMy Answers\n\nSo firstly, I am not a lawyer, I am not claiming to be a lawyer, or have any legal training, and in fact, I find legal documents as the most absolutely boring and dreadful things known to man. That being said…\n\nThe only packages our Lab 3 package calls upon are from Tidyverse, lubridate, litr, and and UseThis. Of the 4, the only package with a GPL3 license is lubridate. The question then come to “Did we do enough with lubridate to warrent it being a ‘derivative work’.\nMy good friend ChatGPT defines a Derivative Work as “A derivative work is a new work that is created by modifying or building upon an existing work that is protected by copyright.”\nWe did not make any modifications to the lubridate package itself, only used it for it’s intended purpose.\nSo from my non-legal legal advice that you should 100% not trust beyond your own common sense, PressLoggeR should be fine under a MIT license on CRAN."
  },
  {
    "objectID": "blog-2023/Blog-7-submissions/charlestbonk/index.html#submission",
    "href": "blog-2023/Blog-7-submissions/charlestbonk/index.html#submission",
    "title": "I’m not a lawyer",
    "section": "Submission",
    "text": "Submission\nWrite answers to the questions directly into the file README.Rmd. Push the blog post to your blog-7 repo. Make sure that all of the checks are passing."
  },
  {
    "objectID": "blog-2023/Blog-7-submissions/TWiedRW/index.html#prompt",
    "href": "blog-2023/Blog-7-submissions/TWiedRW/index.html#prompt",
    "title": "Stat 585",
    "section": "Prompt:",
    "text": "Prompt:\nThe DESCRIPTION file of a package contains the package’s meta information. Most of the fields in this file are quite straight forward: author, version number, and a short package description. When you call library(help=\"<package name>\") for package <package name> you can see the contents of the DESCRIPTION file for that package (and some parts of the NAMESPACE file).\nRead through Colin Fay’s (short) book on Licensing R\nWrite a blog post addressing the following questions:\n\nUnder what license does R operate? What is the license for ggplot2?\n\n\nWhat are the dependencies of the package you made?\nRead through chapter 5.2 of Licensing R. Combine and adjust the code pieces to create the dependencies for a package that is on github rather than CRAN. (Don’t forget about the package desc.) What dependencies does the package have that you created for Lab-3? Which licenses are involved? Are all of these dependencies required? Elaborate.\nUnder which license should this blog post be published? Make sure that you are using an appropriate license. (You can change the current licenses with the help of commands from the use_license_XXX family in the usethis package)\n\n\nCan I publish an R package on CRAN under an MIT license when I have a dependency on a package that is licensed under GPL-3?\nWhen confronted with the above question, ChatGPT gave two – quite different – responses, as shown below. The main point in both responses is ‘your package may be considered derivative work’. At the specific problem of the package developed for Lab 3, what is your opinion about potential copyright infringements when releasing the package with an MIT license? Make sure to take the relevant passage in Colin Fay’s book under consideration.\nThe legal implications of publishing an R package on CRAN under an MIT license while having a dependency on a package that is licensed under GPL-3 are complex and can vary depending on the specific circumstances. It is always advisable to seek legal advice from a licensed attorney if you have any doubts or concerns about licensing issues.\n\nHowever, in general, it is possible to publish an R package on CRAN under an MIT license when you have a dependency on a package that is licensed under GPL-3. This is because the MIT license is a permissive open-source license that allows for more flexibility in how the software can be used and distributed, and it is generally considered compatible with the GPL-3 license.\n\nThat being said, if your package depends on a GPL-3-licensed package, your package may be considered a derivative work and therefore subject to the terms of the GPL-3 license. This means that if you distribute your package, you may need to also distribute the source code for your package under the GPL-3 license or a compatible license, and you may need to ensure that the requirements of the GPL-3 license are met for the entire distribution, including any dependencies.\n\nIt is also worth noting that the R community has its own guidelines and recommendations for package licensing, and it is important to comply with these guidelines if you want to publish your package on CRAN. The CRAN Repository Policy states that packages should have a \"permissive\" or \"GPL-compatible\" license, but does not explicitly require that packages use the GPL license or any other specific license.\n\nIn summary, while it is possible to publish an R package on CRAN under an MIT license while having a dependency on a package that is licensed under GPL-3, it is important to understand the implications of the different licenses and to ensure that you comply with any applicable guidelines and recommendations from the R community.\nAfter harping a bit on copyright infringement in general, ChatGPT changed its response to\nTechnically, you can publish an R package on CRAN under an MIT license when you have a dependency on a package that is licensed under GPL-3, but doing so would not be compliant with the terms of the GPL-3 license.\n\nThe GPL-3 license is a strong copyleft license that requires derivative works to be released under the same license. If your package depends on a GPL-3-licensed package, your package may be considered a derivative work and therefore must be licensed under the GPL-3 license or a compatible license.\n\nThe MIT license, on the other hand, is a permissive license that allows for more flexibility in how the software is used and distributed. However, it is not compatible with the GPL-3 license, and therefore cannot be used for derivative works of GPL-3-licensed software.\n\nPublishing an R package on CRAN under an MIT license when you have a dependency on a package that is licensed under GPL-3 would be a licensing violation, and could potentially result in legal action or other consequences. It is important to comply with the licensing requirements of all dependencies in your package to avoid any legal issues.\nThe ‘harping’ questions:\n\nIs it legal to publish an R package on CRAN under an MIT license when I have a dependency on a package that is licensed under GPL-3?\nIs it illegal to publish an R package on CRAN under an MIT license when I have a dependency on a package that is licensed under GPL-3?\nIs it a copyright infringement to publish an R package on CRAN under an MIT license when I have a dependency on a package that is licensed under GPL-3?\nCan I publish an R package on CRAN under an MIT license when I have a dependency on a package that is licensed under GPL-3 without infringing copyright?"
  },
  {
    "objectID": "blog-2023/Blog-7-submissions/TWiedRW/index.html#submission",
    "href": "blog-2023/Blog-7-submissions/TWiedRW/index.html#submission",
    "title": "Stat 585",
    "section": "Submission",
    "text": "Submission\nWrite answers to the questions directly into the file README.Rmd. Push the blog post to your blog-7 repo. Make sure that all of the checks are passing."
  },
  {
    "objectID": "blog-2023/Blog-7-submissions/kellynay/index.html#prompt",
    "href": "blog-2023/Blog-7-submissions/kellynay/index.html#prompt",
    "title": "R Licensing and Package Dependencies",
    "section": "Prompt:",
    "text": "Prompt:\nThe DESCRIPTION file of a package contains the package’s meta information. Most of the fields in this file are quite straight forward: author, version number, and a short package description. When you call library(help=\"<package name>\") for package <package name> you can see the contents of the DESCRIPTION file for that package (and some parts of the NAMESPACE file).\nRead through Colin Fay’s (short) book on Licensing R\nWrite a blog post addressing the following questions:\n\nUnder what license does R operate?\nR operates under the license GPL-2 | GPL-3.\nSource: https://www.r-project.org/Licenses/#:~:text=R%20as%20a%20package%20is,%2C%20which%20includes%20GPL%2D3%20.\n\n\nWhat is the license for ggplot2?\n\npackageDescription(\"ggplot2\", fields=\"License\")\n\n[1] \"MIT + file LICENSE\"\n\n\n\n\nWhat are the dependencies of the package you made?\n\nPackage dependencies for Team3 according to the description file include:\n\nDepends: R (>= 2.10) Import: tabulizer, tidyr, dplyr, tibble, lubridate, RCurl\n\nLicenses involved for package Team3: MIT + file LICENSE\nAre all of these dependencies required? Not all these dependencies are required because “RCurl” was just another method used to download files from the URL address. Thus, “RCurl” is not required.\nUnder which license should this blog post be published? I am posting this blog under R’s current’s license because I would not mind sharing this this publicly.\n\nRead through chapter 5.2 of Licensing R. Combine and adjust the code pieces to create the dependencies for a package that is on github rather than CRAN. (Don’t forget about the package desc.) What dependencies does the package have that you created for Lab-3? Which licenses are involved? Are all of these dependencies required? Elaborate.\nUnder which license should this blog post be published? Make sure that you are using an appropriate license. (You can change the current licenses with the help of commands from the use_license_XXX family in the usethis package)\n\n\nCan I publish an R package on CRAN under an MIT license when I have a dependency on a package that is licensed under GPL-3?\nWhen confronted with the above question, ChatGPT gave two – quite different – responses, as shown below. The main point in both responses is ‘your package may be considered derivative work’. At the specific problem of the package developed for Lab 3, what is your opinion about potential copyright infringements when releasing the package with an MIT license? Make sure to take the relevant passage in Colin Fay’s book under consideration.\nThe legal implications of publishing an R package on CRAN under an MIT license while having a dependency on a package that is licensed under GPL-3 are complex and can vary depending on the specific circumstances. It is always advisable to seek legal advice from a licensed attorney if you have any doubts or concerns about licensing issues.\n\nHowever, in general, it is possible to publish an R package on CRAN under an MIT license when you have a dependency on a package that is licensed under GPL-3. This is because the MIT license is a permissive open-source license that allows for more flexibility in how the software can be used and distributed, and it is generally considered compatible with the GPL-3 license.\n\nThat being said, if your package depends on a GPL-3-licensed package, your package may be considered a derivative work and therefore subject to the terms of the GPL-3 license. This means that if you distribute your package, you may need to also distribute the source code for your package under the GPL-3 license or a compatible license, and you may need to ensure that the requirements of the GPL-3 license are met for the entire distribution, including any dependencies.\n\nIt is also worth noting that the R community has its own guidelines and recommendations for package licensing, and it is important to comply with these guidelines if you want to publish your package on CRAN. The CRAN Repository Policy states that packages should have a \"permissive\" or \"GPL-compatible\" license, but does not explicitly require that packages use the GPL license or any other specific license.\n\nIn summary, while it is possible to publish an R package on CRAN under an MIT license while having a dependency on a package that is licensed under GPL-3, it is important to understand the implications of the different licenses and to ensure that you comply with any applicable guidelines and recommendations from the R community.\nAfter harping a bit on copyright infringement in general, ChatGPT changed its response to\nTechnically, you can publish an R package on CRAN under an MIT license when you have a dependency on a package that is licensed under GPL-3, but doing so would not be compliant with the terms of the GPL-3 license.\n\nThe GPL-3 license is a strong copyleft license that requires derivative works to be released under the same license. If your package depends on a GPL-3-licensed package, your package may be considered a derivative work and therefore must be licensed under the GPL-3 license or a compatible license.\n\nThe MIT license, on the other hand, is a permissive license that allows for more flexibility in how the software is used and distributed. However, it is not compatible with the GPL-3 license, and therefore cannot be used for derivative works of GPL-3-licensed software.\n\nPublishing an R package on CRAN under an MIT license when you have a dependency on a package that is licensed under GPL-3 would be a licensing violation, and could potentially result in legal action or other consequences. It is important to comply with the licensing requirements of all dependencies in your package to avoid any legal issues.\nThe ‘harping’ questions:\n\nIs it legal to publish an R package on CRAN under an MIT license when I have a dependency on a package that is licensed under GPL-3?\nIs it illegal to publish an R package on CRAN under an MIT license when I have a dependency on a package that is licensed under GPL-3?\nIs it a copyright infringement to publish an R package on CRAN under an MIT license when I have a dependency on a package that is licensed under GPL-3?\nCan I publish an R package on CRAN under an MIT license when I have a dependency on a package that is licensed under GPL-3 without infringing copyright?"
  },
  {
    "objectID": "blog-2023/Blog-7-submissions/kellynay/index.html#submission",
    "href": "blog-2023/Blog-7-submissions/kellynay/index.html#submission",
    "title": "R Licensing and Package Dependencies",
    "section": "Submission",
    "text": "Submission\nWrite answers to the questions directly into the file README.Rmd. Push the blog post to your blog-7 repo. Make sure that all of the checks are passing."
  },
  {
    "objectID": "blog-2023/Blog-7-submissions/drbradford12/index.html#prompt",
    "href": "blog-2023/Blog-7-submissions/drbradford12/index.html#prompt",
    "title": "Legal Stuff",
    "section": "Prompt:",
    "text": "Prompt:\nThe DESCRIPTION file of a package contains the package’s meta information. Most of the fields in this file are quite straight forward: author, version number, and a short package description. When you call library(help=\"<package name>\") for package <package name> you can see the contents of the DESCRIPTION file for that package (and some parts of the NAMESPACE file).\nRead through Colin Fay’s (short) book on Licensing R\nWrite a blog post addressing the following questions:\n\nUnder what license does R operate? What is the license for ggplot2?\n\n\nWhat are the dependencies of the package you made?\nRead through chapter 5.2 of Licensing R. Combine and adjust the code pieces to create the dependencies for a package that is on github rather than CRAN. (Don’t forget about the package desc.) What dependencies does the package have that you created for Lab-3? Which licenses are involved? Are all of these dependencies required? Elaborate.\nUnder which license should this blog post be published? Make sure that you are using an appropriate license. (You can change the current licenses with the help of commands from the use_license_XXX family in the usethis package)\n\n\nCan I publish an R package on CRAN under an MIT license when I have a dependency on a package that is licensed under GPL-3?\nWhen confronted with the above question, ChatGPT gave two – quite different – responses, as shown below. The main point in both responses is ‘your package may be considered derivative work’. At the specific problem of the package developed for Lab 3, what is your opinion about potential copyright infringements when releasing the package with an MIT license? Make sure to take the relevant passage in Colin Fay’s book under consideration.\nThe legal implications of publishing an R package on CRAN under an MIT license while having a dependency on a package that is licensed under GPL-3 are complex and can vary depending on the specific circumstances. It is always advisable to seek legal advice from a licensed attorney if you have any doubts or concerns about licensing issues.\n\nHowever, in general, it is possible to publish an R package on CRAN under an MIT license when you have a dependency on a package that is licensed under GPL-3. This is because the MIT license is a permissive open-source license that allows for more flexibility in how the software can be used and distributed, and it is generally considered compatible with the GPL-3 license.\n\nThat being said, if your package depends on a GPL-3-licensed package, your package may be considered a derivative work and therefore subject to the terms of the GPL-3 license. This means that if you distribute your package, you may need to also distribute the source code for your package under the GPL-3 license or a compatible license, and you may need to ensure that the requirements of the GPL-3 license are met for the entire distribution, including any dependencies.\n\nIt is also worth noting that the R community has its own guidelines and recommendations for package licensing, and it is important to comply with these guidelines if you want to publish your package on CRAN. The CRAN Repository Policy states that packages should have a \"permissive\" or \"GPL-compatible\" license, but does not explicitly require that packages use the GPL license or any other specific license.\n\nIn summary, while it is possible to publish an R package on CRAN under an MIT license while having a dependency on a package that is licensed under GPL-3, it is important to understand the implications of the different licenses and to ensure that you comply with any applicable guidelines and recommendations from the R community.\nAfter harping a bit on copyright infringement in general, ChatGPT changed its response to\nTechnically, you can publish an R package on CRAN under an MIT license when you have a dependency on a package that is licensed under GPL-3, but doing so would not be compliant with the terms of the GPL-3 license.\n\nThe GPL-3 license is a strong copyleft license that requires derivative works to be released under the same license. If your package depends on a GPL-3-licensed package, your package may be considered a derivative work and therefore must be licensed under the GPL-3 license or a compatible license.\n\nThe MIT license, on the other hand, is a permissive license that allows for more flexibility in how the software is used and distributed. However, it is not compatible with the GPL-3 license, and therefore cannot be used for derivative works of GPL-3-licensed software.\n\nPublishing an R package on CRAN under an MIT license when you have a dependency on a package that is licensed under GPL-3 would be a licensing violation, and could potentially result in legal action or other consequences. It is important to comply with the licensing requirements of all dependencies in your package to avoid any legal issues.\nThe ‘harping’ questions:\n\nIs it legal to publish an R package on CRAN under an MIT license when I have a dependency on a package that is licensed under GPL-3?\nIs it illegal to publish an R package on CRAN under an MIT license when I have a dependency on a package that is licensed under GPL-3?\nIs it a copyright infringement to publish an R package on CRAN under an MIT license when I have a dependency on a package that is licensed under GPL-3?\nCan I publish an R package on CRAN under an MIT license when I have a dependency on a package that is licensed under GPL-3 without infringing copyright?"
  },
  {
    "objectID": "blog-2023/Blog-7-submissions/drbradford12/index.html#submission",
    "href": "blog-2023/Blog-7-submissions/drbradford12/index.html#submission",
    "title": "Legal Stuff",
    "section": "Submission",
    "text": "Submission\nWrite answers to the questions directly into the file README.Rmd. Push the blog post to your blog-7 repo. Make sure that all of the checks are passing."
  },
  {
    "objectID": "blog-2023/Blog-7-submissions/HarunCelikOtto/index.html#prompt",
    "href": "blog-2023/Blog-7-submissions/HarunCelikOtto/index.html#prompt",
    "title": "Split-Apply-Combine Post",
    "section": "Prompt:",
    "text": "Prompt:\nThe DESCRIPTION file of a package contains the package’s meta information. Most of the fields in this file are quite straight forward: author, version number, and a short package description. When you call library(help=\"<package name>\") for package <package name> you can see the contents of the DESCRIPTION file for that package (and some parts of the NAMESPACE file).\nRead through Colin Fay’s (short) book on Licensing R\nWrite a blog post addressing the following questions:\n\nUnder what license does R operate? What is the license for ggplot2?\nRunning license() shows us that R operates under the GNU General Public License for both Version 2 and Version 3. Running ?ggplot2 shows that the copyright holder is with RStudio and the CRAN repository for the package indicates that gpplot2 operates under the MIT + file LICENSE.\n\n\nWhat are the dependencies of the package you made?\nThe following are the dependencies of our package based on our manual addition of the usethis package:\n\ndplyr - MIT + file LICENSE (formerly GPL license)\nlubridate - GNU GPL (>=2) (it would be interesting to see what happens to this now that it will roll with tidyverse)\nreadr - MIT + file LICENSE\npurrr - MIT + file LICENSE\nstringr - MIT + file LICENSE\ntabulizer - MIT + file LICENSE\n\nWe can check all of the dependencies with a custom function that filters through CRAN database since most of the these are on CRAN.\n\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\npkgdb <- tools::CRAN_package_db()\n\nThe author of the book suggested using {pkgnet} but I had trouble understanding exactly what the custom function was doing there so I just filtered through the pkgdb data and output the items as a list for legibility. This will show the dependencies, imports and suggests for each package listed above.\n\nget_deps <- function(pkg) {\n  pkgdb %>%\n    select(Package, Depends, Imports, Suggests) %>%\n    filter(Package == pkg) %>%\n    as.list()\n}\n\nget_deps(\"dplyr\")\n\n$Package\n[1] \"dplyr\"\n\n$Depends\n[1] \"R (>= 3.4.0)\"\n\n$Imports\n[1] \"cli (>= 3.4.0), generics, glue (>= 1.3.2), lifecycle (>=\\n1.0.3), magrittr (>= 1.5), methods, pillar (>= 1.5.1), R6,\\nrlang (>= 1.0.6), tibble (>= 2.1.3), tidyselect (>= 1.2.0),\\nutils, vctrs (>= 0.5.2)\"\n\n$Suggests\n[1] \"bench, broom, callr, covr, DBI, dbplyr (>= 2.2.1), ggplot2,\\nknitr, Lahman, lobstr, microbenchmark, nycflights13, purrr,\\nrmarkdown, RMySQL, RPostgreSQL, RSQLite, stringi (>= 1.7.6),\\ntestthat (>= 3.1.5), tidyr (>= 1.3.0), withr\"\n\nget_deps(\"lubridate\")\n\n$Package\n[1] \"lubridate\"\n\n$Depends\n[1] \"methods, R (>= 3.2)\"\n\n$Imports\n[1] \"generics, timechange (>= 0.1.1)\"\n\n$Suggests\n[1] \"covr, knitr, rmarkdown, testthat (>= 2.1.0), vctrs (>= 0.5.0)\"\n\nget_deps(\"purrr\")\n\n$Package\n[1] \"purrr\"\n\n$Depends\n[1] \"R (>= 3.4.0)\"\n\n$Imports\n[1] \"cli (>= 3.4.0), lifecycle (>= 1.0.3), magrittr (>= 1.5.0),\\nrlang (>= 0.4.10), vctrs (>= 0.5.0)\"\n\n$Suggests\n[1] \"covr, dplyr (>= 0.7.8), httr, knitr, lubridate, rmarkdown,\\ntestthat (>= 3.0.0), tibble, tidyselect\"\n\nget_deps(\"readr\")\n\n$Package\n[1] \"readr\"\n\n$Depends\n[1] \"R (>= 3.5)\"\n\n$Imports\n[1] \"cli (>= 3.2.0), clipr, crayon, hms (>= 0.4.1), lifecycle (>=\\n0.2.0), methods, R6, rlang, tibble, utils, vroom (>= 1.6.0)\"\n\n$Suggests\n[1] \"covr, curl, datasets, knitr, rmarkdown, spelling, stringi,\\ntestthat (>= 3.1.2), tzdb (>= 0.1.1), waldo, withr, xml2\"\n\nget_deps(\"stringr\")\n\n$Package\n[1] \"stringr\"\n\n$Depends\n[1] \"R (>= 3.3)\"\n\n$Imports\n[1] \"cli, glue (>= 1.6.1), lifecycle (>= 1.0.3), magrittr, rlang\\n(>= 1.0.0), stringi (>= 1.5.3), vctrs\"\n\n$Suggests\n[1] \"covr, htmltools, htmlwidgets, knitr, rmarkdown, testthat (>=\\n3.0.0)\"\n\n# Not surprisingly tabulizer doesn't return any values since it is not on CRAN\nget_deps(\"tabulizer\")\n\n$Package\ncharacter(0)\n\n$Depends\ncharacter(0)\n\n$Imports\ncharacter(0)\n\n$Suggests\ncharacter(0)\n\n\nFor tabulizer, we will need to get this information from the github repository for the package in the DESCRIPTION file. The only way I’ve thought of being able to access this is through the URL but I don’t think this is modular enough for all packages installed on github with differing remote urls. The {desc} package seems only helpful for manipulating already documented DESCRIPTION files, while the {remotes} package seems to provide options for installation, I could not figure out how to retrieve the DESCRIPTION data for a particular package :(\nRead through chapter 5.2 of Licensing R. Combine and adjust the code pieces to create the dependencies for a package that is on github rather than CRAN. (Don’t forget about the package desc.) What dependencies does the package have that you created for Lab-3? Which licenses are involved? Are all of these dependencies required? Elaborate.\nUnder which license should this blog post be published? Make sure that you are using an appropriate license. (You can change the current licenses with the help of commands from the use_license_XXX family in the usethis package)\nThis blog currently is operating under the Creative Commons Legal Code CC0 1.0 Universal license. It does use RMarkdown which operates under the GNU General Public License and the GNU recommends that the license be distributed in the form of a GPL. To change this, we can use the {usethis} package.\n\nlibrary(\"usethis\")\nusethis::use_gpl_license(version = 3)\n\n✔ Setting active project to '/Users/hofmann/Documents/Teaching/Stat 585/Spring 2023/Stat585-at-ISU.github.io'\n✔ Writing 'LICENSE.md'\n✔ Adding '^LICENSE\\\\.md$' to 'blog-2023/Blog-7-submissions/HarunCelikOtto/.Rbuildignore'\n\n\nThis package is now licensed by GPL Version 4. This can be checked in the License.md file.\n\n\nCan I publish an R package on CRAN under an MIT license when I have a dependency on a package that is licensed under GPL-3?\nWhen confronted with the above question, ChatGPT gave two – quite different – responses, as shown below. The main point in both responses is ‘your package may be considered derivative work’. At the specific problem of the package developed for Lab 3, what is your opinion about potential copyright infringements when releasing the package with an MIT license? Make sure to take the relevant passage in Colin Fay’s book under consideration.\nThe legal implications of publishing an R package on CRAN under an MIT license while having a dependency on a package that is licensed under GPL-3 are complex and can vary depending on the specific circumstances. It is always advisable to seek legal advice from a licensed attorney if you have any doubts or concerns about licensing issues.\n\nHowever, in general, it is possible to publish an R package on CRAN under an MIT license when you have a dependency on a package that is licensed under GPL-3. This is because the MIT license is a permissive open-source license that allows for more flexibility in how the software can be used and distributed, and it is generally considered compatible with the GPL-3 license.\n\nThat being said, if your package depends on a GPL-3-licensed package, your package may be considered a derivative work and therefore subject to the terms of the GPL-3 license. This means that if you distribute your package, you may need to also distribute the source code for your package under the GPL-3 license or a compatible license, and you may need to ensure that the requirements of the GPL-3 license are met for the entire distribution, including any dependencies.\n\nIt is also worth noting that the R community has its own guidelines and recommendations for package licensing, and it is important to comply with these guidelines if you want to publish your package on CRAN. The CRAN Repository Policy states that packages should have a \"permissive\" or \"GPL-compatible\" license, but does not explicitly require that packages use the GPL license or any other specific license.\n\nIn summary, while it is possible to publish an R package on CRAN under an MIT license while having a dependency on a package that is licensed under GPL-3, it is important to understand the implications of the different licenses and to ensure that you comply with any applicable guidelines and recommendations from the R community.\nAfter harping a bit on copyright infringement in general, ChatGPT changed its response to\nTechnically, you can publish an R package on CRAN under an MIT license when you have a dependency on a package that is licensed under GPL-3, but doing so would not be compliant with the terms of the GPL-3 license.\n\nThe GPL-3 license is a strong copyleft license that requires derivative works to be released under the same license. If your package depends on a GPL-3-licensed package, your package may be considered a derivative work and therefore must be licensed under the GPL-3 license or a compatible license.\n\nThe MIT license, on the other hand, is a permissive license that allows for more flexibility in how the software is used and distributed. However, it is not compatible with the GPL-3 license, and therefore cannot be used for derivative works of GPL-3-licensed software.\n\nPublishing an R package on CRAN under an MIT license when you have a dependency on a package that is licensed under GPL-3 would be a licensing violation, and could potentially result in legal action or other consequences. It is important to comply with the licensing requirements of all dependencies in your package to avoid any legal issues.\nThe ‘harping’ questions:\n\nIs it legal to publish an R package on CRAN under an MIT license when I have a dependency on a package that is licensed under GPL-3?\nIs it illegal to publish an R package on CRAN under an MIT license when I have a dependency on a package that is licensed under GPL-3?\nIs it a copyright infringement to publish an R package on CRAN under an MIT license when I have a dependency on a package that is licensed under GPL-3?\nCan I publish an R package on CRAN under an MIT license when I have a dependency on a package that is licensed under GPL-3 without infringing copyright?"
  },
  {
    "objectID": "blog-2023/Blog-7-submissions/HarunCelikOtto/index.html#submission",
    "href": "blog-2023/Blog-7-submissions/HarunCelikOtto/index.html#submission",
    "title": "Split-Apply-Combine Post",
    "section": "Submission",
    "text": "Submission\nWrite answers to the questions directly into the file README.Rmd. Push the blog post to your blog-7 repo. Make sure that all of the checks are passing."
  },
  {
    "objectID": "blog-2023/Blog-7-submissions/valeriehan6/index.html#prompt",
    "href": "blog-2023/Blog-7-submissions/valeriehan6/index.html#prompt",
    "title": "Licenses",
    "section": "Prompt:",
    "text": "Prompt:\nThe DESCRIPTION file of a package contains the package’s meta information. Most of the fields in this file are quite straight forward: author, version number, and a short package description. When you call library(help=\"<package name>\") for package <package name> you can see the contents of the DESCRIPTION file for that package (and some parts of the NAMESPACE file).\nRead through Colin Fay’s (short) book on Licensing R\nWrite a blog post addressing the following questions:\n\nUnder what license does R operate? What is the license for ggplot2?\nR uses a GNU General Public License (either Version 2 or Version 3). ggplot2 uses an MIT license.\n\n\nWhat are the dependencies of the package you made?\nRead through chapter 5.2 of Licensing R. Combine and adjust the code pieces to create the dependencies for a package that is on github rather than CRAN. (Don’t forget about the package desc.) What dependencies does the package have that you created for Lab-3? Which licenses are involved? Are all of these dependencies required? Elaborate.\nThe dependecies are dplyr, lubridate, purrr, R (>= 2.10), readr, tabulizer, and tibble.\nThey use MIT licenses for the most part with one GPL (\\(\\geq 2\\)) license. All these dependencies are required for the package as it’s currently written because we use functions from these packages in our package’s functions.\n\n# code adapted from section 5.2 of https://thinkr-open.github.io/licensing-r/practical.html\n\nlibrary(tidyr)\nlibrary(dplyr)\n\npkgdb <- tools::CRAN_package_db()\n\nextract_from_cran_db <- function(deps, pkgdb){\n  pkgdb %>%\n    as_tibble(.name_repair = \"universal\") %>%\n    filter(Package %in% deps) \n}\n\n# copied from DESCRIPTION file\ndeps <- c(\"dplyr\",\n          \"lubridate\",\n          \"purrr\",\n          \"readr\",\n          \"tabulizer\", # has MIT license (checked its github repo)\n          \"tibble\",\n          \"utils\")\n\ndeps <- extract_from_cran_db(deps, pkgdb)\n\ndeps %>%\n  count(\n    License\n  )\n\nUnder which license should this blog post be published? Make sure that you are using an appropriate license. (You can change the current licenses with the help of commands from the use_license_XXX family in the usethis package)\nThis blog post should be published under the same license as the book (CC BY-NC-SA 4.0 license) since we use modified code from the book. (Note that the libraries we use for the code are all MIT-licensed.)\n\ndeps <- c(\"dplyr\",\n          \"tidyr\",\n          \"tools\")\n\ndeps <- extract_from_cran_db(deps, pkgdb)\n\ndeps %>%\n  count(\n    License\n  )\n\n\n\nCan I publish an R package on CRAN under an MIT license when I have a dependency on a package that is licensed under GPL-3?\nWhen confronted with the above question, ChatGPT gave two – quite different – responses, as shown below. The main point in both responses is ‘your package may be considered derivative work’. At the specific problem of the package developed for Lab 3, what is your opinion about potential copyright infringements when releasing the package with an MIT license? Make sure to take the relevant passage in Colin Fay’s book under consideration.\nThe legal implications of publishing an R package on CRAN under an MIT license while having a dependency on a package that is licensed under GPL-3 are complex and can vary depending on the specific circumstances. It is always advisable to seek legal advice from a licensed attorney if you have any doubts or concerns about licensing issues.\n\nHowever, in general, it is possible to publish an R package on CRAN under an MIT license when you have a dependency on a package that is licensed under GPL-3. This is because the MIT license is a permissive open-source license that allows for more flexibility in how the software can be used and distributed, and it is generally considered compatible with the GPL-3 license.\n\nThat being said, if your package depends on a GPL-3-licensed package, your package may be considered a derivative work and therefore subject to the terms of the GPL-3 license. This means that if you distribute your package, you may need to also distribute the source code for your package under the GPL-3 license or a compatible license, and you may need to ensure that the requirements of the GPL-3 license are met for the entire distribution, including any dependencies.\n\nIt is also worth noting that the R community has its own guidelines and recommendations for package licensing, and it is important to comply with these guidelines if you want to publish your package on CRAN. The CRAN Repository Policy states that packages should have a \"permissive\" or \"GPL-compatible\" license, but does not explicitly require that packages use the GPL license or any other specific license.\n\nIn summary, while it is possible to publish an R package on CRAN under an MIT license while having a dependency on a package that is licensed under GPL-3, it is important to understand the implications of the different licenses and to ensure that you comply with any applicable guidelines and recommendations from the R community.\nAfter harping a bit on copyright infringement in general, ChatGPT changed its response to\nTechnically, you can publish an R package on CRAN under an MIT license when you have a dependency on a package that is licensed under GPL-3, but doing so would not be compliant with the terms of the GPL-3 license.\n\nThe GPL-3 license is a strong copyleft license that requires derivative works to be released under the same license. If your package depends on a GPL-3-licensed package, your package may be considered a derivative work and therefore must be licensed under the GPL-3 license or a compatible license.\n\nThe MIT license, on the other hand, is a permissive license that allows for more flexibility in how the software is used and distributed. However, it is not compatible with the GPL-3 license, and therefore cannot be used for derivative works of GPL-3-licensed software.\n\nPublishing an R package on CRAN under an MIT license when you have a dependency on a package that is licensed under GPL-3 would be a licensing violation, and could potentially result in legal action or other consequences. It is important to comply with the licensing requirements of all dependencies in your package to avoid any legal issues.\nThe ‘harping’ questions:\n\nIs it legal to publish an R package on CRAN under an MIT license when I have a dependency on a package that is licensed under GPL-3?\nIs it illegal to publish an R package on CRAN under an MIT license when I have a dependency on a package that is licensed under GPL-3?\nIs it a copyright infringement to publish an R package on CRAN under an MIT license when I have a dependency on a package that is licensed under GPL-3?\nCan I publish an R package on CRAN under an MIT license when I have a dependency on a package that is licensed under GPL-3 without infringing copyright?\n\nI believe the best route to take would be to publish under the more restrictive license to be safe because it seems that such a dependency is in the “borderline case” of being considered a “combined work.” The argument in the book is that we have to install the dependent packages to run our package’s functions and therefore we would be violating the GPL license. However, it seems that by using an MIT license, we would be saying our code is fine for people to use, so publishing our package under an MIT license would still allow people to use our functions that don’t depend on those GPL-licensed packages or modify code from our package to write their own functions. Essentially, I think the applying the MIT license to our package could still increase the utility for others compared to publishing with the GPL license."
  },
  {
    "objectID": "blog-2023/Blog-7-submissions/valeriehan6/index.html#submission",
    "href": "blog-2023/Blog-7-submissions/valeriehan6/index.html#submission",
    "title": "Licenses",
    "section": "Submission",
    "text": "Submission\nWrite answers to the questions directly into the file README.Rmd. Push the blog post to your blog-7 repo. Make sure that all of the checks are passing."
  },
  {
    "objectID": "blog-2023/Blog-7-submissions/IanParzyszek/index.html#prompt",
    "href": "blog-2023/Blog-7-submissions/IanParzyszek/index.html#prompt",
    "title": "What License when?",
    "section": "Prompt:",
    "text": "Prompt:\nThe DESCRIPTION file of a package contains the package’s meta information. Most of the fields in this file are quite straight forward: author, version number, and a short package description. When you call library(help=\"<package name>\") for package <package name> you can see the contents of the DESCRIPTION file for that package (and some parts of the NAMESPACE file).\nRead through Colin Fay’s (short) book on Licensing R\nWrite a blog post addressing the following questions:\n\nUnder what license does R operate? What is the license for ggplot2?\n— R operates under a General Public License either version 2 from June 1991 or version 3 from June 2007. ggplot2 however runs off of an MIT license. A MIT license is a license that gives explicit consent for the users to reuse their code for any purpose.\n\n\nWhat are the dependencies of the package you made?\nRead through chapter 5.2 of Licensing R. Combine and adjust the code pieces to create the dependencies for a package that is on github rather than CRAN. (Don’t forget about the package desc.) What dependencies does the package have that you created for Lab-3?\n\nusethis::use_package(“dplyr”) usethis::use_package(“tabulizer”) usethis::use_package(“lubridate”) usethis::use_package(“readr”) usethis::use_package(“stringr”)\nWhich licenses are involved? ‘dplyr’ uses an MIT license ‘tabulizer’uses an MIT license ’lubridate’ uses a GPL-2 | GPL-3 license ‘readr’ uses an MIT license ‘stringr’ uses an MIT license\nWe are using an MIT license for our package.\nAre all of these dependencies required? Elaborate.\nThe way we set up our dependecies these packages are required. However, you can set up dependencies in different ways. If you use “Imports” then you need to have that package downloaded when you install the package. Or you could have the dependencies as suggestions and it will just suggest that you download a certain package, but will not make you and will not install the package when you intall the intended package.\nUnder which license should this blog post be published? Make sure that you are using an appropriate license. (You can change the current licenses with the help of commands from the use_license_XXX family in the usethis package)\nFor this blog post I a using a CC-BY-SA-4.0 license. This is used for creative non-comercial purposes.\n\n\nCan I publish an R package on CRAN under an MIT license when I have a dependency on a package that is licensed under GPL-3?\nWhen confronted with the above question, ChatGPT gave two – quite different – responses, as shown below. The main point in both responses is ‘your package may be considered derivative work’. At the specific problem of the package developed for Lab 3, what is your opinion about potential copyright infringements when releasing the package with an MIT license? Make sure to take the relevant passage in Colin Fay’s book under consideration.\nThe thing that stuck out to me most about Colin Fay’s paper was the idea of whether or not the work you are creating is going to be used for commercial use. Because we are not going to be using our package for commercial use I think we should be in the clear. However, I think if we wanted to actually publish this code via CRAN we would have to also publish our code under a GPL-3 license. Even though I have found instances where there have been instances where someone has published a package with GPL dependencies under and MIT license, example being ‘memoise’\nThe legal implications of publishing an R package on CRAN under an MIT license while having a dependency on a package that is licensed under GPL-3 are complex and can vary depending on the specific circumstances. It is always advisable to seek legal advice from a licensed attorney if you have any doubts or concerns about licensing issues.\n\nHowever, in general, it is possible to publish an R package on CRAN under an MIT license when you have a dependency on a package that is licensed under GPL-3. This is because the MIT license is a permissive open-source license that allows for more flexibility in how the software can be used and distributed, and it is generally considered compatible with the GPL-3 license.\n\nThat being said, if your package depends on a GPL-3-licensed package, your package may be considered a derivative work and therefore subject to the terms of the GPL-3 license. This means that if you distribute your package, you may need to also distribute the source code for your package under the GPL-3 license or a compatible license, and you may need to ensure that the requirements of the GPL-3 license are met for the entire distribution, including any dependencies.\n\nIt is also worth noting that the R community has its own guidelines and recommendations for package licensing, and it is important to comply with these guidelines if you want to publish your package on CRAN. The CRAN Repository Policy states that packages should have a \"permissive\" or \"GPL-compatible\" license, but does not explicitly require that packages use the GPL license or any other specific license.\n\nIn summary, while it is possible to publish an R package on CRAN under an MIT license while having a dependency on a package that is licensed under GPL-3, it is important to understand the implications of the different licenses and to ensure that you comply with any applicable guidelines and recommendations from the R community.\nAfter harping a bit on copyright infringement in general, ChatGPT changed its response to\nTechnically, you can publish an R package on CRAN under an MIT license when you have a dependency on a package that is licensed under GPL-3, but doing so would not be compliant with the terms of the GPL-3 license.\n\nThe GPL-3 license is a strong copyleft license that requires derivative works to be released under the same license. If your package depends on a GPL-3-licensed package, your package may be considered a derivative work and therefore must be licensed under the GPL-3 license or a compatible license.\n\nThe MIT license, on the other hand, is a permissive license that allows for more flexibility in how the software is used and distributed. However, it is not compatible with the GPL-3 license, and therefore cannot be used for derivative works of GPL-3-licensed software.\n\nPublishing an R package on CRAN under an MIT license when you have a dependency on a package that is licensed under GPL-3 would be a licensing violation, and could potentially result in legal action or other consequences. It is important to comply with the licensing requirements of all dependencies in your package to avoid any legal issues.\nThe ‘harping’ questions:\n\nIs it legal to publish an R package on CRAN under an MIT license when I have a dependency on a package that is licensed under GPL-3?\n\nNo\n\nIs it illegal to publish an R package on CRAN under an MIT license when I have a dependency on a package that is licensed under GPL-3? Yes? The legality is really unclear, is from what I understood.\nIs it a copyright infringement to publish an R package on CRAN under an MIT license when I have a dependency on a package that is licensed under GPL-3?\n\nYes\n\nCan I publish an R package on CRAN under an MIT license when I have a dependency on a package that is licensed under GPL-3 without infringing copyright?\n\nNo"
  },
  {
    "objectID": "blog-2023/Blog-7-submissions/IanParzyszek/index.html#submission",
    "href": "blog-2023/Blog-7-submissions/IanParzyszek/index.html#submission",
    "title": "What License when?",
    "section": "Submission",
    "text": "Submission\nWrite answers to the questions directly into the file README.Rmd. Push the blog post to your blog-7 repo. Make sure that all of the checks are passing."
  },
  {
    "objectID": "blog-2023/Blog-7-submissions/loganjohnson0/index.html#prompt",
    "href": "blog-2023/Blog-7-submissions/loganjohnson0/index.html#prompt",
    "title": "Legal Stuff",
    "section": "Prompt:",
    "text": "Prompt:\nThe DESCRIPTION file of a package contains the package’s meta information. Most of the fields in this file are quite straight forward: author, version number, and a short package description. When you call library(help=\"<package name>\") for package <package name> you can see the contents of the DESCRIPTION file for that package (and some parts of the NAMESPACE file).\nRead through Colin Fay’s (short) book on Licensing R\nWrite a blog post addressing the following questions:\n\nUnder what license does R operate? What is the license for ggplot2?\n\n\nMy Responses:\n\nR\nR operates under a multitude of licenses, including either the GNU General Public License (GPL) Version 2 or Version 3. R also states that a few files are distributed under the LESSER GNU GPL, version 2.1 or later.\n\n\nggplot2\nggplot2 operates under an MIT + file license.\n\n\n\nWhat are the dependencies of the package you made?\nRead through chapter 5.2 of Licensing R. Combine and adjust the code pieces to create the dependencies for a package that is on github rather than CRAN. (Don’t forget about the package desc.) What dependencies does the package have that you created for Lab-3? Which licenses are involved? Are all of these dependencies required? Elaborate.\nUnder which license should this blog post be published? Make sure that you are using an appropriate license. (You can change the current licenses with the help of commands from the use_license_XXX family in the usethis package)\n\n\nMy Responses:\n• I looked at the emo package and compared it with ggplot2. emo is hosted on github while ggplot2 has CRAN listed as the repository. The ggplot2 package has a different license than the emo package, listed under the MIT + file license or GPL-3 licenses, respectively.\n• Without explicitly adding to the dependencies part of the package, each new package includes the dependency of R (>= 2.10). This is true of the package made during Lab 3. There is an MIT + file license for the new package that we created. Since each of the packages are considered “add-on” or “extensions” of R, and R is licensed under a GPL-2 or GPL-3 license, each of the “add-on” or packages developed have to be licensed under a GPL-compatible license. This blog post could or should be licensed under a Creative Commons Attribution-NonCommercial-NoDerivs 3.0 United States License because it requires attribution while restricting commercial use or derivative work.\n\n\nCan I publish an R package on CRAN under an MIT license when I have a dependency on a package that is licensed under GPL-3?\nWhen confronted with the above question, ChatGPT gave two – quite different – responses, as shown below. The main point in both responses is ‘your package may be considered derivative work’. At the specific problem of the package developed for Lab 3, what is your opinion about potential copyright infringements when releasing the package with an MIT license? Make sure to take the relevant passage in Colin Fay’s book under consideration.\n\n\nMy Responses:\n•This is a tricky questions. Our package in Lab 3 includes data that we did not create. This data is publicly available, but since it is accessing the data, it would be best to have the user of the package acknowledge the license or the initial location of the public data, similar to the example that was used with the textdata and tinytex examples in the book. If the user were to use the get_pd_presslog function from our package, the user could be prompted with a message on the license about the data.\n•I think the legality of the MIT license having a dependency on the GPL-3 license is kind of a gray area. It might depend on the type of data or information under the GPL-3 license. Conversely, my knowledge of the legality of these licenses could be completely the opposite where it is illegal to do this but because of the populations poor understanding of this and the lack of control or enforcement by the GPL-3 license holders, this type of violation continues to pass through the system.\nThe legal implications of publishing an R package on CRAN under an MIT license while having a dependency on a package that is licensed under GPL-3 are complex and can vary depending on the specific circumstances. It is always advisable to seek legal advice from a licensed attorney if you have any doubts or concerns about licensing issues.\n\nHowever, in general, it is possible to publish an R package on CRAN under an MIT license when you have a dependency on a package that is licensed under GPL-3. This is because the MIT license is a permissive open-source license that allows for more flexibility in how the software can be used and distributed, and it is generally considered compatible with the GPL-3 license.\n\nThat being said, if your package depends on a GPL-3-licensed package, your package may be considered a derivative work and therefore subject to the terms of the GPL-3 license. This means that if you distribute your package, you may need to also distribute the source code for your package under the GPL-3 license or a compatible license, and you may need to ensure that the requirements of the GPL-3 license are met for the entire distribution, including any dependencies.\n\nIt is also worth noting that the R community has its own guidelines and recommendations for package licensing, and it is important to comply with these guidelines if you want to publish your package on CRAN. The CRAN Repository Policy states that packages should have a \"permissive\" or \"GPL-compatible\" license, but does not explicitly require that packages use the GPL license or any other specific license.\n\nIn summary, while it is possible to publish an R package on CRAN under an MIT license while having a dependency on a package that is licensed under GPL-3, it is important to understand the implications of the different licenses and to ensure that you comply with any applicable guidelines and recommendations from the R community.\nAfter harping a bit on copyright infringement in general, ChatGPT changed its response to\nTechnically, you can publish an R package on CRAN under an MIT license when you have a dependency on a package that is licensed under GPL-3, but doing so would not be compliant with the terms of the GPL-3 license.\n\nThe GPL-3 license is a strong copyleft license that requires derivative works to be released under the same license. If your package depends on a GPL-3-licensed package, your package may be considered a derivative work and therefore must be licensed under the GPL-3 license or a compatible license.\n\nThe MIT license, on the other hand, is a permissive license that allows for more flexibility in how the software is used and distributed. However, it is not compatible with the GPL-3 license, and therefore cannot be used for derivative works of GPL-3-licensed software.\n\nPublishing an R package on CRAN under an MIT license when you have a dependency on a package that is licensed under GPL-3 would be a licensing violation, and could potentially result in legal action or other consequences. It is important to comply with the licensing requirements of all dependencies in your package to avoid any legal issues.\nThe ‘harping’ questions:\n\nIs it legal to publish an R package on CRAN under an MIT license when I have a dependency on a package that is licensed under GPL-3?\nIs it illegal to publish an R package on CRAN under an MIT license when I have a dependency on a package that is licensed under GPL-3?\nIs it a copyright infringement to publish an R package on CRAN under an MIT license when I have a dependency on a package that is licensed under GPL-3?\nCan I publish an R package on CRAN under an MIT license when I have a dependency on a package that is licensed under GPL-3 without infringing copyright?"
  },
  {
    "objectID": "blog-2023/Blog-7-submissions/loganjohnson0/index.html#submission",
    "href": "blog-2023/Blog-7-submissions/loganjohnson0/index.html#submission",
    "title": "Legal Stuff",
    "section": "Submission",
    "text": "Submission\nWrite answers to the questions directly into the file README.Rmd. Push the blog post to your blog-7 repo. Make sure that all of the checks are passing."
  },
  {
    "objectID": "blog-2023/Blog-7-submissions/Atefeha1995/index.html#prompt",
    "href": "blog-2023/Blog-7-submissions/Atefeha1995/index.html#prompt",
    "title": "All that legal stuff…",
    "section": "Prompt:",
    "text": "Prompt:\nThe DESCRIPTION file of a package contains the package’s meta information. Most of the fields in this file are quite straight forward: author, version number, and a short package description. When you call library(help=\"<package name>\") for package <package name> you can see the contents of the DESCRIPTION file for that package (and some parts of the NAMESPACE file).\nRead through Colin Fay’s (short) book on Licensing R\nWrite a blog post addressing the following questions:\n\nUnder what license does R operate? What is the license for ggplot2?\nFree software known as R was made available under the terms of the GNU General Public License, either version 2 (June 1991) or version 3 (as of the time of writing) (June 2007). I was able to obtain it by using R’s “licence()” function. The MIT + file License governs the distribution of the ggplot2 package.\n\n\nWhat are the dependencies of the package you made?\nRead through chapter 5.2 of Licensing R. Combine and adjust the code pieces to create the dependencies for a package that is on github rather than CRAN. (Don’t forget about the package desc.) What dependencies does the package have that you created for Lab-3? Which licenses are involved? Are all of these dependencies required? Elaborate.\nFirst, as described in Chapter 5.2, I utilized the code and regenerated the results for the golem package. Then, I repeated the process for the package we created for Lab 3 called AmesPD. The outcome for package dependencies is as follows:\n There were 29 observations for dependencies, and the picture above shows the first six observations. Then, I counted the licenses for these dependencies:\n\nThis code was for exploring the dependencies of a R package on CRAN. If we want to do the same for a package in GitHub, we need to just install the package and call the library. Then we can find it’s dependencies using the same method.\nUnder which license should this blog post be published? Make sure that you are using an appropriate license. (You can change the current licenses with the help of commands from the use_license_XXX family in the usethis package)\nWe are currently using license CC0 1.0 Universal which is in LICENSE file. It seems that there are different licenses which gives the user enough information about the repository and it’s files. The license make the user understood that what parts or files he/she can use, and also protect the author rights. We can change the license type, but I won’t do this. For example CC is the keyword of Creative Commons license family.\n\n\nCan I publish an R package on CRAN under an MIT license when I have a dependency on a package that is licensed under GPL-3?\nWhen confronted with the above question, ChatGPT gave two – quite different – responses, as shown below. The main point in both responses is ‘your package may be considered derivative work’. At the specific problem of the package developed for Lab 3, what is your opinion about potential copyright infringements when releasing the package with an MIT license? Make sure to take the relevant passage in Colin Fay’s book under consideration.\nAccording to the Colin Fay book, a package that is GPL-3 licensed is compatible with and recognized by the CRAN policy. As a result, it is conceivable to publish it in CRAN, although doing so requires the consent of every author. The contributors’ discussion and announcement of permissions may take place on Github.\nThe legal implications of publishing an R package on CRAN under an MIT license while having a dependency on a package that is licensed under GPL-3 are complex and can vary depending on the specific circumstances. It is always advisable to seek legal advice from a licensed attorney if you have any doubts or concerns about licensing issues.\n\nHowever, in general, it is possible to publish an R package on CRAN under an MIT license when you have a dependency on a package that is licensed under GPL-3. This is because the MIT license is a permissive open-source license that allows for more flexibility in how the software can be used and distributed, and it is generally considered compatible with the GPL-3 license.\n\nThat being said, if your package depends on a GPL-3-licensed package, your package may be considered a derivative work and therefore subject to the terms of the GPL-3 license. This means that if you distribute your package, you may need to also distribute the source code for your package under the GPL-3 license or a compatible license, and you may need to ensure that the requirements of the GPL-3 license are met for the entire distribution, including any dependencies.\n\nIt is also worth noting that the R community has its own guidelines and recommendations for package licensing, and it is important to comply with these guidelines if you want to publish your package on CRAN. The CRAN Repository Policy states that packages should have a \"permissive\" or \"GPL-compatible\" license, but does not explicitly require that packages use the GPL license or any other specific license.\n\nIn summary, while it is possible to publish an R package on CRAN under an MIT license while having a dependency on a package that is licensed under GPL-3, it is important to understand the implications of the different licenses and to ensure that you comply with any applicable guidelines and recommendations from the R community.\nAfter harping a bit on copyright infringement in general, ChatGPT changed its response to\nTechnically, you can publish an R package on CRAN under an MIT license when you have a dependency on a package that is licensed under GPL-3, but doing so would not be compliant with the terms of the GPL-3 license.\n\nThe GPL-3 license is a strong copyleft license that requires derivative works to be released under the same license. If your package depends on a GPL-3-licensed package, your package may be considered a derivative work and therefore must be licensed under the GPL-3 license or a compatible license.\n\nThe MIT license, on the other hand, is a permissive license that allows for more flexibility in how the software is used and distributed. However, it is not compatible with the GPL-3 license, and therefore cannot be used for derivative works of GPL-3-licensed software.\n\nPublishing an R package on CRAN under an MIT license when you have a dependency on a package that is licensed under GPL-3 would be a licensing violation, and could potentially result in legal action or other consequences. It is important to comply with the licensing requirements of all dependencies in your package to avoid any legal issues.\nThe ‘harping’ questions:\n\nIs it legal to publish an R package on CRAN under an MIT license when I have a dependency on a package that is licensed under GPL-3?\nIs it illegal to publish an R package on CRAN under an MIT license when I have a dependency on a package that is licensed under GPL-3?\nIs it a copyright infringement to publish an R package on CRAN under an MIT license when I have a dependency on a package that is licensed under GPL-3?\nCan I publish an R package on CRAN under an MIT license when I have a dependency on a package that is licensed under GPL-3 without infringing copyright?"
  },
  {
    "objectID": "blog-2023/Blog-7-submissions/Atefeha1995/index.html#submission",
    "href": "blog-2023/Blog-7-submissions/Atefeha1995/index.html#submission",
    "title": "All that legal stuff…",
    "section": "Submission",
    "text": "Submission\nWrite answers to the questions directly into the file README.Rmd. Push the blog post to your blog-7 repo. Make sure that all of the checks are passing."
  },
  {
    "objectID": "blog-2023/Blog-7-submissions/anphan0828/index.html#prompt",
    "href": "blog-2023/Blog-7-submissions/anphan0828/index.html#prompt",
    "title": "It’s not the end…",
    "section": "Prompt:",
    "text": "Prompt:\nThe DESCRIPTION file of a package contains the package’s meta information. Most of the fields in this file are quite straight forward: author, version number, and a short package description. When you call library(help=\"<package name>\") for package <package name> you can see the contents of the DESCRIPTION file for that package (and some parts of the NAMESPACE file).\nRead through Colin Fay’s (short) book on Licensing R\nWrite a blog post addressing the following questions:\n\nlibrary(rmarkdown)\n\n\nUnder what license does R operate? What is the license for ggplot2?\nR operates under many licenses, including GPL-2 | GPL-3 (General Public License, version 2 and 3), all of which are listed here or in Licensing R.\nggplot2 is MIT-licensed as stated on CRAN documentation\n\n\nWhat are the dependencies of the package you made?\nRead through chapter 5.2 of Licensing R.\n\nCombine and adjust the code pieces to create the dependencies for a package that is on github rather than CRAN. (Don’t forget about the package desc.)\n\n## Get all information on CRAN packages\n# install.packages(\"pkgnet\")\nlibrary(pkgnet)\npkgdb <- tools::CRAN_package_db()\n\n## Filter dependencies: input a list of package names, output a dataframe of these packages' information on CRAN\nextract_from_cran_db <- function(pkg_names, pkgdb){\n  pkgdb %>%\n    as_tibble(.name_repair = \"universal\") %>%\n    filter(Package %in% pkg_names)\n}\n\n\n\nWhat dependencies does the package have that you created for Lab-3?\nBecause our package is not on CRAN, we need desc to extract the dependencies.\n\n## Do the following in our team's package repo, load `plogdeps` and `plCRAN` dataframe here\nload(\"Lab-3-UNL-dependencies.RData\")\n# plogdeps <- desc::desc_get_deps(file=\"PressLogTeamUNL/\")\nplogdeps\n\n     type   package  version\n1 Depends         R  >= 2.10\n2 Imports lubridate        *\n3 Imports     purrr        *\n4 Imports tabulizer >= 0.2.3\n5 Imports     dplyr        *\n6 Imports     readr        *\n\n# plCRAN <- extract_from_cran_db(plogdeps$package, pkgdb)%>%\n#  select(Package,Version,Depends,License,License_is_FOSS,License_restricts_use)\nplCRAN\n\n    Package Version             Depends            License License_is_FOSS\n1     dplyr   1.1.0        R (>= 3.4.0) MIT + file LICENSE            <NA>\n2 lubridate   1.9.2 methods, R (>= 3.2)         GPL (>= 2)            <NA>\n3     purrr   1.0.1        R (>= 3.4.0) MIT + file LICENSE            <NA>\n4     readr   2.1.4          R (>= 3.5) MIT + file LICENSE            <NA>\n  License_restricts_use\n1                  <NA>\n2                  <NA>\n3                  <NA>\n4                  <NA>\n\n\n\n\nWhich licenses are involved? Are all of these dependencies required? Elaborate.\n6 dependencies are reported using desc package:\n\nBase R is required\nImports (as shown in plCRAN): lubridate (GPL >= 2), purrr, dplyr, readr (MIT licensed for these 3 pacakges)\ntabulizer also needs to be imported (as shown in plogdeps), but this package is not on CRAN so it is not found in CRAN pkgdb. tabulizer is also under MIT license as shown in this documentation\n\n\n\nUnder which license should this blog post be published? Make sure that you are using an appropriate license. (You can change the current licenses with the help of commands from the use_license_XXX family in the usethis package)\nAccording to the book, blog posts are also copyrighted and the content should be licensed in a way that allows others to reuse (or not reuse) your work. For example, answeres on StackOverflow (what we did in Blog 1) is released in CC-BY-SA 3.0. So I’m guessing this blog post should be licensed similarly.\n\nusethis::use_ccby_license()\n\n✔ Setting active project to '/Users/hofmann/Documents/Teaching/Stat 585/Spring 2023/Stat585-at-ISU.github.io'\n✔ Leaving 'LICENSE.md' unchanged\n\n\n\n\n\nCan I publish an R package on CRAN under an MIT license when I have a dependency on a package that is licensed under GPL-3?\nWhen confronted with the above question, ChatGPT gave two – quite different – responses, as shown below. The main point in both responses is ‘your package may be considered derivative work’. At the specific problem of the package developed for Lab 3, what is your opinion about potential copyright infringements when releasing the package with an MIT license? Make sure to take the relevant passage in Colin Fay’s book under consideration.\nThe legal implications of publishing an R package on CRAN under an MIT license while having a dependency on a package that is licensed under GPL-3 are complex and can vary depending on the specific circumstances. It is always advisable to seek legal advice from a licensed attorney if you have any doubts or concerns about licensing issues.\n\nHowever, in general, it is possible to publish an R package on CRAN under an MIT license when you have a dependency on a package that is licensed under GPL-3. This is because the MIT license is a permissive open-source license that allows for more flexibility in how the software can be used and distributed, and it is generally considered compatible with the GPL-3 license.\n\nThat being said, if your package depends on a GPL-3-licensed package, your package may be considered a derivative work and therefore subject to the terms of the GPL-3 license. This means that if you distribute your package, you may need to also distribute the source code for your package under the GPL-3 license or a compatible license, and you may need to ensure that the requirements of the GPL-3 license are met for the entire distribution, including any dependencies.\n\nIt is also worth noting that the R community has its own guidelines and recommendations for package licensing, and it is important to comply with these guidelines if you want to publish your package on CRAN. The CRAN Repository Policy states that packages should have a \"permissive\" or \"GPL-compatible\" license, but does not explicitly require that packages use the GPL license or any other specific license.\n\nIn summary, while it is possible to publish an R package on CRAN under an MIT license while having a dependency on a package that is licensed under GPL-3, it is important to understand the implications of the different licenses and to ensure that you comply with any applicable guidelines and recommendations from the R community.\nAfter harping a bit on copyright infringement in general, ChatGPT changed its response to\nTechnically, you can publish an R package on CRAN under an MIT license when you have a dependency on a package that is licensed under GPL-3, but doing so would not be compliant with the terms of the GPL-3 license.\n\nThe GPL-3 license is a strong copyleft license that requires derivative works to be released under the same license. If your package depends on a GPL-3-licensed package, your package may be considered a derivative work and therefore must be licensed under the GPL-3 license or a compatible license.\n\nThe MIT license, on the other hand, is a permissive license that allows for more flexibility in how the software is used and distributed. However, it is not compatible with the GPL-3 license, and therefore cannot be used for derivative works of GPL-3-licensed software.\n\nPublishing an R package on CRAN under an MIT license when you have a dependency on a package that is licensed under GPL-3 would be a licensing violation, and could potentially result in legal action or other consequences. It is important to comply with the licensing requirements of all dependencies in your package to avoid any legal issues.\nThe ‘harping’ questions:\n\nIs it legal to publish an R package on CRAN under an MIT license when I have a dependency on a package that is licensed under GPL-3?\nIs it illegal to publish an R package on CRAN under an MIT license when I have a dependency on a package that is licensed under GPL-3?\nIs it a copyright infringement to publish an R package on CRAN under an MIT license when I have a dependency on a package that is licensed under GPL-3?\nCan I publish an R package on CRAN under an MIT license when I have a dependency on a package that is licensed under GPL-3 without infringing copyright?\n\n\nMy answer\nAs we can see in this part of the GPL FAQ, “Linking a GPL covered work statically or dynamically with other modules is making a combined work based on the GPL covered work”. That would mean that, as R is GPL, any work linking dynamically or statically to R would have to be GPL-based also\nI got this from the book, but I am not sure if it means that if my package dependency is licensed under GPL-3, my package has to be licensed under GPL-3 also. I really struggled understanding these legal stuff."
  },
  {
    "objectID": "blog-2023/Blog-7-submissions/anphan0828/index.html#submission",
    "href": "blog-2023/Blog-7-submissions/anphan0828/index.html#submission",
    "title": "It’s not the end…",
    "section": "Submission",
    "text": "Submission\nWrite answers to the questions directly into the file README.Rmd. Push the blog post to your blog-7 repo. Make sure that all of the checks are passing."
  },
  {
    "objectID": "blog-2023/Blog-7-submissions/hardtme/index.html#prompt",
    "href": "blog-2023/Blog-7-submissions/hardtme/index.html#prompt",
    "title": "Legal Details of Licenses",
    "section": "Prompt:",
    "text": "Prompt:\nThe DESCRIPTION file of a package contains the package’s meta information. Most of the fields in this file are quite straight forward: author, version number, and a short package description. When you call library(help=\"<package name>\") for package <package name> you can see the contents of the DESCRIPTION file for that package (and some parts of the NAMESPACE file).\nRead through Colin Fay’s (short) book on Licensing R\nWrite a blog post addressing the following questions:\n\nUnder what license does R operate? What is the license for ggplot2?\nAfter running license(), I learned that R primarily operates under GPL-2 and GPL-3 while some header files operate under LGPL-2.1. Calling library(help = \"ggplot2\") shows that the ggplot2 package uses the MIT license.\n\n\nWhat are the dependencies of the package you made?\nRead through chapter 5.2 of Licensing R. Combine and adjust the code pieces to create the dependencies for a package that is on github rather than CRAN. (Don’t forget about the package desc.) What dependencies does the package have that you created for Lab-3? Which licenses are involved? Are all of these dependencies required? Elaborate.\nThe current listed dependencies of my Lab 3 team’s TwoTeam4 package (and their licenses) are\n\nR (GPL-2 and GPL-3 while some header files operate under LGPL-2)\ndplyr (MIT)\nlubridate (GPL-2 | GPL-3)\nreadr (MIT)\npurrr (MIT)\nstringr (MIT)\ntabulizer (MIT)\n\nWe do need all of these dependencies in our package because the functions we created within our package call functions from the dependencies.\nIf we run the following code, we can see that our TwoTeam4 package has more dependencies than we listed. This more extensive list of dependencies includes dependencies of our dependencies. We can find the licenses for all of these packages using utils::packageDescription(\"<package_name>\", field = \"License\").\n\nlibrary(pkgnet)\nlibrary(TwoTeam4)\nteam_depends <- DependencyReporter$new()$set_package(\"TwoTeam4\")$nodes$node\n\nThe more extensive list of dependencies (and their licenses) includes\n\nR6 (MIT)\nbit (GPL-2 | GPL-3)\nbit64 (GPL-2 | GPL-3)\ncli (MIT)\nclipr (GPL-3)\ncrayon (MIT)\ndplyr (MIT)\nellipsis (MIT)\nfansi (GPL-2 | GPL-3)\ngenerics (MIT)\nglue (MIT)\ngrDevices (Part of R and thus probably GPL-2 and GPL-3)\ngraphics (Part of R and thus probably GPL-2 and GPL-3)\nhms (MIT)\nlifecycle (MIT)\nlubridate (GPL >=2)\nmagrittr (MIT)\nmethods (Part of R and thus probably GPL-2 and GPL-3)\npillar (MIT)\npkgconfig (MIT)\npng (GPL-2 | GPL-3)\npurrr (MIT)\nrJava (LGPL-2.1)\nreadr (MIT)\nrlang (MIT)\nstats (Part of R and thus probably GPL-2 and GPL-3)\nstringi (custom LICENSE)\nstringr (MIT)\ntabulizer (MIT)\ntabulizerjars (MIT)\ntibble (MIT)\ntidyselect (MIT)\ntimechange (GPL-3)\ntools (Part of R and thus probably GPL-2 and GPL-3)\ntzdb (MIT)\nutf8 (Apache License (== 2.0)\nutils (Part of R and thus probably GPL-2 and GPL-3)\nvctrs (MIT)\nvroom (MIT)\nwithr (MIT)\n\nUnder which license should this blog post be published? Make sure that you are using an appropriate license. (You can change the current licenses with the help of commands from the use_license_XXX family in the usethis package)\nAfter reading the examples in chapter 4 of Licensing R, I chose to use a CC-BY-4.0 license for this blog post.\n\n\n\n\n\nCan I publish an R package on CRAN under an MIT license when I have a dependency on a package that is licensed under GPL-3?\nWhen confronted with the above question, ChatGPT gave two – quite different – responses, as shown below. The main point in both responses is ‘your package may be considered derivative work’. At the specific problem of the package developed for Lab 3, what is your opinion about potential copyright infringements when releasing the package with an MIT license? Make sure to take the relevant passage in Colin Fay’s book under consideration.\nThe legal implications of publishing an R package on CRAN under an MIT license while having a dependency on a package that is licensed under GPL-3 are complex and can vary depending on the specific circumstances. It is always advisable to seek legal advice from a licensed attorney if you have any doubts or concerns about licensing issues.\n\nHowever, in general, it is possible to publish an R package on CRAN under an MIT license when you have a dependency on a package that is licensed under GPL-3. This is because the MIT license is a permissive open-source license that allows for more flexibility in how the software can be used and distributed, and it is generally considered compatible with the GPL-3 license.\n\nThat being said, if your package depends on a GPL-3-licensed package, your package may be considered a derivative work and therefore subject to the terms of the GPL-3 license. This means that if you distribute your package, you may need to also distribute the source code for your package under the GPL-3 license or a compatible license, and you may need to ensure that the requirements of the GPL-3 license are met for the entire distribution, including any dependencies.\n\nIt is also worth noting that the R community has its own guidelines and recommendations for package licensing, and it is important to comply with these guidelines if you want to publish your package on CRAN. The CRAN Repository Policy states that packages should have a \"permissive\" or \"GPL-compatible\" license, but does not explicitly require that packages use the GPL license or any other specific license.\n\nIn summary, while it is possible to publish an R package on CRAN under an MIT license while having a dependency on a package that is licensed under GPL-3, it is important to understand the implications of the different licenses and to ensure that you comply with any applicable guidelines and recommendations from the R community.\nAfter harping a bit on copyright infringement in general, ChatGPT changed its response to\nTechnically, you can publish an R package on CRAN under an MIT license when you have a dependency on a package that is licensed under GPL-3, but doing so would not be compliant with the terms of the GPL-3 license.\n\nThe GPL-3 license is a strong copyleft license that requires derivative works to be released under the same license. If your package depends on a GPL-3-licensed package, your package may be considered a derivative work and therefore must be licensed under the GPL-3 license or a compatible license.\n\nThe MIT license, on the other hand, is a permissive license that allows for more flexibility in how the software is used and distributed. However, it is not compatible with the GPL-3 license, and therefore cannot be used for derivative works of GPL-3-licensed software.\n\nPublishing an R package on CRAN under an MIT license when you have a dependency on a package that is licensed under GPL-3 would be a licensing violation, and could potentially result in legal action or other consequences. It is important to comply with the licensing requirements of all dependencies in your package to avoid any legal issues.\nThe ‘harping’ questions:\n\nIs it legal to publish an R package on CRAN under an MIT license when I have a dependency on a package that is licensed under GPL-3?\n\nI think so.\n\nIs it illegal to publish an R package on CRAN under an MIT license when I have a dependency on a package that is licensed under GPL-3?\n\nI don’t think so.\n\nIs it a copyright infringement to publish an R package on CRAN under an MIT license when I have a dependency on a package that is licensed under GPL-3?\n\nI don’t think so.\n\nCan I publish an R package on CRAN under an MIT license when I have a dependency on a package that is licensed under GPL-3 without infringing copyright?\n\nI think so.\nWe can consider the readr package as an example of the above issues. The readr package imports the clipr package and thus has the clipr package as a dependency. The clipr package is released under GPL-3 while readr is released under the MIT license. I assume that the developers of a tidyverse package like readr made sure that there are no legal issues or copyright infringement issues that could arise when including a package with the GPL-3 license as a dependency to a package that uses the MIT license. Hence, if readr can be published on CRAN under the MIT license while having a dependency on a package under the GPL-3 license, it seems reasonable that other packages in similar situations should also be able to be published on CRAN without repercussions.\nIn chapter 3 of Licensing R, David Fay notes that all derivative works of GPL licensed works need to be released under a GPL-compatible license. Later in chapter 3, I learned that the MIT license is GPL-compatible. This makes it seem like there is nothing wrong with releasing a package under the MIT license when it has a dependency on a GPL licensed package. To be even more on the safe side, you should also make the source code of your MIT-licensed package available in a GPL-compliant way.\nI was interested in the topic of licensing R packages, so I did some further research and came across R Packages (2e) by Hadley Wickham and Jenny Bryan. In [section 13.6]{https://r-pkgs.org/license.html} of R Packages (2e), the authors note that in their opinion, the license of your R package and the licenses of R packages whose exported functions you use via Imports or Suggests don’t have to match. Based on my reading of chapter 4 in David Fay’s Licensing R, I would argue that there is at least one case where you have to be careful about license matching. Suppose that the license of one of your package’s dependencies does not allow for commercial use. If you intend that your R package can be used in a commercial setting, you should find another way to implement your code that does not use the dependency with a restrictive license.\nIn the case of my lab 3 team’s TwoTeam4 package, I think we would be able to publish it on CRAN under an MIT license even though some of its dependencies are GPL licensed.The package needs some cleaning up first, though. I would also like to check into the rJava package’s LGPL-2.1 license, the stringi package’s custom license, and the utf8 package’s Apache license just to be safe."
  },
  {
    "objectID": "blog-2023/Blog-7-submissions/hardtme/index.html#submission",
    "href": "blog-2023/Blog-7-submissions/hardtme/index.html#submission",
    "title": "Legal Details of Licenses",
    "section": "Submission",
    "text": "Submission\nWrite answers to the questions directly into the file README.Rmd. Push the blog post to your blog-7 repo. Make sure that all of the checks are passing."
  },
  {
    "objectID": "blog-2023/Blog-7-submissions/santos-cl/index.html#prompt",
    "href": "blog-2023/Blog-7-submissions/santos-cl/index.html#prompt",
    "title": "Dependencies",
    "section": "Prompt:",
    "text": "Prompt:\nThe DESCRIPTION file of a package contains the package’s meta information. Most of the fields in this file are quite straight forward: author, version number, and a short package description. When you call library(help=\"<package name>\") for package <package name> you can see the contents of the DESCRIPTION file for that package (and some parts of the NAMESPACE file).\nRead through Colin Fay’s (short) book on Licensing R\nWrite a blog post addressing the following questions:\n\nUnder what license does R operate? What is the license for ggplot2?\nR operates under the the GNU General Public License(V2, from 1991; V3 from 2007). Additionally, a small number of files are distributed under the Lesser GNU General Public License ( > V2.1).\nShow in New Window\n\nThis software is distributed under the terms of the GNU General\nPublic License, either Version 2, June 1991 or Version 3, June 2007.\nThe terms of version 2 of the license are in a file called COPYING\nwhich you should have received with\nthis software and which can be displayed by RShowDoc(\"COPYING\").\nVersion 3 of the license can be displayed by RShowDoc(\"GPL-3\").\n\nCopies of both versions 2 and 3 of the license can be found\nat https://www.R-project.org/Licenses/.\n\nA small number of files (the API header files listed in\nR_DOC_DIR/COPYRIGHTS) are distributed under the\nLESSER GNU GENERAL PUBLIC LICENSE, version 2.1 or later.\nThis can be displayed by RShowDoc(\"LGPL-2.1\"),\nor obtained at the URI given.\nVersion 3 of the license can be displayed by RShowDoc(\"LGPL-3\").\n\n'Share and Enjoy.'\nOn the other hand, ggplot2 operates under a different license: MIT + file\n[1] \"MIT + file LICENSE\"\n\n\nWhat are the dependencies of the package you made?\nRead through chapter 5.2 of Licensing R. Combine and adjust the code pieces to create the dependencies for a package that is on github rather than CRAN. (Don’t forget about the package desc.) What dependencies does the package have that you created for Lab-3? Which licenses are involved? Are all of these dependencies required? Elaborate.\nThe DESCRIPTION file for the package we, from Team 2, made does not list any dependencies but the package definitely has dependencies. We have failed to include the package dependencies. However, the package needs depends on the packages tabulizer, tidyverse, and lubridate.\nPackage: Team2\nTitle: Get police presslogs\nVersion: 0.0.0.9000\nAuthors@R: c( person(\"Caio\", \"dos Santos\", , \"clsantos@iastate.edu\", role = c(\"aut\", \"cre\")), person(\"Alexandrea\", \"Arabio\", ,\n              \"aarabio@iastate.edu\", role = \"aut\"), person(\"Maxwell\", \"Skinner\", , \"mskinn25@iastate.edu\", role = \"aut\") )\nDescription: This package contains 3 functions to download, extract, and filter presslog data. Also, it contains a sample data\n              set.\nLicense: MIT + file LICENSE\nEncoding: UTF-8\nRoxygen: list(markdown = TRUE)\nRoxygenNote: 7.2.3\nDepends: R (>= 2.10)\nRemotes: github::ropensci/tabulizer\nLazyData: true\nLitrVersionUsed: 0.7.0\nLitrId: 3071b204a7d4052aa4f9e994be3b30a9\nNeedsCompilation: no\nPackaged: 2023-03-07 21:17:37 UTC; santo\nAuthor: Caio dos Santos [aut, cre], Alexandrea Arabio [aut], Maxwell Skinner [aut]\nMaintainer: Caio dos Santos <clsantos@iastate.edu>\nBuilt: R 4.2.1; ; 2023-03-07 21:17:38 UTC; windows\n\n-- File: C:/Users/santo/AppData/Local/R/win-library/4.2/Team2/Meta/package.rds \nWhen we try to retrieve the package dependencies, we get the following error:\nINFO [2023-03-08 19:09:36] Constructing dependency network for Team2\nFATAL [2023-03-08 19:09:36] Package 'Team2' does not have any dependencies in [Imports, Depends]. If you think this is an error consider adding more dependency types in your definition of DependencyReporter. For example: DependencyReporter$new(dep_types = c('Imports', 'Depends', 'Suggests'))\nUnder which license should this blog post be published? Make sure that you are using an appropriate license. (You can change the current licenses with the help of commands from the use_license_XXX family in the usethis package)\nAn appropriate license for this This blog post seems to be ***CC-BY-NC-SA***.\n\n\nCan I publish an R package on CRAN under an MIT license when I have a dependency on a package that is licensed under GPL-3?\nWhen confronted with the above question, ChatGPT gave two – quite different – responses, as shown below. The main point in both responses is ‘your package may be considered derivative work’. At the specific problem of the package developed for Lab 3, what is your opinion about potential copyright infringements when releasing the package with an MIT license? Make sure to take the relevant passage in Colin Fay’s book under consideration.\nThe legal implications of publishing an R package on CRAN under an MIT license while having a dependency on a package that is licensed under GPL-3 are complex and can vary depending on the specific circumstances. It is always advisable to seek legal advice from a licensed attorney if you have any doubts or concerns about licensing issues.\n\nHowever, in general, it is possible to publish an R package on CRAN under an MIT license when you have a dependency on a package that is licensed under GPL-3. This is because the MIT license is a permissive open-source license that allows for more flexibility in how the software can be used and distributed, and it is generally considered compatible with the GPL-3 license.\n\nThat being said, if your package depends on a GPL-3-licensed package, your package may be considered a derivative work and therefore subject to the terms of the GPL-3 license. This means that if you distribute your package, you may need to also distribute the source code for your package under the GPL-3 license or a compatible license, and you may need to ensure that the requirements of the GPL-3 license are met for the entire distribution, including any dependencies.\n\nIt is also worth noting that the R community has its own guidelines and recommendations for package licensing, and it is important to comply with these guidelines if you want to publish your package on CRAN. The CRAN Repository Policy states that packages should have a \"permissive\" or \"GPL-compatible\" license, but does not explicitly require that packages use the GPL license or any other specific license.\n\nIn summary, while it is possible to publish an R package on CRAN under an MIT license while having a dependency on a package that is licensed under GPL-3, it is important to understand the implications of the different licenses and to ensure that you comply with any applicable guidelines and recommendations from the R community.\nAfter harping a bit on copyright infringement in general, ChatGPT changed its response to\nTechnically, you can publish an R package on CRAN under an MIT license when you have a dependency on a package that is licensed under GPL-3, but doing so would not be compliant with the terms of the GPL-3 license.\n\nThe GPL-3 license is a strong copyleft license that requires derivative works to be released under the same license. If your package depends on a GPL-3-licensed package, your package may be considered a derivative work and therefore must be licensed under the GPL-3 license or a compatible license.\n\nThe MIT license, on the other hand, is a permissive license that allows for more flexibility in how the software is used and distributed. However, it is not compatible with the GPL-3 license, and therefore cannot be used for derivative works of GPL-3-licensed software.\n\nPublishing an R package on CRAN under an MIT license when you have a dependency on a package that is licensed under GPL-3 would be a licensing violation, and could potentially result in legal action or other consequences. It is important to comply with the licensing requirements of all dependencies in your package to avoid any legal issues.\nThe ‘harping’ questions:\n\nIs it legal to publish an R package on CRAN under an MIT license when I have a dependency on a package that is licensed under GPL-3?\nIs it illegal to publish an R package on CRAN under an MIT license when I have a dependency on a package that is licensed under GPL-3?\nIs it a copyright infringement to publish an R package on CRAN under an MIT license when I have a dependency on a package that is licensed under GPL-3?\nCan I publish an R package on CRAN under an MIT license when I have a dependency on a package that is licensed under GPL-3 without infringing copyright?\n\nTo me, it seems like you would be all right to publish on CRAN an MIT-licensed package that depends upon a GPL-3 licensed package. The reason is that, when you list a package as a dependency of you the package you are not actually including that code behind that package in your code. For instance, say that package is taken down, and people cannot access that specific package anymore. The new package, distributed under the MIT license, will not have pieces of that package included. It might sounds too simplistic but an analogy would be to require every auto dealership to also have a license for wholesale fuel. Althought the cars they distribute run on fuel, they deliver the fuel with the car. That being said, I am just an agronomist so I do not really understand much about all the legal implications of these licenses."
  },
  {
    "objectID": "blog-2023/Blog-7-submissions/sudi007/index.html#prompt",
    "href": "blog-2023/Blog-7-submissions/sudi007/index.html#prompt",
    "title": "All that legal stuff",
    "section": "Prompt:",
    "text": "Prompt:\nThe DESCRIPTION file of a package contains the package’s meta information. Most of the fields in this file are quite straight forward: author, version number, and a short package description. When you call library(help=\"<package name>\") for package <package name> you can see the contents of the DESCRIPTION file for that package (and some parts of the NAMESPACE file).\nRead through Colin Fay’s (short) book on Licensing R\n\n#library(devtools)\n#library(tools)\n#library(pkgnet)\n#library(ggplot2)\n\nWrite a blog post addressing the following questions:\n\nUnder what license does R operate? What is the license for ggplot2?\nR operates under the GNU General Public License, either Version 2, June 1991, or Version 3, June 2007. The GNU General Public License is a free-for-all license for software and other creative work. Under this license, users can not only use the software but also modify and distribute it as long as all the changes are made as part of the same license. The R-package, ggplot2, also operates under the GNU General Public License version 2.\n\n\nWhat are the dependencies of the package you made?\nThe dependencies of the the package that was made for lab 3 are tabulizer, tidyr, dplyr, tibble, lubridate, RCurl\nThe following is the package description This is the description file for the lab 3 our group created Package: Team3 Title: Reading Ames Police Presslogs Version: 0.0.0.9000 Authors@R: person(“Sabrena”, “Rutledge”, , “sabrenar@iastate.edu”, role = c(“aut”, “cre”)) Description: Convert Ames Police Presslogs from pdf to dataframes. It could also have some functions, but for now all it has is some data. License: MIT + file LICENSE Encoding: UTF-8 Roxygen: list(markdown = TRUE) RoxygenNote: 7.2.3 Depends: R (>= 2.10) Import: tabulizer, tidyr, dplyr, tibble, lubridate, RCurl Remotes: github::ropensci/tabulizer LazyData: true LitrVersionUsed: 0.8.0 LitrId: b446015960e43bc7c5ae99da41fc132b\nRead through chapter 5.2 of Licensing R. Combine and adjust the code pieces to create the dependencies for a package that is on github rather than CRAN. (Don’t forget about the package desc.) #installing a github package\n\n# Install devtools package if not installed\n#install.packages(\"devtools\")\n#devtools::install_github(\"tidyverse/ggplot2\",force = TRUE)\n#remotes::install_github(\"tidyverse/ggplot2\",force = TRUE)\n\n\n# Get dependencies of ggplot2\npackage_dependencies(\"ggplot2\", which = \"all\")\n#devtools::session_info(\"ggplot2\")\n\nggplot2\n[1] “cli” “glue” “grDevices” “grid” “gtable” “isoband”\n[7] “lifecycle” “MASS” “mgcv” “rlang” “scales” “stats”\n[13] “tibble” “vctrs” “withr” “covr” “dplyr” “ggplot2movies”\n[19] “hexbin” “Hmisc” “knitr” “lattice” “mapproj” “maps”\n[25] “maptools” “multcomp” “munsell” “nlme” “profvis” “quantreg”\n[31] “ragg” “RColorBrewer” “rgeos” “rmarkdown” “rpart” “sf”\n[37] “svglite” “testthat” “vdiffr” “xml2” “sp”\n\ndesc <- packageDescription(\"ggplot2\")\ndesc\n\nPackage: ggplot2\nVersion: 3.4.1\nTitle: Create Elegant Data Visualisations Using the Grammar of Graphics\nAuthors@R: c( person(\"Hadley\", \"Wickham\", , \"hadley@posit.co\", role =\n        \"aut\", comment = c(ORCID = \"0000-0003-4757-117X\")),\n        person(\"Winston\", \"Chang\", role = \"aut\", comment = c(ORCID =\n        \"0000-0002-1576-2126\")), person(\"Lionel\", \"Henry\", role =\n        \"aut\"), person(\"Thomas Lin\", \"Pedersen\", ,\n        \"thomas.pedersen@posit.co\", role = c(\"aut\", \"cre\"), comment =\n        c(ORCID = \"0000-0002-5147-4711\")), person(\"Kohske\",\n        \"Takahashi\", role = \"aut\"), person(\"Claus\", \"Wilke\", role =\n        \"aut\", comment = c(ORCID = \"0000-0002-7470-9261\")),\n        person(\"Kara\", \"Woo\", role = \"aut\", comment = c(ORCID =\n        \"0000-0002-5125-4188\")), person(\"Hiroaki\", \"Yutani\", role =\n        \"aut\", comment = c(ORCID = \"0000-0002-3385-7233\")),\n        person(\"Dewey\", \"Dunnington\", role = \"aut\", comment = c(ORCID =\n        \"0000-0002-9415-4582\")), person(\"RStudio\", role = c(\"cph\",\n        \"fnd\")) )\nDescription: A system for 'declaratively' creating graphics, based on\n        \"The Grammar of Graphics\". You provide the data, tell 'ggplot2'\n        how to map variables to aesthetics, what graphical primitives\n        to use, and it takes care of the details.\nLicense: MIT + file LICENSE\nURL: https://ggplot2.tidyverse.org,\n        https://github.com/tidyverse/ggplot2\nBugReports: https://github.com/tidyverse/ggplot2/issues\nDepends: R (>= 3.3)\nImports: cli, glue, grDevices, grid, gtable (>= 0.1.1), isoband,\n        lifecycle (> 1.0.1), MASS, mgcv, rlang (>= 1.0.0), scales (>=\n        1.2.0), stats, tibble, vctrs (>= 0.5.0), withr (>= 2.5.0)\nSuggests: covr, dplyr, ggplot2movies, hexbin, Hmisc, knitr, lattice,\n        mapproj, maps, maptools, multcomp, munsell, nlme, profvis,\n        quantreg, ragg, RColorBrewer, rgeos, rmarkdown, rpart, sf (>=\n        0.7-3), svglite (>= 1.2.0.9001), testthat (>= 3.1.2), vdiffr\n        (>= 1.0.0), xml2\nEnhances: sp\nVignetteBuilder: knitr\nConfig/Needs/website: ggtext, tidyr, forcats, tidyverse/tidytemplate\nConfig/testthat/edition: 3\nEncoding: UTF-8\nLazyData: true\nRoxygenNote: 7.2.1\nCollate: 'ggproto.r' 'ggplot-global.R' 'aaa-.r'\n        'aes-colour-fill-alpha.r' .....\nNeedsCompilation: no\nPackaged: 2023-02-06 09:42:01 UTC; thomas\nAuthor: Hadley Wickham [aut] (<https://orcid.org/0000-0003-4757-117X>),\n        Winston Chang [aut] (<https://orcid.org/0000-0002-1576-2126>),\n        Lionel Henry [aut], Thomas Lin Pedersen [aut, cre]\n        (<https://orcid.org/0000-0002-5147-4711>), Kohske Takahashi\n        [aut], Claus Wilke [aut]\n        (<https://orcid.org/0000-0002-7470-9261>), Kara Woo [aut]\n        (<https://orcid.org/0000-0002-5125-4188>), Hiroaki Yutani [aut]\n        (<https://orcid.org/0000-0002-3385-7233>), Dewey Dunnington\n        [aut] (<https://orcid.org/0000-0002-9415-4582>), RStudio [cph,\n        fnd]\nMaintainer: Thomas Lin Pedersen <thomas.pedersen@posit.co>\nRepository: CRAN\nDate/Publication: 2023-02-10 13:20:06 UTC\nBuilt: R 4.2.0; ; 2023-02-11 13:46:44 UTC; unix\n\n-- File: /Library/Frameworks/R.framework/Versions/4.2/Resources/library/ggplot2/Meta/package.rds \n\n\n#What dependencies does the package have that you created for Lab-3?\nThe dependencies the package that was created in lab 3 is tabulizer, tidyr, dplyr, tibble, lubridate, and RCurl package\n#Which licenses are involved?\n#for the package\nfor the package created in lab 3 MIT + file license\n#for the dependencies\nInformation for tabulizer package:“MIT + file LICENSE”\nInformation for tidyr package:“MIT + file LICENSE”\nInformation for dplyr package:“MIT + file LICENSE”\nInformation for tibble package:“MIT + file LICENSE”\nInformation for lubridate package:“GPL (>= 2)”\nInformation for RCurl package:“BSD_3_clause + file LICENSE”\n#Are all of these dependencies required? Elaborate.\nyes all of these dependencies are required as they are the part of the analysis and the functions that are created within the package requires these dependencies\n#Under which license should this blog post be published?\nThis blog should be published under the CC0 (Creative Commons Zero) license. CC0 ensures open access to all the creative work such as written pieces, painting, and music, among others. Open access means that the creator has waived all copyright on their work, allowing users to modify, re-create and distribute it without any restriction. However, as CC0 is termed as a public domain dedication, it is outside the purview of the regular open-source licenses such as GPL and MIT.\nMake sure that you are using an appropriate license. (You can change the current licenses with the help of commands from the use_license_XXX family in the usethis package)\n\n\nCan I publish an R package on CRAN under an MIT license when I have a dependency on a package that is licensed under GPL-3?\nWhen confronted with the above question, ChatGPT gave two – quite different – responses, as shown below. The main point in both responses is ‘your package may be considered derivative work’. At the specific problem of the package developed for Lab 3, what is your opinion about potential copyright infringements when releasing the package with an MIT license? Make sure to take the relevant passage in Colin Fay’s book under consideration.\nThe legal implications of publishing an R package on CRAN under an MIT license while having a dependency on a package that is licensed under GPL-3 are complex and can vary depending on the specific circumstances. It is always advisable to seek legal advice from a licensed attorney if you have any doubts or concerns about licensing issues.\n\nHowever, in general, it is possible to publish an R package on CRAN under an MIT license when you have a dependency on a package that is licensed under GPL-3. This is because the MIT license is a permissive open-source license that allows for more flexibility in how the software can be used and distributed, and it is generally considered compatible with the GPL-3 license.\n\nThat being said, if your package depends on a GPL-3-licensed package, your package may be considered a derivative work and therefore subject to the terms of the GPL-3 license. This means that if you distribute your package, you may need to also distribute the source code for your package under the GPL-3 license or a compatible license, and you may need to ensure that the requirements of the GPL-3 license are met for the entire distribution, including any dependencies.\n\nIt is also worth noting that the R community has its own guidelines and recommendations for package licensing, and it is important to comply with these guidelines if you want to publish your package on CRAN. The CRAN Repository Policy states that packages should have a \"permissive\" or \"GPL-compatible\" license, but does not explicitly require that packages use the GPL license or any other specific license.\n\nIn summary, while it is possible to publish an R package on CRAN under an MIT license while having a dependency on a package that is licensed under GPL-3, it is important to understand the implications of the different licenses and to ensure that you comply with any applicable guidelines and recommendations from the R community.\nAfter harping a bit on copyright infringement in general, ChatGPT changed its response to\nTechnically, you can publish an R package on CRAN under an MIT license when you have a dependency on a package that is licensed under GPL-3, but doing so would not be compliant with the terms of the GPL-3 license.\n\nThe GPL-3 license is a strong copyleft license that requires derivative works to be released under the same license. If your package depends on a GPL-3-licensed package, your package may be considered a derivative work and therefore must be licensed under the GPL-3 license or a compatible license.\n\nThe MIT license, on the other hand, is a permissive license that allows for more flexibility in how the software is used and distributed. However, it is not compatible with the GPL-3 license, and therefore cannot be used for derivative works of GPL-3-licensed software.\n\nPublishing an R package on CRAN under an MIT license when you have a dependency on a package that is licensed under GPL-3 would be a licensing violation, and could potentially result in legal action or other consequences. It is important to comply with the licensing requirements of all dependencies in your package to avoid any legal issues.\nThe ‘harping’ questions:\n\nIs it legal to publish an R package on CRAN under an MIT license when I have a dependency on a package that is licensed under GPL-3?\nIs it illegal to publish an R package on CRAN under an MIT license when I have a dependency on a package that is licensed under GPL-3?\nIs it a copyright infringement to publish an R package on CRAN under an MIT license when I have a dependency on a package that is licensed under GPL-3?\nCan I publish an R package on CRAN under an MIT license when I have a dependency on a package that is licensed under GPL-3 without infringing copyright?\n\n#summary of all the above questions\nHere’s a common answer to all the “harping” questions. According to the book, it is legal to publish an R package on CRAN under an MIT license when I have a dependency on a package that is licensed under GPL-3. However, there are certain considerations that one needs to be aware of. First of all, the MIT license is permissible license, which means that it has no restrictions on the use, modification, and distribution of the software. On the other hand, the GPT-3 license is a copyleft license which requires that any software distributed is also licensed under GPT-3.Considering these requirements, even if a code under a permissible license such as MIT combined with one that uses a GPT-3 license, it must meet the requisites of the stricter GPT-3 license."
  },
  {
    "objectID": "blog-2023/Blog-7-submissions/sudi007/index.html#submission",
    "href": "blog-2023/Blog-7-submissions/sudi007/index.html#submission",
    "title": "All that legal stuff",
    "section": "Submission",
    "text": "Submission\nWrite answers to the questions directly into the file README.Rmd. Push the blog post to your blog-7 repo. Make sure that all of the checks are passing."
  },
  {
    "objectID": "blog-2023/Blog-7-submissions/motinaaa/index.html#prompt",
    "href": "blog-2023/Blog-7-submissions/motinaaa/index.html#prompt",
    "title": "Stat 585",
    "section": "Prompt:",
    "text": "Prompt:\nThe DESCRIPTION file of a package contains the package’s meta information. Most of the fields in this file are quite straight forward: author, version number, and a short package description. When you call library(help=\"<package name>\") for package <package name> you can see the contents of the DESCRIPTION file for that package (and some parts of the NAMESPACE file).\nRead through Colin Fay’s (short) book on Licensing R\nWrite a blog post addressing the following questions:\n\nUnder what license does R operate? What is the license for ggplot2?\n\n\nWhat are the dependencies of the package you made?\nRead through chapter 5.2 of Licensing R. Combine and adjust the code pieces to create the dependencies for a package that is on github rather than CRAN. (Don’t forget about the package desc.) What dependencies does the package have that you created for Lab-3? Which licenses are involved? Are all of these dependencies required? Elaborate.\nUnder which license should this blog post be published? Make sure that you are using an appropriate license. (You can change the current licenses with the help of commands from the use_license_XXX family in the usethis package)\n\n\nCan I publish an R package on CRAN under an MIT license when I have a dependency on a package that is licensed under GPL-3?\nWhen confronted with the above question, ChatGPT gave two – quite different – responses, as shown below. The main point in both responses is ‘your package may be considered derivative work’. At the specific problem of the package developed for Lab 3, what is your opinion about potential copyright infringements when releasing the package with an MIT license? Make sure to take the relevant passage in Colin Fay’s book under consideration.\nThe legal implications of publishing an R package on CRAN under an MIT license while having a dependency on a package that is licensed under GPL-3 are complex and can vary depending on the specific circumstances. It is always advisable to seek legal advice from a licensed attorney if you have any doubts or concerns about licensing issues.\n\nHowever, in general, it is possible to publish an R package on CRAN under an MIT license when you have a dependency on a package that is licensed under GPL-3. This is because the MIT license is a permissive open-source license that allows for more flexibility in how the software can be used and distributed, and it is generally considered compatible with the GPL-3 license.\n\nThat being said, if your package depends on a GPL-3-licensed package, your package may be considered a derivative work and therefore subject to the terms of the GPL-3 license. This means that if you distribute your package, you may need to also distribute the source code for your package under the GPL-3 license or a compatible license, and you may need to ensure that the requirements of the GPL-3 license are met for the entire distribution, including any dependencies.\n\nIt is also worth noting that the R community has its own guidelines and recommendations for package licensing, and it is important to comply with these guidelines if you want to publish your package on CRAN. The CRAN Repository Policy states that packages should have a \"permissive\" or \"GPL-compatible\" license, but does not explicitly require that packages use the GPL license or any other specific license.\n\nIn summary, while it is possible to publish an R package on CRAN under an MIT license while having a dependency on a package that is licensed under GPL-3, it is important to understand the implications of the different licenses and to ensure that you comply with any applicable guidelines and recommendations from the R community.\nAfter harping a bit on copyright infringement in general, ChatGPT changed its response to\nTechnically, you can publish an R package on CRAN under an MIT license when you have a dependency on a package that is licensed under GPL-3, but doing so would not be compliant with the terms of the GPL-3 license.\n\nThe GPL-3 license is a strong copyleft license that requires derivative works to be released under the same license. If your package depends on a GPL-3-licensed package, your package may be considered a derivative work and therefore must be licensed under the GPL-3 license or a compatible license.\n\nThe MIT license, on the other hand, is a permissive license that allows for more flexibility in how the software is used and distributed. However, it is not compatible with the GPL-3 license, and therefore cannot be used for derivative works of GPL-3-licensed software.\n\nPublishing an R package on CRAN under an MIT license when you have a dependency on a package that is licensed under GPL-3 would be a licensing violation, and could potentially result in legal action or other consequences. It is important to comply with the licensing requirements of all dependencies in your package to avoid any legal issues.\nThe ‘harping’ questions:\n\nIs it legal to publish an R package on CRAN under an MIT license when I have a dependency on a package that is licensed under GPL-3?\nIs it illegal to publish an R package on CRAN under an MIT license when I have a dependency on a package that is licensed under GPL-3?\nIs it a copyright infringement to publish an R package on CRAN under an MIT license when I have a dependency on a package that is licensed under GPL-3?\nCan I publish an R package on CRAN under an MIT license when I have a dependency on a package that is licensed under GPL-3 without infringing copyright?"
  },
  {
    "objectID": "blog-2023/Blog-7-submissions/motinaaa/index.html#submission",
    "href": "blog-2023/Blog-7-submissions/motinaaa/index.html#submission",
    "title": "Stat 585",
    "section": "Submission",
    "text": "Submission\nWrite answers to the questions directly into the file README.Rmd. Push the blog post to your blog-7 repo. Make sure that all of the checks are passing."
  },
  {
    "objectID": "blog-2023/Blog-7-submissions/Sabrenar/index.html#prompt",
    "href": "blog-2023/Blog-7-submissions/Sabrenar/index.html#prompt",
    "title": "Licenses and Packages",
    "section": "Prompt:",
    "text": "Prompt:\nThe DESCRIPTION file of a package contains the package’s meta information. Most of the fields in this file are quite straight forward: author, version number, and a short package description. When you call library(help=\"<package name>\") for package <package name> you can see the contents of the DESCRIPTION file for that package (and some parts of the NAMESPACE file).\nRead through Colin Fay’s (short) book on Licensing R\nWrite a blog post addressing the following questions:\n\nUnder what license does R operate? What is the license for ggplot2?\nR operates under versions 2 and 3 of a GNU General Public License with “absolutely no warranty.” The specifics of the two licenses can be found from RShowDoc(“COPYING”) and RShowDoc(“GPL-3”) respectively. Meanwhile ggplot2 has a MIT license that allows permission to anyone who obtains a copy of the ggplot2 software.\n\n\nWhat are the dependencies of the package you made?\nRead through chapter 5.2 of Licensing R. Combine and adjust the code pieces to create the dependencies for a package that is on github rather than CRAN. (Don’t forget about the package desc.) What dependencies does the package have that you created for Lab-3? The dependencies of the lab3 package are tabulizer, dplyr, tidyr, tibble, lubridate, RCurl, cli, fansi, generics, glue, lifecycle, magrittr, methods, pillar, pkgconfig, purr, R6, rlang, stingr, tidyselect, timechange, utils, vctrs, grDevices, utf8, withr, graphics, png, rJava, tabulizerjars, tools, and stats.\nWhich licenses are involved? These dependencies mostly have an MIT + file license, but two have GPL-3 license. Additionally only utf8 has an Apache License (== 2.0) | file license.\nAre all of these dependencies required? Elaborate. Not all of these dependencies are required. The following are not required: methods, utils, graphics, grDevices, tools, and stats. In order to determine whether a package was required, I found the list of packages in my library and found those that are not present. Those dependencies that are not present must not be required to run the created package.\nUnder which license should this blog post be published? Make sure that you are using an appropriate license. (You can change the current licenses with the help of commands from the use_license_XXX family in the usethis package) Since there are no dependencies, data, or code contained within this blog, this blog should be published with an MIT license.\n\n\nCan I publish an R package on CRAN under an MIT license when I have a dependency on a package that is licensed under GPL-3?\nWhen confronted with the above question, ChatGPT gave two – quite different – responses, as shown below. The main point in both responses is ‘your package may be considered derivative work’. At the specific problem of the package developed for Lab 3, what is your opinion about potential copyright infringements when releasing the package with an MIT license? Make sure to take the relevant passage in Colin Fay’s book under consideration.\nThe legal implications of publishing an R package on CRAN under an MIT license while having a dependency on a package that is licensed under GPL-3 are complex and can vary depending on the specific circumstances. It is always advisable to seek legal advice from a licensed attorney if you have any doubts or concerns about licensing issues.\n\nHowever, in general, it is possible to publish an R package on CRAN under an MIT license when you have a dependency on a package that is licensed under GPL-3. This is because the MIT license is a permissive open-source license that allows for more flexibility in how the software can be used and distributed, and it is generally considered compatible with the GPL-3 license.\n\nThat being said, if your package depends on a GPL-3-licensed package, your package may be considered a derivative work and therefore subject to the terms of the GPL-3 license. This means that if you distribute your package, you may need to also distribute the source code for your package under the GPL-3 license or a compatible license, and you may need to ensure that the requirements of the GPL-3 license are met for the entire distribution, including any dependencies.\n\nIt is also worth noting that the R community has its own guidelines and recommendations for package licensing, and it is important to comply with these guidelines if you want to publish your package on CRAN. The CRAN Repository Policy states that packages should have a \"permissive\" or \"GPL-compatible\" license, but does not explicitly require that packages use the GPL license or any other specific license.\n\nIn summary, while it is possible to publish an R package on CRAN under an MIT license while having a dependency on a package that is licensed under GPL-3, it is important to understand the implications of the different licenses and to ensure that you comply with any applicable guidelines and recommendations from the R community.\nAfter harping a bit on copyright infringement in general, ChatGPT changed its response to\nTechnically, you can publish an R package on CRAN under an MIT license when you have a dependency on a package that is licensed under GPL-3, but doing so would not be compliant with the terms of the GPL-3 license.\n\nThe GPL-3 license is a strong copyleft license that requires derivative works to be released under the same license. If your package depends on a GPL-3-licensed package, your package may be considered a derivative work and therefore must be licensed under the GPL-3 license or a compatible license.\n\nThe MIT license, on the other hand, is a permissive license that allows for more flexibility in how the software is used and distributed. However, it is not compatible with the GPL-3 license, and therefore cannot be used for derivative works of GPL-3-licensed software.\n\nPublishing an R package on CRAN under an MIT license when you have a dependency on a package that is licensed under GPL-3 would be a licensing violation, and could potentially result in legal action or other consequences. It is important to comply with the licensing requirements of all dependencies in your package to avoid any legal issues.\nThe ‘harping’ questions:\n\nIs it legal to publish an R package on CRAN under an MIT license when I have a dependency on a package that is licensed under GPL-3?\nIs it illegal to publish an R package on CRAN under an MIT license when I have a dependency on a package that is licensed under GPL-3?\nIs it a copyright infringement to publish an R package on CRAN under an MIT license when I have a dependency on a package that is licensed under GPL-3?\nCan I publish an R package on CRAN under an MIT license when I have a dependency on a package that is licensed under GPL-3 without infringing copyright?\n\nAnswering the above question in regards to lab 3: While Colin Fay’s book gave an excellent way to check the various licenses of all dependencies, he did not provide an opinion about potential copyright infringement when releasing packages with an MIT license. It seems as though as long as there was no restricted-use licenses, releasing a package with a MIT license is fine. In terms of the specifics of releasing a package with an MIT license when a dependency has a GPL-3 license, I am of the opinion that since GPL-3 specifies that “you have the freedom to change the software or use pieces of it in new free programs” and that “if you distribute copies of such a program, whether gratis or for a fee, you must pass on to the recipients the same freedoms that you received. You must make sure that they, too, receive or can get the source code.” As such, if a new program is using a dependency as it is intended and is not claiming the work as its own (by listing the dependencies), then this falls under the rights of the user by the GPL3 license. Thus, in these circumstances it is acceptable to release a MIT license package despite having a GPL3 license dependency. As to the specifics of lab 3, the only required packages are tidyverse (including its sub-packages lubridate and tibble) and tabulizer. Both tidyverse and tabulizer have MIT licenses, so the above question is not applicable."
  },
  {
    "objectID": "blog-2023/Blog-7-submissions/Sabrenar/index.html#submission",
    "href": "blog-2023/Blog-7-submissions/Sabrenar/index.html#submission",
    "title": "Licenses and Packages",
    "section": "Submission",
    "text": "Submission\nWrite answers to the questions directly into the file README.Rmd. Push the blog post to your blog-7 repo. Make sure that all of the checks are passing."
  },
  {
    "objectID": "blog-2023/Blog-7-submissions/luobo119/index.html#prompt",
    "href": "blog-2023/Blog-7-submissions/luobo119/index.html#prompt",
    "title": "License",
    "section": "Prompt:",
    "text": "Prompt:\nThe DESCRIPTION file of a package contains the package’s meta information. Most of the fields in this file are quite straight forward: author, version number, and a short package description. When you call library(help=\"<package name>\") for package <package name> you can see the contents of the DESCRIPTION file for that package (and some parts of the NAMESPACE file).\nRead through Colin Fay’s (short) book on Licensing R\nWrite a blog post addressing the following questions:\n\nUnder what license does R operate? What is the license for ggplot2?\nR: GPL-2 | GPL-3. The GNU General Public License, either Version 2, June 1991 or Version 3, June 2007.\nggplot2: MIT + file LICENSE\n\n\nWhat are the dependencies of the package you made?\nRead through chapter 5.2 of Licensing R. Combine and adjust the code pieces to create the dependencies for a package that is on github rather than CRAN. (Don’t forget about the package desc.)\n\nWhat dependencies does the package have that you created for Lab-3?\nR6, cli, dplyr, fansi, generics, glue, grDevices, graphics, lifecycle, magrittr, methods, pillar, pkgconfig, rlang, stats, tibble, tidyselect, utf8, utils, vctrs, withr, lubridate, timechange, purrr, bit, bit64, clipr, crayon, ellipsis, hms, readr, tzdb, vroom, png, rJava, tabulizer, tabulizerjars, tools\n\n\nWhich licenses are involved?\nApache License (== 2.0), file LICENSE, GPL-2, GPL-3, MIT + file LICENSE, GPL (>= 2), LGPL-2.1\n\n\nAre all of these dependencies required? Elaborate.\nNo. For example in ‘tabulizer’ package, ‘png’ is one dependency, but we only use ‘extract_tables’ function from ‘tabulizer’ package, which can also work without ‘png’ package. So not all dependencies are required. But when you install ‘tabulizer’ package, ‘png’ will be asked to be installed.\n\n\nUnder which license should this blog post be published? Make sure that you are using an appropriate license. (You can change the current licenses with the help of commands from the use_license_XXX family in the usethis package)\nGPL-3 since ‘Rmarkdown’ is needed in this blog.\n\n\n\nCan I publish an R package on CRAN under an MIT license when I have a dependency on a package that is licensed under GPL-3?\nWhen confronted with the above question, ChatGPT gave two – quite different – responses, as shown below. The main point in both responses is ‘your package may be considered derivative work’. At the specific problem of the package developed for Lab 3, what is your opinion about potential copyright infringements when releasing the package with an MIT license? Make sure to take the relevant passage in Colin Fay’s book under consideration.\nThe legal implications of publishing an R package on CRAN under an MIT license while having a dependency on a package that is licensed under GPL-3 are complex and can vary depending on the specific circumstances. It is always advisable to seek legal advice from a licensed attorney if you have any doubts or concerns about licensing issues.\n\nHowever, in general, it is possible to publish an R package on CRAN under an MIT license when you have a dependency on a package that is licensed under GPL-3. This is because the MIT license is a permissive open-source license that allows for more flexibility in how the software can be used and distributed, and it is generally considered compatible with the GPL-3 license.\n\nThat being said, if your package depends on a GPL-3-licensed package, your package may be considered a derivative work and therefore subject to the terms of the GPL-3 license. This means that if you distribute your package, you may need to also distribute the source code for your package under the GPL-3 license or a compatible license, and you may need to ensure that the requirements of the GPL-3 license are met for the entire distribution, including any dependencies.\n\nIt is also worth noting that the R community has its own guidelines and recommendations for package licensing, and it is important to comply with these guidelines if you want to publish your package on CRAN. The CRAN Repository Policy states that packages should have a \"permissive\" or \"GPL-compatible\" license, but does not explicitly require that packages use the GPL license or any other specific license.\n\nIn summary, while it is possible to publish an R package on CRAN under an MIT license while having a dependency on a package that is licensed under GPL-3, it is important to understand the implications of the different licenses and to ensure that you comply with any applicable guidelines and recommendations from the R community.\nAfter harping a bit on copyright infringement in general, ChatGPT changed its response to\nTechnically, you can publish an R package on CRAN under an MIT license when you have a dependency on a package that is licensed under GPL-3, but doing so would not be compliant with the terms of the GPL-3 license.\n\nThe GPL-3 license is a strong copyleft license that requires derivative works to be released under the same license. If your package depends on a GPL-3-licensed package, your package may be considered a derivative work and therefore must be licensed under the GPL-3 license or a compatible license.\n\nThe MIT license, on the other hand, is a permissive license that allows for more flexibility in how the software is used and distributed. However, it is not compatible with the GPL-3 license, and therefore cannot be used for derivative works of GPL-3-licensed software.\n\nPublishing an R package on CRAN under an MIT license when you have a dependency on a package that is licensed under GPL-3 would be a licensing violation, and could potentially result in legal action or other consequences. It is important to comply with the licensing requirements of all dependencies in your package to avoid any legal issues.\n\nThe ‘harping’ questions:\n\nIs it legal to publish an R package on CRAN under an MIT license when I have a dependency on a package that is licensed under GPL-3?\n\nNo. There might be legal issue.\n\nIs it illegal to publish an R package on CRAN under an MIT license when I have a dependency on a package that is licensed under GPL-3?\n\nNo. By complying all the licensing requirements and getting the permission from all the contributors, there may not be a legal issue.\n\nIs it a copyright infringement to publish an R package on CRAN under an MIT license when I have a dependency on a package that is licensed under GPL-3?\n\nYes. MIT is a permissive license and GPL-3 is strongly protective license. There might be copyright infringement.\n\nCan I publish an R package on CRAN under an MIT license when I have a dependency on a package that is licensed under GPL-3 without infringing copyright?\n\nYes, I think you can change the license if all contributors agree and there is no infringing copyright.\nMy opinion about this is that even though it is doable, it requires a lot of extra work and it may take time and effort to get permission from every and adjust everything to comply with the license requirement. So it might be better to decide from the beginning about which license to use."
  },
  {
    "objectID": "blog-2023/Blog-7-submissions/luobo119/index.html#submission",
    "href": "blog-2023/Blog-7-submissions/luobo119/index.html#submission",
    "title": "License",
    "section": "Submission",
    "text": "Submission\nWrite answers to the questions directly into the file README.Rmd. Push the blog post to your blog-7 repo. Make sure that all of the checks are passing."
  },
  {
    "objectID": "blog-2023/Blog-7-submissions/AArabio/index.html#prompt",
    "href": "blog-2023/Blog-7-submissions/AArabio/index.html#prompt",
    "title": "License Fun",
    "section": "Prompt:",
    "text": "Prompt:\nThe DESCRIPTION file of a package contains the package’s meta information. Most of the fields in this file are quite straight forward: author, version number, and a short package description. When you call library(help=\"<package name>\") for package <package name> you can see the contents of the DESCRIPTION file for that package (and some parts of the NAMESPACE file).\nRead through Colin Fay’s (short) book on Licensing R\nWrite a blog post addressing the following questions:\n\nUnder what license does R operate? What is the license for ggplot2?\nR as a package is licensed under GPL-2 | GPL-3 . File doc/COPYING is the same as GPL-2 . Some files are licensed under ‘GPL (version 2 or later)’, which includes GPL-3 … ggplot2 operates under MIT + file LICENSE …\n\n\nWhat are the dependencies of the package you made?\nRead through chapter 5.2 of Licensing R. Combine and adjust the code pieces to create the dependencies for a package that is on github rather than CRAN. (Don’t forget about the package desc.) What dependencies does the package have that you created for Lab-3? Which licenses are involved? Are all of these dependencies required? Elaborate.\nUnder which license should this blog post be published? Make sure that you are using an appropriate license. (You can change the current licenses with the help of commands from the use_license_XXX family in the usethis package)\nusethis::\nCreative commons licenses appropriate for data packages: CC0: dedicated to public domain.\nMost of the dependencies are required but updates may change this depending on packaging … we would likey publush this blog under the GPL-3 license… I would not want anyone to take my name and be able to say that I wrote something or had a certain opinion that was untrue or invalid.\n\n\nCan I publish an R package on CRAN under an MIT license when I have a dependency on a package that is licensed under GPL-3?\nI do think that it would be okay to publish an R package on CRAN under an MIT license when I have a dependency on a package that is licensed under GPL-3 as long as the dependency was properly stated and regarded. I think that as long as one is covering themselves and following the requirements as stated for their package then there shouldn’t be a problem …\nWhen confronted with the above question, ChatGPT gave two – quite different – responses, as shown below. The main point in both responses is ‘your package may be considered derivative work’. At the specific problem of the package developed for Lab 3, what is your opinion about potential copyright infringements when releasing the package with an MIT license? Make sure to take the relevant passage in Colin Fay’s book under consideration.\nThe legal implications of publishing an R package on CRAN under an MIT license while having a dependency on a package that is licensed under GPL-3 are complex and can vary depending on the specific circumstances. It is always advisable to seek legal advice from a licensed attorney if you have any doubts or concerns about licensing issues.\n\nHowever, in general, it is possible to publish an R package on CRAN under an MIT license when you have a dependency on a package that is licensed under GPL-3. This is because the MIT license is a permissive open-source license that allows for more flexibility in how the software can be used and distributed, and it is generally considered compatible with the GPL-3 license.\n\nThat being said, if your package depends on a GPL-3-licensed package, your package may be considered a derivative work and therefore subject to the terms of the GPL-3 license. This means that if you distribute your package, you may need to also distribute the source code for your package under the GPL-3 license or a compatible license, and you may need to ensure that the requirements of the GPL-3 license are met for the entire distribution, including any dependencies.\n\nIt is also worth noting that the R community has its own guidelines and recommendations for package licensing, and it is important to comply with these guidelines if you want to publish your package on CRAN. The CRAN Repository Policy states that packages should have a \"permissive\" or \"GPL-compatible\" license, but does not explicitly require that packages use the GPL license or any other specific license.\n\nIn summary, while it is possible to publish an R package on CRAN under an MIT license while having a dependency on a package that is licensed under GPL-3, it is important to understand the implications of the different licenses and to ensure that you comply with any applicable guidelines and recommendations from the R community.\nAfter harping a bit on copyright infringement in general, ChatGPT changed its response to\nTechnically, you can publish an R package on CRAN under an MIT license when you have a dependency on a package that is licensed under GPL-3, but doing so would not be compliant with the terms of the GPL-3 license.\n\nThe GPL-3 license is a strong copyleft license that requires derivative works to be released under the same license. If your package depends on a GPL-3-licensed package, your package may be considered a derivative work and therefore must be licensed under the GPL-3 license or a compatible license.\n\nThe MIT license, on the other hand, is a permissive license that allows for more flexibility in how the software is used and distributed. However, it is not compatible with the GPL-3 license, and therefore cannot be used for derivative works of GPL-3-licensed software.\n\nPublishing an R package on CRAN under an MIT license when you have a dependency on a package that is licensed under GPL-3 would be a licensing violation, and could potentially result in legal action or other consequences. It is important to comply with the licensing requirements of all dependencies in your package to avoid any legal issues.\nThe ‘harping’ questions:\n\nIs it legal to publish an R package on CRAN under an MIT license when I have a dependency on a package that is licensed under GPL-3?\nIs it illegal to publish an R package on CRAN under an MIT license when I have a dependency on a package that is licensed under GPL-3?\nIs it a copyright infringement to publish an R package on CRAN under an MIT license when I have a dependency on a package that is licensed under GPL-3?\nCan I publish an R package on CRAN under an MIT license when I have a dependency on a package that is licensed under GPL-3 without infringing copyright?"
  },
  {
    "objectID": "blog-2023/Blog-7-submissions/AArabio/index.html#submission",
    "href": "blog-2023/Blog-7-submissions/AArabio/index.html#submission",
    "title": "License Fun",
    "section": "Submission",
    "text": "Submission\nWrite answers to the questions directly into the file README.Rmd. Push the blog post to your blog-7 repo. Make sure that all of the checks are passing.\nThis is essentially asking for an assessment of licenses - this is, again a pure writing assignment, no coding involved besides fixing the Yaml front matter. There is no right or wrong answer regarding the question of whether you -without looking at the specifics of the code- can or can not publish a package as MIT that depends on a GPL-3 package. What counts is the strength of your argument in favor of your decision. :)"
  },
  {
    "objectID": "blog-2023/Blog-7-submissions/Starwiiin/index.html#prompt",
    "href": "blog-2023/Blog-7-submissions/Starwiiin/index.html#prompt",
    "title": "All that legal stuff…",
    "section": "Prompt:",
    "text": "Prompt:\nThe DESCRIPTION file of a package contains the package’s meta information. Most of the fields in this file are quite straight forward: author, version number, and a short package description. When you call library(help=\"<package name>\") for package <package name> you can see the contents of the DESCRIPTION file for that package (and some parts of the NAMESPACE file).\nRead through Colin Fay’s (short) book on Licensing R\nWrite a blog post addressing the following questions:\n\nUnder what license does R operate? What is the license for ggplot2?\nParvin’s answer: R software is a free software which was released under the terms of the GNU General Public License, either version 2 (June 1991) or version 3 (June 2007). I used the “licence()” in the R and could get it. ggplot2 package is distributed based on the MIT + file License.\n\n\nWhat are the dependencies of the package you made?\nRead through chapter 5.2 of Licensing R. Combine and adjust the code pieces to create the dependencies for a package that is on github rather than CRAN. (Don’t forget about the package desc.) What dependencies does the package have that you created for Lab-3? Which licenses are involved? Are all of these dependencies required? Elaborate.\nParvin’s answer: Unfortunately, I could not get the dependencies for out team’s package (Team 6) beacuse of one issue in importing the package. So, I tried to get the dependencoes and run the code on the package of another team which is named “AmesPD” from “Team1”. For the first part using the get_deps function, I got:\nINFO [2023-03-09 16:10:54] Constructing dependency network for Team1\nINFO [2023-03-09 16:10:54] ...done constructing dependency network.\nFor the next part, I got:\nNew names:\n• `Authors@R` -> `Authors.R`\n• `Classification/ACM` -> `Classification.ACM`\n• `Classification/ACM-2012` -> `Classification.ACM.2012`\n• `Classification/JEL` -> `Classification.JEL`\n• `Classification/MSC` -> `Classification.MSC`\n• `Classification/MSC-2010` -> `Classification.MSC.2010`\n• `Date/Publication` -> `Date.Publication`\n• `X-CRAN-Comment` -> `X.CRAN.Comment`\n• `Reverse depends` -> `Reverse.depends`\n• `Reverse imports` -> `Reverse.imports`\n• `Reverse linking to` -> `Reverse.linking.to`\n• `Reverse suggests` -> `Reverse.suggests`\n• `Reverse enhances` -> `Reverse.enhances`\nFor the next part, I got:\n A tibble: 8 × 2\n  License                                    n\n  <chr>                                  <int>\n1 Apache License (== 2.0) | file LICENSE     1\n2 Apache License 2.0                         1\n3 GPL (>= 2)                                 2\n4 GPL-2 | GPL-3                              2\n5 GPL-3                                      1\n6 LGPL-2.1                                   1\n7 MIT + file LICENSE                        19\n8 file LICENSE                               1\nIn this way, we can get the dependencies of the package that we made in the lab or any package which is available in Github.\nUnder which license should this blog post be published? Make sure that you are using an appropriate license. (You can change the current licenses with the help of commands from the use_license_XXX family in the usethis package)\nFor this blog, we are using the license cc0-1.0; I am gonna keep this license.\n\n\nCan I publish an R package on CRAN under an MIT license when I have a dependency on a package that is licensed under GPL-3?\nWhen confronted with the above question, ChatGPT gave two – quite different – responses, as shown below. The main point in both responses is ‘your package may be considered derivative work’. At the specific problem of the package developed for Lab 3, what is your opinion about potential copyright infringements when releasing the package with an MIT license? Make sure to take the relevant passage in Colin Fay’s book under consideration.\nParvin’s answer: My understanding from the Colin Fay’s book was that a package which is licensed under GPL-3 is compatible and accepted by the CRAN policy. Therefore, it is possible to publish it in CRAN but it needs the permission of the all the contributors. The conversation and permission announcement may happen in the Github between the contributors. I just mentioned the points that was said in the book and it was not said in the following information from ChatGPT.\nThe legal implications of publishing an R package on CRAN under an MIT license while having a dependency on a package that is licensed under GPL-3 are complex and can vary depending on the specific circumstances. It is always advisable to seek legal advice from a licensed attorney if you have any doubts or concerns about licensing issues.\n\nHowever, in general, it is possible to publish an R package on CRAN under an MIT license when you have a dependency on a package that is licensed under GPL-3. This is because the MIT license is a permissive open-source license that allows for more flexibility in how the software can be used and distributed, and it is generally considered compatible with the GPL-3 license.\n\nThat being said, if your package depends on a GPL-3-licensed package, your package may be considered a derivative work and therefore subject to the terms of the GPL-3 license. This means that if you distribute your package, you may need to also distribute the source code for your package under the GPL-3 license or a compatible license, and you may need to ensure that the requirements of the GPL-3 license are met for the entire distribution, including any dependencies.\n\nIt is also worth noting that the R community has its own guidelines and recommendations for package licensing, and it is important to comply with these guidelines if you want to publish your package on CRAN. The CRAN Repository Policy states that packages should have a \"permissive\" or \"GPL-compatible\" license, but does not explicitly require that packages use the GPL license or any other specific license.\n\nIn summary, while it is possible to publish an R package on CRAN under an MIT license while having a dependency on a package that is licensed under GPL-3, it is important to understand the implications of the different licenses and to ensure that you comply with any applicable guidelines and recommendations from the R community.\nAfter harping a bit on copyright infringement in general, ChatGPT changed its response to\nTechnically, you can publish an R package on CRAN under an MIT license when you have a dependency on a package that is licensed under GPL-3, but doing so would not be compliant with the terms of the GPL-3 license.\n\nThe GPL-3 license is a strong copyleft license that requires derivative works to be released under the same license. If your package depends on a GPL-3-licensed package, your package may be considered a derivative work and therefore must be licensed under the GPL-3 license or a compatible license.\n\nThe MIT license, on the other hand, is a permissive license that allows for more flexibility in how the software is used and distributed. However, it is not compatible with the GPL-3 license, and therefore cannot be used for derivative works of GPL-3-licensed software.\n\nPublishing an R package on CRAN under an MIT license when you have a dependency on a package that is licensed under GPL-3 would be a licensing violation, and could potentially result in legal action or other consequences. It is important to comply with the licensing requirements of all dependencies in your package to avoid any legal issues.\nThe ‘harping’ questions:\n\nIs it legal to publish an R package on CRAN under an MIT license when I have a dependency on a package that is licensed under GPL-3?\nIs it illegal to publish an R package on CRAN under an MIT license when I have a dependency on a package that is licensed under GPL-3?\nIs it a copyright infringement to publish an R package on CRAN under an MIT license when I have a dependency on a package that is licensed under GPL-3?\nCan I publish an R package on CRAN under an MIT license when I have a dependency on a package that is licensed under GPL-3 without infringing copyright?"
  },
  {
    "objectID": "blog-2023/Blog-7-submissions/Starwiiin/index.html#submission",
    "href": "blog-2023/Blog-7-submissions/Starwiiin/index.html#submission",
    "title": "All that legal stuff…",
    "section": "Submission",
    "text": "Submission\nWrite answers to the questions directly into the file README.Rmd. Push the blog post to your blog-7 repo. Make sure that all of the checks are passing."
  },
  {
    "objectID": "blog-2023/Blog-2-submissions/xyzyc/ZhouYingchao.html",
    "href": "blog-2023/Blog-2-submissions/xyzyc/ZhouYingchao.html",
    "title": "Happy Git with R",
    "section": "",
    "text": "git and Github are tools for helping with versioning of files in collaborative efforts as well as archiving entries for your future self. Unfortunately working with git isn’t always completely straightforward. Jenny Bryan’s book “Happy git and github with R” helps with that. The book is available from http://happygitwithr.com/. Have a look over the index and pick one of the chapters for a more in-depth read.\nWrite a blog post answering the following questions:\n\nWrite a short (100-150 words) summary of the chapter you read in-depth.\n\nI read the chapter “9. Personal access token for HTTPS”.\nThis chapter mainly teaches us how to set up a personal access token (PAT) to allow the local computer talk to the GitHub. Note the password for login on GitHub is not an acceptable credential.\nThe whole generating and storing process may be done through R package usethis. Commands usethis::create_github_token() will generate the PAT and gitcreds::gitcreds_set() can store the credential.\nYou may also generate the PAT on https://github.com/settings/tokens and store the token generated at a secure place.\nBu default, the APT will expire in 30 days. And you need to re-generate and re-store the APT in the same steps.\n\nLooking back at all of the team projects you have been involved in, describe the biggest mishap you had. Could that have been avoided using git? How?.\n\nIt was a mess…\nI once worked with a classmate. We had a Github repository but I didn’t know how to push the changes from Rstudio or terminal, so every time I actually only committed the changes without pushing them to Github. I also occasionally uploaded my R script to Github page.\nHowever, once after I made a major change, I didn’t upload my file in a timely manner and my classmate worked with the wrong code for a day. When they taught me how to push to Github after this, the main branch was several steps ahead due to me uploading .R file. We had to force the push and lost some commits.\nUnfortunately, it turned out that we needed some old code that we lost in that force push… And we had to take some trouble to recover the commits.\nIf I had learned how to push from Rstudio (or just terminal) and only updated the code through push, we would have a clean record of the code.\n\nGive an example of one new git feature that you learned about from Jenny Bryan’s book..\n\nYou may use git remote set-url to change between https://github.com/usr/project.git and git@github.com:usr/project.git and switch between HTTPS and SSH credentials. (I currently use SSH. It’s good to know I can switch freely.)"
  },
  {
    "objectID": "blog-2023/Blog-2-submissions/kundan7kumar/KumarKundan.html",
    "href": "blog-2023/Blog-2-submissions/kundan7kumar/KumarKundan.html",
    "title": "Happy Git with R",
    "section": "",
    "text": "git and Github are tools for helping with versioning of files in collaborative efforts as well as archiving entries for your future self. Unfortunately working with git isn’t always completely straightforward. Jenny Bryan’s book “Happy git and github with R” helps with that. The book is available from http://happygitwithr.com/. Have a look over the index and pick one of the chapters for a more in-depth read.\nWrite a blog post answering the following questions:\n\nWrite a short (100-150 words) summary of the chapter you read in-depth.\n\nSolution: I have gone through Chapter 18 in depth, it provides a comprehensive introduction as well as hand-on experience to R Markdown which is a wonderful tool for creating documents and reports, it also allows to embed R code within a document and produces a various format output like HTML, pdf, word using knitr options. It also helps in creating the first R Markdown document with ‘Hello World’ and also covers the basics of formatting and styling text, including how to add headings, images,bullet points, and tables. Apart from formatting and styling it also explains how to customize CSS and themes to the document. It will help with creating professional reports as well as documents of the work. Moreover, it also explains the how to connect and push R markdown file to GitHub and how to publish the report.\n\nLooking back at all of the team projects you have been involved in, describe the biggest mishap you had. Could that have been avoided using git? How?.\n\nSolution: Being a software developer in the past, I have used versioning tools like git and subversion. When I started using git within my team, I ended up with multiples mishap in the team projects. one of the scenarios I pulled the code and try editing it but forget to commit and push, and then I pulled the latest version again which ended up losing my own work. As there is no backup copy of my code and I was working on master copy, the pulled request overwrites my work.\nIt could be avoided if I used branching concept of git. Branching ensures my work is saved even if I pull the latest version of the code from the main branch. If I knew the standard procedure of git, I may not end up losing my work. I think branching is one of the best ways to cooperate and contribute to team projects.\n\nGive an example of one new git feature that you learned about from Jenny Bryan’s book..\n\nSolution: From chapter 12 of Jenny Bryan’s book, I learnt how to connect RStudio with Git and GitHub. In my case, Somehow, RStudio are not able to detect git, install the git explained in chapter 6 of the book and finally able to connect RStudio to git and GitHub."
  },
  {
    "objectID": "blog-2023/Blog-2-submissions/anyeshar/RayAnyesha.html",
    "href": "blog-2023/Blog-2-submissions/anyeshar/RayAnyesha.html",
    "title": "Happy Git with R",
    "section": "",
    "text": "git and Github are tools for helping with versioning of files in collaborative efforts as well as archiving entries for your future self. Unfortunately working with git isn’t always completely straightforward. Jenny Bryan’s book “Happy git and github with R” helps with that. The book is available from http://happygitwithr.com/. Have a look over the index and pick one of the chapters for a more in-depth read.\nWrite a blog post answering the following questions:\n\nWrite a short (100-150 words) summary of the chapter you read in-depth.\nLooking back at all of the team projects you have been involved in, describe the biggest mishap you had. Could that have been avoided using git? How?.\nGive an example of one new git feature that you learned about from Jenny Bryan’s book..\nWrite a short (100-150 words) summary of the chapter you read in-depth. I read chapter 9 about the person access tokens for HTTPS. GitHub requires a personal access token so that they know the person who is trying to make changes is the correct user. The password we use to login is not sufficient to verify credentials which is why we need this specific personal access token. All you have to do is generate a token and then enter it when you set up credentials. You can set a time for expiration, and once the token expires you have to regenerate a new one. This chapter also details the difference between HTTPS and SSH. HTTPS is strongly recommended over SSH because it is easier to work with and can be used with GitHub’s API which is called in some R packages.\nLooking back at all of the team projects you have been involved in, describe the biggest mishap you had. Could that have been avoided using git? How? A big problem working on a group project is sharing code. Often we can split up the work so we don’t need to share code, but if we do we often email files back and forth which can be tedious and sometimes not the most up to date. Using GitHub would solve this problem and branching could ensure we can work parallelly.\nGive an example of one new git feature that you learned about from Jenny Bryan’s book. I also read the chapter on branches. I have never used branches before. This seems important because you can work on stuff without messing with the main branch."
  },
  {
    "objectID": "blog-2023/Blog-2-submissions/Landon-Getting/GettingLandon.html",
    "href": "blog-2023/Blog-2-submissions/Landon-Getting/GettingLandon.html",
    "title": "Happy Git with R",
    "section": "",
    "text": "git and Github are tools for helping with versioning of files in collaborative efforts as well as archiving entries for your future self. Unfortunately working with git isn’t always completely straightforward. Jenny Bryan’s book “Happy git and github with R” helps with that. The book is available from http://happygitwithr.com/. Have a look over the index and pick one of the chapters for a more in-depth read.\nWrite a blog post answering the following questions:\n\nWrite a short (100-150 words) summary of the chapter you read in-depth.\nLooking back at all of the team projects you have been involved in, describe the biggest mishap you had. Could that have been avoided using git? How?.\nGive an example of one new git feature that you learned about from Jenny Bryan’s book.."
  },
  {
    "objectID": "blog-2023/Blog-2-submissions/Landon-Getting/GettingLandon.html#chapter-27-the-repeated-amend---summary",
    "href": "blog-2023/Blog-2-submissions/Landon-Getting/GettingLandon.html#chapter-27-the-repeated-amend---summary",
    "title": "Happy Git with R",
    "section": "Chapter 27: The Repeated Amend - Summary",
    "text": "Chapter 27: The Repeated Amend - Summary\nDuring Lab 1, you may have encountered a similar situation to our group. Our repository was quickly filled with many small commits that ranged from changing a single argument to entire sections of the lab. The repeated amend workflow will be useful in the future as I strive to make my version history more digestible for collaborators.\nInstead of performing many small commits, the amend action allows you to edit a previous commit as you make unforeseen positive progress. This is possible in RStudio through the “amend previous commit” check box in the commit interface window. Once you have completed a section of code or accomplished a goal, then commit. The commit history will show you finished the section or accomplished the goal in a single commit rather than many smaller commits. Once you’ve tested the code and feel good about the commit, you can push it and repeat the process for the next task."
  },
  {
    "objectID": "blog-2023/Blog-2-submissions/Landon-Getting/GettingLandon.html#team-mishap",
    "href": "blog-2023/Blog-2-submissions/Landon-Getting/GettingLandon.html#team-mishap",
    "title": "Happy Git with R",
    "section": "Team Mishap",
    "text": "Team Mishap\nIn an introductory data mining class, my group took an especially long time to develop, train, and test our model because no one knew which file was most updated or advanced. We desperately needed a lesson on reproducible code as well. R scripts were named after the author and usually had a number or adjective to further describe the iteration (ex. Landon_6 or Zach_CleanData). Git would have eliminated this confusion through a main branch that is pulled from and pushed to as progress is made individually.\nIn many of the scripts, file paths were hard coded. Instead of saving a cleaned or manipulated data frame as a new file in a common repo, we each spent hours running code to produce it as an object in our local R Studio. It was a disaster. The group has come a long way since the project and it is funny to look back on our ineptitude."
  },
  {
    "objectID": "blog-2023/Blog-2-submissions/Landon-Getting/GettingLandon.html#new-git-feature",
    "href": "blog-2023/Blog-2-submissions/Landon-Getting/GettingLandon.html#new-git-feature",
    "title": "Happy Git with R",
    "section": "New Git Feature!",
    "text": "New Git Feature!\nIf you become stuck during a cycle of repeated amends (or at any time prior to a commit), utilize the “Diff” or “Commit” actions in RStudio to either discard all changes or discard a chunk of changes."
  },
  {
    "objectID": "blog-2023/Blog-2-submissions/Hiiiua/HuaMuxin.html",
    "href": "blog-2023/Blog-2-submissions/Hiiiua/HuaMuxin.html",
    "title": "Happy Git with R",
    "section": "",
    "text": "git and Github are tools for helping with versioning of files in collaborative efforts as well as archiving entries for your future self. Unfortunately working with git isn’t always completely straightforward. Jenny Bryan’s book “Happy git and github with R” helps with that. The book is available from http://happygitwithr.com/. Have a look over the index and pick one of the chapters for a more in-depth read.\nWrite a blog post answering the following questions:\n\nWrite a short (100-150 words) summary of the chapter you read in-depth.\nThe chapter Branches talks about how to work individually on experimental ideas without harming the main project. Basically, one only needs to create and check out a branch, then it will be easy to switch back and forth between the branches to work on the edition as needed. Once the work has been done, one can always merge in main. However, there could be conflicts in merging, they come from divergence in the branches and the right way to resolve the conflict is pulling out the unmerged file and see the lines in conflict and edit them. It’s always an option to abort merging and back to the previous state.\nLooking back at all of the team projects you have been involved in, describe the biggest mishap you had. Could that have been avoided using git? How?.\nI used to work with teammates on a project. During the data cleaning part, we can’t specifically divide the work so each of us wanted to some explorations so we fell in the dilemma that if we should committing our own exploration or not. It should be a good idea to check out branches before deciding if we want to add any new codes.\nGive an example of one new git feature that you learned about from Jenny Bryan’s book..\nA new feature I learned from this book is taking advantage of refs to identify a specific point in the repo’s history."
  },
  {
    "objectID": "blog-2023/Blog-2-submissions/charlestbonk/BonkCharlie.html",
    "href": "blog-2023/Blog-2-submissions/charlestbonk/BonkCharlie.html",
    "title": "Happy Git with R",
    "section": "",
    "text": "git and Github are tools for helping with versioning of files in collaborative efforts as well as archiving entries for your future self. Unfortunately working with git isn’t always completely straightforward. Jenny Bryan’s book “Happy git and github with R” helps with that. The book is available from http://happygitwithr.com/. Have a look over the index and pick one of the chapters for a more in-depth read.\nWrite a blog post answering the following questions:\n\nWrite a short (100-150 words) summary of the chapter you read in-depth.\n\n\nThe chapter the I read was “29. Pull, But you have Local Work”, where Bryan talks through how to resolve a common way to have merge conflicts: when you want to push but can’t until you pull but you have changes locally, so you can’t pull with automatic merging. She covers both how to manage pulling with in-progress work both commited and not commited. She also talked about what to do when the easier steps don’t work out; git stash won’t always work, so here’s what to do if it doesn’t. She also touched on rebasing, and on continuing your own work in a temporary branch from main.\n\n\nLooking back at all of the team projects you have been involved in, describe the biggest mishap you had. Could that have been avoided using git? How?.\n\n\nWhile working on my Capstone project in undergrad, a group member of mine had his laptop destroyed by a dog knocking a beer over. We lost about 2 weeks of work that day. If we were using git, we (probably) would have lost significantly less work, and I wouldn’t have had to stay up multiple days to work on the code that he had lost. Git would have been good both to help store the code, that way things like that could have been easily avoided and worked around, but also, git pushes and pulls are much easier than emailing R scripts around.\n\n\nGive an example of one new git feature that you learned about from Jenny Bryan’s book..\n\n\nI am horrified of merge conflicts. I still am horrified of merge conflicts. But now, I am a little less scared, especially knowing that they are common and happen all of the time. Even if I forget the exacts on how to manage merge conflicts, I do also know now where I can go for a relatively clear step-by-step walkthrough of managing pulling when I have work of my own (becuase that is easier than saving all of my work in an external document and then deleting my directory locally and then make a new directory and connect it to the repo and then move my changes back, just so I can pull the most recent work.)"
  },
  {
    "objectID": "blog-2023/Blog-2-submissions/TWiedRW/WiederichTyler.html",
    "href": "blog-2023/Blog-2-submissions/TWiedRW/WiederichTyler.html",
    "title": "Happy Git with R",
    "section": "",
    "text": "git and Github are tools for helping with versioning of files in collaborative efforts as well as archiving entries for your future self. Unfortunately working with git isn’t always completely straightforward. Jenny Bryan’s book “Happy git and github with R” helps with that. The book is available from http://happygitwithr.com/. Have a look over the index and pick one of the chapters for a more in-depth read.\nWrite a blog post answering the following questions:\n\nWrite a short (100-150 words) summary of the chapter you read in-depth.\n\nFor this blog, I looked at Chapter 29: “Pull, but you have local work”. When work is saved locally and not saved to GitHub, pulling the repo is done normally without error. If one pulls and the file exists differently in the repo, then an error occurs. git stash will save local changes when pulling. This won’t change the fact that the files are still in conflict, but it provides temporary relief.\n\nLooking back at all of the team projects you have been involved in, describe the biggest mishap you had. Could that have been avoided using git? How?.\n\nThe biggest mishap is probably having merge conflicts with git. Sometimes when I can’t figure out how to pull/merge when conflicts exist, I simply delete what I have and pull from the repo to start again fresh (after saving my work somewhere locally).\n\nGive an example of one new git feature that you learned about from Jenny Bryan’s book..\n\ngit stash save and git stash pop. Although the author mentions staying away from these in favor of other methods, I think they are neat tricks!"
  },
  {
    "objectID": "blog-2023/Blog-2-submissions/charchit/ShuklaCharchit.html",
    "href": "blog-2023/Blog-2-submissions/charchit/ShuklaCharchit.html",
    "title": "Happy Git with R",
    "section": "",
    "text": "git and Github are tools for helping with versioning of files in collaborative efforts as well as archiving entries for your future self. Unfortunately working with git isn’t always completely straightforward. Jenny Bryan’s book “Happy git and github with R” helps with that. The book is available from http://happygitwithr.com/. Have a look over the index and pick one of the chapters for a more in-depth read.\nWrite a blog post answering the following questions:\n\nWrite a short (100-150 words) summary of the chapter you read in-depth.\n\nI read Chapter 1 and Chapter 30 in depth and glanced over the rest of them to understand the basic functionality of GIT. Chapter 1 talks about why GIT is important, and chapter 30 talks about working with your future self.\nOne of the most important feature of GIT is version control. It allows user to use “track changes” like function of microsoft word but much better. There are many hosting services like github, bitbucket, gitlab or self hosting. Learning how to use GIT initially has a steep learning curve however it pays off in the long run when a lot of the conflicts and new code is written and need to be rewritten in the future. Other advantages of GIT relates to “Exposure”: showing your work to the world, “keener”: learning from other people, “Collaboration”: feature such as Google Doc (multiple people working on the same file at the same time) and editing/saving etc like an email. There are a few types of repository, most common ones are public and private. The above discussed tools and tech of github allows to fix issues, bugs in softwares, and collbaorate effectively in any programming language including R.\nTime Travel: As we all know time travel is impossible in our current understanding of universe and physics. However, the closest thing to time travel we have is the past files and storage. Git allows you to go back in time and check your previous work to use it in the future work or even copy or build something off of it completely new. Two functions of Git such as History and Blame helps in seeing the past work and the person who committed those changes.\n\nLooking back at all of the team projects you have been involved in, describe the biggest mishap you had. Could that have been avoided using git? How?.\n\nBiggest mishap are usually about the contributions and communcation in a team. I do not think it would be completely avoided by the GIT but it could however be helpful to have a version control to communicate and collaborate effectively within the team. Also, having cloud storage helps a lot in working on different computers (considering me and my tomorrow’s self is a team). One of the research I am doing needs files to be updated constantly in python. I am using Box drive as a version control. If I had to create a new file everytime I make changes in the file I will have a thousand files in one month. My work is mostly only two people and we are fairly good in communicating with each other so it does not conflict too much. However, in the past when there were 3 or more people, it was a big problem to divide the work. Git can help in dividing the work very well and people not butting into each other’s work.\n\nGive an example of one new git feature that you learned about from Jenny Bryan’s book..\n\nI heard about GIT many times in the past few years however I have never used it. This is the first time installing and using the GIT in a class, so everything in the Jenny Bryan’s book is new to me and there is a lot to learn. I lerned that it would be hard intially but it will get better with time, however one thing which might always bother even after being good at it is merging. I am not really sure how it will be hard but I am looking forward to learn to use this tool better in my projects and the labs and hopefully in my research."
  },
  {
    "objectID": "blog-2023/Blog-2-submissions/kellynay/NascimentoThompson_Kelly.html",
    "href": "blog-2023/Blog-2-submissions/kellynay/NascimentoThompson_Kelly.html",
    "title": "Happy Git with R",
    "section": "",
    "text": "git and Github are tools for helping with versioning of files in collaborative efforts as well as archiving entries for your future self. Unfortunately working with git isn’t always completely straightforward. Jenny Bryan’s book “Happy git and github with R” helps with that. The book is available from http://happygitwithr.com/. Have a look over the index and pick one of the chapters for a more in-depth read.\nWrite a blog post answering the following questions:\n\nWrite a short (100-150 words) summary of the chapter you read in-depth.\n\nChapter 20 (“Repo, commit, diff, tag”) Git is a version control framework aiming to help developers who collaborate on big software projects. Repo or repositories are set of files that Git manages as they evolve. For new or existing projects, RStudio users are recommended to dedicate a local directory for it, create an RStudio project, and create a Git repository. By doing so, these applications will leave notes for themselves in hidden files or directories. When saving files, a commit is made, taking a snapshot of all files in the project instead of saving individual files. Diff is the set of differences between two file commits. One common practice in Git projects is writing a commit message each time a commit is made. These messages help colleagues understand recent changes made in the project. A tag is a name that represents the version of the project or references the last commit made.\n\nLooking back at all of the team projects you have been involved in, describe the biggest mishap you had. Could that have been avoided using git? How?.\n\nMy research involves modeling soil erosion at the STRIPS sites (https://www.nrem.iastate.edu/research/STRIPS/). I get rainfall, runoff, and sediment field data for ground truth validation purposes from another research group. These daily measurements from 2016 to 2022 are saved in Excel files created from R scripts. The data includes column names such as “treatment, site, date, rainfall, and runoff.” When I filtered the data, I noticed the rainfall data was included under the treatment column, and they are not supposed to be there. I contacted the collaborator who handled the data and asked the reasoning behind it; he explained it was for graphing purposes, saying that he would add an updated file to the Cybox folder removing the rainfall data from the treatment column. Git could avoid this issue because we would have access to the scripts that generate such files, and I would not have to go to Cybox to download a new version of the field data. Thus, it is important to work in a version control system in a case like this, where files are updated every year.\n\nGive an example of one new git feature that you learned about from Jenny Bryan’s book..\n\nI followed the steps on Chapter 11 - “Connect to GitHub”. I created a new repository on github.com and cloned the repo to my local computer using the Git Bash shell. Following the book instructions I was able to change my working directory, list its files, and display the README file. I also installed GitHub Desktop and cloned repos from github.com. I tested by cloning Blog 1 to my computer."
  },
  {
    "objectID": "blog-2023/Blog-2-submissions/drbradford12/index.html",
    "href": "blog-2023/Blog-2-submissions/drbradford12/index.html",
    "title": "Happy Git with R",
    "section": "",
    "text": "git and Github are tools for helping with versioning of files in collaborative efforts as well as archiving entries for your future self. Unfortunately working with git isn’t always completely straightforward. Jenny Bryan’s book “Happy git and github with R” helps with that. The book is available from http://happygitwithr.com/. Have a look over the index and pick one of the chapters for a more in-depth read.\nWrite a blog post answering the following questions:\n\nWrite a short (100-150 words) summary of the chapter you read in-depth.\n\nDenise’s Answer:\nThe Chapter on Daily Workflows talked about the following:\n\nSetting up your repository - making sure to setup a .gitignore file to keep Git from tracking files that don’t need to be.\nCreating branches and switching between them - use Git to make branches and switch between them.\nCommitting changes - how to stage and commit changes with Git.\nPulling and pushing changes - how to use Git to pull changes from a remote repository and push changes made locally to a remote repository.\nResolving merge conflicts - how to solve merge conflicts that can happen when working on a project with other people.\n\nThe chapter ends with ways on how to stay organized and productive when using Git and GitHub for daily workflows by working to use descriptive branch names, review pull requests regularly, and set up notifications for important events in the repository.\n\nLooking back at all of the team projects you have been involved in, describe the biggest mishap you had. Could that have been avoided using git? How?\n\nDenise’s Answer:\nThe biggest mishap that I’ve been involved in was in many different workplaces that had no repo for code sharing. The most relevant example of lack of repo for code sharing when working with the Nebraska MAP Academy. It would have been nice to have code from the previous student that worked on the project before. Once, I moved on, it was hard to send the code to someone that hasn’t used R before. The biggest issue was sharing a folder on One Drive.\nGit would have been much easier to have people see the work that I’ve done and replicate the work for themselves, once I moved on. Now that Git has actions and markdown formats, I believe it would be much easier to have a seamless workflow.\n\nGive an example of one new git feature that you learned about from Jenny Bryan’s book.\n\nDenise’s Answer:\nThe new git feature that I learned was from the chapter of “Daily Workflow.” What I would like to do a better job with my Git work is to first stop using the desktop version to make sure that I understand the git workflow, while I’ve used the terminal for a few years, I still use the Desktop version to make sure that the correct documents were pushed. When working alone, I don’t use a separate branch from master, this can be a bit problematic in the long-term."
  },
  {
    "objectID": "blog-2023/Blog-2-submissions/mattkava/KavanaughMatthew.html",
    "href": "blog-2023/Blog-2-submissions/mattkava/KavanaughMatthew.html",
    "title": "Happy Git with R",
    "section": "",
    "text": "Write a blog post answering the following questions:\n\nWrite a short (100-150 words) summary of the chapter you read in-depth. For this blog, I read Chapter 30, which is called “Time Travel: See The Past”. It discussed the various ways in which one is able to retrieve a prior version of a project if they desire to make a change or simply want to analyze the history of their work. The first section summarizes hyperlinks, which allow access to commits on a Github repository and access to past versions. Hyperlinks allow one to select specific lines of code in a certain state and share them with others, making for easy collaboration on any project. The “blame” feature enables those who have access to see the commit history, including who edited a file and when such edit occurred. Similarly, the “history” feature enables one to see commits on a single file rather than the entire repository. Finally, the “search” feature enables a user to locate code, commits, or comments on specific files in a repository.\nLooking back at all of the team projects you have been involved in, describe the biggest mishap you had. Could that have been avoided using git? How?. In my R programming class during my senior year of college, my group and I were working on a project that entailed analysis of air pollution and its impacts on a number of health conditions, such as obesity, asthma, diabetes, and cancer. Each member of the group analyzed a different variable and produced a number of graphs using ggplot2 as well as linear correlation tests and graphs that were produced using the base R capabilities. Unfortunately, this occurred during the busy period at the end of the semester, and several of our 5 group members had many other projects and exams that were taking place. Additionally, one of the group members got badly sick, and was unable to attend group meetings or even complete much work virtually. Hence, group meetings came to a halt, and we had made little progress on the project with only two days remaining until the due date. Hence, we ended up pulling an all nighter the night before the due date in which we all sat down to knock in out. There were varying levels of experience with R programming, so several of us had to teach others how use ggplot2 and several other R packages. It was frustrating to have to do so much work last minute, and git definitely could have solved this problem. It would have been easy to share R markdown and code files via a shared repository so that others in the group could see what had been done and by who. Additionally, using git would have allowed our team to provide suggestions to each person’s contribution and allowed us to continue progressing on the project remotely, even when some members were not available.\nGive an example of one new git feature that you learned about from Jenny Bryan’s book.. One example of a git feature that I learned about from this chapter was the issue search feature. This is an advanced search feature that allows for a quick way to search for specific issues within a repository using the built-in features of is:issue and is:open. This allows someone to easily find and troubleshoot issues without needing to look through hundreds or thousands of lines of code."
  },
  {
    "objectID": "blog-2023/Blog-2-submissions/HarunCelikOtto/CelikHarun.html",
    "href": "blog-2023/Blog-2-submissions/HarunCelikOtto/CelikHarun.html",
    "title": "Happy Git with R",
    "section": "",
    "text": "git and Github are tools for helping with versioning of files in collaborative efforts as well as archiving entries for your future self. Unfortunately working with git isn’t always completely straightforward. Jenny Bryan’s book “Happy git and github with R” helps with that. The book is available from http://happygitwithr.com/. Have a look over the index and pick one of the chapters for a more in-depth read.\nMy answers:\n\nWhile I learned new things from all the chapters I had an interest in checking, I especially found the “Resetting” chapter to be resourceful. Simply, there are three methods for resetting a commit. The git reset ---hard HEAD^ will undo everything, losing all changes. The git reset HEAD^ will only undo the commit and clear the stage but your files stay the same. Finally git reset --soft HEAD^ will undo the commit and restore the staged changes. If the intention is to change the earlier message, there is also a possibility to amend recent commit messages by using git commit --amend -m \"New commit message\". Resetting is an important component to commit’s because we all make committing mistakes in our projects and these offer an alternative to “burning it all down.”\nI think the biggest mishap has always been not taking enough time to properly design the workflow that we wanted to use as a team. We would have one directory in Box, another in Github and people would start using their own local files for work without committing and since some branched and others didn’t, Git would have a difficult time understanding our project. An effort I want to make moving forward is really detailing exactly how we want to move forward with workflow and incorporating everyone’s ideas on workflow flexibility as projects evolves.\nI did not know about the --amend command. I also only recently learned about the different reset options after I made mistakes to a repository that I burned down (but didn’t have to had I known about these commands ahead of time)."
  },
  {
    "objectID": "blog-2023/Blog-2-submissions/HaomingWang123/WangHaoming.html",
    "href": "blog-2023/Blog-2-submissions/HaomingWang123/WangHaoming.html",
    "title": "Happy Git with R",
    "section": "",
    "text": "git and Github are tools for helping with versioning of files in collaborative efforts as well as archiving entries for your future self. Unfortunately working with git isn’t always completely straightforward. Jenny Bryan’s book “Happy git and github with R” helps with that. The book is available from http://happygitwithr.com/. Have a look over the index and pick one of the chapters for a more in-depth read.\nWrite a blog post answering the following questions:\n\nWrite a short (100-150 words) summary of the chapter you read in-depth.\n\nI read the Chapter One of “Happy git and github with R”. After reading this chapter, I had an overall idea of the purposes of using Git and GitHub to improve our R programming experience. I have learned that, with GitHub, not only can we collaborate with our colleagues on projects in a more convenient way, but we are also provided a real-time backup and a record of our work progress. This backup helps us easily pick up our previous work, and the record of our work progress makes the bugs easier to be detected in case we fail to get a desired result. Another interesting point about GitHub that I learned from this chapter is Pull Requests. I found it useful especially for developing those complex packages with many different functions.\n\nLooking back at all of the team projects you have been involved in, describe the biggest mishap you had. Could that have been avoided using git? How?.\n\nOnce I had a project that requires me to generate some training data and use it to train a neural network model. I created two R script files, one for my training data and another for my neural network training model. After I generated my data, I forgot to save it in my local file and I directly used it to train my model. Since the data was quite large, the neural network training took me about 40 minutes. As R finished training my model, it suddenly crashed and I failed to save all my data and model which was very annoying. However, with git, although I might fail to save my model locally if my R crashes, I still have my codes and I can immediately get my training data by running the codes. In this case, it would take me much less time to restore all my work and model.\n\nGive an example of one new git feature that you learned about from Jenny Bryan’s book..\n\nOne new git feature I learned about is the user’s ability to track the package development and do their own modifications as the proposed changes. This feature provides me a platform to get a closer look at those packages I frequently use. After knowing that I am also able to do some modifications to make them better, I am also motivated to thoroughly understand the functionality of those famous packages."
  },
  {
    "objectID": "blog-2023/Blog-2-submissions/valeriehan6/HanValerie.html",
    "href": "blog-2023/Blog-2-submissions/valeriehan6/HanValerie.html",
    "title": "Happy Git with R",
    "section": "",
    "text": "git and Github are tools for helping with versioning of files in collaborative efforts as well as archiving entries for your future self. Unfortunately working with git isn’t always completely straightforward. Jenny Bryan’s book “Happy git and github with R” helps with that. The book is available from http://happygitwithr.com/. Have a look over the index and pick one of the chapters for a more in-depth read.\nWrite a blog post answering the following questions:\n\nWrite a short (100-150 words) summary of the chapter you read in-depth.\n\nI read https://happygitwithr.com/workflows-browsability.html#workflows-browsability, which talks about which files should be saved to a repository to make for a good browsing experience.\nGitHub displays Markdown files well (but not RMarkdown or HTML), so when writing in RMarkdown, you should make sure to save the intermediate Markdown file to the GitHub repo. This can be done in the YAML header with\n\noutput:  \n  html_document:  \n    keep_md: TRUE\n\nAlso note that any file named README.md will automatically appear on the GitHub page of the directory it’s in.\nData file-wise, deliminated files (.csv or .tsv) are rendered well by GitHub, though some cleaning may need to be done since GitHub is a bit picky with certain formatting like quotes. For results files, PNGs are the best, though GitHub has added some PDF functionality. For other document types, the open-source Pandoc program can convert many different formats into Markdown.\n\nLooking back at all of the team projects you have been involved in, describe the biggest mishap you had. Could that have been avoided using git? How?.\n\nIn general, the biggest team project mishaps have been when one person isn’t contributing. I’m not sure this could be directly solved with GitHub since we were all aware the person wasn’t contributing. However, if the instructor required that the project used a GitHub repo to save work/progress (and would check commits on the repo), perhaps the non-contributing member would have felt more pressure to contribute to the repo. In all but one of the code-heavy projects, we did use GitHub to save our work (though it wasn’t available to instructor) and for non-code stuff we used Google docs, so we didn’t face other direct problems that would’ve been solved by git.\n\nGive an example of one new git feature that you learned about from Jenny Bryan’s book..\n\nI learned a new workflow https://happygitwithr.com/repeated-amend.html. I didn’t realize that it could be valuable to commit but not push when in “WIP” mode to create little “footholds” for yourself. I’ll try to use the command:\ngit commit --amend --no-edit\nin the future."
  },
  {
    "objectID": "blog-2023/Blog-2-submissions/IanParzyszek/ParzyszekIan.html",
    "href": "blog-2023/Blog-2-submissions/IanParzyszek/ParzyszekIan.html",
    "title": "Happy Git with R",
    "section": "",
    "text": "Chapter 27: The Repeated Amend: Ian Parzyszek 1)\nIn this chapter we focused on situations where you are making continual changes and updates to a project, but you don’t want to continually have a lot of commits. This could look sloppy and not as useful. However, you also do not want to have very few commits and not have a lot to fall back on. They gave an example of a rock climber and you want to have enough ankers to protect you, but too many can slow you down. They introduced the idea of adding the idea of “WIP” amendments. This is used when you made some changes and you may be in the middle of something and it will signal to other people that more commits may be coming. It seemed to me that ideally you want to have “WIP” comments which denotes that these changes only exist in your local repo, yet on git. Then you can continue to finish what you are working on. And on your end you may see a history that looks like this: A – B –C – WIP–D But once you finish what you have done push it only once you have finished D…then your repository commit history will look like this: A—B—C—D (much nicer) The Chapter went on to talk about what if you did push this intermediate step of WIP what do you do? Should you go back and change it so it looks nicer, should you not? And it all depends on the collaborators you have and if you believe that may have pulled from Git.\n\nThe biggest mishap I have had in a group project (that maybe git could be useful) was probably when two people were working together in the same room on part of the project and someone else was working remotely. What had happened was we were both making changes to the same part of the project at the same time, but didn’t know about it then when we came back together we found out that now we have to find a way to bring everything together again. I think maybe git could have been used in a way that it could have found a way to merge to two versions together and we could find a way to pick and choose which sections we would keep. I know we said we would learn about this soon, so I’m not exactly sure how this works in git, but I imagine it could be helpful.\n\n3). I don’t think this is necessarily a feature of git itself but rather an understanding that git users have, and that is the “WIP” commit message. Which can be extremely usefully whenever you are working with a group. If you accidently push something it lets your group know that you are in the middle of something and it is not yet to finalized or have a functional project yet. And it is also useful so that you yourself won’t have bunch of cluttered commits in your history."
  },
  {
    "objectID": "blog-2023/Blog-2-submissions/loganjohnson0/JohnsonLogan.html",
    "href": "blog-2023/Blog-2-submissions/loganjohnson0/JohnsonLogan.html",
    "title": "Happy Git with R",
    "section": "",
    "text": "git and Github are tools for helping with versioning of files in collaborative efforts as well as archiving entries for your future self. Unfortunately working with git isn’t always completely straightforward. Jenny Bryan’s book “Happy git and github with R” helps with that. The book is available from http://happygitwithr.com/. Have a look over the index and pick one of the chapters for a more in-depth read.\nWrite a blog post answering the following questions:\n\nWrite a short (100-150 words) summary of the chapter you read in-depth.\n\nI read Chapter 16 for a more in-depth understanding of how to start using GitHub with RStudio with existing projects. Assuming GitHub accounts are already created, Jenny recommends starting a new repository for the project. On your local machine, all your scripts and code should be in a single project. Because it is your own local files, your are cloning to your local machine. Using the “usethis” package from R, it is simple to set up a GitHub repository on your machine. The “usethis” package performs some additional set up in the background. There is a more manual method to set up the repository, however, it is just not as simple. You can then copy your R projects into the newly created GitHub repository on your computer. You can then begin to commit and push your files to GitHub and confirm that they transitioned over to GitHub correctly.\n\nLooking back at all of the team projects you have been involved in, describe the biggest mishap you had. Could that have been avoided using git? How?.\n\nWhen I first began using R and RStudio, a fellow graduate student was helping me learn how to code while also providing his own code to share on the project. In this instance, we both had code on our computer that had various changes made independently of each other. After a few months, we both had worked on and off with these data. Had we been using GitHub, it would have been a lot easier to share the tips and tricks that we both learned from each other to make the code better. We also would have been able to keep up with each other’s analyses a lot easier than sending code over email.\n\nGive an example of one new git feature that you learned about from Jenny Bryan’s book..\n\nI am basically brand new to git and GitHub. I’ve learned more about the commit, push, and pull process. Understanding how these function helps me a lot. I realize that I can keep files on my computer without having to worry about pushing everything I do to GitHub. I also better understand the process of pulling, committing, and pushing to always have the most up to date version of a piece of code."
  },
  {
    "objectID": "blog-2023/Blog-2-submissions/Atefeha1995/AnisiAtefeh.html",
    "href": "blog-2023/Blog-2-submissions/Atefeha1995/AnisiAtefeh.html",
    "title": "Happy Git with R",
    "section": "",
    "text": "git and Github are tools for helping with versioning of files in collaborative efforts as well as archiving entries for your future self. Unfortunately working with git isn’t always completely straightforward. Jenny Bryan’s book “Happy git and github with R” helps with that. The book is available from http://happygitwithr.com/. Have a look over the index and pick one of the chapters for a more in-depth read.\nWrite a blog post answering the following questions:\n\nWrite a short (100-150 words) summary of the chapter you read in-depth.\n\nI finished reading Happy Git and GitHub for the use R, chapter 4. Creating a GitHub account is covered in the fourth chapter. I already had a little basic knowledge of Git and GitHub, but I’m always looking to learn more. Everyone can register at GitHub for free from here. I discovered that a GitHub username should:\n\nInclude real name and be original, brief, and simple to read.\nnot be tied to time, the school’s name, etc.\nnot include uppercase and lowercase letters, use hyphens to separate words.\nbe a good username while you can modify your username anytime later.\n\nGitHub provides unlimited free private repositories with a maximum of three external collaborators. If you are an academic member, educational/research staff member, or student, you can also take advantage of GitHub Education. formally recognized charities and nonprofits can benefit from GitHub for Good. You must purchase plans with a number of advanced features if you require private repositories with more than three external collaborators.Current plans and pricing information is available here.\n\nLooking back at all of the team projects you have been involved in, describe the biggest mishap you had. Could that have been avoided using git? How?.\n\nMost of the time, in our team projects, we face challenges that can be avoided by using GitHub. For example, in a team project I am currently working on, we upload our updated presentations in a shared Box folder. We created different sub folders for different collaborators, and each member should upload her/ his files in a specific folder mentioning its date and time. Now all of these files can be uploaded to a private repository, and everyone in the team can see changes with their related date and time and the member who made those changes. In this way, every document can be accessible easier for all the team members, and later, the team can make this repository public if possible, and others can also use the information you found and not reinvent the wheel.\n\nGive an example of one new git feature that you learned about from Jenny Bryan’s book..\n\nI could not read all the chapters from the book, but it is very interesting that I found that GitHub can be connected with Rstudio. We can easily use these two for our projects. Regarding chapter 15 in the book, it seems that we can make changes in R studio and then commit the changes to the local repository, and then we can push our local changes to GitHub."
  },
  {
    "objectID": "blog-2023/Blog-2-submissions/anphan0828/PhanAn.html",
    "href": "blog-2023/Blog-2-submissions/anphan0828/PhanAn.html",
    "title": "Happy Git with R",
    "section": "",
    "text": "git and Github are tools for helping with versioning of files in collaborative efforts as well as archiving entries for your future self. Unfortunately working with git isn’t always completely straightforward. Jenny Bryan’s book “Happy git and github with R” helps with that. The book is available from http://happygitwithr.com/. Have a look over the index and pick one of the chapters for a more in-depth read.\nWrite a blog post answering the following questions:\n\nWrite a short (100-150 words) summary of the chapter you read in-depth.\n\nI chose chapter 9: Personal access token for HTTPS to read because I was having trouble with it when I first approached Git and GitHub.\nThe chapter talks about how a user can connect to GitHub remotely from their local computer since a regular password is no longer accepted as a credential. There are two protocols, HTTPS and SSH, and HTTPs is actually recommended by GitHub. Either protocol works independently with any repository. The chapter lists instructions to generate and use personal access token (PAT) both on the website and from R. There are ways to store the PAT (which I personally was so frustrated with losing it all the time) via some R packages. Last but not least, the chapter discusses frequently occurred problems and solutions.\n\nLooking back at all of the team projects you have been involved in, describe the biggest mishap you had. Could that have been avoided using git? How?.\n\nVersion conflicts are annoying and almost inevitable for any projects with collaborations. Even with personal projects, I found myself (a lot of times) rewriting what I have already done a few weeks ago because I did not keep track of the versions. That is when Git comes to the rescue and it forces me to organize my projects better.\nFor collaborative projects, each of us figures that we should clone the repo, then create a branch for our own local copy to add changes. Without a branch, conflicts occur if the master copy of file.txt had been modified by user A (after user B cloned it) but user B later pushes another modified file.txt to remote. Git would then require user B to pull before pushing their version, but that would overwrite their copy they want to push, causing so many problems. We actually learn git branching on a website: learngitbranching.js.org to, once and for all, sort this problem out with Git. The website is highly interactive and explains how Git works in a convenient way for user.\nFor personal projects, I used to not keep track of the versions, i.e., just modify the script repeatedly, which is not a good practice. My PI suggested that I upload my project/software to GitHub and also to PyPI (so that it can be installed in Python) for transparency and version control. It was tough getting to know Git but worth it. I mainly use Git locally and just push the files I want to the remote repository. Now all of the previous versions are stored in Git and I can access them anytime. Furthermore, I now know that I can do all such stuff within RStudio (I have only used Git in the terminal)\n\nGive an example of one new git feature that you learned about from Jenny Bryan’s book.\n\nStoring and viewing PAT using R is definitely helpful, which cannot be done on the GitHub website. I still do not know why GitHub does not allow it, maybe for security reason, but I am glad gitcreds lets me see my PAT anytime. I added an Rmarkdown file MyExample.Rmd where I tried to store and view my current PAT"
  },
  {
    "objectID": "blog-2023/Blog-2-submissions/hardtme/HardtMarieBlog2.html",
    "href": "blog-2023/Blog-2-submissions/hardtme/HardtMarieBlog2.html",
    "title": "Happy Git with R",
    "section": "",
    "text": "git and Github are tools for helping with versioning of files in collaborative efforts as well as archiving entries for your future self. Unfortunately working with git isn’t always completely straightforward. Jenny Bryan’s book “Happy git and github with R” helps with that. The book is available from http://happygitwithr.com/. Have a look over the index and pick one of the chapters for a more in-depth read.\nWrite a blog post answering the following questions:\n\nWrite a short (100-150 words) summary of the chapter you read in-depth.\n\nI read Chapter 12: Connect RStudio to Git/GitHub. To have RStudio and GitHub communicate with each other, you should start with a new repository on GitHub that is initialized with a README. Then you need to copy a link to the GitHub repository, either HTTPS or SSH (whichever you prefer). Once everything is set up in GitHub, you move to RStudio and create a new project with version control. Then you paste the URL for your GitHub repository into the “Repository URL” box in RStudio and finish the project creation process. Assuming everything went smoothly, you should be able to see the README.md file from GitHub in your RStudio project. To further make sure everything is set up correctly, you can change the README.md file in RStudio, commit the changes, and push them to GitHub. If the changes appear in GitHub online, you’re good to go!\n\nLooking back at all of the team projects you have been involved in, describe the biggest mishap you had. Could that have been avoided using git? How?.\n\nI have experienced a common inconvenience in several group projects and group homework assignments in my graduate statistics classes. The assignments usually involved writing a report or showing our work and including R code. If there hadn’t been the requirement to include R code, we probably would have used a collaboration tool like Overleaf to write the report. Since we also had to include working R code, this meant the groups preferred to work with RMarkdown files. After deciding which group member would type each question, we would each work on our own individual RMarkdown file, send them to each other when we were finished with our work, and then copy and paste everyone’s work into one file for submission. Using git would have been a lot easier because all group members could have been able to see each other’s work sooner. Combining the work into one file also would have been much simpler with git.\n\nGive an example of one new git feature that you learned about from Jenny Bryan’s book.. I learned that you can connect RStudio to GitHub using HTTPS instead of SSH. When I last worked with RStudio and GitHub together (a few years ago), I thought you could only connect the two using SSH. The HTTPS method seems much easier."
  },
  {
    "objectID": "blog-2023/Blog-2-submissions/santos-cl/dosSantosCaio.html",
    "href": "blog-2023/Blog-2-submissions/santos-cl/dosSantosCaio.html",
    "title": "Happy Git with R",
    "section": "",
    "text": "In the 30th Happy git with R, Jane Bryan describes how one can use GitHub to time travel. Although she does not mean actual time travel, she describes a particularly useful feature of Git: the ability too look at previous versions of one’s code. There a multiple instances in which this would be useful. For instance, one might want to refer back to the color scheme used in one of the previous drafts of a manuscript; or worse, one might have to convert their barplot to a boxplot after arguing with their advisor that the boxplot was the better option from the beginning. In summary, regardless of why one would have to refer back to previous version of their code, Git facilitates this process."
  },
  {
    "objectID": "blog-2023/Blog-2-submissions/santos-cl/dosSantosCaio.html#new-git-features-from-the-book",
    "href": "blog-2023/Blog-2-submissions/santos-cl/dosSantosCaio.html#new-git-features-from-the-book",
    "title": "Happy Git with R",
    "section": "New git features from the book",
    "text": "New git features from the book\nI was not familiar with the idea that one could refer other people to a specific version of a repository just by providing them with the hyperlink. This is fascinating, as project discussions could be much more effective since collaborators could simply say: I believe this aspect of the project worked better in version XX.XX, follow this link to check for yourself what I mean."
  },
  {
    "objectID": "blog-2023/Blog-2-submissions/sudi007/SudeshBhagat.html",
    "href": "blog-2023/Blog-2-submissions/sudi007/SudeshBhagat.html",
    "title": "Happy Git with R",
    "section": "",
    "text": "git and Github are tools for helping with versioning of files in collaborative efforts as well as archiving entries for your future self. Unfortunately working with git isn’t always completely straightforward. Jenny Bryan’s book “Happy git and github with R” helps with that. The book is available from http://happygitwithr.com/. Have a look over the index and pick one of the chapters for a more in-depth read.\nWrite a blog post answering the following questions:\n\nWrite a short (100-150 words) summary of the chapter you read in-depth. The chapter I read in-depth was Chapter1, Why Git? Why GitHub? This chapter caught my attention because although one may have used Git, it helps to get a refresher on the precise function of Git, along with its features. It introduces Git and GitHub to a new user in novice terms and with analogies that are easy to understand. The chapter also explains how to get Git working for users, where the first step is to install Git and connect it with GitHub and R. The chapter warns of probable challenges like merging projects when working collaboratively. Special features such as issues and pull request are presented, in addition to information about the benefits of using R with Git and GitHub. Target audience is discussed to help users discern whether Git and GitHub are of use to them.\nLooking back at all of the team projects you have been involved in, describe the biggest mishap you had. Could that have been avoided using git? How?. Version control has been a challenge I have often faced in team projects, leading to working late nights under pressure. For example, for one of the classes last semester, a team of four was working on a project. Each one of us was working on a different aspect of the project which was stored on their local computers. It was then time to combine the various different files and present a final document. It was difficult to combine these individual sets of large files. The resultant document was difficult to understand. Using Git, these files could have been stored on the Git repository, with everyone accessing different sections of the document. This feature would have facilitated such collaboration that more than one person would have been able to see and work on the final combined file.\nGive an example of one new git feature that you learned about from Jenny Bryan’s book.. A new feature that I learned from the book was how it can be combined with RStudio. I use RStudio for my projects. Knowing that RStudio can be combined with Git helps me understand how changes can be made to projects in RStudio and then stored in the Git repository."
  },
  {
    "objectID": "blog-2023/Blog-2-submissions/gnbltrn/BeltranGino.html",
    "href": "blog-2023/Blog-2-submissions/gnbltrn/BeltranGino.html",
    "title": "Happy Git with R",
    "section": "",
    "text": "**Summary of Chapter 6. Install Git.\nThis chapter includes instructions on how to install Git Bash. Given that I am new to Github and Git, I found it somewhat confusing at first. I had watched YouTube videos to familiarize myself with github and run into several videos about Git Bash, but did not know what it was, so after I completed the instructions in the book and installed Git in my PC, I then realized they were the same. After reading this chapter in more detail, I learned that Git has multiple names.\nSummary.\ngit –version ## git version 2.39.1\nOption 1 (highly recommended) from the link below (I used this option): https://gitforwindows.org/ Option 2 (recommended): Install Git for Windows via the Chocolatey package manager. I personally did not use this option. choco install git.install\nThe rest of the chapter if for Mac and Linux users, which I didn’t use.\n**Biggest Mishap Experience.\nI have worked on a number of projects, big and small, but I have no experience working on coding or software development projects. It seems to me, git and github apply the concepts of “document control” and “versioning” to coding, which allows the user to have one source of truth while cooperate with others. I have used other tools such as MS Project, SharePoint, SAP/R3, and more recently MS OneDrive for the same purpose of document control and cooperation. I have had no big mishap so far. However, I can mention that when not using these tools, authoring with others, a new document for instance, can be significantly more troublesome and painful. Just having the ability to go back to a previous version can be a life saver.\n**Git Example of One New Feature.\nEverything from Git and the book was new to me, but I can highlight I didn’t know about the capability of R to be connected with github to work in a team environment."
  },
  {
    "objectID": "blog-2023/Blog-2-submissions/gnbltrn/BeltranGino.html#prompt",
    "href": "blog-2023/Blog-2-submissions/gnbltrn/BeltranGino.html#prompt",
    "title": "Happy Git with R",
    "section": "Prompt:",
    "text": "Prompt:\ngit and Github are tools for helping with versioning of files in collaborative efforts as well as archiving entries for your future self. Unfortunately working with git isn’t always completely straightforward. Jenny Bryan’s book “Happy git and github with R” helps with that. The book is available from http://happygitwithr.com/. Have a look over the index and pick one of the chapters for a more in-depth read.\nWrite a blog post answering the following questions:\n\nWrite a short (100-150 words) summary of the chapter you read in-depth.\nLooking back at all of the team projects you have been involved in, describe the biggest mishap you had. Could that have been avoided using git? How?.\nGive an example of one new git feature that you learned about from Jenny Bryan’s book.."
  },
  {
    "objectID": "blog-2023/Blog-2-submissions/motinaaa/KashanianMotahareh.html",
    "href": "blog-2023/Blog-2-submissions/motinaaa/KashanianMotahareh.html",
    "title": "Happy Git with R",
    "section": "",
    "text": "git and Github are tools for helping with versioning of files in collaborative efforts as well as archiving entries for your future self. Unfortunately working with git isn’t always completely straightforward. Jenny Bryan’s book “Happy git and github with R” helps with that. The book is available from http://happygitwithr.com/. Have a look over the index and pick one of the chapters for a more in-depth read.\nWrite a blog post answering the following questions:\n\nWrite a short (100-150 words) summary of the chapter you read in-depth."
  },
  {
    "objectID": "blog-2023/Blog-2-submissions/motinaaa/KashanianMotahareh.html#chapter-5-install-or-upgrade-r-and-rstudio",
    "href": "blog-2023/Blog-2-submissions/motinaaa/KashanianMotahareh.html#chapter-5-install-or-upgrade-r-and-rstudio",
    "title": "Happy Git with R",
    "section": "Chapter 5: Install or upgrade R and RStudio",
    "text": "Chapter 5: Install or upgrade R and RStudio\n**Install R from here: https://cloud.r-project.org\n**Install RStudio from here: https://www.rstudio.com/products/rstudio/download/preview/\n**Update your R packages: update.packages(ask = FALSE, checkBuilt = TRUE)\nUsing old versions of software can be a hassle. For the best experience, it’s recommended to be on 4.something in R at this point. Keep at least one minor version up-to-date. Two minor versions behind will cause you problems as CRAN no longer supports pre-built binary add-on packages. Preview releases are similar to general releases, but they are used as release candidates in the build-up to new general releases. Preview version includes new features, but it is also very stable and highly usable. RStudio updates much more frequently than R itself. RStudio requires monthly updates, while R requires annual updates.\n\nLooking back at all of the team projects you have been involved in, describe the biggest mishap you had. Could that have been avoided using git? How?. My last project was an interdisciplinary project in collaboration with chemical engineers, and we worked more often asynchronously than synchronously. When it comes to collaborating with distributed teams on projects, there are many challenges that must be overcome. The majority of the time I was unaware of their current changes in their experimental results, which had an effect on my results and added to my workload, as I had to go back and forth all the time to observe what they were doing. It is likely that GitHub could make this process much simpler in many ways, as it could track changes and go back to previous versions of a project, which would make the collaboration much easier.\nGive an example of one new git feature that you learned about from Jenny Bryan’s book.. I Learn more about branches in this book. With Git, users have the option of working on a line that runs parallel to the main files of the project. Branch is the term used to describe these lines. As a feature of Git, branches provide a way for developers to modify the project without having to make any changes to the original version of the code. Whenever a version is being developed, a production quality branch of the code will always be present in the master branch. On the branches, you can test and work on any new features you will be launching and then you can merge them with the main branch as soon as they are ready. With the help of a few Git commands, branching and merging can be done very quickly and easily. There is a possibility that one version of a project may contain a number of different branches as per the requirements of the user."
  },
  {
    "objectID": "blog-2023/Blog-2-submissions/maxwellskinner2002/SkinnerMaxwell.html",
    "href": "blog-2023/Blog-2-submissions/maxwellskinner2002/SkinnerMaxwell.html",
    "title": "Happy Git with R",
    "section": "",
    "text": "git and Github are tools for helping with versioning of files in collaborative efforts as well as archiving entries for your future self. Unfortunately working with git isn’t always completely straightforward. Jenny Bryan’s book “Happy git and github with R” helps with that. The book is available from http://happygitwithr.com/. Have a look over the index and pick one of the chapters for a more in-depth read.\nWrite a blog post answering the following questions:\n\nWrite a short (100-150 words) summary of the chapter you read in-depth.\n\nThe chapter I read was Chapter 9: Personal access token for HTTPS. The chapter focused on access tokens and the differences and uses between HTTPS versus SSH. Access tokens are important in interacting with remote Git servers like Github. Using credentials like an access token proves we are a specific Github user. Git can communicate with a remote server either through HTTPS or SSH, the different protocols use different credentials. With HTTPS you will use an access token. An access token can be made a number of ways but as simple as using the R function “usethis::create_github_token()” in the command line. SSH keys were talked about in chapter 10.\n\nLooking back at all of the team projects you have been involved in, describe the biggest mishap you had. Could that have been avoided using git? How?.\n\nIn my final project for DS201, my team’s final project was entirely based in Google Colab. While Colab is a great resource for individual work and can be used if one is forced to use Google Drive or similar Google products, it is not great for organizing work accross multiple people. There were many issues that came with storing files in google drive and importing them into a script in Colab. As well, my team couldn’t ever figure out how to correctly mount each individual’s google drive to the project to be able to import things like excel files so we were forced to do the majority of work from just one computer instead of doing work equally accross everyone.\nUsing git would have solved this issue completely. Sharing files and making sure everyone is working with the same version of a file would have been solved simply by using git. Importing something as simple as an excel file is easy as the we can put the script and the excel file in the same folder for easy access. Github has made group projects now an ease. Minimal hiccups when it comes to productivity and having teammates work on the same file from different locations.\n\nGive an example of one new git feature that you learned about from Jenny Bryan’s book..\n\nIn Chapter 9, Jenny talks about the R function “usethis::create_github_token()” which is used to get and store a personal access token. And using a R package such as gitcreds, we can store this generated token locally onto your computer. This is great for working with remote servers and kinds of Github servers that require tokens. As with the changes in July 2020 detailed in this article github.blog/2020-12-15-token-authentication-requirements-for-git-operations/ , the only way to access Git operations is through token authentication."
  },
  {
    "objectID": "blog-2023/Blog-2-submissions/Sabrenar/RutledgeSabrena.html",
    "href": "blog-2023/Blog-2-submissions/Sabrenar/RutledgeSabrena.html",
    "title": "Happy Git with R",
    "section": "",
    "text": "git and Github are tools for helping with versioning of files in collaborative efforts as well as archiving entries for your future self. Unfortunately working with git isn’t always completely straightforward. Jenny Bryan’s book “Happy git and github with R” helps with that. The book is available from http://happygitwithr.com/. Have a look over the index and pick one of the chapters for a more in-depth read.\nWrite a blog post answering the following questions:\n\nWrite a short (100-150 words) summary of the chapter you read in-depth.\n\nI read chapter 27 titled “The Repeated Amend.” It detailed a method to save several incremental changes to a Git repo in only one commit instead of several commits. This method is analogous to working on a word document and saving a new version after a larger change versus after only a few small changes.\nThe author outlines a workflow for the method then provides a couple work-arounds for common problems. The author’s method is to have several amended commits on the local repo then push a “finalized” commit to the Github repo. The biggest point of this chapter is to NOT push the local repo to the Github repo frequently.\n\nLooking back at all of the team projects you have been involved in, describe the biggest mishap you had. Could that have been avoided using git? How?.\n\nThe biggest mishap I’ve had in team project is updated scripts for the project not being in the same location as the data. Frequently, the data has been in one server, and the finalized data analysis scripts have been on a Github repo. This could have been avoided if there was a some sort of readme file directing readers to the Github in the directory with the data.\n\nGive an example of one new git feature that you learned about from Jenny Bryan’s book..\n\nI learned about Git commands from “Happy Git and Github for the useR.” I have only accessed Github repos from their respective Github websites."
  },
  {
    "objectID": "blog-2023/Blog-2-submissions/luobo119/BaiYichuan.html",
    "href": "blog-2023/Blog-2-submissions/luobo119/BaiYichuan.html",
    "title": "Happy Git with R",
    "section": "",
    "text": "git and Github are tools for helping with versioning of files in collaborative efforts as well as archiving entries for your future self. Unfortunately working with git isn’t always completely straightforward. Jenny Bryan’s book “Happy git and github with R” helps with that. The book is available from http://happygitwithr.com/. Have a look over the index and pick one of the chapters for a more in-depth read.\nWrite a blog post answering the following questions:\n\nWrite a short (100-150 words) summary of the chapter you read in-depth.\n\nChapter selected: 29 Pull, but you have local work This chapter introduce how to pull changes from upstream when you have local changes since the last pull. If the local changes do not affect the work from upstream, you can directly use ‘git pull’. If there are overlapped changes between remote and local files, you can either use ‘git stash’ or make a commit, which is preferred by the author. The simplest option is to fetch remote commits and merge them. For the conflicted parts, you need to either pick up one version of the changes or create a hybrid to resolve the conflicts. After using ‘git add’ to mark the files, you could commit and push. Another option is to use ‘git pull –rebase’, which pulls the upstream work in one commit and embodies the local work in another with no merge commits.\n\nLooking back at all of the team projects you have been involved in, describe the biggest mishap you had. Could that have been avoided using git? How?.\n\nWhen working with others, I and my teammates did separate parts but we still looked at each other’s code and made small changes that we thought are necessary. But as time goes by, we forgot the changes we made and there is something we should not change or the code would crash. And it is hard to find out the problem because the code could be long. This can be avoided by using git. We can look at the commit history and it is easier to find which changes are made and which cause the problem.\n\nGive an example of one new git feature that you learned about from Jenny Bryan’s book..\n\n‘git stash’ would be a new feature I never used before. This feature allows you to temporarily store the changes you made locally away. And then you are allowed to use other commands such as ‘git pull’. In the Chapter 29, they use ‘git stash store’ to store the local changes in the stash list and use ‘git stash pop’ to get back the stashed state and apply it to the current state."
  },
  {
    "objectID": "blog-2023/Blog-2-submissions/AArabio/ArabioAlexandra.html",
    "href": "blog-2023/Blog-2-submissions/AArabio/ArabioAlexandra.html",
    "title": "Happy Git with R",
    "section": "",
    "text": "git and Github are tools for helping with versioning of files in collaborative efforts as well as archiving entries for your future self. Unfortunately working with git isn’t always completely straightforward. Jenny Bryan’s book “Happy git and github with R” helps with that. The book is available from http://happygitwithr.com/. Have a look over the index and pick one of the chapters for a more in-depth read.\nWrite a blog post answering the following questions:\n\nWrite a short (100-150 words) summary of the chapter you read in-depth.\n\nChapter 22: Branches The concept of branching allows an individual to ‘branch out’ from the main project to explore their own idea without anything happening to the original or main working code. Git works with this concept seamlessly allowing for branches to open and merge back quickly. One can create their own branch, switch between branches, and merge a branch with only a line of code. This chapter also explains how to deal with possible issue that may occur and recognizes that a conflict does not mean a disaster (this is often why we use branches… to avoid disaster). One of the main reasons for branching is to allow for brainstorming, consideration, and implementing new ideas… this is how progress is made.\n\nLooking back at all of the team projects you have been involved in, describe the biggest mishap you had. Could that have been avoided using git? How?.\n\nThrough majority of the team projects that I have been involved in, the largest mishap occurs from ‘stepping on each others toes’… When working in a group where everyone wants to be able to get something accomplished to achieve the best possible outcome, it can be subjective to each individual. When working on PowerPoint slides or writing a report; people tend to have differences in opinions on what the best layout is or the best wording for certain sentences. This is where I have found the greatest conflict because it becomes difficult if we are all working on the same document to change things without the work of others getting loss in the process and work may get lost. This problem could possibly be able to be avoided using git as it has its own system for backing up previous work, seeing who made changes, and when they were made.\n\nGive an example of one new git feature that you learned about from Jenny Bryan’s book..\n\nI have not read Jenny Bryan’s book previously and found it to be a great resource. Though I knew the general basics of git, I appreciated that the book walked through the processes of learning git and showed it truly as a processes and that confusion is okay and expected. Because of this I learned more about possible errors that could occur throughout the merging process and how to tackle them if they present themselves as issues. I also learned through this book that it is better to start a new project on GitHub first prior to working in a new project in R."
  },
  {
    "objectID": "blog-2023/Blog-2-submissions/Starwiiin/MohammadiarvejehParvin.html",
    "href": "blog-2023/Blog-2-submissions/Starwiiin/MohammadiarvejehParvin.html",
    "title": "Happy Git with R",
    "section": "",
    "text": "git and Github are tools for helping with versioning of files in collaborative efforts as well as archiving entries for your future self. Unfortunately working with git isn’t always completely straightforward. Jenny Bryan’s book “Happy git and github with R” helps with that. The book is available from http://happygitwithr.com/. Have a look over the index and pick one of the chapters for a more in-depth read.\nWrite a blog post answering the following questions:\n\nWrite a short (100-150 words) summary of the chapter you read in-depth. Question 1: (I read the chapter 22, “Branches”)\n\nMy answer: Basically, branching is used to take a detour from the main stream to work on the code without making any instant changes to the source file. This characteristic lets people work at the same time on the project without any conflicts or errors. To use this feature, we should create a new branch. One person may or may not create multiple branches; in this case, the person can use “git checkout” to switch between the branches. One important point is that when we switch to another branch while we are not done with the other branch(es), we should commit the in progress branch temporarily. When we want to resume working on the incomplete branch, we should reset the target branch. It worth to mention that there are different type of resetting such as soft, hard, and mixed that help resetting back to different past stages of the interest. Finally, we can merge the complete branch. If we want to merge more than one branches, it is possible to see the conflict message if we have changed the same part in the both branches. In this situation, we can get the status and check the conflict easily. Also, we always can go back to the previous stages of the branch to check and do the revisions accordingly. 2. Looking back at all of the team projects you have been involved in, describe the biggest mishap you had. Could that have been avoided using git? How?. Question 2: My answer: I think one of the biggest challenge that I experienced during my Ph.D. in team working was that we had to work individually on our ideas and we could not document everyone’s work properly. Also, we did not access to each others works while we were working. Another problem was in the review process of each others work; if one might change something based on another person’s feedback, the change was not tracked easily. The advantage of working with fit is that everyone work in one repository, save everything in one location, always accessible for other team members, easy to review other people’s work, easy to track changes. 3. Give an example of one new git feature that you learned about from Jenny Bryan’s book..\nQuestion 3: My answer: I found the branch option very useful for collaborations! suppose our team is working on a competition which is a classification problem. There is a source code that applied a random forest model and got an average classification performance. Now, I guess that I can improve the model by tuning the hyper parameters with either Bayesian optimization or grid search. I can easily create two branches; one for examination of Bayesian optimization, another for implementation of the grid search. In this case, I can work on the two ideas separately without any changes in the source file, test the both ideas, pick the best one, and merge the final version."
  },
  {
    "objectID": "Untitled.html",
    "href": "Untitled.html",
    "title": "Untitled",
    "section": "",
    "text": "Breviary et al. (2006); Spence and Wainer (1997)\n\n\n\n\nReferences\n\nBreviary, The Commercial And Political Atlas And Statistical, William Playfair, Howard Wainer, and Ian Spence. 2006. “A Visionary and a Scoundrel.” American Scientist 94 (3): 274–75. https://doi.org/10.1511/2006.59.274.\n\n\nSpence, Ian, and Howard Wainer. 1997. “Who Was Playfair?” CHANCE 10 (January): 35–37."
  },
  {
    "objectID": "blog-testing.html",
    "href": "blog-testing.html",
    "title": "Blog",
    "section": "",
    "text": "Order By\n       Default\n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Title\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\nDate\n\n\nTitle\n\n\nAuthor\n\n\n\n\n\n\n\n\nPrompt:\n\n\n\n\n\n\n\n\nPrompt:\n\n\n\n\n\n\n\n\nPrompt:\n\n\n\n\n\n\n\n\nPrompt:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPrompt:\n\n\n\n\n\n\n\n\nPrompt:\n\n\n\n\n\n\nApr 6, 2023\n\n\nWeb scraping etiquette …\n\n\nYingchao Zhou\n\n\n\n\nApr 6, 2023\n\n\nWeb scraping\n\n\nKundan Kumar\n\n\n\n\nApr 6, 2023\n\n\nWeb scraping Blog.\n\n\nAR\n\n\n\n\nApr 6, 2023\n\n\nBeing kind to Wikipedia\n\n\nLandon Getting\n\n\n\n\nApr 6, 2023\n\n\nWeb scraping etiquette …\n\n\nMuxin Hua\n\n\n\n\nApr 6, 2023\n\n\nWeb scraping etiquette …\n\n\nWho wrote this\n\n\n\n\nApr 6, 2023\n\n\nWeb scraping\n\n\nCharch\n\n\n\n\nApr 6, 2023\n\n\nReflections on Ethical Web Scraping\n\n\nKelly Nascimento Thompson\n\n\n\n\nApr 6, 2023\n\n\nWeb scraping etiquette …\n\n\nDenise Bradford\n\n\n\n\nApr 6, 2023\n\n\nWeb Scraping\n\n\nHarun Celik\n\n\n\n\nApr 6, 2023\n\n\nWeb scraping etiquette …\n\n\nWho wrote this\n\n\n\n\nApr 6, 2023\n\n\nWeb scraping etiquette …\n\n\nIan Parzyszek\n\n\n\n\nApr 6, 2023\n\n\nWeb scraping etiquette …\n\n\nWho wrote this\n\n\n\n\nApr 6, 2023\n\n\nWeb scraping etiquette …\n\n\nAtefeh Anisi\n\n\n\n\nApr 6, 2023\n\n\nWeb scraping etiquette …\n\n\nWho wrote this\n\n\n\n\nApr 6, 2023\n\n\nWeb Scraping Etiquette …\n\n\nMarie Hardt\n\n\n\n\nApr 6, 2023\n\n\nWeb scraping etiquette …\n\n\nCdS\n\n\n\n\nApr 6, 2023\n\n\nWeb scraping etiquette\n\n\nSudesh Ramesh Bhagat\n\n\n\n\nApr 6, 2023\n\n\nWeb scraping etiquette …\n\n\nMotina\n\n\n\n\nApr 6, 2023\n\n\nWeb scraping etiquette …\n\n\nWho wrote this\n\n\n\n\nApr 6, 2023\n\n\nWeb scraping etiquette …\n\n\nSabrena Rutledge\n\n\n\n\nApr 6, 2023\n\n\nWeb scraping etiquette\n\n\nycb\n\n\n\n\nApr 6, 2023\n\n\nWeb scraping etiquette …\n\n\nAlexandra Arabio\n\n\n\n\nApr 6, 2023\n\n\nWeb scraping etiquette …\n\n\nParvin Mohammadiarvejeh\n\n\n\n\nApr 6, 2023\n\n\nWeb scraping etiquette … – Prompt 10\n\n\nWho wrote this\n\n\n\n\nMar 30, 2023\n\n\nFix TeamUNL\n\n\nYingchao Zhou\n\n\n\n\nMar 30, 2023\n\n\nError Fixing for the package\n\n\nKundan Kumar\n\n\n\n\nMar 30, 2023\n\n\nFixing thing from Lab 2\n\n\nAR\n\n\n\n\nMar 30, 2023\n\n\nSolving package problems!\n\n\nLandon Getting\n\n\n\n\nMar 30, 2023\n\n\nFix a warning in CMD check\n\n\nMuxin Hua\n\n\n\n\nMar 30, 2023\n\n\nErrors and warnings in packages\n\n\nTyler Wiederich\n\n\n\n\nMar 30, 2023\n\n\nall-for-one\n\n\nCharch\n\n\n\n\nMar 30, 2023\n\n\nFixing Package Errors\n\n\nKelly Nascimento Thompson\n\n\n\n\nMar 30, 2023\n\n\nUndefined Object Error\n\n\nHarun Celik\n\n\n\n\nMar 30, 2023\n\n\nFixing a note\n\n\nValerie Han\n\n\n\n\nMar 30, 2023\n\n\nTrying to Make the World a Better Place\n\n\nIan Parzyszek\n\n\n\n\nMar 30, 2023\n\n\nAll For One\n\n\nLogan Johnson\n\n\n\n\nMar 30, 2023\n\n\nErrors and warnings in packages\n\n\nAtefeh Anisi\n\n\n\n\nMar 30, 2023\n\n\nThe painful green ticks\n\n\nAn Phan\n\n\n\n\nMar 30, 2023\n\n\nI Fixed It!\n\n\nMarie Hardt\n\n\n\n\nMar 30, 2023\n\n\nFixing a thing\n\n\nCdS\n\n\n\n\nMar 30, 2023\n\n\nErrors and warnings in packages\n\n\nsudesh_Bhagat\n\n\n\n\nMar 30, 2023\n\n\nGreen is the new Black\n\n\nMotina\n\n\n\n\nMar 30, 2023\n\n\nPackage Errors and Warnings\n\n\nSabrena Rutledge\n\n\n\n\nMar 30, 2023\n\n\nProblems in Building the R Package\n\n\nycb\n\n\n\n\nMar 30, 2023\n\n\nFun with errors\n\n\nAlexandra Arabio\n\n\n\n\nMar 30, 2023\n\n\nErrors and warnings in packages\n\n\nParvin Mohammadiarvejeh\n\n\n\n\nMar 30, 2023\n\n\nFix a thing – Prompt 9\n\n\nWho wrote this\n\n\n\n\nMar 23, 2023\n\n\nSimple personal website\n\n\nYingchao Zhou\n\n\n\n\nMar 23, 2023\n\n\nPersonal Website\n\n\nKundan Kumar\n\n\n\n\nMar 23, 2023\n\n\nWebsite Blog\n\n\nAR\n\n\n\n\nMar 23, 2023\n\n\nBecoming a Website Engineer\n\n\nLandon Getting\n\n\n\n\nMar 23, 2023\n\n\nGithub Page\n\n\nMuxin Hua\n\n\n\n\nMar 23, 2023\n\n\nBuilding website\n\n\nCharch\n\n\n\n\nMar 23, 2023\n\n\nBuilding a Website\n\n\nKelly Nascimento Thompson\n\n\n\n\nMar 23, 2023\n\n\nMy professional self\n\n\nDRB\n\n\n\n\nMar 23, 2023\n\n\nHarun’s Quarto Blog Page\n\n\nHarun Celik\n\n\n\n\nMar 23, 2023\n\n\nBuilding a website\n\n\nValerie Han\n\n\n\n\nMar 23, 2023\n\n\nIan and Remmys Website\n\n\nIan Parzyszek\n\n\n\n\nMar 23, 2023\n\n\nBuilding my own website\n\n\nLogan Johnson\n\n\n\n\nMar 23, 2023\n\n\nMy professional self\n\n\nAtefeh Anisi\n\n\n\n\nMar 23, 2023\n\n\nLet’s RMarkdown that Site\n\n\nAn Phan\n\n\n\n\nMar 23, 2023\n\n\nAdventures in Website Building\n\n\nMarie Hardt\n\n\n\n\nMar 23, 2023\n\n\nWhat should I include? What should I not?\n\n\nCdS\n\n\n\n\nMar 23, 2023\n\n\nMy professional self\n\n\nsudesh_Bhagat\n\n\n\n\nMar 23, 2023\n\n\nWelcome to the Club!\n\n\nMotina\n\n\n\n\nMar 23, 2023\n\n\nCreating a Website\n\n\nSabrena Rutledge\n\n\n\n\nMar 23, 2023\n\n\nWebsite Generation\n\n\nycb\n\n\n\n\nMar 23, 2023\n\n\nAll About Ally\n\n\nAlexandra Arabio\n\n\n\n\nMar 23, 2023\n\n\nMy Website\n\n\nParvin Mohammadiarvejeh\n\n\n\n\nMar 23, 2023\n\n\nMake your own website – Prompt 8\n\n\nWho wrote this\n\n\n\n\nMar 9, 2023\n\n\nAll that legal stuff… – Prompt 7\n\n\nWho wrote this\n\n\n\n\nMar 9, 2023\n\n\nLicense\n\n\nYingchao Zhou\n\n\n\n\nMar 9, 2023\n\n\nR licensing\n\n\nKundan Kumar\n\n\n\n\nMar 9, 2023\n\n\nLicensing Blog\n\n\nAR\n\n\n\n\nMar 9, 2023\n\n\nLearning Licensing\n\n\nLandon Getting\n\n\n\n\nMar 9, 2023\n\n\nLicenses\n\n\nMuxin Hua\n\n\n\n\nMar 9, 2023\n\n\nR Licensing and Package Dependencies\n\n\nKelly Nascimento Thompson\n\n\n\n\nMar 9, 2023\n\n\nSplit-Apply-Combine Post\n\n\nHarun Celik\n\n\n\n\nMar 9, 2023\n\n\nLicenses\n\n\nValerie Han\n\n\n\n\nMar 9, 2023\n\n\nWhat License when?\n\n\nIan Parzyszek\n\n\n\n\nMar 9, 2023\n\n\nLegal Stuff\n\n\nLogan Johnson\n\n\n\n\nMar 9, 2023\n\n\nAll that legal stuff…\n\n\nAtefeh Anisi\n\n\n\n\nMar 9, 2023\n\n\nIt’s not the end…\n\n\nAn Phan\n\n\n\n\nMar 9, 2023\n\n\nLegal Details of Licenses\n\n\nMarie Hardt\n\n\n\n\nMar 9, 2023\n\n\nDependencies\n\n\nCDS\n\n\n\n\nMar 9, 2023\n\n\nAll that legal stuff\n\n\nSudesh Bhagat\n\n\n\n\nMar 9, 2023\n\n\nLicenses and Packages\n\n\nSabrena Rutledge\n\n\n\n\nMar 9, 2023\n\n\nLicense\n\n\nyc bai\n\n\n\n\nMar 9, 2023\n\n\nLicense Fun\n\n\nAlexandra Arabio\n\n\n\n\nMar 9, 2023\n\n\nAll that legal stuff…\n\n\nParvin Mohammadiarvejeh\n\n\n\n\nMar 2, 2023\n\n\nrenv package\n\n\nYingchao Zhou\n\n\n\n\nMar 2, 2023\n\n\nrenv R package\n\n\nKundan Kumar\n\n\n\n\nMar 2, 2023\n\n\nrenv blog\n\n\nAR\n\n\n\n\nMar 2, 2023\n\n\nExploring renv\n\n\nLandon Getting\n\n\n\n\nMar 2, 2023\n\n\nMore on reproducibility\n\n\nMuxin Hua\n\n\n\n\nMar 2, 2023\n\n\nBlog 6\n\n\nTyler Wiederich\n\n\n\n\nMar 2, 2023\n\n\nRenv\n\n\nCharch\n\n\n\n\nMar 2, 2023\n\n\nRenv package overview\n\n\nKelly Nascimento Thompson\n\n\n\n\nMar 2, 2023\n\n\nSplit-Apply-Combine Post\n\n\nHarun Celik\n\n\n\n\nMar 2, 2023\n\n\nrenv\n\n\nValerie Han\n\n\n\n\nMar 2, 2023\n\n\nLearning Renv\n\n\nIan Parzyszek\n\n\n\n\nMar 2, 2023\n\n\n‘renv’ Package and Data Reproducibility\n\n\nLogan Johnson\n\n\n\n\nMar 2, 2023\n\n\nWorking with ‘renv’ package\n\n\nAtefeh Anisi\n\n\n\n\nMar 2, 2023\n\n\nExploring renv\n\n\nMarie Hardt\n\n\n\n\nMar 2, 2023\n\n\nR env\n\n\nCaio dos Santos\n\n\n\n\nMar 2, 2023\n\n\nGithub Actions\n\n\nSudesh Bhagat\n\n\n\n\nMar 2, 2023\n\n\nBadge is Coool!\n\n\nMotina\n\n\n\n\nMar 2, 2023\n\n\nReproducibility\n\n\nSabrena Rutledge\n\n\n\n\nMar 2, 2023\n\n\nrenv package\n\n\nyc bai\n\n\n\n\nMar 2, 2023\n\n\ntitle :)\n\n\nAlexandra Arabio\n\n\n\n\nMar 2, 2023\n\n\nMore on reproducibility…\n\n\nParvin Mohammadiarvejeh\n\n\n\n\nMar 2, 2023\n\n\nMore on reproducibility… – Prompt 6\n\n\nWho wrote this\n\n\n\n\nFeb 23, 2023\n\n\nKeep track of results and data\n\n\nYingchao Zhou\n\n\n\n\nFeb 23, 2023\n\n\nEthics and Reproducibility\n\n\nKundan Kumar\n\n\n\n\nFeb 23, 2023\n\n\nReading about COVID Calculators\n\n\nAR\n\n\n\n\nFeb 23, 2023\n\n\nTREEFINDER - Leveraging Research Software for Political Agendas\n\n\nLandon Getting\n\n\n\n\nFeb 23, 2023\n\n\nRetraction\n\n\nMuxin Hua\n\n\n\n\nFeb 23, 2023\n\n\nUC Berkeley’s Ninov 2.0\n\n\nNot Charlie\n\n\n\n\nFeb 23, 2023\n\n\nRetraction\n\n\nCharch\n\n\n\n\nFeb 23, 2023\n\n\nRules for Research Reproducibility\n\n\nKelly Nascimento Thompson\n\n\n\n\nFeb 23, 2023\n\n\nRetraction Watch – Reliability and Sensitivity of Neuromuscular and Perceptual Fatigue Measures in Collegiate Men’s Basketball\n\n\nDenise Bradford\n\n\n\n\nFeb 23, 2023\n\n\nBlog Five\n\n\nHarun Celik\n\n\n\n\nFeb 23, 2023\n\n\nReproducibility\n\n\nValerie Han\n\n\n\n\nFeb 23, 2023\n\n\nReplication of Data Presentation\n\n\nIan Parzyszek\n\n\n\n\nFeb 23, 2023\n\n\nImportance of Data Reproducibility\n\n\nLogan Johnson\n\n\n\n\nFeb 23, 2023\n\n\nHow to make our research reproducible\n\n\nAtefeh Anisi\n\n\n\n\nFeb 23, 2023\n\n\nPaper retracted alert!\n\n\nAn Phan\n\n\n\n\nFeb 23, 2023\n\n\nEthics in Reproducible Research\n\n\nMarie Hardt\n\n\n\n\nFeb 23, 2023\n\n\nDotting I’s and crossing T’s…\n\n\nCaio dos Santos\n\n\n\n\nFeb 23, 2023\n\n\nEthics and Reproducibility\n\n\nSudesh Bhagat\n\n\n\n\nFeb 23, 2023\n\n\nThe One Where Ethics Meet Reproducibility\n\n\nMotina\n\n\n\n\nFeb 23, 2023\n\n\nReproducing Randomness\n\n\nMaxwell Skinner\n\n\n\n\nFeb 23, 2023\n\n\nEthically Managing Data\n\n\nSabrena Rutledge\n\n\n\n\nFeb 23, 2023\n\n\nReproducible Computational Research\n\n\nyc bai\n\n\n\n\nFeb 23, 2023\n\n\nNumber 10\n\n\nAlexandra Arabio\n\n\n\n\nFeb 23, 2023\n\n\nEthics and Reproducibility…\n\n\nParvin Mohammadiarvejeh\n\n\n\n\nFeb 23, 2023\n\n\nEthics and Reproducibility… – Prompt 5\n\n\nWho wrote this\n\n\n\n\nFeb 16, 2023\n\n\nThe Split-Apply-Combine paradigm - Prompt 4\n\n\nWho wrote this\n\n\n\n\nFeb 16, 2023\n\n\nSplit, apply, combine\n\n\nYingchao Zhou\n\n\n\n\nFeb 16, 2023\n\n\nThe Split-Apply-Combine Strategy for Data Analysis\n\n\nKundan Kumar\n\n\n\n\nFeb 16, 2023\n\n\ndplyr vs plyr\n\n\nLandon Getting\n\n\n\n\nFeb 16, 2023\n\n\nTitle of your post\n\n\nNot Charlie\n\n\n\n\nFeb 16, 2023\n\n\nSplit-apply-combine\n\n\nTyler Wiederich\n\n\n\n\nFeb 16, 2023\n\n\nplyr and dplyr\n\n\nCharchit Shukla\n\n\n\n\nFeb 16, 2023\n\n\nTesting the ‘dplyr’ functionality\n\n\nKelly Nascimento Thompson\n\n\n\n\nFeb 16, 2023\n\n\nTitle of your post\n\n\nFirstname Lastname\n\n\n\n\nFeb 16, 2023\n\n\nSplit-Apply-Combine Post\n\n\nHarun Celik\n\n\n\n\nFeb 16, 2023\n\n\nThe Split-Apply-Combine Strategy\n\n\nValerie Han\n\n\n\n\nFeb 16, 2023\n\n\nGetting familiar with dpylr\n\n\nIan Parzyszek\n\n\n\n\nFeb 16, 2023\n\n\n‘plyr’ to d’plyr’\n\n\nLogan Johnson\n\n\n\n\nFeb 16, 2023\n\n\nSplit-apply-combine\n\n\nAn Phan\n\n\n\n\nFeb 16, 2023\n\n\nSplit-Apply-Combine\n\n\nMarie Hardt\n\n\n\n\nFeb 16, 2023\n\n\nplyr-dplyr-baseR\n\n\nCaio dos Santos\n\n\n\n\nFeb 16, 2023\n\n\nSplit-apply-combine\n\n\nSudesh Bhagat\n\n\n\n\nFeb 16, 2023\n\n\nTitle of your post\n\n\nMaxwell Skinner\n\n\n\n\nFeb 16, 2023\n\n\nSplit-apply-combine\n\n\nyc bai\n\n\n\n\nFeb 16, 2023\n\n\nSplit, Apply, Combine - Relevancy\n\n\nAlexandra Arabio\n\n\n\n\nFeb 16, 2023\n\n\nSplit-apply-combine\n\n\nParvin Mohammadiarvejeh\n\n\n\n\nFeb 9, 2023\n\n\nBuilding a Book\n\n\nYingchao Zhou\n\n\n\n\nFeb 9, 2023\n\n\nBuilding a Book\n\n\nKundan Kummar\n\n\n\n\nFeb 9, 2023\n\n\nBuilding a Book\n\n\nar\n\n\n\n\nFeb 9, 2023\n\n\nBook Building is Backbreaking\n\n\nLandon Getting\n\n\n\n\nFeb 9, 2023\n\n\nBuilding a Book\n\n\nMuxin Hua\n\n\n\n\nFeb 9, 2023\n\n\nBuilding a Book\n\n\nMatt Kavanaugh\n\n\n\n\nFeb 9, 2023\n\n\nBipity-Bopity-Book?\n\n\nNot Charlie\n\n\n\n\nFeb 9, 2023\n\n\nBuilding a book\n\n\nTyler Wiederich\n\n\n\n\nFeb 9, 2023\n\n\nBuilding a Book\n\n\nCharch\n\n\n\n\nFeb 9, 2023\n\n\nRendering a book using ‘bookdown’\n\n\nKelly Nascimento Thompson\n\n\n\n\nFeb 9, 2023\n\n\nError Fixing Process\n\n\nHarun Celik\n\n\n\n\nFeb 9, 2023\n\n\nBuilding a Book\n\n\nJust Testing\n\n\n\n\nFeb 9, 2023\n\n\nTitle of your post\n\n\nFirstname Lastname\n\n\n\n\nFeb 9, 2023\n\n\nBuilding a Book\n\n\nLogan Johnson\n\n\n\n\nFeb 9, 2023\n\n\nI finally built a book\n\n\nAtefeh Anisi\n\n\n\n\nFeb 9, 2023\n\n\nBuilding a Book\n\n\nAn Phan\n\n\n\n\nFeb 9, 2023\n\n\nAdventures in Book Building\n\n\nMarie Hardt\n\n\n\n\nFeb 9, 2023\n\n\nBuilding a Book\n\n\nCaio dos Santos\n\n\n\n\nFeb 9, 2023\n\n\nBuilding a Book\n\n\nSudesh Bhagat\n\n\n\n\nFeb 9, 2023\n\n\nDrawning in ERRORS\n\n\nMotina\n\n\n\n\nFeb 9, 2023\n\n\nTitle of your post\n\n\nFirstname Lastname\n\n\n\n\nFeb 9, 2023\n\n\nBuilding a book with R’s bookdown\n\n\nSabrena Rutledge\n\n\n\n\nFeb 9, 2023\n\n\nExperience of building a book\n\n\nYCB\n\n\n\n\nFeb 9, 2023\n\n\nBuilding a Book\n\n\nAA\n\n\n\n\nFeb 9, 2023\n\n\nBuilding a book\n\n\nParvin Mohammadiarvejeh\n\n\n\n\nFeb 9, 2023\n\n\nBuilding a book – Prompt 3\n\n\nWho wrote this\n\n\n\n\nFeb 5, 2023\n\n\nHappy Git with R\n\n\nHarun Celik\n\n\n\n\nFeb 3, 2023\n\n\nHappy Git with R\n\n\nSudesh Bhagat\n\n\n\n\nFeb 2, 2023\n\n\nHappy Git with R\n\n\nThe Prompt for Blog 2\n\n\n\n\nFeb 2, 2023\n\n\nHappy Git with R\n\n\nYingchao Zhou\n\n\n\n\nFeb 2, 2023\n\n\nHappy Git with R\n\n\nKundan Kumar\n\n\n\n\nFeb 2, 2023\n\n\nHappy Git with R\n\n\nYour Name\n\n\n\n\nFeb 2, 2023\n\n\nHappy Git with R\n\n\nLandon Getting\n\n\n\n\nFeb 2, 2023\n\n\nHappy Git with R\n\n\nMuxin Hua\n\n\n\n\nFeb 2, 2023\n\n\nHappy Git with R\n\n\nNot Charlie\n\n\n\n\nFeb 2, 2023\n\n\nHappy Git with R\n\n\nTyler Wiederich\n\n\n\n\nFeb 2, 2023\n\n\nHappy Git with R\n\n\nCharch\n\n\n\n\nFeb 2, 2023\n\n\nHappy Git with R\n\n\nKelly Nascimento Thompson\n\n\n\n\nFeb 2, 2023\n\n\nHappy Git with R\n\n\nDRB\n\n\n\n\nFeb 2, 2023\n\n\nHappy Git with R\n\n\nMatt Kavanaugh\n\n\n\n\nFeb 2, 2023\n\n\nHappy Git with R\n\n\nHaoming Wang\n\n\n\n\nFeb 2, 2023\n\n\nHappy Git with R\n\n\nValerie Han\n\n\n\n\nFeb 2, 2023\n\n\nHappy Git with R\n\n\nIan Parzyszek\n\n\n\n\nFeb 2, 2023\n\n\nHappy Git with R\n\n\nLogan Johnson\n\n\n\n\nFeb 2, 2023\n\n\nHappy Git with R\n\n\nAtefeh Anisi\n\n\n\n\nFeb 2, 2023\n\n\nHappy Git with R\n\n\nAn Phan\n\n\n\n\nFeb 2, 2023\n\n\nHappy Git with R\n\n\nMarie Hardt\n\n\n\n\nFeb 2, 2023\n\n\nHappy Git with R\n\n\nSomebody\n\n\n\n\nFeb 2, 2023\n\n\nHappy Git with R\n\n\nGino Beltran\n\n\n\n\nFeb 2, 2023\n\n\nHappy Git with R\n\n\nMotina\n\n\n\n\nFeb 2, 2023\n\n\nHappy Git with R\n\n\nMaxwell Skinner\n\n\n\n\nFeb 2, 2023\n\n\nHappy Git with R\n\n\nSabrena Rutledge\n\n\n\n\nFeb 2, 2023\n\n\nHappy Git with R\n\n\nYCB\n\n\n\n\nFeb 2, 2023\n\n\nHappy Git with R\n\n\nAlexadra Arabio\n\n\n\n\nFeb 2, 2023\n\n\nHappy Git with R\n\n\nParvin Mohammadiarvejeh\n\n\n\n\nJan 26, 2023\n\n\nAsking Good Questions\n\n\nYingchao Zhou\n\n\n\n\nJan 26, 2023\n\n\nAsking Good Questions\n\n\nKundan Kumar\n\n\n\n\nJan 26, 2023\n\n\nAsking Good Questions\n\n\nAnyesha Ray\n\n\n\n\nJan 26, 2023\n\n\nAsking Good Questions\n\n\nLandon Getting\n\n\n\n\nJan 26, 2023\n\n\nAsking Good Questions\n\n\nMuxin Hua\n\n\n\n\nJan 26, 2023\n\n\nAsking Good Questions\n\n\nMatt Kavanaugh\n\n\n\n\nJan 26, 2023\n\n\nAsking Good Questions\n\n\nCharlie Bonk\n\n\n\n\nJan 26, 2023\n\n\nAsking Good Questions\n\n\nTyler Wiederich\n\n\n\n\nJan 26, 2023\n\n\nAsking Good Questions\n\n\nCharchit Shukla\n\n\n\n\nJan 26, 2023\n\n\nAsking Good Questions\n\n\nKelly Nascimento Thompson\n\n\n\n\nJan 26, 2023\n\n\nAsking Good Questions\n\n\nDenise Bradford\n\n\n\n\nJan 26, 2023\n\n\nAsking Good Questions\n\n\nCelik Harun\n\n\n\n\nJan 26, 2023\n\n\nAsking Good Questions\n\n\nHaoming Wang\n\n\n\n\nJan 26, 2023\n\n\nAsking Good Questions\n\n\nValerie Han\n\n\n\n\nJan 26, 2023\n\n\nAsking Good Questions\n\n\nIan Parzyszek\n\n\n\n\nJan 26, 2023\n\n\nAsking Good Questions\n\n\nLogan Johnson\n\n\n\n\nJan 26, 2023\n\n\nAsking Good Questions\n\n\nAnisi Atefeh\n\n\n\n\nJan 26, 2023\n\n\nAsking Good Questions\n\n\nAn Pham\n\n\n\n\nJan 26, 2023\n\n\nAsking Good Questions\n\n\nMarie Hardt\n\n\n\n\nJan 26, 2023\n\n\nAsking Good Questions\n\n\nCaio dos Santos\n\n\n\n\nJan 26, 2023\n\n\nAsking Good Questions\n\n\nBhagat Sudesh\n\n\n\n\nJan 26, 2023\n\n\nAsking Good Questions\n\n\nGino Beltran\n\n\n\n\nJan 26, 2023\n\n\nAsking Good Questions\n\n\nMotahareh Kashanian\n\n\n\n\nJan 26, 2023\n\n\nAsking Good Questions\n\n\nSabrena Rutledge\n\n\n\n\nJan 26, 2023\n\n\nAsking Good Questions\n\n\nYichuan Bai\n\n\n\n\nJan 26, 2023\n\n\nAsking Good Questions\n\n\nAlexandra Arabio\n\n\n\n\nJan 26, 2023\n\n\nAsking Good Questions\n\n\nParvin Mohammadiarvejeh\n\n\n\n\nMar 9, 2022\n\n\nI’m not a lawyer\n\n\nNot Charlie\n\n\n\n\nMar 9, 2022\n\n\nLegal Stuff\n\n\nDRB\n\n\n\n\nFeb 16, 2022\n\n\nplyr to dplyr\n\n\nAR\n\n\n\n\nFeb 16, 2022\n\n\nSplit Apply Combine\n\n\nMuxin Hua\n\n\n\n\nFeb 16, 2022\n\n\nBlog post 4 - Split-Apply-Combine\n\n\nDenise Bradford\n\n\n\n\nFeb 16, 2022\n\n\nWorking with ‘Plyr’ package\n\n\nAtefeh Anisi\n\n\n\n\nFeb 9, 2022\n\n\nReading a Chapter in adv-r\n\n\nDenise Bradford\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "schedule.html",
    "href": "schedule.html",
    "title": "Schedule",
    "section": "",
    "text": "The full syllabus is available here"
  },
  {
    "objectID": "schedule.html#course-topics",
    "href": "schedule.html#course-topics",
    "title": "Schedule",
    "section": "Course Topics",
    "text": "Course Topics\n\n\n\nWeek\nTopic\nNotes\n\n\n\n\n1 - 2\nWorking Environment and Review Git, GitHub, and R Markdown\nJan 17  Course intro & syllabus | Collaborations - test case | data: 2015 BRFSS data for Iowa | Code book: BRFSS Codebook 2015\n\n\n \n \nJan 19 Collaborations - test case - part 2 | a solution to the test case\n\n\n \n \nJan 24 tools for collaborations | R Markdown refresher | to add or not to add? that is the git-tion\n\n\n3 - 5\nData structures in R: factors, lists, trees\nJan 26 Results from R & friends | Reviewing elements of the tidyverse: ggplot2, dplyr, tidyr with solutions\n\n\n \n \nJan 31 Reviewing elements of the tidyverse: ggplot2, dplyr, tidyr with solutions\n\n\n \n \nFeb 2 Lab #1\n\n\n \n \nFeb 7 Review of basic R types and structures, first look at lists, code\n\n\n \n \nFeb 9 List objects\n\n\n \n \nFeb 14 Recap of Blog 3, List objects, code\n\n\n \n \nFeb 16 Lab #2\n\n\n6\nSplit-apply-combine strategies with lists, Review of functional programming, conditionals, loops.\nFeb 21 Dates and time, code\n\n\n \n \nFeb 23 Reviewing Functions, Split-apply-combine with lists, code\n\n\n7-8\nPackage system in R\nFeb 28 A first R package, Let’s do that again with litr, code\n\n\n \n \nMar 2 Lab #3\n\n\n \n \nMar 7 Data in packages, Package dependencies\n\n\n \n \nMar 9 Logistics, Package dependencies, The error fixing cycle\n\n\n \n \nMar 21 Let’s do that again: Packages in R, Data in packages\n\n\n9-10\nTesting code & Critical analysis of code\nMar 23 Connecting a package to Github, Continuous Integration, Unit testing\n\n\n \n \nMar 28 The one where Austria was abducted …\n\n\n11\nWeb scraping, working with text: awk and grep\nMar 30 One more set of tests, Intro to web-scraping\n\n\n \n \nApr 4 Web-scraping - your turn :), working with APIs, code from class\n\n\n12\nEvent driven programming\nApr 6 Hands-on session: Project check-in. Make sure to prep some questions!\n\n\n \n \nApr 11 Intro to shiny apps, zipped folder of example apps, Dashboards\n\n\n \n \nApr 13 Lab 4: a shiny app!\n\n\n13\nParsing data, profiling code\nApr 18\n\n\n \n \nApr 20\n\n\n14\nDatabases\nApr 25\n\n\n \n \nApr 27\n\n\n15, Finals\nProject Presentations\nMay 2\n\n\n \n \nMay 4\n\n\n \n \nMay 11, 12-2pm"
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Blog",
    "section": "",
    "text": "Order By\n       Default\n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Title\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\nDate\n\n\nTitle\n\n\nAuthor\n\n\n\n\n\n\n\n\nPrompt:\n\n\n\n\n\n\n\n\nPrompt:\n\n\n\n\n\n\n\n\nPrompt:\n\n\n\n\n\n\n\n\nPrompt:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPrompt:\n\n\n\n\n\n\n\n\nPrompt:\n\n\n\n\n\n\nApr 6, 2023\n\n\nWeb scraping etiquette …\n\n\nYingchao Zhou\n\n\n\n\nApr 6, 2023\n\n\nWeb scraping\n\n\nKundan Kumar\n\n\n\n\nApr 6, 2023\n\n\nWeb scraping Blog.\n\n\nAR\n\n\n\n\nApr 6, 2023\n\n\nBeing kind to Wikipedia\n\n\nLandon Getting\n\n\n\n\nApr 6, 2023\n\n\nWeb scraping etiquette …\n\n\nMuxin Hua\n\n\n\n\nApr 6, 2023\n\n\nWeb scraping etiquette …\n\n\nWho wrote this\n\n\n\n\nApr 6, 2023\n\n\nWeb scraping\n\n\nCharch\n\n\n\n\nApr 6, 2023\n\n\nReflections on Ethical Web Scraping\n\n\nKelly Nascimento Thompson\n\n\n\n\nApr 6, 2023\n\n\nWeb scraping etiquette …\n\n\nDenise Bradford\n\n\n\n\nApr 6, 2023\n\n\nWeb Scraping\n\n\nHarun Celik\n\n\n\n\nApr 6, 2023\n\n\nWeb scraping etiquette …\n\n\nWho wrote this\n\n\n\n\nApr 6, 2023\n\n\nWeb scraping etiquette …\n\n\nIan Parzyszek\n\n\n\n\nApr 6, 2023\n\n\nWeb scraping etiquette …\n\n\nWho wrote this\n\n\n\n\nApr 6, 2023\n\n\nWeb scraping etiquette …\n\n\nAtefeh Anisi\n\n\n\n\nApr 6, 2023\n\n\nWeb scraping etiquette …\n\n\nWho wrote this\n\n\n\n\nApr 6, 2023\n\n\nWeb Scraping Etiquette …\n\n\nMarie Hardt\n\n\n\n\nApr 6, 2023\n\n\nWeb scraping etiquette …\n\n\nCdS\n\n\n\n\nApr 6, 2023\n\n\nWeb scraping etiquette\n\n\nSudesh Ramesh Bhagat\n\n\n\n\nApr 6, 2023\n\n\nWeb scraping etiquette …\n\n\nMotina\n\n\n\n\nApr 6, 2023\n\n\nWeb scraping etiquette …\n\n\nWho wrote this\n\n\n\n\nApr 6, 2023\n\n\nWeb scraping etiquette …\n\n\nSabrena Rutledge\n\n\n\n\nApr 6, 2023\n\n\nWeb scraping etiquette\n\n\nycb\n\n\n\n\nApr 6, 2023\n\n\nWeb scraping etiquette …\n\n\nAlexandra Arabio\n\n\n\n\nApr 6, 2023\n\n\nWeb scraping etiquette …\n\n\nParvin Mohammadiarvejeh\n\n\n\n\nApr 6, 2023\n\n\nWeb scraping etiquette … – Prompt 10\n\n\nWho wrote this\n\n\n\n\nMar 30, 2023\n\n\nFix TeamUNL\n\n\nYingchao Zhou\n\n\n\n\nMar 30, 2023\n\n\nError Fixing for the package\n\n\nKundan Kumar\n\n\n\n\nMar 30, 2023\n\n\nFixing thing from Lab 2\n\n\nAR\n\n\n\n\nMar 30, 2023\n\n\nSolving package problems!\n\n\nLandon Getting\n\n\n\n\nMar 30, 2023\n\n\nFix a warning in CMD check\n\n\nMuxin Hua\n\n\n\n\nMar 30, 2023\n\n\nErrors and warnings in packages\n\n\nTyler Wiederich\n\n\n\n\nMar 30, 2023\n\n\nall-for-one\n\n\nCharch\n\n\n\n\nMar 30, 2023\n\n\nFixing Package Errors\n\n\nKelly Nascimento Thompson\n\n\n\n\nMar 30, 2023\n\n\nUndefined Object Error\n\n\nHarun Celik\n\n\n\n\nMar 30, 2023\n\n\nFixing a note\n\n\nValerie Han\n\n\n\n\nMar 30, 2023\n\n\nTrying to Make the World a Better Place\n\n\nIan Parzyszek\n\n\n\n\nMar 30, 2023\n\n\nAll For One\n\n\nLogan Johnson\n\n\n\n\nMar 30, 2023\n\n\nErrors and warnings in packages\n\n\nAtefeh Anisi\n\n\n\n\nMar 30, 2023\n\n\nThe painful green ticks\n\n\nAn Phan\n\n\n\n\nMar 30, 2023\n\n\nI Fixed It!\n\n\nMarie Hardt\n\n\n\n\nMar 30, 2023\n\n\nFixing a thing\n\n\nCdS\n\n\n\n\nMar 30, 2023\n\n\nErrors and warnings in packages\n\n\nsudesh_Bhagat\n\n\n\n\nMar 30, 2023\n\n\nGreen is the new Black\n\n\nMotina\n\n\n\n\nMar 30, 2023\n\n\nPackage Errors and Warnings\n\n\nSabrena Rutledge\n\n\n\n\nMar 30, 2023\n\n\nProblems in Building the R Package\n\n\nycb\n\n\n\n\nMar 30, 2023\n\n\nFun with errors\n\n\nAlexandra Arabio\n\n\n\n\nMar 30, 2023\n\n\nErrors and warnings in packages\n\n\nParvin Mohammadiarvejeh\n\n\n\n\nMar 30, 2023\n\n\nFix a thing – Prompt 9\n\n\nWho wrote this\n\n\n\n\nMar 23, 2023\n\n\nSimple personal website\n\n\nYingchao Zhou\n\n\n\n\nMar 23, 2023\n\n\nPersonal Website\n\n\nKundan Kumar\n\n\n\n\nMar 23, 2023\n\n\nWebsite Blog\n\n\nAR\n\n\n\n\nMar 23, 2023\n\n\nBecoming a Website Engineer\n\n\nLandon Getting\n\n\n\n\nMar 23, 2023\n\n\nGithub Page\n\n\nMuxin Hua\n\n\n\n\nMar 23, 2023\n\n\nBuilding website\n\n\nCharch\n\n\n\n\nMar 23, 2023\n\n\nBuilding a Website\n\n\nKelly Nascimento Thompson\n\n\n\n\nMar 23, 2023\n\n\nMy professional self\n\n\nDRB\n\n\n\n\nMar 23, 2023\n\n\nHarun’s Quarto Blog Page\n\n\nHarun Celik\n\n\n\n\nMar 23, 2023\n\n\nBuilding a website\n\n\nValerie Han\n\n\n\n\nMar 23, 2023\n\n\nIan and Remmys Website\n\n\nIan Parzyszek\n\n\n\n\nMar 23, 2023\n\n\nBuilding my own website\n\n\nLogan Johnson\n\n\n\n\nMar 23, 2023\n\n\nMy professional self\n\n\nAtefeh Anisi\n\n\n\n\nMar 23, 2023\n\n\nLet’s RMarkdown that Site\n\n\nAn Phan\n\n\n\n\nMar 23, 2023\n\n\nAdventures in Website Building\n\n\nMarie Hardt\n\n\n\n\nMar 23, 2023\n\n\nWhat should I include? What should I not?\n\n\nCdS\n\n\n\n\nMar 23, 2023\n\n\nMy professional self\n\n\nsudesh_Bhagat\n\n\n\n\nMar 23, 2023\n\n\nWelcome to the Club!\n\n\nMotina\n\n\n\n\nMar 23, 2023\n\n\nCreating a Website\n\n\nSabrena Rutledge\n\n\n\n\nMar 23, 2023\n\n\nWebsite Generation\n\n\nycb\n\n\n\n\nMar 23, 2023\n\n\nAll About Ally\n\n\nAlexandra Arabio\n\n\n\n\nMar 23, 2023\n\n\nMy Website\n\n\nParvin Mohammadiarvejeh\n\n\n\n\nMar 23, 2023\n\n\nMake your own website – Prompt 8\n\n\nWho wrote this\n\n\n\n\nMar 9, 2023\n\n\nAll that legal stuff… – Prompt 7\n\n\nWho wrote this\n\n\n\n\nMar 9, 2023\n\n\nLicense\n\n\nYingchao Zhou\n\n\n\n\nMar 9, 2023\n\n\nR licensing\n\n\nKundan Kumar\n\n\n\n\nMar 9, 2023\n\n\nLicensing Blog\n\n\nAR\n\n\n\n\nMar 9, 2023\n\n\nLearning Licensing\n\n\nLandon Getting\n\n\n\n\nMar 9, 2023\n\n\nLicenses\n\n\nMuxin Hua\n\n\n\n\nMar 9, 2023\n\n\nR Licensing and Package Dependencies\n\n\nKelly Nascimento Thompson\n\n\n\n\nMar 9, 2023\n\n\nSplit-Apply-Combine Post\n\n\nHarun Celik\n\n\n\n\nMar 9, 2023\n\n\nLicenses\n\n\nValerie Han\n\n\n\n\nMar 9, 2023\n\n\nWhat License when?\n\n\nIan Parzyszek\n\n\n\n\nMar 9, 2023\n\n\nLegal Stuff\n\n\nLogan Johnson\n\n\n\n\nMar 9, 2023\n\n\nAll that legal stuff…\n\n\nAtefeh Anisi\n\n\n\n\nMar 9, 2023\n\n\nIt’s not the end…\n\n\nAn Phan\n\n\n\n\nMar 9, 2023\n\n\nLegal Details of Licenses\n\n\nMarie Hardt\n\n\n\n\nMar 9, 2023\n\n\nDependencies\n\n\nCDS\n\n\n\n\nMar 9, 2023\n\n\nAll that legal stuff\n\n\nSudesh Bhagat\n\n\n\n\nMar 9, 2023\n\n\nLicenses and Packages\n\n\nSabrena Rutledge\n\n\n\n\nMar 9, 2023\n\n\nLicense\n\n\nyc bai\n\n\n\n\nMar 9, 2023\n\n\nLicense Fun\n\n\nAlexandra Arabio\n\n\n\n\nMar 9, 2023\n\n\nAll that legal stuff…\n\n\nParvin Mohammadiarvejeh\n\n\n\n\nMar 2, 2023\n\n\nrenv package\n\n\nYingchao Zhou\n\n\n\n\nMar 2, 2023\n\n\nrenv R package\n\n\nKundan Kumar\n\n\n\n\nMar 2, 2023\n\n\nrenv blog\n\n\nAR\n\n\n\n\nMar 2, 2023\n\n\nExploring renv\n\n\nLandon Getting\n\n\n\n\nMar 2, 2023\n\n\nMore on reproducibility\n\n\nMuxin Hua\n\n\n\n\nMar 2, 2023\n\n\nBlog 6\n\n\nTyler Wiederich\n\n\n\n\nMar 2, 2023\n\n\nRenv\n\n\nCharch\n\n\n\n\nMar 2, 2023\n\n\nRenv package overview\n\n\nKelly Nascimento Thompson\n\n\n\n\nMar 2, 2023\n\n\nSplit-Apply-Combine Post\n\n\nHarun Celik\n\n\n\n\nMar 2, 2023\n\n\nrenv\n\n\nValerie Han\n\n\n\n\nMar 2, 2023\n\n\nLearning Renv\n\n\nIan Parzyszek\n\n\n\n\nMar 2, 2023\n\n\n‘renv’ Package and Data Reproducibility\n\n\nLogan Johnson\n\n\n\n\nMar 2, 2023\n\n\nWorking with ‘renv’ package\n\n\nAtefeh Anisi\n\n\n\n\nMar 2, 2023\n\n\nExploring renv\n\n\nMarie Hardt\n\n\n\n\nMar 2, 2023\n\n\nR env\n\n\nCaio dos Santos\n\n\n\n\nMar 2, 2023\n\n\nGithub Actions\n\n\nSudesh Bhagat\n\n\n\n\nMar 2, 2023\n\n\nBadge is Coool!\n\n\nMotina\n\n\n\n\nMar 2, 2023\n\n\nReproducibility\n\n\nSabrena Rutledge\n\n\n\n\nMar 2, 2023\n\n\nrenv package\n\n\nyc bai\n\n\n\n\nMar 2, 2023\n\n\ntitle :)\n\n\nAlexandra Arabio\n\n\n\n\nMar 2, 2023\n\n\nMore on reproducibility…\n\n\nParvin Mohammadiarvejeh\n\n\n\n\nMar 2, 2023\n\n\nMore on reproducibility… – Prompt 6\n\n\nWho wrote this\n\n\n\n\nFeb 23, 2023\n\n\nKeep track of results and data\n\n\nYingchao Zhou\n\n\n\n\nFeb 23, 2023\n\n\nEthics and Reproducibility\n\n\nKundan Kumar\n\n\n\n\nFeb 23, 2023\n\n\nReading about COVID Calculators\n\n\nAR\n\n\n\n\nFeb 23, 2023\n\n\nTREEFINDER - Leveraging Research Software for Political Agendas\n\n\nLandon Getting\n\n\n\n\nFeb 23, 2023\n\n\nRetraction\n\n\nMuxin Hua\n\n\n\n\nFeb 23, 2023\n\n\nUC Berkeley’s Ninov 2.0\n\n\nNot Charlie\n\n\n\n\nFeb 23, 2023\n\n\nRetraction\n\n\nCharch\n\n\n\n\nFeb 23, 2023\n\n\nRules for Research Reproducibility\n\n\nKelly Nascimento Thompson\n\n\n\n\nFeb 23, 2023\n\n\nRetraction Watch – Reliability and Sensitivity of Neuromuscular and Perceptual Fatigue Measures in Collegiate Men’s Basketball\n\n\nDenise Bradford\n\n\n\n\nFeb 23, 2023\n\n\nBlog Five\n\n\nHarun Celik\n\n\n\n\nFeb 23, 2023\n\n\nReproducibility\n\n\nValerie Han\n\n\n\n\nFeb 23, 2023\n\n\nReplication of Data Presentation\n\n\nIan Parzyszek\n\n\n\n\nFeb 23, 2023\n\n\nImportance of Data Reproducibility\n\n\nLogan Johnson\n\n\n\n\nFeb 23, 2023\n\n\nHow to make our research reproducible\n\n\nAtefeh Anisi\n\n\n\n\nFeb 23, 2023\n\n\nPaper retracted alert!\n\n\nAn Phan\n\n\n\n\nFeb 23, 2023\n\n\nEthics in Reproducible Research\n\n\nMarie Hardt\n\n\n\n\nFeb 23, 2023\n\n\nDotting I’s and crossing T’s…\n\n\nCaio dos Santos\n\n\n\n\nFeb 23, 2023\n\n\nEthics and Reproducibility\n\n\nSudesh Bhagat\n\n\n\n\nFeb 23, 2023\n\n\nThe One Where Ethics Meet Reproducibility\n\n\nMotina\n\n\n\n\nFeb 23, 2023\n\n\nReproducing Randomness\n\n\nMaxwell Skinner\n\n\n\n\nFeb 23, 2023\n\n\nEthically Managing Data\n\n\nSabrena Rutledge\n\n\n\n\nFeb 23, 2023\n\n\nReproducible Computational Research\n\n\nyc bai\n\n\n\n\nFeb 23, 2023\n\n\nNumber 10\n\n\nAlexandra Arabio\n\n\n\n\nFeb 23, 2023\n\n\nEthics and Reproducibility…\n\n\nParvin Mohammadiarvejeh\n\n\n\n\nFeb 23, 2023\n\n\nEthics and Reproducibility… – Prompt 5\n\n\nWho wrote this\n\n\n\n\nFeb 16, 2023\n\n\nThe Split-Apply-Combine paradigm - Prompt 4\n\n\nWho wrote this\n\n\n\n\nFeb 16, 2023\n\n\nSplit, apply, combine\n\n\nYingchao Zhou\n\n\n\n\nFeb 16, 2023\n\n\nThe Split-Apply-Combine Strategy for Data Analysis\n\n\nKundan Kumar\n\n\n\n\nFeb 16, 2023\n\n\ndplyr vs plyr\n\n\nLandon Getting\n\n\n\n\nFeb 16, 2023\n\n\nTitle of your post\n\n\nNot Charlie\n\n\n\n\nFeb 16, 2023\n\n\nSplit-apply-combine\n\n\nTyler Wiederich\n\n\n\n\nFeb 16, 2023\n\n\nplyr and dplyr\n\n\nCharchit Shukla\n\n\n\n\nFeb 16, 2023\n\n\nTesting the ‘dplyr’ functionality\n\n\nKelly Nascimento Thompson\n\n\n\n\nFeb 16, 2023\n\n\nTitle of your post\n\n\nFirstname Lastname\n\n\n\n\nFeb 16, 2023\n\n\nSplit-Apply-Combine Post\n\n\nHarun Celik\n\n\n\n\nFeb 16, 2023\n\n\nThe Split-Apply-Combine Strategy\n\n\nValerie Han\n\n\n\n\nFeb 16, 2023\n\n\nGetting familiar with dpylr\n\n\nIan Parzyszek\n\n\n\n\nFeb 16, 2023\n\n\n‘plyr’ to d’plyr’\n\n\nLogan Johnson\n\n\n\n\nFeb 16, 2023\n\n\nSplit-apply-combine\n\n\nAn Phan\n\n\n\n\nFeb 16, 2023\n\n\nSplit-Apply-Combine\n\n\nMarie Hardt\n\n\n\n\nFeb 16, 2023\n\n\nplyr-dplyr-baseR\n\n\nCaio dos Santos\n\n\n\n\nFeb 16, 2023\n\n\nSplit-apply-combine\n\n\nSudesh Bhagat\n\n\n\n\nFeb 16, 2023\n\n\nTitle of your post\n\n\nMaxwell Skinner\n\n\n\n\nFeb 16, 2023\n\n\nSplit-apply-combine\n\n\nyc bai\n\n\n\n\nFeb 16, 2023\n\n\nSplit, Apply, Combine - Relevancy\n\n\nAlexandra Arabio\n\n\n\n\nFeb 16, 2023\n\n\nSplit-apply-combine\n\n\nParvin Mohammadiarvejeh\n\n\n\n\nFeb 9, 2023\n\n\nBuilding a Book\n\n\nYingchao Zhou\n\n\n\n\nFeb 9, 2023\n\n\nBuilding a Book\n\n\nKundan Kummar\n\n\n\n\nFeb 9, 2023\n\n\nBuilding a Book\n\n\nar\n\n\n\n\nFeb 9, 2023\n\n\nBook Building is Backbreaking\n\n\nLandon Getting\n\n\n\n\nFeb 9, 2023\n\n\nBuilding a Book\n\n\nMuxin Hua\n\n\n\n\nFeb 9, 2023\n\n\nBuilding a Book\n\n\nMatt Kavanaugh\n\n\n\n\nFeb 9, 2023\n\n\nBipity-Bopity-Book?\n\n\nNot Charlie\n\n\n\n\nFeb 9, 2023\n\n\nBuilding a book\n\n\nTyler Wiederich\n\n\n\n\nFeb 9, 2023\n\n\nBuilding a Book\n\n\nCharch\n\n\n\n\nFeb 9, 2023\n\n\nRendering a book using ‘bookdown’\n\n\nKelly Nascimento Thompson\n\n\n\n\nFeb 9, 2023\n\n\nError Fixing Process\n\n\nHarun Celik\n\n\n\n\nFeb 9, 2023\n\n\nBuilding a Book\n\n\nJust Testing\n\n\n\n\nFeb 9, 2023\n\n\nTitle of your post\n\n\nFirstname Lastname\n\n\n\n\nFeb 9, 2023\n\n\nBuilding a Book\n\n\nLogan Johnson\n\n\n\n\nFeb 9, 2023\n\n\nI finally built a book\n\n\nAtefeh Anisi\n\n\n\n\nFeb 9, 2023\n\n\nBuilding a Book\n\n\nAn Phan\n\n\n\n\nFeb 9, 2023\n\n\nAdventures in Book Building\n\n\nMarie Hardt\n\n\n\n\nFeb 9, 2023\n\n\nBuilding a Book\n\n\nCaio dos Santos\n\n\n\n\nFeb 9, 2023\n\n\nBuilding a Book\n\n\nSudesh Bhagat\n\n\n\n\nFeb 9, 2023\n\n\nDrawning in ERRORS\n\n\nMotina\n\n\n\n\nFeb 9, 2023\n\n\nTitle of your post\n\n\nFirstname Lastname\n\n\n\n\nFeb 9, 2023\n\n\nBuilding a book with R’s bookdown\n\n\nSabrena Rutledge\n\n\n\n\nFeb 9, 2023\n\n\nExperience of building a book\n\n\nYCB\n\n\n\n\nFeb 9, 2023\n\n\nBuilding a Book\n\n\nAA\n\n\n\n\nFeb 9, 2023\n\n\nBuilding a book\n\n\nParvin Mohammadiarvejeh\n\n\n\n\nFeb 9, 2023\n\n\nBuilding a book – Prompt 3\n\n\nWho wrote this\n\n\n\n\nFeb 5, 2023\n\n\nHappy Git with R\n\n\nHarun Celik\n\n\n\n\nFeb 3, 2023\n\n\nHappy Git with R\n\n\nSudesh Bhagat\n\n\n\n\nFeb 2, 2023\n\n\nHappy Git with R\n\n\nThe Prompt for Blog 2\n\n\n\n\nFeb 2, 2023\n\n\nHappy Git with R\n\n\nYingchao Zhou\n\n\n\n\nFeb 2, 2023\n\n\nHappy Git with R\n\n\nKundan Kumar\n\n\n\n\nFeb 2, 2023\n\n\nHappy Git with R\n\n\nYour Name\n\n\n\n\nFeb 2, 2023\n\n\nHappy Git with R\n\n\nLandon Getting\n\n\n\n\nFeb 2, 2023\n\n\nHappy Git with R\n\n\nMuxin Hua\n\n\n\n\nFeb 2, 2023\n\n\nHappy Git with R\n\n\nNot Charlie\n\n\n\n\nFeb 2, 2023\n\n\nHappy Git with R\n\n\nTyler Wiederich\n\n\n\n\nFeb 2, 2023\n\n\nHappy Git with R\n\n\nCharch\n\n\n\n\nFeb 2, 2023\n\n\nHappy Git with R\n\n\nKelly Nascimento Thompson\n\n\n\n\nFeb 2, 2023\n\n\nHappy Git with R\n\n\nDRB\n\n\n\n\nFeb 2, 2023\n\n\nHappy Git with R\n\n\nMatt Kavanaugh\n\n\n\n\nFeb 2, 2023\n\n\nHappy Git with R\n\n\nHaoming Wang\n\n\n\n\nFeb 2, 2023\n\n\nHappy Git with R\n\n\nValerie Han\n\n\n\n\nFeb 2, 2023\n\n\nHappy Git with R\n\n\nIan Parzyszek\n\n\n\n\nFeb 2, 2023\n\n\nHappy Git with R\n\n\nLogan Johnson\n\n\n\n\nFeb 2, 2023\n\n\nHappy Git with R\n\n\nAtefeh Anisi\n\n\n\n\nFeb 2, 2023\n\n\nHappy Git with R\n\n\nAn Phan\n\n\n\n\nFeb 2, 2023\n\n\nHappy Git with R\n\n\nMarie Hardt\n\n\n\n\nFeb 2, 2023\n\n\nHappy Git with R\n\n\nSomebody\n\n\n\n\nFeb 2, 2023\n\n\nHappy Git with R\n\n\nGino Beltran\n\n\n\n\nFeb 2, 2023\n\n\nHappy Git with R\n\n\nMotina\n\n\n\n\nFeb 2, 2023\n\n\nHappy Git with R\n\n\nMaxwell Skinner\n\n\n\n\nFeb 2, 2023\n\n\nHappy Git with R\n\n\nSabrena Rutledge\n\n\n\n\nFeb 2, 2023\n\n\nHappy Git with R\n\n\nYCB\n\n\n\n\nFeb 2, 2023\n\n\nHappy Git with R\n\n\nAlexadra Arabio\n\n\n\n\nFeb 2, 2023\n\n\nHappy Git with R\n\n\nParvin Mohammadiarvejeh\n\n\n\n\nJan 26, 2023\n\n\nAsking Good Questions\n\n\nYingchao Zhou\n\n\n\n\nJan 26, 2023\n\n\nAsking Good Questions\n\n\nKundan Kumar\n\n\n\n\nJan 26, 2023\n\n\nAsking Good Questions\n\n\nAnyesha Ray\n\n\n\n\nJan 26, 2023\n\n\nAsking Good Questions\n\n\nLandon Getting\n\n\n\n\nJan 26, 2023\n\n\nAsking Good Questions\n\n\nMuxin Hua\n\n\n\n\nJan 26, 2023\n\n\nAsking Good Questions\n\n\nMatt Kavanaugh\n\n\n\n\nJan 26, 2023\n\n\nAsking Good Questions\n\n\nCharlie Bonk\n\n\n\n\nJan 26, 2023\n\n\nAsking Good Questions\n\n\nTyler Wiederich\n\n\n\n\nJan 26, 2023\n\n\nAsking Good Questions\n\n\nCharchit Shukla\n\n\n\n\nJan 26, 2023\n\n\nAsking Good Questions\n\n\nKelly Nascimento Thompson\n\n\n\n\nJan 26, 2023\n\n\nAsking Good Questions\n\n\nDenise Bradford\n\n\n\n\nJan 26, 2023\n\n\nAsking Good Questions\n\n\nCelik Harun\n\n\n\n\nJan 26, 2023\n\n\nAsking Good Questions\n\n\nHaoming Wang\n\n\n\n\nJan 26, 2023\n\n\nAsking Good Questions\n\n\nValerie Han\n\n\n\n\nJan 26, 2023\n\n\nAsking Good Questions\n\n\nIan Parzyszek\n\n\n\n\nJan 26, 2023\n\n\nAsking Good Questions\n\n\nLogan Johnson\n\n\n\n\nJan 26, 2023\n\n\nAsking Good Questions\n\n\nAnisi Atefeh\n\n\n\n\nJan 26, 2023\n\n\nAsking Good Questions\n\n\nAn Pham\n\n\n\n\nJan 26, 2023\n\n\nAsking Good Questions\n\n\nMarie Hardt\n\n\n\n\nJan 26, 2023\n\n\nAsking Good Questions\n\n\nCaio dos Santos\n\n\n\n\nJan 26, 2023\n\n\nAsking Good Questions\n\n\nBhagat Sudesh\n\n\n\n\nJan 26, 2023\n\n\nAsking Good Questions\n\n\nGino Beltran\n\n\n\n\nJan 26, 2023\n\n\nAsking Good Questions\n\n\nMotahareh Kashanian\n\n\n\n\nJan 26, 2023\n\n\nAsking Good Questions\n\n\nSabrena Rutledge\n\n\n\n\nJan 26, 2023\n\n\nAsking Good Questions\n\n\nYichuan Bai\n\n\n\n\nJan 26, 2023\n\n\nAsking Good Questions\n\n\nAlexandra Arabio\n\n\n\n\nJan 26, 2023\n\n\nAsking Good Questions\n\n\nParvin Mohammadiarvejeh\n\n\n\n\nMar 9, 2022\n\n\nI’m not a lawyer\n\n\nNot Charlie\n\n\n\n\nMar 9, 2022\n\n\nLegal Stuff\n\n\nDRB\n\n\n\n\nFeb 16, 2022\n\n\nplyr to dplyr\n\n\nAR\n\n\n\n\nFeb 16, 2022\n\n\nSplit Apply Combine\n\n\nMuxin Hua\n\n\n\n\nFeb 16, 2022\n\n\nBlog post 4 - Split-Apply-Combine\n\n\nDenise Bradford\n\n\n\n\nFeb 16, 2022\n\n\nWorking with ‘Plyr’ package\n\n\nAtefeh Anisi\n\n\n\n\nFeb 9, 2022\n\n\nReading a Chapter in adv-r\n\n\nDenise Bradford\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "labs/04-lab-slides.html#resources",
    "href": "labs/04-lab-slides.html#resources",
    "title": "Lab 4 - Adding a shiny app",
    "section": "Resources",
    "text": "Resources\n\ngetting a shiny app into an R package: https://stat585-at-isu.github.io/materials-2023/10_interactive/02_shiny.html#12\nshiny in general: https://shiny.rstudio.com/tutorial/\nfor maps: leaflet package, https://rstudio.github.io/leaflet/shiny.html\nfor time series: plotly package, https://plotly-r.com/linking-views-with-shiny.html"
  }
]