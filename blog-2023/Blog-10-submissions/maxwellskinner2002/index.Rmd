---
author: "Who wrote this"
title: "Web scraping etiquette ..."
categories: "Web scraping etiquette ..."
date: "2023-04-06"
output: github_document
---
 
## Prompt:

With great power comes great responsibility - a large part of the web is based on data and services that scrape those data. 
Now that we start to apply scraping mechanisms, we need to think about how to apply those skills without becoming a burden to the internet society.

Find sources on ethical web scraping - some readings that might help you get started with that are: 

  - [James Densmore](https://towardsdatascience.com/ethics-in-web-scraping-b96b18136f01)

  - R package [polite](https://github.com/dmi3kno/polite)

  - [JAMI @ EMPIRICAL](https://www.empiricaldata.org/dataladyblog/a-guide-to-ethical-web-scraping)


After reading through some of the ethics essays
write a blog post addressing the following questions: 

1. **What are your main three takeaways for ethical web scraping? - Give examples, or cite your sources.**
2. **What is a ROBOTS.TXT file? Identify one instance and explain what it allows/prevents.**
3. **Identify a website that you would like to scrape (or one an example from class) and implement a scrape using the `polite` package.**

Instructions:

Submit to your repo. Make sure that all of the github actions pass (check menu item Actions - all of the actions should have green checks)

